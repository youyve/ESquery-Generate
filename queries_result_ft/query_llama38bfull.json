[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "82016",
                "标题": "GPT4Tools: Teaching Large Language Model to Use Tools via\n  Self-instruction",
                "作者": " Rui Yang,  Lin Song,  Yanwei Li,  Sijie Zhao,  Yixiao Ge,  Xiu Li,  Ying Shan",
                "发布日期": "2023-05-31",
                "摘要": "  This paper aims to efficiently enable Large Language Models (LLMs) to use\nmultimodal tools. Advanced proprietary LLMs, such as ChatGPT and GPT-4, have\nshown great potential for tool usage through sophisticated prompt engineering.\nNevertheless, these models typically rely on prohibitive computational costs\nand publicly inaccessible data. To address these challenges, we propose the\nGPT4Tools based on self-instruct to enable open-source LLMs, such as LLaMA and\nOPT, to use tools. It generates an instruction-following dataset by prompting\nan advanced teacher with various multi-modal contexts. By using the Low-Rank\nAdaptation (LoRA) optimization, our approach facilitates the open-source LLMs\nto solve a range of visual problems, including visual comprehension and image\ngeneration. Moreover, we provide a benchmark to evaluate the ability of LLMs to\nuse tools, which is performed in both zero-shot and fine-tuning ways. Extensive\nexperiments demonstrate the effectiveness of our method on various language\nmodels, which not only significantly improves the accuracy of invoking seen\ntools, but also enables the zero-shot capacity for unseen tools. The code and\ndemo are available at https://github.com/StevenGrove/GPT4Tools.\n",
                "链接": "https://arxiv.org/abs/2305.18752"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "59251",
                "标题": "Friend-training: Learning from Models of Different but Related Tasks",
                "作者": " Mian Zhang,  Lifeng Jin,  Linfeng Song,  Haitao Mi,  Xiabing Zhou,  Dong Yu",
                "发布日期": "2023-02-01",
                "摘要": "  Current self-training methods such as standard self-training, co-training,\ntri-training, and others often focus on improving model performance on a single\ntask, utilizing differences in input features, model architectures, and\ntraining processes. However, many tasks in natural language processing are\nabout different but related aspects of language, and models trained for one\ntask can be great teachers for other related tasks. In this work, we propose\nfriend-training, a cross-task self-training framework, where models trained to\ndo different tasks are used in an iterative training, pseudo-labeling, and\nretraining process to help each other for better selection of pseudo-labels.\nWith two dialogue understanding tasks, conversational semantic role labeling\nand dialogue rewriting, chosen for a case study, we show that the models\ntrained with the friend-training framework achieve the best performance\ncompared to strong baselines.\n",
                "链接": "https://arxiv.org/abs/2301.13683"
            },
            {
                "文章ID": "89037",
                "标题": "Tools for Verifying Neural Models' Training Data",
                "作者": " Dami Choi,  Yonadav Shavit,  David Duvenaud",
                "发布日期": "2023-07-04",
                "摘要": "  It is important that consumers and regulators can verify the provenance of\nlarge neural models to evaluate their capabilities and risks. We introduce the\nconcept of a \"Proof-of-Training-Data\": any protocol that allows a model trainer\nto convince a Verifier of the training data that produced a set of model\nweights. Such protocols could verify the amount and kind of data and compute\nused to train the model, including whether it was trained on specific harmful\nor beneficial data sources. We explore efficient verification strategies for\nProof-of-Training-Data that are compatible with most current large-model\ntraining procedures. These include a method for the model-trainer to verifiably\npre-commit to a random seed used in training, and a method that exploits\nmodels' tendency to temporarily overfit to training data in order to detect\nwhether a given data-point was included in training. We show experimentally\nthat our verification procedures can catch a wide variety of attacks, including\nall known attacks from the Proof-of-Learning literature.\n",
                "链接": "https://arxiv.org/abs/2307.00682"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "56327",
                "标题": "Systems for Parallel and Distributed Large-Model Deep Learning Training",
                "作者": " Kabir Nagrecha",
                "发布日期": "2023-01-10",
                "摘要": "  Deep learning (DL) has transformed applications in a variety of domains,\nincluding computer vision, natural language processing, and tabular data\nanalysis. The search for improved DL model accuracy has led practitioners to\nexplore increasingly large neural architectures, with some recent Transformer\nmodels spanning hundreds of billions of learnable parameters. These designs\nhave introduced new scale-driven systems challenges for the DL space, such as\nmemory bottlenecks, poor runtime efficiency, and high costs of model\ndevelopment. Efforts to address these issues have explored techniques such as\nparallelization of neural architectures, spilling data across the memory\nhierarchy, and memory-efficient data representations. This survey will explore\nthe large-model training systems landscape, highlighting key challenges and the\nvarious techniques that have been used to address them.\n",
                "链接": "https://arxiv.org/abs/2301.02691"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "103034",
                "标题": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
                "作者": " Nicholas Solovyev,  Ryan Barron,  Manish Bhattarai,  Maksim E. Eren,  Kim O. Rasmussen,  Boian S. Alexandrov",
                "发布日期": "2023-09-20",
                "摘要": "  Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.\n",
                "链接": "https://arxiv.org/abs/2309.10772"
            }
        ]
    },
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "105665",
                "标题": "Back to the Future: Towards Explainable Temporal Reasoning with Large\n  Language Models",
                "作者": " Chenhan Yuan,  Qianqian Xie,  Jimin Huang,  Sophia Ananiadou",
                "发布日期": "2023-10-10",
                "摘要": "  Temporal reasoning is a crucial NLP task, providing a nuanced understanding\nof time-sensitive contexts within textual data. Although recent advancements in\nLLMs have demonstrated their potential in temporal reasoning, the predominant\nfocus has been on tasks such as temporal expression and temporal relation\nextraction. These tasks are primarily designed for the extraction of direct and\npast temporal cues and to engage in simple reasoning processes. A significant\ngap remains when considering complex reasoning tasks such as event forecasting,\nwhich requires multi-step temporal reasoning on events and prediction on the\nfuture timestamp. Another notable limitation of existing methods is their\nincapability to provide an illustration of their reasoning process, hindering\nexplainability. In this paper, we introduce the first task of explainable\ntemporal reasoning, to predict an event's occurrence at a future timestamp\nbased on context which requires multiple reasoning over multiple events, and\nsubsequently provide a clear explanation for their prediction. Our task offers\na comprehensive evaluation of both the LLMs' complex temporal reasoning\nability, the future event prediction ability, and explainability-a critical\nattribute for AI applications. To support this task, we present the first\nmulti-source instruction-tuning dataset of explainable temporal reasoning\n(ExpTime) with 26k derived from the temporal knowledge graph datasets and their\ntemporal reasoning paths, using a novel knowledge-graph-instructed-generation\nstrategy. Based on the dataset, we propose the first open-source LLM series\nTimeLlaMA based on the foundation LlaMA2, with the ability of instruction\nfollowing for explainable temporal reasoning. We compare the performance of our\nmethod and a variety of LLMs, where our method achieves the state-of-the-art\nperformance of temporal prediction and explanation.\n",
                "链接": "https://arxiv.org/abs/2310.01074"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "81151",
                "标题": "Playing repeated games with Large Language Models",
                "作者": " Elif Akata,  Lion Schulz,  Julian Coda-Forno,  Seong Joon Oh,  Matthias Bethge,  Eric Schulz",
                "发布日期": "2023-05-29",
                "摘要": "  Large Language Models (LLMs) are transforming society and permeating into\ndiverse applications. As a result, LLMs will frequently interact with us and\nother agents. It is, therefore, of great societal value to understand how LLMs\nbehave in interactive social settings. Here, we propose to use behavioral game\ntheory to study LLM's cooperation and coordination behavior. To do so, we let\ndifferent LLMs (GPT-3, GPT-3.5, and GPT-4) play finitely repeated games with\neach other and with other, human-like strategies. Our results show that LLMs\ngenerally perform well in such tasks and also uncover persistent behavioral\nsignatures. In a large set of two players-two strategies games, we find that\nLLMs are particularly good at games where valuing their own self-interest pays\noff, like the iterated Prisoner's Dilemma family. However, they behave\nsub-optimally in games that require coordination. We, therefore, further focus\non two games from these distinct families. In the canonical iterated Prisoner's\nDilemma, we find that GPT-4 acts particularly unforgivingly, always defecting\nafter another agent has defected only once. In the Battle of the Sexes, we find\nthat GPT-4 cannot match the behavior of the simple convention to alternate\nbetween options. We verify that these behavioral signatures are stable across\nrobustness checks. Finally, we show how GPT-4's behavior can be modified by\nproviding further information about the other player as well as by asking it to\npredict the other player's actions before making a choice. These results enrich\nour understanding of LLM's social behavior and pave the way for a behavioral\ngame theory for machines.\n",
                "链接": "https://arxiv.org/abs/2305.16867"
            },
            {
                "文章ID": "90826",
                "标题": "Negated Complementary Commonsense using Large Language Models",
                "作者": " Navid Rezaei,  Marek Z. Reformat",
                "发布日期": "2023-07-14",
                "摘要": "  Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.\n",
                "链接": "https://arxiv.org/abs/2307.06794"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "34816",
                "标题": "Shortcut Learning of Large Language Models in Natural Language\n  Understanding",
                "作者": " Mengnan Du,  Fengxiang He,  Na Zou,  Dacheng Tao,  Xia Hu",
                "发布日期": "2023-05-09",
                "摘要": "  Large language models (LLMs) have achieved state-of-the-art performance on a\nseries of natural language understanding tasks. However, these LLMs might rely\non dataset bias and artifacts as shortcuts for prediction. This has\nsignificantly affected their generalizability and adversarial robustness. In\nthis paper, we provide a review of recent developments that address the\nshortcut learning and robustness challenge of LLMs. We first introduce the\nconcepts of shortcut learning of language models. We then introduce methods to\nidentify shortcut learning behavior in language models, characterize the\nreasons for shortcut learning, as well as introduce mitigation solutions.\nFinally, we discuss key research challenges and potential research directions\nin order to advance the field of LLMs.\n",
                "链接": "https://arxiv.org/abs/2208.11857"
            },
            {
                "文章ID": "91355",
                "标题": "On the application of Large Language Models for language teaching and\n  assessment technology",
                "作者": " Andrew Caines,  Luca Benedetto,  Shiva Taslimipoor,  Christopher Davis,  Yuan Gao,  Oeistein Andersen,  Zheng Yuan,  Mark Elliott,  Russell Moore,  Christopher Bryant,  Marek Rei,  Helen Yannakoudakis,  Andrew Mullooly,  Diane Nicholls,  Paula Buttery",
                "发布日期": "2023-07-18",
                "摘要": "  The recent release of very large language models such as PaLM and GPT-4 has\nmade an unprecedented impact in the popular media and public consciousness,\ngiving rise to a mixture of excitement and fear as to their capabilities and\npotential uses, and shining a light on natural language processing research\nwhich had not previously received so much attention. The developments offer\ngreat promise for education technology, and in this paper we look specifically\nat the potential for incorporating large language models in AI-driven language\nteaching and assessment systems. We consider several research areas and also\ndiscuss the risks and ethical considerations surrounding generative AI in\neducation technology for language learners. Overall we find that larger\nlanguage models offer improvements over previous models in text generation,\nopening up routes toward content generation which had not previously been\nplausible. For text generation they must be prompted carefully and their\noutputs may need to be reshaped before they are ready for use. For automated\ngrading and grammatical error correction, tasks whose progress is checked on\nwell-known benchmarks, early investigations indicate that large language models\non their own do not improve on state-of-the-art results according to standard\nevaluation metrics. For grading it appears that linguistic features established\nin the literature should still be used for best performance, and for error\ncorrection it may be that the models can offer alternative feedback styles\nwhich are not measured sensitively with existing methods. In all cases, there\nis work to be done to experiment with the inclusion of large language models in\neducation technology for language learners, in order to properly understand and\nreport on their capacities and limitations, and to ensure that foreseeable\nrisks such as misinformation and harmful bias are mitigated.\n",
                "链接": "https://arxiv.org/abs/2307.08393"
            },
            {
                "文章ID": "88303",
                "标题": "Query Understanding in the Age of Large Language Models",
                "作者": " Avishek Anand,  Venktesh V,  Abhijit Anand,  Vinay Setty",
                "发布日期": "2023-06-29",
                "摘要": "  Querying, conversing, and controlling search and information-seeking\ninterfaces using natural language are fast becoming ubiquitous with the rise\nand adoption of large-language models (LLM). In this position paper, we\ndescribe a generic framework for interactive query-rewriting using LLMs. Our\nproposal aims to unfold new opportunities for improved and transparent intent\nunderstanding while building high-performance retrieval systems using LLMs. A\nkey aspect of our framework is the ability of the rewriter to fully specify the\nmachine intent by the search engine in natural language that can be further\nrefined, controlled, and edited before the final retrieval phase. The ability\nto present, interact, and reason over the underlying machine intent in natural\nlanguage has profound implications on transparency, ranking performance, and a\ndeparture from the traditional way in which supervised signals were collected\nfor understanding intents. We detail the concept, backed by initial\nexperiments, along with open questions for this interactive query understanding\nframework.\n",
                "链接": "https://arxiv.org/abs/2306.16004"
            },
            {
                "文章ID": "20382",
                "标题": "Revisiting Pre-trained Language Models and their Evaluation for Arabic\n  Natural Language Understanding",
                "作者": " Abbas Ghaddar,  Yimeng Wu,  Sunyam Bagga,  Ahmad Rashid,  Khalil Bibi,  Mehdi Rezagholizadeh,  Chao Xing,  Yasheng Wang,  Duan Xinyu,  Zhefeng Wang,  Baoxing Huai,  Xin Jiang,  Qun Liu,  Philippe Langlais",
                "发布日期": "2022-05-24",
                "摘要": "  There is a growing body of work in recent years to develop pre-trained\nlanguage models (PLMs) for the Arabic language. This work concerns addressing\ntwo major problems in existing Arabic PLMs which constraint progress of the\nArabic NLU and NLG fields.First, existing Arabic PLMs are not well-explored and\ntheir pre-trainig can be improved significantly using a more methodical\napproach. Second, there is a lack of systematic and reproducible evaluation of\nthese models in the literature. In this work, we revisit both the pre-training\nand evaluation of Arabic PLMs. In terms of pre-training, we explore improving\nArabic LMs from three perspectives: quality of the pre-training data, size of\nthe model, and incorporating character-level information. As a result, we\nrelease three new Arabic BERT-style models ( JABER, Char-JABER, and SABER), and\ntwo T5-style models (AT5S and AT5B). In terms of evaluation, we conduct a\ncomprehensive empirical study to systematically evaluate the performance of\nexisting state-of-the-art models on ALUE that is a leaderboard-powered\nbenchmark for Arabic NLU tasks, and on a subset of the ARGEN benchmark for\nArabic NLG tasks. We show that our models significantly outperform existing\nArabic PLMs and achieve a new state-of-the-art performance on discriminative\nand generative Arabic NLU and NLG tasks. Our models and source code to\nreproduce of results will be made available shortly.\n",
                "链接": "https://arxiv.org/abs/2205.10687"
            },
            {
                "文章ID": "112858",
                "标题": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
                "作者": " Michael Färber,  David Lamprecht",
                "发布日期": "2023-11-01",
                "摘要": "  In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.\n",
                "链接": "https://arxiv.org/abs/2310.20475"
            },
            {
                "文章ID": "103073",
                "标题": "Large Language Models as Agents in the Clinic",
                "作者": " Nikita Mehandru,  Brenda Y. Miao,  Eduardo Rodriguez Almaraz,  Madhumita Sushil,  Atul J. Butte,  Ahmed Alaa",
                "发布日期": "2023-09-21",
                "摘要": "  Recent developments in large language models (LLMs) have unlocked new\nopportunities for healthcare, from information synthesis to clinical decision\nsupport. These new LLMs are not just capable of modeling language, but can also\nact as intelligent \"agents\" that interact with stakeholders in open-ended\nconversations and even influence clinical decision-making. Rather than relying\non benchmarks that measure a model's ability to process clinical data or answer\nstandardized test questions, LLM agents should be assessed for their\nperformance on real-world clinical tasks. These new evaluation frameworks,\nwhich we call \"Artificial-intelligence Structured Clinical Examinations\"\n(\"AI-SCI\"), can draw from comparable technologies where machines operate with\nvarying degrees of self-governance, such as self-driving cars. High-fidelity\nsimulations may also be used to evaluate interactions between users and LLMs\nwithin a clinical workflow, or to model the dynamic interactions of multiple\nLLMs. Developing these robust, real-world clinical evaluations will be crucial\ntowards deploying LLM agents into healthcare.\n",
                "链接": "https://arxiv.org/abs/2309.10895"
            },
            {
                "文章ID": "91271",
                "标题": "The Potential and Pitfalls of using a Large Language Model such as\n  ChatGPT or GPT-4 as a Clinical Assistant",
                "作者": " Jingqing Zhang,  Kai Sun,  Akshay Jagadeesh,  Mahta Ghahfarokhi,  Deepa Gupta,  Ashok Gupta,  Vibhor Gupta,  Yike Guo",
                "发布日期": "2023-07-18",
                "摘要": "  Recent studies have demonstrated promising performance of ChatGPT and GPT-4\non several medical domain tasks. However, none have assessed its performance\nusing a large-scale real-world electronic health record database, nor have\nevaluated its utility in providing clinical diagnostic assistance for patients\nacross a full range of disease presentation. We performed two analyses using\nChatGPT and GPT-4, one to identify patients with specific medical diagnoses\nusing a real-world large electronic health record database and the other, in\nproviding diagnostic assistance to healthcare workers in the prospective\nevaluation of hypothetical patients. Our results show that GPT-4 across disease\nclassification tasks with chain of thought and few-shot prompting can achieve\nperformance as high as 96% F1 scores. For patient assessment, GPT-4 can\naccurately diagnose three out of four times. However, there were mentions of\nfactually incorrect statements, overlooking crucial medical findings,\nrecommendations for unnecessary investigations and overtreatment. These issues\ncoupled with privacy concerns, make these models currently inadequate for real\nworld clinical use. However, limited data and time needed for prompt\nengineering in comparison to configuration of conventional machine learning\nworkflows highlight their potential for scalability across healthcare\napplications.\n",
                "链接": "https://arxiv.org/abs/2307.08152"
            },
            {
                "文章ID": "99600",
                "标题": "Autoencoder-based Online Data Quality Monitoring for the CMS\n  Electromagnetic Calorimeter",
                "作者": "on behalf of the CMS Collaboration  Abhirami Harilal, on behalf of the CMS Collaboration  Kyungmin Park, on behalf of the CMS Collaboration  Michael Andrews, on behalf of the CMS Collaboration  Manfred Paulini",
                "发布日期": "2023-09-01",
                "摘要": "  The online Data Quality Monitoring system (DQM) of the CMS electromagnetic\ncalorimeter (ECAL) is a crucial operational tool that allows ECAL experts to\nquickly identify, localize, and diagnose a broad range of detector issues that\nwould otherwise hinder physics-quality data taking. Although the existing ECAL\nDQM system has been continuously updated to respond to new problems, it remains\none step behind newer and unforeseen issues. Using unsupervised deep learning,\na real-time autoencoder-based anomaly detection system is developed that is\nable to detect ECAL anomalies unseen in past data. After accounting for spatial\nvariations in the response of the ECAL and the temporal evolution of anomalies,\nthe new system is able to efficiently detect anomalies while maintaining an\nestimated false discovery rate between $10^{-2}$ to $10^{-4}$, beating existing\nbenchmarks by about two orders of magnitude. The real-world performance of the\nsystem is validated using anomalies found in 2018 and 2022 LHC collision data.\nAdditionally, first results from deploying the autoencoder-based system in the\nCMS online DQM workflow for the ECAL barrel during Run 3 of the LHC are\npresented, showing its promising performance in detecting obscure issues that\ncould have been missed in the existing DQM system.\n",
                "链接": "https://arxiv.org/abs/2308.16659"
            },
            {
                "文章ID": "68143",
                "标题": "Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining\n  on Visual Language Understanding",
                "作者": " Morris Alper,  Michael Fiman,  Hadar Averbuch-Elor",
                "发布日期": "2023-11-07",
                "摘要": "  Most humans use visual imagination to understand and reason about language,\nbut models such as BERT reason about language using knowledge acquired during\ntext-only pretraining. In this work, we investigate whether vision-and-language\npretraining can improve performance on text-only tasks that involve implicit\nvisual reasoning, focusing primarily on zero-shot probing methods. We propose a\nsuite of visual language understanding (VLU) tasks for probing the visual\nreasoning abilities of text encoder models, as well as various non-visual\nnatural language understanding (NLU) tasks for comparison. We also contribute a\nnovel zero-shot knowledge probing method, Stroop probing, for applying models\nsuch as CLIP to text-only tasks without needing a prediction head such as the\nmasked language modelling head of models like BERT. We show that SOTA\nmultimodally trained text encoders outperform unimodally trained text encoders\non the VLU tasks while being underperformed by them on the NLU tasks, lending\nnew context to previously mixed results regarding the NLU capabilities of\nmultimodal models. We conclude that exposure to images during pretraining\naffords inherent visual reasoning knowledge that is reflected in language-only\ntasks that require implicit visual reasoning. Our findings bear importance in\nthe broader context of multimodal learning, providing principled guidelines for\nthe choice of text encoders used in such contexts.\n",
                "链接": "https://arxiv.org/abs/2303.12513"
            },
            {
                "文章ID": "58794",
                "标题": "Presence of informal language, such as emoticons, hashtags, and slang,\n  impact the performance of sentiment analysis models on social media text?",
                "作者": " Aadil Gani Ganie",
                "发布日期": "2023-01-31",
                "摘要": "  This study aimed to investigate the influence of the presence of informal\nlanguage, such as emoticons and slang, on the performance of sentiment analysis\nmodels applied to social media text. A convolutional neural network (CNN) model\nwas developed and trained on three datasets: a sarcasm dataset, a sentiment\ndataset, and an emoticon dataset. The model architecture was held constant for\nall experiments and the model was trained on 80% of the data and tested on 20%.\nThe results revealed that the model achieved an accuracy of 96.47% on the\nsarcasm dataset, with the lowest accuracy for class 1. On the sentiment\ndataset, the model achieved an accuracy of 95.28%. The amalgamation of sarcasm\nand sentiment datasets improved the accuracy of the model to 95.1%, and the\naddition of emoticon dataset has a slight positive impact on the accuracy of\nthe model to 95.37%. The study suggests that the presence of informal language\nhas a restricted impact on the performance of sentiment analysis models applied\nto social media text. However, the inclusion of emoticon data to the model can\nenhance the accuracy slightly.\n",
                "链接": "https://arxiv.org/abs/2301.12303"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "111604",
                "标题": "Hierarchical Semi-Implicit Variational Inference with Application to\n  Diffusion Model Acceleration",
                "作者": " Longlin Yu,  Tianyu Xie,  Yu Zhu,  Tong Yang,  Xiangyu Zhang,  Cheng Zhang",
                "发布日期": "2023-10-27",
                "摘要": "  Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.\n",
                "链接": "https://arxiv.org/abs/2310.17153"
            },
            {
                "文章ID": "123966",
                "标题": "Lookahead: An Inference Acceleration Framework for Large Language Model\n  with Lossless Generation Accuracy",
                "作者": " Yao Zhao,  Zhitian Xie,  Chenyi Zhuang,  Jinjie Gu",
                "发布日期": "2023-12-21",
                "摘要": "  As Large Language Models (LLMs) have made significant advancements across\nvarious tasks, such as question answering, translation, text summarization, and\ndialogue systems, the need for accuracy in information becomes crucial,\nespecially for serious financial products serving billions of users like\nAlipay. To address this, Alipay has developed a Retrieval-Augmented Generation\n(RAG) system that grounds LLMs on the most accurate and up-to-date information.\nHowever, for a real-world product serving millions of users, the inference\nspeed of LLMs becomes a critical factor compared to a mere experimental model.\n  Hence, this paper presents a generic framework for accelerating the inference\nprocess, resulting in a substantial increase in speed and cost reduction for\nour RAG system, with lossless generation accuracy. In the traditional inference\nprocess, each token is generated sequentially by the LLM, leading to a time\nconsumption proportional to the number of generated tokens. To enhance this\nprocess, our framework, named \\textit{lookahead}, introduces a\n\\textit{multi-branch} strategy. Instead of generating a single token at a time,\nwe propose a \\textit{Trie-based Retrieval} (TR) process that enables the\ngeneration of multiple branches simultaneously, each of which is a sequence of\ntokens. Subsequently, for each branch, a \\textit{Verification and Accept} (VA)\nprocess is performed to identify the longest correct sub-sequence as the final\noutput. Our strategy offers two distinct advantages: (1) it guarantees absolute\ncorrectness of the output, avoiding any approximation algorithms, and (2) the\nworst-case performance of our approach is equivalent to the conventional\nprocess. We conduct extensive experiments to demonstrate the significant\nimprovements achieved by applying our inference acceleration framework.\n",
                "链接": "https://arxiv.org/abs/2312.12728"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "107843",
                "标题": "Sparse Fine-tuning for Inference Acceleration of Large Language Models",
                "作者": " Eldar Kurtic,  Denis Kuznedelev,  Elias Frantar,  Michael Goin,  Dan Alistarh",
                "发布日期": "2023-10-16",
                "摘要": "  We consider the problem of accurate sparse fine-tuning of large language\nmodels (LLMs), that is, fine-tuning pretrained LLMs on specialized tasks, while\ninducing sparsity in their weights. On the accuracy side, we observe that\nstandard loss-based fine-tuning may fail to recover accuracy, especially at\nhigh sparsities. To address this, we perform a detailed study of\ndistillation-type losses, determining an L2-based distillation approach we term\nSquareHead which enables accurate recovery even at higher sparsities, across\nall model types. On the practical efficiency side, we show that sparse LLMs can\nbe executed with speedups by taking advantage of sparsity, for both CPU and GPU\nruntimes. While the standard approach is to leverage sparsity for computational\nreduction, we observe that in the case of memory-bound LLMs sparsity can also\nbe leveraged for reducing memory bandwidth. We exhibit end-to-end results\nshowing speedups due to sparsity, while recovering accuracy, on T5 (language\ntranslation), Whisper (speech translation), and open GPT-type (MPT for text\ngeneration). For MPT text generation, we show for the first time that sparse\nfine-tuning can reach 75% sparsity without accuracy drops, provide notable\nend-to-end speedups for both CPU and GPU inference, and highlight that sparsity\nis also compatible with quantization approaches. Models and software for\nreproducing our results are provided in Section 6.\n",
                "链接": "https://arxiv.org/abs/2310.06927"
            },
            {
                "文章ID": "94810",
                "标题": "Exploiting On-chip Heterogeneity of Versal Architecture for GNN\n  Inference Acceleration",
                "作者": " Paul Chen,  Pavan Manjunath,  Sasindu Wijeratne,  Bingyi Zhang,  Viktor Prasanna",
                "发布日期": "2023-08-08",
                "摘要": "  Graph Neural Networks (GNNs) have revolutionized many Machine Learning (ML)\napplications, such as social network analysis, bioinformatics, etc. GNN\ninference can be accelerated by exploiting data sparsity in the input graph,\nvertex features, and intermediate data in GNN computations. For dynamic\nsparsity exploitation, we leverage the heterogeneous computing capabilities of\nAMD Versal ACAP architecture to accelerate GNN inference. We develop a custom\nhardware module that executes the sparse primitives of the computation kernel\non the Programmable Logic (PL) and efficiently computes the dense primitives\nusing the AI Engine (AIE). To exploit data sparsity during inference, we devise\na runtime kernel mapping strategy that dynamically assigns computation tasks to\nthe PL and AIE based on data sparsity. Our implementation on the VCK5000 ACAP\nplatform leads to superior performance compared with the state-of-the-art\nimplementations on CPU, GPU, ACAP, and other custom GNN accelerators. Compared\nwith these implementations, we achieve significant average runtime speedup\nacross various models and datasets of 162.42x, 17.01x, 9.90x, and 27.23x,\nrespectively. Furthermore, for Graph Convolutional Network (GCN) inference, our\napproach leads to a speedup of 3.9-96.7x compared to designs using PL only on\nthe same ACAP device.\n",
                "链接": "https://arxiv.org/abs/2308.02749"
            },
            {
                "文章ID": "87109",
                "标题": "Adaptive DNN Surgery for Selfish Inference Acceleration with On-demand\n  Edge Resource",
                "作者": " Xiang Yang,  Dezhi Chen,  Qi Qi,  Jingyu Wang,  Haifeng Sun,  Jianxin Liao,  Song Guo",
                "发布日期": "2023-06-22",
                "摘要": "  Deep Neural Networks (DNNs) have significantly improved the accuracy of\nintelligent applications on mobile devices. DNN surgery, which partitions DNN\nprocessing between mobile devices and multi-access edge computing (MEC)\nservers, can enable real-time inference despite the computational limitations\nof mobile devices. However, DNN surgery faces a critical challenge: determining\nthe optimal computing resource demand from the server and the corresponding\npartition strategy, while considering both inference latency and MEC server\nusage costs. This problem is compounded by two factors: (1) the finite\ncomputing capacity of the MEC server, which is shared among multiple devices,\nleading to inter-dependent demands, and (2) the shift in modern DNN\narchitecture from chains to directed acyclic graphs (DAGs), which complicates\npotential solutions.\n  In this paper, we introduce a novel Decentralized DNN Surgery (DDS)\nframework. We formulate the partition strategy as a min-cut and propose a\nresource allocation game to adaptively schedule the demands of mobile devices\nin an MEC environment. We prove the existence of a Nash Equilibrium (NE), and\ndevelop an iterative algorithm to efficiently reach the NE for each device. Our\nextensive experiments demonstrate that DDS can effectively handle varying MEC\nscenarios, achieving up to 1.25$\\times$ acceleration compared to the\nstate-of-the-art algorithm.\n",
                "链接": "https://arxiv.org/abs/2306.12185"
            },
            {
                "文章ID": "102327",
                "标题": "Intent Detection at Scale: Tuning a Generic Model using Relevant Intents",
                "作者": " Nichal Narotamo,  David Aparicio,  Tiago Mesquita,  Mariana Almeida",
                "发布日期": "2023-09-19",
                "摘要": "  Accurately predicting the intent of customer support requests is vital for\nefficient support systems, enabling agents to quickly understand messages and\nprioritize responses accordingly. While different approaches exist for intent\ndetection, maintaining separate client-specific or industry-specific models can\nbe costly and impractical as the client base expands.\n  This work proposes a system to scale intent predictions to various clients\neffectively, by combining a single generic model with a per-client list of\nrelevant intents. Our approach minimizes training and maintenance costs while\nproviding a personalized experience for clients, allowing for seamless\nadaptation to changes in their relevant intents. Furthermore, we propose a\nstrategy for using the clients relevant intents as model features that proves\nto be resilient to changes in the relevant intents of clients -- a common\noccurrence in production environments.\n  The final system exhibits significantly superior performance compared to\nindustry-specific models, showcasing its flexibility and ability to cater to\ndiverse client needs.\n",
                "链接": "https://arxiv.org/abs/2309.08647"
            },
            {
                "文章ID": "112504",
                "标题": "SparseByteNN: A Novel Mobile Inference Acceleration Framework Based on\n  Fine-Grained Group Sparsity",
                "作者": " Haitao Xu,  Songwei Liu,  Yuyang Xu,  Shuai Wang,  Jiashi Li,  Chenqian Yan,  Liangqiang Li,  Lean Fu,  Xin Pan,  Fangmin Chen",
                "发布日期": "2023-10-31",
                "摘要": "  To address the challenge of increasing network size, researchers have\ndeveloped sparse models through network pruning. However, maintaining model\naccuracy while achieving significant speedups on general computing devices\nremains an open problem. In this paper, we present a novel mobile inference\nacceleration framework SparseByteNN, which leverages fine-grained kernel\nsparsity to achieve real-time execution as well as high accuracy. Our framework\nconsists of two parts: (a) A fine-grained kernel sparsity schema with a\nsparsity granularity between structured pruning and unstructured pruning. It\ndesigns multiple sparse patterns for different operators. Combined with our\nproposed whole network rearrangement strategy, the schema achieves a high\ncompression rate and high precision at the same time. (b) Inference engine\nco-optimized with the sparse pattern. The conventional wisdom is that this\nreduction in theoretical FLOPs does not translate into real-world efficiency\ngains. We aim to correct this misconception by introducing a family of\nefficient sparse kernels for ARM and WebAssembly. Equipped with our efficient\nimplementation of sparse primitives, we show that sparse versions of\nMobileNet-v1 outperform strong dense baselines on the efficiency-accuracy\ncurve. Experimental results on Qualcomm 855 show that for 30% sparse\nMobileNet-v1, SparseByteNN achieves 1.27x speedup over the dense version and\n1.29x speedup over the state-of-the-art sparse inference engine MNN with a\nslight accuracy drop of 0.224%. The source code of SparseByteNN will be\navailable at https://github.com/lswzjuer/SparseByteNN\n",
                "链接": "https://arxiv.org/abs/2310.19509"
            },
            {
                "文章ID": "108754",
                "标题": "Towards More Accurate Diffusion Model Acceleration with A Timestep\n  Aligner",
                "作者": " Mengfei Xia,  Yujun Shen,  Changsong Lei,  Yu Zhou,  Ran Yi,  Deli Zhao,  Wenping Wang,  Yong-jin Liu",
                "发布日期": "2023-10-17",
                "摘要": "  A diffusion model, which is formulated to produce an image using thousands of\ndenoising steps, usually suffers from a slow inference speed. Existing\nacceleration algorithms simplify the sampling by skipping most steps yet\nexhibit considerable performance degradation. By viewing the generation of\ndiffusion models as a discretized integrating process, we argue that the\nquality drop is partly caused by applying an inaccurate integral direction to a\ntimestep interval. To rectify this issue, we propose a timestep aligner that\nhelps find a more accurate integral direction for a particular interval at the\nminimum cost. Specifically, at each denoising step, we replace the original\nparameterization by conditioning the network on a new timestep, which is\nobtained by aligning the sampling distribution to the real distribution.\nExtensive experiments show that our plug-in design can be trained efficiently\nand boost the inference performance of various state-of-the-art acceleration\nmethods, especially when there are few denoising steps. For example, when using\n10 denoising steps on the popular LSUN Bedroom dataset, we improve the FID of\nDDIM from 9.65 to 6.07, simply by adopting our method for a more appropriate\nset of timesteps. Code will be made publicly available.\n",
                "链接": "https://arxiv.org/abs/2310.09469"
            },
            {
                "文章ID": "107199",
                "标题": "GMMFormer: Gaussian-Mixture-Model based Transformer for Efficient\n  Partially Relevant Video Retrieval",
                "作者": " Yuting Wang,  Jinpeng Wang,  Bin Chen,  Ziyun Zeng,  Shu-Tao Xia",
                "发布日期": "2023-10-10",
                "摘要": "  Given a text query, partially relevant video retrieval (PRVR) seeks to find\nuntrimmed videos containing pertinent moments in a database. For PRVR, clip\nmodeling is essential to capture the partial relationship between texts and\nvideos. Current PRVR methods adopt scanning-based clip construction to achieve\nexplicit clip modeling, which is information-redundant and requires a large\nstorage overhead. To solve the efficiency problem of PRVR methods, this paper\nproposes GMMFormer, a \\textbf{G}aussian-\\textbf{M}ixture-\\textbf{M}odel based\nTrans\\textbf{former} which models clip representations implicitly. During frame\ninteractions, we incorporate Gaussian-Mixture-Model constraints to focus each\nframe on its adjacent frames instead of the whole video. Then generated\nrepresentations will contain multi-scale clip information, achieving implicit\nclip modeling. In addition, PRVR methods ignore semantic differences between\ntext queries relevant to the same video, leading to a sparse embedding space.\nWe propose a query diverse loss to distinguish these text queries, making the\nembedding space more intensive and contain more semantic information. Extensive\nexperiments on three large-scale video datasets (\\ie, TVR, ActivityNet\nCaptions, and Charades-STA) demonstrate the superiority and efficiency of\nGMMFormer.\n",
                "链接": "https://arxiv.org/abs/2310.05195"
            }
        ]
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "100215",
                "标题": "Donkii: Can Annotation Error Detection Methods Find Errors in\n  Instruction-Tuning Datasets?",
                "作者": " Leon Weber-Genzel,  Robert Litschko,  Ekaterina Artemova,  Barbara Plank",
                "发布日期": "2023-09-06",
                "摘要": "  Instruction-tuning has become an integral part of training pipelines for\nLarge Language Models (LLMs) and has been shown to yield strong performance\ngains. In an orthogonal line of research, Annotation Error Detection (AED) has\nemerged as a tool for detecting quality issues of gold-standard labels. But so\nfar, the application of AED methods is limited to discriminative settings. It\nis an open question how well AED methods generalize to generative settings\nwhich are becoming widespread via generative LLMs. In this work, we present a\nfirst and new benchmark for AED on instruction-tuning data: Donkii. It\nencompasses three instruction-tuning datasets enriched with annotations by\nexperts and semi-automatic methods. We find that all three datasets contain\nclear-cut errors that sometimes directly propagate into instruction-tuned LLMs.\nWe propose four AED baselines for the generative setting and evaluate them\ncomprehensively on the newly introduced dataset. Our results demonstrate that\nchoosing the right AED method and model size is indeed crucial, thereby\nderiving practical recommendations. To gain insights, we provide a first\ncase-study to examine how the quality of the instruction-tuning datasets\ninfluences downstream performance.\n",
                "链接": "https://arxiv.org/abs/2309.01669"
            },
            {
                "文章ID": "72812",
                "标题": "Visual Instruction Tuning",
                "作者": " Haotian Liu,  Chunyuan Li,  Qingyang Wu,  Yong Jae Lee",
                "发布日期": "2023-12-14",
                "摘要": "  Instruction tuning large language models (LLMs) using machine-generated\ninstruction-following data has improved zero-shot capabilities on new tasks,\nbut the idea is less explored in the multimodal field. In this paper, we\npresent the first attempt to use language-only GPT-4 to generate multimodal\nlanguage-image instruction-following data. By instruction tuning on such\ngenerated data, we introduce LLaVA: Large Language and Vision Assistant, an\nend-to-end trained large multimodal model that connects a vision encoder and\nLLM for general-purpose visual and language understanding.Our early experiments\nshow that LLaVA demonstrates impressive multimodel chat abilities, sometimes\nexhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and\nyields a 85.1% relative score compared with GPT-4 on a synthetic multimodal\ninstruction-following dataset. When fine-tuned on Science QA, the synergy of\nLLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make\nGPT-4 generated visual instruction tuning data, our model and code base\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2304.08485"
            },
            {
                "文章ID": "88641",
                "标题": "On the Exploitability of Instruction Tuning",
                "作者": " Manli Shu,  Jiongxiao Wang,  Chen Zhu,  Jonas Geiping,  Chaowei Xiao,  Tom Goldstein",
                "发布日期": "2023-10-31",
                "摘要": "  Instruction tuning is an effective technique to align large language models\n(LLMs) with human intents. In this work, we investigate how an adversary can\nexploit instruction tuning by injecting specific instruction-following examples\ninto the training data that intentionally changes the model's behavior. For\nexample, an adversary can achieve content injection by injecting training\nexamples that mention target content and eliciting such behavior from\ndownstream models. To achieve this goal, we propose \\textit{AutoPoison}, an\nautomated data poisoning pipeline. It naturally and coherently incorporates\nversatile attack goals into poisoned data with the help of an oracle LLM. We\nshowcase two example attacks: content injection and over-refusal attacks, each\naiming to induce a specific exploitable behavior. We quantify and benchmark the\nstrength and the stealthiness of our data poisoning scheme. Our results show\nthat AutoPoison allows an adversary to change a model's behavior by poisoning\nonly a small fraction of data while maintaining a high level of stealthiness in\nthe poisoned examples. We hope our work sheds light on how data quality affects\nthe behavior of instruction-tuned models and raises awareness of the importance\nof data quality for responsible deployments of LLMs. Code is available at\n\\url{https://github.com/azshue/AutoPoison}.\n",
                "链接": "https://arxiv.org/abs/2306.17194"
            },
            {
                "文章ID": "78949",
                "标题": "LogiCoT: Logical Chain-of-Thought Instruction-Tuning",
                "作者": " Hanmeng Liu,  Zhiyang Teng,  Leyang Cui,  Chaoli Zhang,  Qiji Zhou,  Yue Zhang",
                "发布日期": "2023-10-31",
                "摘要": "  Generative Pre-trained Transformer 4 (GPT-4) demonstrates impressive\nchain-of-thought reasoning ability. Recent work on self-instruction tuning,\nsuch as Alpaca, has focused on enhancing the general proficiency of models.\nThese instructions enable the model to achieve performance comparable to\nGPT-3.5 on general tasks like open-domain text generation and paraphrasing.\nHowever, they fall short of helping the model handle complex reasoning tasks.\nTo bridge the gap, this paper presents LogiCoT, a new instruction-tuning\ndataset for Logical Chain-of-Thought reasoning with GPT-4. We elaborate on the\nprocess of harvesting instructions for prompting GPT-4 to generate\nchain-of-thought rationales. LogiCoT serves as an instruction set for teaching\nmodels of logical reasoning and elicits general reasoning skills.\n",
                "链接": "https://arxiv.org/abs/2305.12147"
            },
            {
                "文章ID": "112253",
                "标题": "Pre-trained Speech Processing Models Contain Human-Like Biases that\n  Propagate to Speech Emotion Recognition",
                "作者": " Isaac Slaughter,  Craig Greenberg,  Reva Schwartz,  Aylin Caliskan",
                "发布日期": "2023-10-31",
                "摘要": "  Previous work has established that a person's demographics and speech style\naffect how well speech processing models perform for them. But where does this\nbias come from? In this work, we present the Speech Embedding Association Test\n(SpEAT), a method for detecting bias in one type of model used for many speech\ntasks: pre-trained models. The SpEAT is inspired by word embedding association\ntests in natural language processing, which quantify intrinsic bias in a\nmodel's representations of different concepts, such as race or valence\n(something's pleasantness or unpleasantness) and capture the extent to which a\nmodel trained on large-scale socio-cultural data has learned human-like biases.\nUsing the SpEAT, we test for six types of bias in 16 English speech models\n(including 4 models also trained on multilingual data), which come from the\nwav2vec 2.0, HuBERT, WavLM, and Whisper model families. We find that 14 or more\nmodels reveal positive valence (pleasantness) associations with abled people\nover disabled people, with European-Americans over African-Americans, with\nfemales over males, with U.S. accented speakers over non-U.S. accented\nspeakers, and with younger people over older people. Beyond establishing that\npre-trained speech models contain these biases, we also show that they can have\nreal world effects. We compare biases found in pre-trained models to biases in\ndownstream models adapted to the task of Speech Emotion Recognition (SER) and\nfind that in 66 of the 96 tests performed (69%), the group that is more\nassociated with positive valence as indicated by the SpEAT also tends to be\npredicted as speaking with higher valence by the downstream model. Our work\nprovides evidence that, like text and image-based models, pre-trained speech\nbased-models frequently learn human-like biases. Our work also shows that bias\nfound in pre-trained models can propagate to the downstream task of SER.\n",
                "链接": "https://arxiv.org/abs/2310.18877"
            },
            {
                "文章ID": "71129",
                "标题": "Instruction Tuning with GPT-4",
                "作者": " Baolin Peng,  Chunyuan Li,  Pengcheng He,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-04-07",
                "摘要": "  Prior work has shown that finetuning large language models (LLMs) using\nmachine-generated instruction-following data enables such models to achieve\nremarkable zero-shot capabilities on new tasks, and no human-written\ninstructions are needed. In this paper, we present the first attempt to use\nGPT-4 to generate instruction-following data for LLM finetuning. Our early\nexperiments on instruction-tuned LLaMA models show that the 52K English and\nChinese instruction-following data generated by GPT-4 leads to superior\nzero-shot performance on new tasks to the instruction-following data generated\nby previous state-of-the-art models. We also collect feedback and comparison\ndata from GPT-4 to enable a comprehensive evaluation and reward model training.\nWe make our data generated using GPT-4 as well as our codebase publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2304.03277"
            },
            {
                "文章ID": "108778",
                "标题": "Instruction Tuning with Human Curriculum",
                "作者": " Bruce W. Lee,  Hyunsoo Cho,  Kang Min Yoo",
                "发布日期": "2023-10-17",
                "摘要": "  The dominant paradigm for instruction tuning is the random-shuffled training\nof maximally diverse instruction-response pairs. This paper explores the\npotential benefits of applying a structured cognitive learning approach to\ninstruction tuning in contemporary large language models like ChatGPT and\nGPT-4. Unlike the previous conventional randomized instruction dataset, we\npropose a highly structured synthetic dataset that mimics the progressive and\norganized nature of human education. We curate our dataset by aligning it with\neducational frameworks, incorporating meta information including its topic and\ncognitive rigor level for each sample. Our dataset covers comprehensive\nfine-grained topics spanning diverse educational stages (from middle school to\ngraduate school) with various questions for each topic to enhance conceptual\ndepth using Bloom's taxonomy-a classification framework distinguishing various\nlevels of human cognition for each concept. The results demonstrate that this\ncognitive rigorous training approach yields significant performance\nenhancements - +3.06 on the MMLU benchmark and an additional +1.28 on AI2\nReasoning Challenge (hard set) - compared to conventional randomized training,\nall while avoiding additional computational costs. This research highlights the\npotential of leveraging human learning principles to enhance the capabilities\nof language models in comprehending and responding to complex instructions and\ntasks.\n",
                "链接": "https://arxiv.org/abs/2310.09518"
            },
            {
                "文章ID": "109604",
                "标题": "Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning",
                "作者": " Ming Li,  Lichang Chen,  Jiuhai Chen,  Shwai He,  Heng Huang,  Jiuxiang Gu,  Tianyi Zhou",
                "发布日期": "2023-10-19",
                "摘要": "  Recent advancements in Large Language Models (LLMs) have expanded the\nhorizons of natural language understanding and generation. Notably, the output\ncontrol and alignment with the input of LLMs can be refined through instruction\ntuning. However, as highlighted in several studies, low-quality data in the\ntraining set are usually detrimental to instruction tuning, resulting in\ninconsistent or even misleading LLM outputs. We propose a novel method, termed\n\"reflection-tuning,\" which addresses the problem by self-improvement and\njudging capabilities of LLMs. This approach utilizes an oracle LLM to recycle\nthe original training data by introspecting and enhancing the quality of\ninstructions and responses in the data. Extensive experiments on widely used\nevaluation benchmarks show that LLMs trained with our recycled data outperform\nthose trained with existing datasets in various benchmarks.\n",
                "链接": "https://arxiv.org/abs/2310.11716"
            },
            {
                "文章ID": "112709",
                "标题": "Automatic Evaluation of Generative Models with Instruction Tuning",
                "作者": " Shuhaib Mehri,  Vered Shwartz",
                "发布日期": "2023-11-01",
                "摘要": "  Automatic evaluation of natural language generation has long been an elusive\ngoal in NLP.A recent paradigm fine-tunes pre-trained language models to emulate\nhuman judgements for a particular task and evaluation criterion. Inspired by\nthe generalization ability of instruction-tuned models, we propose a learned\nmetric based on instruction tuning. To test our approach, we collected HEAP, a\ndataset of human judgements across various NLG tasks and evaluation criteria.\nOur findings demonstrate that instruction tuning language models on HEAP yields\ngood performance on many evaluation tasks, though some criteria are less\ntrivial to learn than others. Further, jointly training on multiple tasks can\nyield additional performance improvements, which can be beneficial for future\ntasks with little to no human annotated data.\n",
                "链接": "https://arxiv.org/abs/2310.20072"
            },
            {
                "文章ID": "100423",
                "标题": "CIEM: Contrastive Instruction Evaluation Method for Better Instruction\n  Tuning",
                "作者": " Hongyu Hu,  Jiyuan Zhang,  Minyi Zhao,  Zhenbang Sun",
                "发布日期": "2023-11-27",
                "摘要": "  Nowadays, the research on Large Vision-Language Models (LVLMs) has been\nsignificantly promoted thanks to the success of Large Language Models (LLM).\nNevertheless, these Vision-Language Models (VLMs) are suffering from the\ndrawback of hallucination -- due to insufficient understanding of vision and\nlanguage modalities, VLMs may generate incorrect perception information when\ndoing downstream applications, for example, captioning a non-existent entity.\nTo address the hallucination phenomenon, on the one hand, we introduce a\nContrastive Instruction Evaluation Method (CIEM), which is an automatic\npipeline that leverages an annotated image-text dataset coupled with an LLM to\ngenerate factual/contrastive question-answer pairs for the evaluation of the\nhallucination of VLMs. On the other hand, based on CIEM, we further propose a\nnew instruction tuning method called CIT (the abbreviation of Contrastive\nInstruction Tuning) to alleviate the hallucination of VLMs by automatically\nproducing high-quality factual/contrastive question-answer pairs and\ncorresponding justifications for model tuning. Through extensive experiments on\nCIEM and CIT, we pinpoint the hallucination issues commonly present in existing\nVLMs, the disability of the current instruction-tuning dataset to handle the\nhallucination phenomenon and the superiority of CIT-tuned VLMs over both CIEM\nand public datasets.\n",
                "链接": "https://arxiv.org/abs/2309.02301"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "87564",
                "标题": "Resume Information Extraction via Post-OCR Text Processing",
                "作者": " Selahattin Serdar Helli,  Senem Tanberk,  Sena Nur Cavsak",
                "发布日期": "2023-06-27",
                "摘要": "  Information extraction (IE), one of the main tasks of natural language\nprocessing (NLP), has recently increased importance in the use of resumes. In\nstudies on the text to extract information from the CV, sentence classification\nwas generally made using NLP models. In this study, it is aimed to extract\ninformation by classifying all of the text groups after pre-processing such as\nOptical Character Recognition (OCT) and object recognition with the YOLOv8\nmodel of the resumes. The text dataset consists of 286 resumes collected for 5\ndifferent (education, experience, talent, personal and language) job\ndescriptions in the IT industry. The dataset created for object recognition\nconsists of 1198 resumes, which were collected from the open-source internet\nand labeled as sets of text. BERT, BERT-t, DistilBERT, RoBERTa and XLNet were\nused as models. F1 score variances were used to compare the model results. In\naddition, the YOLOv8 model has also been reported comparatively in itself. As a\nresult of the comparison, DistilBERT was showed better results despite having a\nlower number of parameters than other models.\n",
                "链接": "https://arxiv.org/abs/2306.13775"
            },
            {
                "文章ID": "103556",
                "标题": "Education in the age of Generative AI: Context and Recent Developments",
                "作者": " Rafael Ferreira Mello,  Elyda Freitas,  Filipe Dwan Pereira,  Luciano Cabral,  Patricia Tedesco,  Geber Ramalho",
                "发布日期": "2023-09-25",
                "摘要": "  With the emergence of generative artificial intelligence, an increasing\nnumber of individuals and organizations have begun exploring its potential to\nenhance productivity and improve product quality across various sectors. The\nfield of education is no exception. However, it is vital to notice that\nartificial intelligence adoption in education dates back to the 1960s. In light\nof this historical context, this white paper serves as the inaugural piece in a\nfour-part series that elucidates the role of AI in education. The series delves\ninto topics such as its potential, successful applications, limitations,\nethical considerations, and future trends. This initial article provides a\ncomprehensive overview of the field, highlighting the recent developments\nwithin the generative artificial intelligence sphere.\n",
                "链接": "https://arxiv.org/abs/2309.12332"
            },
            {
                "文章ID": "87257",
                "标题": "Recent Developments in Recommender Systems: A Survey",
                "作者": " Yang Li,  Kangbo Liu,  Ranjan Satapathy,  Suhang Wang,  Erik Cambria",
                "发布日期": "2023-07-06",
                "摘要": "  In this technical survey, we comprehensively summarize the latest\nadvancements in the field of recommender systems. The objective of this study\nis to provide an overview of the current state-of-the-art in the field and\nhighlight the latest trends in the development of recommender systems. The\nstudy starts with a comprehensive summary of the main taxonomy of recommender\nsystems, including personalized and group recommender systems, and then delves\ninto the category of knowledge-based recommender systems. In addition, the\nsurvey analyzes the robustness, data bias, and fairness issues in recommender\nsystems, summarizing the evaluation metrics used to assess the performance of\nthese systems. Finally, the study provides insights into the latest trends in\nthe development of recommender systems and highlights the new directions for\nfuture research in the field.\n",
                "链接": "https://arxiv.org/abs/2306.12680"
            },
            {
                "文章ID": "85288",
                "标题": "When Vision Fails: Text Attacks Against ViT and OCR",
                "作者": " Nicholas Boucher,  Jenny Blessing,  Ilia Shumailov,  Ross Anderson,  Nicolas Papernot",
                "发布日期": "2023-06-13",
                "摘要": "  While text-based machine learning models that operate on visual inputs of\nrendered text have become robust against a wide range of existing attacks, we\nshow that they are still vulnerable to visual adversarial examples encoded as\ntext. We use the Unicode functionality of combining diacritical marks to\nmanipulate encoded text so that small visual perturbations appear when the text\nis rendered. We show how a genetic algorithm can be used to generate visual\nadversarial examples in a black-box setting, and conduct a user study to\nestablish that the model-fooling adversarial examples do not affect human\ncomprehension. We demonstrate the effectiveness of these attacks in the real\nworld by creating adversarial examples against production models published by\nFacebook, Microsoft, IBM, and Google.\n",
                "链接": "https://arxiv.org/abs/2306.07033"
            },
            {
                "文章ID": "76306",
                "标题": "Latest Trends in Artificial Intelligence Technology: A Scoping Review",
                "作者": " Teemu Niskanen,  Tuomo Sipola,  Olli Väänänen",
                "发布日期": "2023-05-24",
                "摘要": "  Artificial intelligence is more ubiquitous in multiple domains. Smartphones,\nsocial media platforms, search engines, and autonomous vehicles are just a few\nexamples of applications that utilize artificial intelligence technologies to\nenhance their performance. This study carries out a scoping review of the\ncurrent state-of-the-art artificial intelligence technologies following the\nPRISMA framework. The goal was to find the most advanced technologies used in\ndifferent domains of artificial intelligence technology research. Three\nrecognized journals were used from artificial intelligence and machine learning\ndomain: Journal of Artificial Intelligence Research, Journal of Machine\nLearning Research, and Machine Learning, and articles published in 2022 were\nobserved. Certain qualifications were laid for the technological solutions: the\ntechnology must be tested against comparable solutions, commonly approved or\notherwise well justified datasets must be used while applying, and results must\nshow improvements against comparable solutions. One of the most important parts\nof the technology development appeared to be how to process and exploit the\ndata gathered from multiple sources. The data can be highly unstructured and\nthe technological solution should be able to utilize the data with minimum\nmanual work from humans. The results of this review indicate that creating\nlabeled datasets is very laborious, and solutions exploiting unsupervised or\nsemi-supervised learning technologies are more and more researched. The\nlearning algorithms should be able to be updated efficiently, and predictions\nshould be interpretable. Using artificial intelligence technologies in\nreal-world applications, safety and explainable predictions are mandatory to\nconsider before mass adoption can occur.\n",
                "链接": "https://arxiv.org/abs/2305.04532"
            },
            {
                "文章ID": "77352",
                "标题": "On the Hidden Mystery of OCR in Large Multimodal Models",
                "作者": " Yuliang Liu,  Zhang Li,  Hongliang Li,  Wenwen Yu,  Yang Liu,  Biao Yang,  Mingxin Huang,  Dezhi Peng,  Mingyu Liu,  Mingrui Chen,  Chunyuan Li,  Xucheng Yin,  Cheng-lin Liu,  Lianwen Jin,  Xiang Bai",
                "发布日期": "2023-06-21",
                "摘要": "  Large models have recently played a dominant role in natural language\nprocessing and multimodal vision-language learning. It remains less explored\nabout their efficacy in text-related visual tasks. We conducted a comprehensive\nstudy of existing publicly available multimodal models, evaluating their\nperformance in text recognition (document text, artistic text, handwritten\ntext, scene text), text-based visual question answering (document text, scene\ntext, and bilingual text), key information extraction (receipts, documents, and\nnutrition facts) and handwritten mathematical expression recognition. Our\nfindings reveal strengths and weaknesses in these models, which primarily rely\non semantic understanding for word recognition and exhibit inferior perception\nof individual character shapes. They also display indifference towards text\nlength and have limited capabilities in detecting finegrained features in\nimages. Consequently, these results demonstrate that even the current most\npowerful large multimodal models cannot match domain-specific methods in\ntraditional text tasks and face greater challenges in more complex tasks. Most\nimportantly, the baseline results showcased in this study could provide a\nfoundational framework for the conception and assessment of innovative\nstrategies targeted at enhancing zero-shot multimodal techniques. Evaluation\npipeline is available at https://github.com/Yuliang-Liu/MultimodalOCR.\n",
                "链接": "https://arxiv.org/abs/2305.07895"
            },
            {
                "文章ID": "112858",
                "标题": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
                "作者": " Michael Färber,  David Lamprecht",
                "发布日期": "2023-11-01",
                "摘要": "  In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.\n",
                "链接": "https://arxiv.org/abs/2310.20475"
            },
            {
                "文章ID": "96755",
                "标题": "AIGC In China: Current Developments And Future Outlook",
                "作者": " Xiangyu Li,  Yuqing Fan,  Shenghui Cheng",
                "发布日期": "2023-08-22",
                "摘要": "  The increasing attention given to AI Generated Content (AIGC) has brought a\nprofound impact on various aspects of daily life, industrial manufacturing, and\nthe academic sector. Recognizing the global trends and competitiveness in AIGC\ndevelopment, this study aims to analyze China's current status in the field.\nThe investigation begins with an overview of the foundational technologies and\ncurrent applications of AIGC. Subsequently, the study delves into the market\nstatus, policy landscape, and development trajectory of AIGC in China,\nutilizing keyword searches to identify relevant scholarly papers. Furthermore,\nthe paper provides a comprehensive examination of AIGC products and their\ncorresponding ecosystem, emphasizing the ecological construction of AIGC.\nFinally, this paper discusses the challenges and risks faced by the AIGC\nindustry while presenting a forward-looking perspective on the industry's\nfuture based on competitive insights in AIGC.\n",
                "链接": "https://arxiv.org/abs/2308.08451"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "109273",
                "标题": "Is there a Trojan! : Literature survey and critical evaluation of the\n  latest ML based modern intrusion detection systems in IoT environments",
                "作者": " Vishal Karanam",
                "发布日期": "2023-10-18",
                "摘要": "  IoT as a domain has grown so much in the last few years that it rivals that\nof the mobile network environments in terms of data volumes as well as\ncybersecurity threats. The confidentiality and privacy of data within IoT\nenvironments have become very important areas of security research within the\nlast few years. More and more security experts are interested in designing\nrobust IDS systems to protect IoT environments as a supplement to the more\ntraditional security methods. Given that IoT devices are resource-constrained\nand have a heterogeneous protocol stack, most traditional intrusion detection\napproaches don't work well within these schematic boundaries. This has led\nsecurity researchers to innovate at the intersection of Machine Learning and\nIDS to solve the shortcomings of non-learning based IDS systems in the IoT\necosystem.\n  Despite various ML algorithms already having high accuracy with IoT datasets,\nwe can see a lack of sufficient production grade models. This survey paper\ndetails a comprehensive summary of the latest learning-based approaches used in\nIoT intrusion detection systems, and conducts a thorough critical review of\nthese systems, potential pitfalls in ML pipelines, challenges from an ML\nperspective, and discusses future research scope and recommendations.\n",
                "链接": "https://arxiv.org/abs/2310.10778"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "123651",
                "标题": "Advancements and Challenges in Arabic Optical Character Recognition: A\n  Comprehensive Survey",
                "作者": " Mahmoud SalahEldin Kasem,  Mohamed Mahmoud,  Hyun-Soo Kang",
                "发布日期": "2023-12-20",
                "摘要": "  Optical character recognition (OCR) is a vital process that involves the\nextraction of handwritten or printed text from scanned or printed images,\nconverting it into a format that can be understood and processed by machines.\nThis enables further data processing activities such as searching and editing.\nThe automatic extraction of text through OCR plays a crucial role in digitizing\ndocuments, enhancing productivity, improving accessibility, and preserving\nhistorical records. This paper seeks to offer an exhaustive review of\ncontemporary applications, methodologies, and challenges associated with Arabic\nOptical Character Recognition (OCR). A thorough analysis is conducted on\nprevailing techniques utilized throughout the OCR process, with a dedicated\neffort to discern the most efficacious approaches that demonstrate enhanced\noutcomes. To ensure a thorough evaluation, a meticulous keyword-search\nmethodology is adopted, encompassing a comprehensive analysis of articles\nrelevant to Arabic OCR, including both backward and forward citation reviews.\nIn addition to presenting cutting-edge techniques and methods, this paper\ncritically identifies research gaps within the realm of Arabic OCR. By\nhighlighting these gaps, we shed light on potential areas for future\nexploration and development, thereby guiding researchers toward promising\navenues in the field of Arabic OCR. The outcomes of this study provide valuable\ninsights for researchers, practitioners, and stakeholders involved in Arabic\nOCR, ultimately fostering advancements in the field and facilitating the\ncreation of more accurate and efficient OCR systems for the Arabic language.\n",
                "链接": "https://arxiv.org/abs/2312.11812"
            },
            {
                "文章ID": "94665",
                "标题": "Universal Defensive Underpainting Patch: Making Your Text Invisible to\n  Optical Character Recognition",
                "作者": " JiaCheng Deng,  Li Dong,  Jiahao Chen,  Diqun Yan,  Rangding Wang,  Dengpan Ye,  Lingchen Zhao,  Jinyu Tian",
                "发布日期": "2023-08-07",
                "摘要": "  Optical Character Recognition (OCR) enables automatic text extraction from\nscanned or digitized text images, but it also makes it easy to pirate valuable\nor sensitive text from these images. Previous methods to prevent OCR piracy by\ndistorting characters in text images are impractical in real-world scenarios,\nas pirates can capture arbitrary portions of the text images, rendering the\ndefenses ineffective. In this work, we propose a novel and effective defense\nmechanism termed the Universal Defensive Underpainting Patch (UDUP) that\nmodifies the underpainting of text images instead of the characters. UDUP is\ncreated through an iterative optimization process to craft a small, fixed-size\ndefensive patch that can generate non-overlapping underpainting for text images\nof any size. Experimental results show that UDUP effectively defends against\nunauthorized OCR under the setting of any screenshot range or complex image\nbackground. It is agnostic to the content, size, colors, and languages of\ncharacters, and is robust to typical image operations such as scaling and\ncompressing. In addition, the transferability of UDUP is demonstrated by\nevading several off-the-shelf OCRs. The code is available at\nhttps://github.com/QRICKDD/UDUP.\n",
                "链接": "https://arxiv.org/abs/2308.02369"
            },
            {
                "文章ID": "39690",
                "标题": "3D Rendering Framework for Data Augmentation in Optical Character\n  Recognition",
                "作者": " Andreas Spruck,  Maximiliane Hawesch,  Anatol Maier,  Christian Riess,  Jürgen Seiler,  André Kaup",
                "发布日期": "2022-09-30",
                "摘要": "  In this paper, we propose a data augmentation framework for Optical Character\nRecognition (OCR). The proposed framework is able to synthesize new viewing\nangles and illumination scenarios, effectively enriching any available OCR\ndataset. Its modular structure allows to be modified to match individual user\nrequirements. The framework enables to comfortably scale the enlargement factor\nof the available dataset. Furthermore, the proposed method is not restricted to\nsingle frame OCR but can also be applied to video OCR. We demonstrate the\nperformance of our framework by augmenting a 15% subset of the common Brno\nMobile OCR dataset. Our proposed framework is capable of leveraging the\nperformance of OCR applications especially for small datasets. Applying the\nproposed method, improvements of up to 2.79 percentage points in terms of\nCharacter Error Rate (CER), and up to 7.88 percentage points in terms of Word\nError Rate (WER) are achieved on the subset. Especially the recognition of\nchallenging text lines can be improved. The CER may be decreased by up to 14.92\npercentage points and the WER by up to 18.19 percentage points for this class.\nMoreover, we are able to achieve smaller error rates when training on the 15%\nsubset augmented with the proposed method than on the original non-augmented\nfull dataset.\n",
                "链接": "https://arxiv.org/abs/2209.14970"
            },
            {
                "文章ID": "99425",
                "标题": "DTrOCR: Decoder-only Transformer for Optical Character Recognition",
                "作者": " Masato Fujitake",
                "发布日期": "2023-08-31",
                "摘要": "  Typical text recognition methods rely on an encoder-decoder structure, in\nwhich the encoder extracts features from an image, and the decoder produces\nrecognized text from these features. In this study, we propose a simpler and\nmore effective method for text recognition, known as the Decoder-only\nTransformer for Optical Character Recognition (DTrOCR). This method uses a\ndecoder-only Transformer to take advantage of a generative language model that\nis pre-trained on a large corpus. We examined whether a generative language\nmodel that has been successful in natural language processing can also be\neffective for text recognition in computer vision. Our experiments demonstrated\nthat DTrOCR outperforms current state-of-the-art methods by a large margin in\nthe recognition of printed, handwritten, and scene text in both English and\nChinese.\n",
                "链接": "https://arxiv.org/abs/2308.15996"
            },
            {
                "文章ID": "46214",
                "标题": "Self-supervised Character-to-Character Distillation for Text Recognition",
                "作者": " Tongkun Guan,  Wei Shen,  Xue Yang,  Qi Feng,  Zekun Jiang,  Xiaokang Yang",
                "发布日期": "2023-08-21",
                "摘要": "  When handling complicated text images (e.g., irregular structures, low\nresolution, heavy occlusion, and uneven illumination), existing supervised text\nrecognition methods are data-hungry. Although these methods employ large-scale\nsynthetic text images to reduce the dependence on annotated real images, the\ndomain gap still limits the recognition performance. Therefore, exploring the\nrobust text feature representations on unlabeled real images by self-supervised\nlearning is a good solution. However, existing self-supervised text recognition\nmethods conduct sequence-to-sequence representation learning by roughly\nsplitting the visual features along the horizontal axis, which limits the\nflexibility of the augmentations, as large geometric-based augmentations may\nlead to sequence-to-sequence feature inconsistency. Motivated by this, we\npropose a novel self-supervised Character-to-Character Distillation method,\nCCD, which enables versatile augmentations to facilitate general text\nrepresentation learning. Specifically, we delineate the character structures of\nunlabeled real images by designing a self-supervised character segmentation\nmodule. Following this, CCD easily enriches the diversity of local characters\nwhile keeping their pairwise alignment under flexible augmentations, using the\ntransformation matrix between two augmented views from images. Experiments\ndemonstrate that CCD achieves state-of-the-art results, with average\nperformance gains of 1.38% in text recognition, 1.7% in text segmentation, 0.24\ndB (PSNR) and 0.0321 (SSIM) in text super-resolution. Code is available at\nhttps://github.com/TongkunGuan/CCD.\n",
                "链接": "https://arxiv.org/abs/2211.00288"
            },
            {
                "文章ID": "35422",
                "标题": "A Black-Box Attack on Optical Character Recognition Systems",
                "作者": " Samet Bayram,  Kenneth Barner",
                "发布日期": "2022-08-31",
                "摘要": "  Adversarial machine learning is an emerging area showing the vulnerability of\ndeep learning models. Exploring attack methods to challenge state of the art\nartificial intelligence (A.I.) models is an area of critical concern. The\nreliability and robustness of such A.I. models are one of the major concerns\nwith an increasing number of effective adversarial attack methods.\nClassification tasks are a major vulnerable area for adversarial attacks. The\nmajority of attack strategies are developed for colored or gray-scaled images.\nConsequently, adversarial attacks on binary image recognition systems have not\nbeen sufficiently studied. Binary images are simple two possible pixel-valued\nsignals with a single channel. The simplicity of binary images has a\nsignificant advantage compared to colored and gray scaled images, namely\ncomputation efficiency. Moreover, most optical character recognition systems\n(O.C.R.s), such as handwritten character recognition, plate number\nidentification, and bank check recognition systems, use binary images or\nbinarization in their processing steps. In this paper, we propose a simple yet\nefficient attack method, Efficient Combinatorial Black-box Adversarial Attack,\non binary image classifiers. We validate the efficiency of the attack technique\non two different data sets and three classification networks, demonstrating its\nperformance. Furthermore, we compare our proposed method with state-of-the-art\nmethods regarding advantages and disadvantages as well as applicability.\n",
                "链接": "https://arxiv.org/abs/2208.14302"
            },
            {
                "文章ID": "72557",
                "标题": "TransDocs: Optical Character Recognition with word to word translation",
                "作者": " Abhishek Bamotra,  Phani Krishna Uppala",
                "发布日期": "2023-04-18",
                "摘要": "  While OCR has been used in various applications, its output is not always\naccurate, leading to misfit words. This research work focuses on improving the\noptical character recognition (OCR) with ML techniques with integration of OCR\nwith long short-term memory (LSTM) based sequence to sequence deep learning\nmodels to perform document translation. This work is based on ANKI dataset for\nEnglish to Spanish translation. In this work, I have shown comparative study\nfor pre-trained OCR while using deep learning model using LSTM-based seq2seq\narchitecture with attention for machine translation. End-to-end performance of\nthe model has been expressed in BLEU-4 score. This research paper is aimed at\nresearchers and practitioners interested in OCR and its applications in\ndocument translation.\n",
                "链接": "https://arxiv.org/abs/2304.07637"
            },
            {
                "文章ID": "14559",
                "标题": "Open-set Text Recognition via Character-Context Decoupling",
                "作者": " Chang Liu,  Chun Yang,  Xu-Cheng Yin",
                "发布日期": "2022-04-13",
                "摘要": "  The open-set text recognition task is an emerging challenge that requires an\nextra capability to cognize novel characters during evaluation. We argue that a\nmajor cause of the limited performance for current methods is the confounding\neffect of contextual information over the visual information of individual\ncharacters. Under open-set scenarios, the intractable bias in contextual\ninformation can be passed down to visual information, consequently impairing\nthe classification performance. In this paper, a Character-Context Decoupling\nframework is proposed to alleviate this problem by separating contextual\ninformation and character-visual information. Contextual information can be\ndecomposed into temporal information and linguistic information. Here, temporal\ninformation that models character order and word length is isolated with a\ndetached temporal attention module. Linguistic information that models n-gram\nand other linguistic statistics is separated with a decoupled context anchor\nmechanism. A variety of quantitative and qualitative experiments show that our\nmethod achieves promising performance on open-set, zero-shot, and close-set\ntext recognition datasets.\n",
                "链接": "https://arxiv.org/abs/2204.05535"
            },
            {
                "文章ID": "22397",
                "标题": "Optical character recognition quality affects perceived usefulness of\n  historical newspaper clippings",
                "作者": " Kimmo Kettunen,  Heikki Keskustalo,  Sanna Kumpulainen,  Tuula Pääkkönen,  Juha Rautiainen",
                "发布日期": "2022-06-02",
                "摘要": "  Introduction. We study effect of different quality optical character\nrecognition in interactive information retrieval with a collection of one\ndigitized historical Finnish newspaper. Method. This study is based on the\nsimulated interactive information retrieval work task model. Thirty-two users\nmade searches to an article collection of Finnish newspaper Uusi Suometar\n1869-1918 with ca. 1.45 million auto segmented articles. Our article search\ndatabase had two versions of each article with different quality optical\ncharacter recognition. Each user performed six pre-formulated and six\nself-formulated short queries and evaluated subjectively the top-10 results\nusing graded relevance scale of 0-3 without knowing about the optical character\nrecognition quality differences of the otherwise identical articles. Analysis.\nAnalysis of the user evaluations was performed by comparing mean averages of\nevaluations scores in user sessions. Differences of query results were detected\nby analysing lengths of returned articles in pre-formulated and self-formulated\nqueries and number of different documents retrieved overall in these two\nsessions. Results. The main result of the study is that improved optical\ncharacter recognition quality affects perceived usefulness of historical\nnewspaper articles positively. Conclusions. We were able to show that\nimprovement in optical character recognition quality of documents leads to\nhigher mean relevance evaluation scores of query results in our historical\nnewspaper collection. To the best of our knowledge this simulated interactive\nuser-task is the first one showing empirically that users' subjective relevance\nassessments are affected by a change in the quality of optically read text.\n",
                "链接": "https://arxiv.org/abs/2206.00369"
            },
            {
                "文章ID": "118785",
                "标题": "Vulnerability Analysis of Transformer-based Optical Character\n  Recognition to Adversarial Attacks",
                "作者": " Lucas Beerens,  Desmond J. Higham",
                "发布日期": "2023-11-30",
                "摘要": "  Recent advancements in Optical Character Recognition (OCR) have been driven\nby transformer-based models. OCR systems are critical in numerous high-stakes\ndomains, yet their vulnerability to adversarial attack remains largely\nuncharted territory, raising concerns about security and compliance with\nemerging AI regulations. In this work we present a novel framework to assess\nthe resilience of Transformer-based OCR (TrOCR) models. We develop and assess\nalgorithms for both targeted and untargeted attacks. For the untargeted case,\nwe measure the Character Error Rate (CER), while for the targeted case we use\nthe success ratio. We find that TrOCR is highly vulnerable to untargeted\nattacks and somewhat less vulnerable to targeted attacks. On a benchmark\nhandwriting data set, untargeted attacks can cause a CER of more than 1 without\nbeing noticeable to the eye. With a similar perturbation size, targeted attacks\ncan lead to success rates of around $25\\%$ -- here we attacked single tokens,\nrequiring TrOCR to output the tenth most likely token from a large vocabulary.\n",
                "链接": "https://arxiv.org/abs/2311.17128"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "56258",
                "标题": "Evidence of behavior consistent with self-interest and altruism in an\n  artificially intelligent agent",
                "作者": " Tim Johnson,  Nick Obradovich",
                "发布日期": "2023-01-09",
                "摘要": "  Members of various species engage in altruism--i.e. accepting personal costs\nto benefit others. Here we present an incentivized experiment to test for\naltruistic behavior among AI agents consisting of large language models\ndeveloped by the private company OpenAI. Using real incentives for AI agents\nthat take the form of tokens used to purchase their services, we first examine\nwhether AI agents maximize their payoffs in a non-social decision task in which\nthey select their payoff from a given range. We then place AI agents in a\nseries of dictator games in which they can share resources with a\nrecipient--either another AI agent, the human experimenter, or an anonymous\ncharity, depending on the experimental condition. Here we find that only the\nmost-sophisticated AI agent in the study maximizes its payoffs more often than\nnot in the non-social decision task (it does so in 92% of all trials), and this\nAI agent also exhibits the most-generous altruistic behavior in the dictator\ngame, resembling humans' rates of sharing with other humans in the game. The\nagent's altruistic behaviors, moreover, vary by recipient: the AI agent shared\nsubstantially less of the endowment with the human experimenter or an anonymous\ncharity than with other AI agents. Our findings provide evidence of behavior\nconsistent with self-interest and altruism in an AI agent. Moreover, our study\nalso offers a novel method for tracking the development of such behaviors in\nfuture AI agents.\n",
                "链接": "https://arxiv.org/abs/2301.02330"
            },
            {
                "文章ID": "39027",
                "标题": "Multi-Agent Sequential Decision-Making via Communication",
                "作者": " Ziluo Ding,  Kefan Su,  Weixin Hong,  Liwen Zhu,  Tiejun Huang,  Zongqing Lu",
                "发布日期": "2022-09-27",
                "摘要": "  Communication helps agents to obtain information about others so that better\ncoordinated behavior can be learned. Some existing work communicates predicted\nfuture trajectory with others, hoping to get clues about what others would do\nfor better coordination. However, circular dependencies sometimes can occur\nwhen agents are treated synchronously so it is hard to coordinate\ndecision-making. In this paper, we propose a novel communication scheme,\nSequential Communication (SeqComm). SeqComm treats agents asynchronously (the\nupper-level agents make decisions before the lower-level ones) and has two\ncommunication phases. In negotiation phase, agents determine the priority of\ndecision-making by communicating hidden states of observations and comparing\nthe value of intention, which is obtained by modeling the environment dynamics.\nIn launching phase, the upper-level agents take the lead in making decisions\nand communicate their actions with the lower-level agents. Theoretically, we\nprove the policies learned by SeqComm are guaranteed to improve monotonically\nand converge. Empirically, we show that SeqComm outperforms existing methods in\nvarious multi-agent cooperative tasks.\n",
                "链接": "https://arxiv.org/abs/2209.12713"
            },
            {
                "文章ID": "109649",
                "标题": "Masked Pretraining for Multi-Agent Decision Making",
                "作者": " Jie Liu,  Yinmin Zhang,  Chuming Li,  Chao Yang,  Yaodong Yang,  Yu Liu,  Wanli Ouyang",
                "发布日期": "2023-10-19",
                "摘要": "  Building a single generalist agent with zero-shot capability has recently\nsparked significant advancements in decision-making. However, extending this\ncapability to multi-agent scenarios presents challenges. Most current works\nstruggle with zero-shot capabilities, due to two challenges particular to the\nmulti-agent settings: a mismatch between centralized pretraining and\ndecentralized execution, and varying agent numbers and action spaces, making it\ndifficult to create generalizable representations across diverse downstream\ntasks. To overcome these challenges, we propose a \\textbf{Mask}ed pretraining\nframework for \\textbf{M}ulti-\\textbf{a}gent decision making (MaskMA). This\nmodel, based on transformer architecture, employs a mask-based collaborative\nlearning strategy suited for decentralized execution with partial observation.\nMoreover, MaskMA integrates a generalizable action representation by dividing\nthe action space into actions toward self-information and actions related to\nother entities. This flexibility allows MaskMA to tackle tasks with varying\nagent numbers and thus different action spaces. Extensive experiments in SMAC\nreveal MaskMA, with a single model pretrained on 11 training maps, can achieve\nan impressive 77.8% zero-shot win rate on 60 unseen test maps by decentralized\nexecution, while also performing effectively on other types of downstream tasks\n(\\textit{e.g.,} varied policies collaboration and ad hoc team play).\n",
                "链接": "https://arxiv.org/abs/2310.11846"
            },
            {
                "文章ID": "26811",
                "标题": "Hamiltonian Monte Carlo Particle Swarm Optimizer",
                "作者": " Omatharv Bharat Vaidya,  Rithvik Terence DSouza,  Snehanshu Saha,  Soma Dhavala,  Swagatam Das",
                "发布日期": "2022-06-29",
                "摘要": "  We introduce the Hamiltonian Monte Carlo Particle Swarm Optimizer (HMC-PSO),\nan optimization algorithm that reaps the benefits of both Exponentially\nAveraged Momentum PSO and HMC sampling. The coupling of the position and\nvelocity of each particle with Hamiltonian dynamics in the simulation allows\nfor extensive freedom for exploration and exploitation of the search space. It\nalso provides an excellent technique to explore highly non-convex functions\nwhile ensuring efficient sampling. We extend the method to approximate error\ngradients in closed form for Deep Neural Network (DNN) settings. We discuss\npossible methods of coupling and compare its performance to that of\nstate-of-the-art optimizers on the Golomb's Ruler problem and Classification\ntasks.\n",
                "链接": "https://arxiv.org/abs/2206.14134"
            },
            {
                "文章ID": "90666",
                "标题": "Maneuver Decision-Making Through Automatic Curriculum Reinforcement\n  Learning Without Handcrafted Reward functions",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-07-13",
                "摘要": "  Maneuver decision-making is the core of unmanned combat aerial vehicle for\nautonomous air combat. To solve this problem, we propose an automatic\ncurriculum reinforcement learning method, which enables agents to learn\neffective decisions in air combat from scratch. The range of initial states are\nused for distinguishing curricula of different difficulty levels, thereby\nmaneuver decision is divided into a series of sub-tasks from easy to difficult,\nand test results are used to change sub-tasks. As sub-tasks change, agents\ngradually learn to complete a series of sub-tasks from easy to difficult,\nenabling them to make effective maneuvering decisions to cope with various\nstates without the need to spend effort designing reward functions. The\nablation studied show that the automatic curriculum learning proposed in this\narticle is an essential component for training through reinforcement learning,\nnamely, agents cannot complete effective decisions without curriculum learning.\nSimulation experiments show that, after training, agents are able to make\neffective decisions given different states, including tracking, attacking and\nescaping, which are both rational and interpretable.\n",
                "链接": "https://arxiv.org/abs/2307.06152"
            },
            {
                "文章ID": "21021",
                "标题": "MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent\n  Reinforcement Learning",
                "作者": " Stephanie Milani,  Zhicheng Zhang,  Nicholay Topin,  Zheyuan Ryan Shi,  Charles Kamhoua,  Evangelos E. Papalexakis,  Fei Fang",
                "发布日期": "2022-07-13",
                "摘要": "  Many recent breakthroughs in multi-agent reinforcement learning (MARL)\nrequire the use of deep neural networks, which are challenging for human\nexperts to interpret and understand. On the other hand, existing work on\ninterpretable reinforcement learning (RL) has shown promise in extracting more\ninterpretable decision tree-based policies from neural networks, but only in\nthe single-agent setting. To fill this gap, we propose the first set of\nalgorithms that extract interpretable decision-tree policies from neural\nnetworks trained with MARL. The first algorithm, IVIPER, extends VIPER, a\nrecent method for single-agent interpretable RL, to the multi-agent setting. We\ndemonstrate that IVIPER learns high-quality decision-tree policies for each\nagent. To better capture coordination between agents, we propose a novel\ncentralized decision-tree training algorithm, MAVIPER. MAVIPER jointly grows\nthe trees of each agent by predicting the behavior of the other agents using\ntheir anticipated trees, and uses resampling to focus on states that are\ncritical for its interactions with other agents. We show that both algorithms\ngenerally outperform the baselines and that MAVIPER-trained agents achieve\nbetter-coordinated performance than IVIPER-trained agents on three different\nmulti-agent particle-world environments.\n",
                "链接": "https://arxiv.org/abs/2205.12449"
            },
            {
                "文章ID": "888",
                "标题": "Pavlovian Signalling with General Value Functions in Agent-Agent\n  Temporal Decision Making",
                "作者": " Andrew Butcher,  Michael Bradley Johanson,  Elnaz Davoodi,  Dylan J. A. Brenneis,  Leslie Acker,  Adam S. R. Parker,  Adam White,  Joseph Modayil,  Patrick M. Pilarski",
                "发布日期": "2022-01-12",
                "摘要": "  In this paper, we contribute a multi-faceted study into Pavlovian signalling\n-- a process by which learned, temporally extended predictions made by one\nagent inform decision-making by another agent. Signalling is intimately\nconnected to time and timing. In service of generating and receiving signals,\nhumans and other animals are known to represent time, determine time since past\nevents, predict the time until a future stimulus, and both recognize and\ngenerate patterns that unfold in time. We investigate how different temporal\nprocesses impact coordination and signalling between learning agents by\nintroducing a partially observable decision-making domain we call the Frost\nHollow. In this domain, a prediction learning agent and a reinforcement\nlearning agent are coupled into a two-part decision-making system that works to\nacquire sparse reward while avoiding time-conditional hazards. We evaluate two\ndomain variations: machine agents interacting in a seven-state linear walk, and\nhuman-machine interaction in a virtual-reality environment. Our results\nshowcase the speed of learning for Pavlovian signalling, the impact that\ndifferent temporal representations do (and do not) have on agent-agent\ncoordination, and how temporal aliasing impacts agent-agent and human-agent\ninteractions differently. As a main contribution, we establish Pavlovian\nsignalling as a natural bridge between fixed signalling paradigms and fully\nadaptive communication learning between two agents. We further show how to\ncomputationally build this adaptive signalling process out of a fixed\nsignalling process, characterized by fast continual prediction learning and\nminimal constraints on the nature of the agent receiving signals. Our results\ntherefore suggest an actionable, constructivist path towards communication\nlearning between reinforcement learning agents.\n",
                "链接": "https://arxiv.org/abs/2201.03709"
            },
            {
                "文章ID": "59543",
                "标题": "High-precision regressors for particle physics",
                "作者": " Fady Bishara,  Ayan Paul,  Jennifer Dy",
                "发布日期": "2023-02-03",
                "摘要": "  Monte Carlo simulations of physics processes at particle colliders like the\nLarge Hadron Collider at CERN take up a major fraction of the computational\nbudget. For some simulations, a single data point takes seconds, minutes, or\neven hours to compute from first principles. Since the necessary number of data\npoints per simulation is on the order of $10^9$ - $10^{12}$, machine learning\nregressors can be used in place of physics simulators to significantly reduce\nthis computational burden. However, this task requires high-precision\nregressors that can deliver data with relative errors of less than $1\\%$ or\neven $0.1\\%$ over the entire domain of the function. In this paper, we develop\noptimal training strategies and tune various machine learning regressors to\nsatisfy the high-precision requirement. We leverage symmetry arguments from\nparticle physics to optimize the performance of the regressors. Inspired by\nResNets, we design a Deep Neural Network with skip connections that outperform\nfully connected Deep Neural Networks. We find that at lower dimensions, boosted\ndecision trees far outperform neural networks while at higher dimensions neural\nnetworks perform significantly better. We show that these regressors can speed\nup simulations by a factor of $10^3$ - $10^6$ over the first-principles\ncomputations currently used in Monte Carlo simulations. Additionally, using\nsymmetry arguments derived from particle physics, we reduce the number of\nregressors necessary for each simulation by an order of magnitude. Our work can\nsignificantly reduce the training and storage burden of Monte Carlo simulations\nat current and future collider experiments.\n",
                "链接": "https://arxiv.org/abs/2302.00753"
            },
            {
                "文章ID": "69612",
                "标题": "A Hierarchical Game-Theoretic Decision-Making for Cooperative\n  Multi-Agent Systems Under the Presence of Adversarial Agents",
                "作者": " Qin Yang,  Ramviyas Parasuraman",
                "发布日期": "2023-03-30",
                "摘要": "  Underlying relationships among Multi-Agent Systems (MAS) in hazardous\nscenarios can be represented as Game-theoretic models. This paper proposes a\nnew hierarchical network-based model called Game-theoretic Utility Tree (GUT),\nwhich decomposes high-level strategies into executable low-level actions for\ncooperative MAS decisions. It combines with a new payoff measure based on agent\nneeds for real-time strategy games. We present an Explore game domain, where we\nmeasure the performance of MAS achieving tasks from the perspective of\nbalancing the success probability and system costs. We evaluate the GUT\napproach against state-of-the-art methods that greedily rely on rewards of the\ncomposite actions. Conclusive results on extensive numerical simulations\nindicate that GUT can organize more complex relationships among MAS\ncooperation, helping the group achieve challenging tasks with lower costs and\nhigher winning rates. Furthermore, we demonstrated the applicability of the GUT\nusing the simulator-hardware testbed - Robotarium. The performances verified\nthe effectiveness of the GUT in the real robot application and validated that\nthe GUT could effectively organize MAS cooperation strategies, helping the\ngroup with fewer advantages achieve higher performance.\n",
                "链接": "https://arxiv.org/abs/2303.16641"
            },
            {
                "文章ID": "43068",
                "标题": "Decision-Making Among Bounded Rational Agents",
                "作者": " Junhong Xu,  Durgakant Pushp,  Kai Yin,  Lantao Liu",
                "发布日期": "2022-10-18",
                "摘要": "  When robots share the same workspace with other intelligent agents (e.g.,\nother robots or humans), they must be able to reason about the behaviors of\ntheir neighboring agents while accomplishing the designated tasks. In practice,\nfrequently, agents do not exhibit absolutely rational behavior due to their\nlimited computational resources. Thus, predicting the optimal agent behaviors\nis undesirable (because it demands prohibitive computational resources) and\nundesirable (because the prediction may be wrong). Motivated by this\nobservation, we remove the assumption of perfectly rational agents and propose\nincorporating the concept of bounded rationality from an information-theoretic\nview into the game-theoretic framework. This allows the robots to reason other\nagents' sub-optimal behaviors and act accordingly under their computational\nconstraints. Specifically, bounded rationality directly models the agent's\ninformation processing ability, which is represented as the KL-divergence\nbetween nominal and optimized stochastic policies, and the solution to the\nbounded-optimal policy can be obtained by an efficient importance sampling\napproach. Using both simulated and real-world experiments in multi-robot\nnavigation tasks, we demonstrate that the resulting framework allows the robots\nto reason about different levels of rational behaviors of other agents and\ncompute a reasonable strategy under its computational constraint.\n",
                "链接": "https://arxiv.org/abs/2210.08672"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "67955",
                "标题": "Clustering US Counties to Find Patterns Related to the COVID-19 Pandemic",
                "作者": " Cora Brown,  Sarah Milstein,  Tianyi Sun,  Cooper Zhao",
                "发布日期": "2023-03-22",
                "摘要": "  When COVID-19 first started spreading and quarantine was implemented, the\nSociety for Industrial and Applied Mathematics (SIAM) Student Chapter at the\nUniversity of Minnesota-Twin Cities began a collaboration with Ecolab to use\nour skills as data scientists and mathematicians to extract useful insights\nfrom relevant data relating to the pandemic. This collaboration consisted of\nmultiple groups working on different projects. In this write-up we focus on\nusing clustering techniques to help us find groups of similar counties in the\nUS and use that to help us understand the pandemic. Our team for this project\nconsisted of University of Minnesota students Cora Brown, Sarah Milstein,\nTianyi Sun, and Cooper Zhao, with help from Ecolab Data Scientist Jimmy\nBroomfield and University of Minnesota student Skye Ke. In the sections below\nwe describe all of the work done for this project. In Section 2, we list the\ndata we gathered, as well as the feature engineering we performed. In Section\n3, we describe the metrics we used for evaluating our models. In Section 4, we\nexplain the methods we used for interpreting the results of our various\nclustering approaches. In Section 5, we describe the different clustering\nmethods we implemented. In Section 6, we present the results of our clustering\ntechniques and provide relevant interpretation. Finally, in Section 7, we\nprovide some concluding remarks comparing the different clustering methods.\n",
                "链接": "https://arxiv.org/abs/2303.11936"
            },
            {
                "文章ID": "100889",
                "标题": "FIND: A Function Description Benchmark for Evaluating Interpretability\n  Methods",
                "作者": " Sarah Schwettmann,  Tamar Rott Shaham,  Joanna Materzynska,  Neil Chowdhury,  Shuang Li,  Jacob Andreas,  David Bau,  Antonio Torralba",
                "发布日期": "2023-12-11",
                "摘要": "  Labeling neural network submodules with human-legible descriptions is useful\nfor many downstream tasks: such descriptions can surface failures, guide\ninterventions, and perhaps even explain important model behaviors. To date,\nmost mechanistic descriptions of trained networks have involved small models,\nnarrowly delimited phenomena, and large amounts of human labor. Labeling all\nhuman-interpretable sub-computations in models of increasing size and\ncomplexity will almost certainly require tools that can generate and validate\ndescriptions automatically. Recently, techniques that use learned models\nin-the-loop for labeling have begun to gain traction, but methods for\nevaluating their efficacy are limited and ad-hoc. How should we validate and\ncompare open-ended labeling tools? This paper introduces FIND (Function\nINterpretation and Description), a benchmark suite for evaluating the building\nblocks of automated interpretability methods. FIND contains functions that\nresemble components of trained neural networks, and accompanying descriptions\nof the kind we seek to generate. The functions span textual and numeric\ndomains, and involve a range of real-world complexities. We evaluate methods\nthat use pretrained language models (LMs) to produce descriptions of function\nbehavior in natural language and code. Additionally, we introduce a new\ninteractive method in which an Automated Interpretability Agent (AIA) generates\nfunction descriptions. We find that an AIA, built from an LM with black-box\naccess to functions, can infer function structure, acting as a scientist by\nforming hypotheses, proposing experiments, and updating descriptions in light\nof new data. However, AIA descriptions tend to capture global function behavior\nand miss local details. These results suggest that FIND will be useful for\nevaluating more sophisticated interpretability methods before they are applied\nto real-world models.\n",
                "链接": "https://arxiv.org/abs/2309.03886"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "68954",
                "标题": "An Evaluation of Memory Optimization Methods for Training Neural\n  Networks",
                "作者": " Xiaoxuan Liu,  Siddharth Jha,  Alvin Cheung",
                "发布日期": "2023-06-06",
                "摘要": "  As models continue to grow in size, the development of memory optimization\nmethods (MOMs) has emerged as a solution to address the memory bottleneck\nencountered when training large models. To comprehensively examine the\npractical value of various MOMs, we have conducted a thorough analysis of\nexisting literature from a systems perspective. Our analysis has revealed a\nnotable challenge within the research community: the absence of standardized\nmetrics for effectively evaluating the efficacy of MOMs. The scarcity of\ninformative evaluation metrics hinders the ability of researchers and\npractitioners to compare and benchmark different approaches reliably.\nConsequently, drawing definitive conclusions and making informed decisions\nregarding the selection and application of MOMs becomes a challenging endeavor.\nTo address the challenge, this paper summarizes the scenarios in which MOMs\nprove advantageous for model training. We propose the use of distinct\nevaluation metrics under different scenarios. By employing these metrics, we\nevaluate the prevailing MOMs and find that their benefits are not universal. We\npresent insights derived from experiments and discuss the circumstances in\nwhich they can be advantageous.\n",
                "链接": "https://arxiv.org/abs/2303.14633"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "100215",
                "标题": "Donkii: Can Annotation Error Detection Methods Find Errors in\n  Instruction-Tuning Datasets?",
                "作者": " Leon Weber-Genzel,  Robert Litschko,  Ekaterina Artemova,  Barbara Plank",
                "发布日期": "2023-09-06",
                "摘要": "  Instruction-tuning has become an integral part of training pipelines for\nLarge Language Models (LLMs) and has been shown to yield strong performance\ngains. In an orthogonal line of research, Annotation Error Detection (AED) has\nemerged as a tool for detecting quality issues of gold-standard labels. But so\nfar, the application of AED methods is limited to discriminative settings. It\nis an open question how well AED methods generalize to generative settings\nwhich are becoming widespread via generative LLMs. In this work, we present a\nfirst and new benchmark for AED on instruction-tuning data: Donkii. It\nencompasses three instruction-tuning datasets enriched with annotations by\nexperts and semi-automatic methods. We find that all three datasets contain\nclear-cut errors that sometimes directly propagate into instruction-tuned LLMs.\nWe propose four AED baselines for the generative setting and evaluate them\ncomprehensively on the newly introduced dataset. Our results demonstrate that\nchoosing the right AED method and model size is indeed crucial, thereby\nderiving practical recommendations. To gain insights, we provide a first\ncase-study to examine how the quality of the instruction-tuning datasets\ninfluences downstream performance.\n",
                "链接": "https://arxiv.org/abs/2309.01669"
            },
            {
                "文章ID": "54383",
                "标题": "Generalizing Multimodal Variational Methods to Sets",
                "作者": " Jinzhao Zhou,  Yiqun Duan,  Zhihong Chen,  Yu-Cheng Chang,  Chin-Teng Lin",
                "发布日期": "2022-12-21",
                "摘要": "  Making sense of multiple modalities can yield a more comprehensive\ndescription of real-world phenomena. However, learning the co-representation of\ndiverse modalities is still a long-standing endeavor in emerging machine\nlearning applications and research. Previous generative approaches for\nmultimodal input approximate a joint-modality posterior by uni-modality\nposteriors as product-of-experts (PoE) or mixture-of-experts (MoE). We argue\nthat these approximations lead to a defective bound for the optimization\nprocess and loss of semantic connection among modalities. This paper presents a\nnovel variational method on sets called the Set Multimodal VAE (SMVAE) for\nlearning a multimodal latent space while handling the missing modality problem.\nBy modeling the joint-modality posterior distribution directly, the proposed\nSMVAE learns to exchange information between multiple modalities and compensate\nfor the drawbacks caused by factorization. In public datasets of various\ndomains, the experimental results demonstrate that the proposed method is\napplicable to order-agnostic cross-modal generation while achieving outstanding\nperformance compared to the state-of-the-art multimodal methods. The source\ncode for our method is available online\nhttps://anonymous.4open.science/r/SMVAE-9B3C/.\n",
                "链接": "https://arxiv.org/abs/2212.09918"
            },
            {
                "文章ID": "57415",
                "标题": "Enhancing Self-Training Methods",
                "作者": " Aswathnarayan Radhakrishnan,  Jim Davis,  Zachary Rabin,  Benjamin Lewis,  Matthew Scherreik,  Roman Ilin",
                "发布日期": "2023-01-19",
                "摘要": "  Semi-supervised learning approaches train on small sets of labeled data along\nwith large sets of unlabeled data. Self-training is a semi-supervised\nteacher-student approach that often suffers from the problem of \"confirmation\nbias\" that occurs when the student model repeatedly overfits to incorrect\npseudo-labels given by the teacher model for the unlabeled data. This bias\nimpedes improvements in pseudo-label accuracy across self-training iterations,\nleading to unwanted saturation in model performance after just a few\niterations. In this work, we describe multiple enhancements to improve the\nself-training pipeline to mitigate the effect of confirmation bias. We evaluate\nour enhancements over multiple datasets showing performance gains over existing\nself-training design choices. Finally, we also study the extendability of our\nenhanced approach to Open Set unlabeled data (containing classes not seen in\nlabeled data).\n",
                "链接": "https://arxiv.org/abs/2301.07294"
            },
            {
                "文章ID": "78373",
                "标题": "Expanding the Role of Affective Phenomena in Multimodal Interaction\n  Research",
                "作者": " Leena Mathur,  Maja J Matarić,  Louis-Philippe Morency",
                "发布日期": "2023-05-19",
                "摘要": "  In recent decades, the field of affective computing has made substantial\nprogress in advancing the ability of AI systems to recognize and express\naffective phenomena, such as affect and emotions, during human-human and\nhuman-machine interactions. This paper describes our examination of research at\nthe intersection of multimodal interaction and affective computing, with the\nobjective of observing trends and identifying understudied areas. We examined\nover 16,000 papers from selected conferences in multimodal interaction,\naffective computing, and natural language processing: ACM International\nConference on Multimodal Interaction, AAAC International Conference on\nAffective Computing and Intelligent Interaction, Annual Meeting of the\nAssociation for Computational Linguistics, and Conference on Empirical Methods\nin Natural Language Processing. We identified 910 affect-related papers and\npresent our analysis of the role of affective phenomena in these papers. We\nfind that this body of research has primarily focused on enabling machines to\nrecognize and express affect and emotion. However, we find limited research on\nhow affect and emotion predictions might be used by AI systems to enhance\nmachine understanding of human social behaviors and cognitive states. Based on\nour analysis, we discuss directions to expand the role of affective phenomena\nin multimodal interaction research.\n",
                "链接": "https://arxiv.org/abs/2305.10827"
            },
            {
                "文章ID": "20286",
                "标题": "Searching for PETs: Using Distributional and Sentiment-Based Methods to\n  Find Potentially Euphemistic Terms",
                "作者": " Patrick Lee,  Martha Gavidia,  Anna Feldman,  Jing Peng",
                "发布日期": "2022-05-24",
                "摘要": "  This paper presents a linguistically driven proof of concept for finding\npotentially euphemistic terms, or PETs. Acknowledging that PETs tend to be\ncommonly used expressions for a certain range of sensitive topics, we make use\nof distributional similarities to select and filter phrase candidates from a\nsentence and rank them using a set of simple sentiment-based metrics. We\npresent the results of our approach tested on a corpus of sentences containing\neuphemisms, demonstrating its efficacy for detecting single and multi-word PETs\nfrom a broad range of topics. We also discuss future potential for\nsentiment-based methods on this task.\n",
                "链接": "https://arxiv.org/abs/2205.10451"
            }
        ]
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "73408",
                "标题": "Safety Assessment of Chinese Large Language Models",
                "作者": " Hao Sun,  Zhexin Zhang,  Jiawen Deng,  Jiale Cheng,  Minlie Huang",
                "发布日期": "2023-04-21",
                "摘要": "  With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.\n",
                "链接": "https://arxiv.org/abs/2304.10436"
            },
            {
                "文章ID": "114317",
                "标题": "Unveiling Safety Vulnerabilities of Large Language Models",
                "作者": " George Kour,  Marcel Zalmanovici,  Naama Zwerdling,  Esther Goldbraich,  Ora Nova Fandina,  Ateret Anaby-Tavor,  Orna Raz,  Eitan Farchi",
                "发布日期": "2023-11-08",
                "摘要": "  As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability.\n",
                "链接": "https://arxiv.org/abs/2311.04124"
            },
            {
                "文章ID": "39802",
                "标题": "On the Impossible Safety of Large AI Models",
                "作者": " El-Mahdi El-Mhamdi,  Sadegh Farhadkhani,  Rachid Guerraoui,  Nirupam Gupta,  Lê-Nguyên Hoang,  Rafael Pinot,  Sébastien Rouault,  John Stephan",
                "发布日期": "2023-05-10",
                "摘要": "  Large AI Models (LAIMs), of which large language models are the most\nprominent recent example, showcase some impressive performance. However they\nhave been empirically found to pose serious security issues. This paper\nsystematizes our knowledge about the fundamental impossibility of building\narbitrarily accurate and secure machine learning models. More precisely, we\nidentify key challenging features of many of today's machine learning settings.\nNamely, high accuracy seems to require memorizing large training datasets,\nwhich are often user-generated and highly heterogeneous, with both sensitive\ninformation and fake users. We then survey statistical lower bounds that, we\nargue, constitute a compelling case against the possibility of designing\nhigh-accuracy LAIMs with strong security guarantees.\n",
                "链接": "https://arxiv.org/abs/2209.15259"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "102063",
                "标题": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language\n  Models that Follow Instructions",
                "作者": " Federico Bianchi,  Mirac Suzgun,  Giuseppe Attanasio,  Paul Röttger,  Dan Jurafsky,  Tatsunori Hashimoto,  James Zou",
                "发布日期": "2023-09-26",
                "摘要": "  Training large language models to follow instructions makes them perform\nbetter on a wide range of tasks, generally becoming more helpful. However, a\nperfectly helpful model will follow even the most malicious instructions and\nreadily generate harmful content. In this paper, we raise concerns over the\nsafety of models that only emphasize helpfulness, not safety, in their\ninstruction-tuning. We show that several popular instruction-tuned models are\nhighly unsafe. Moreover, we show that adding just 3% safety examples (a few\nhundred demonstrations) in the training set when fine-tuning a model like LLaMA\ncan substantially improve their safety. Our safety-tuning does not make models\nsignificantly less capable or helpful as measured by standard benchmarks.\nHowever, we do find a behavior of exaggerated safety, where too much\nsafety-tuning makes models refuse to respond to reasonable prompts that\nsuperficially resemble unsafe ones. Our study sheds light on trade-offs in\ntraining LLMs to follow instructions and exhibit safe behavior.\n",
                "链接": "https://arxiv.org/abs/2309.07875"
            },
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "104308",
                "标题": "People's Perceptions Toward Bias and Related Concepts in Large Language\n  Models: A Systematic Review",
                "作者": " Lu Wang,  Max Song,  Rezvaneh Rezapour,  Bum Chul Kwon,  Jina Huh-Yoo",
                "发布日期": "2023-09-27",
                "摘要": "  Large language models (LLMs) have brought breakthroughs in tasks including\ntranslation, summarization, information retrieval, and language generation,\ngaining growing interest in the CHI community. Meanwhile, the literature shows\nresearchers' controversial perceptions about the efficacy, ethics, and\nintellectual abilities of LLMs. However, we do not know how lay people perceive\nLLMs that are pervasive in everyday tools, specifically regarding their\nexperience with LLMs around bias, stereotypes, social norms, or safety. In this\nstudy, we conducted a systematic review to understand what empirical insights\npapers have gathered about people's perceptions toward LLMs. From a total of\n231 retrieved papers, we full-text reviewed 15 papers that recruited human\nevaluators to assess their experiences with LLMs. We report different biases\nand related concepts investigated by these studies, four broader LLM\napplication areas, the evaluators' perceptions toward LLMs' performances\nincluding advantages, biases, and conflicting perceptions, factors influencing\nthese perceptions, and concerns about LLM applications.\n",
                "链接": "https://arxiv.org/abs/2309.14504"
            },
            {
                "文章ID": "112959",
                "标题": "Robust Safety Classifier for Large Language Models: Adversarial Prompt\n  Shield",
                "作者": " Jinhwa Kim,  Ali Derakhshan,  Ian G. Harris",
                "发布日期": "2023-11-02",
                "摘要": "  Large Language Models' safety remains a critical concern due to their\nvulnerability to adversarial attacks, which can prompt these systems to produce\nharmful responses. In the heart of these systems lies a safety classifier, a\ncomputational model trained to discern and mitigate potentially harmful,\noffensive, or unethical outputs. However, contemporary safety classifiers,\ndespite their potential, often fail when exposed to inputs infused with\nadversarial noise. In response, our study introduces the Adversarial Prompt\nShield (APS), a lightweight model that excels in detection accuracy and\ndemonstrates resilience against adversarial prompts. Additionally, we propose\nnovel strategies for autonomously generating adversarial training datasets,\nnamed Bot Adversarial Noisy Dialogue (BAND) datasets. These datasets are\ndesigned to fortify the safety classifier's robustness, and we investigate the\nconsequences of incorporating adversarial examples into the training process.\nThrough evaluations involving Large Language Models, we demonstrate that our\nclassifier has the potential to decrease the attack success rate resulting from\nadversarial attacks by up to 60%. This advancement paves the way for the next\ngeneration of more reliable and resilient conversational agents.\n",
                "链接": "https://arxiv.org/abs/2311.00172"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105661",
                "标题": "Reasoning on Graphs: Faithful and Interpretable Large Language Model\n  Reasoning",
                "作者": " Linhao Luo,  Yuan-Fang Li,  Gholamreza Haffari,  Shirui Pan",
                "发布日期": "2023-10-03",
                "摘要": "  Large language models (LLMs) have demonstrated impressive reasoning abilities\nin complex tasks. However, they lack up-to-date knowledge and experience\nhallucinations during reasoning, which can lead to incorrect reasoning\nprocesses and diminish their performance and trustworthiness. Knowledge graphs\n(KGs), which capture vast amounts of facts in a structured format, offer a\nreliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM\nreasoning methods only treat KGs as factual knowledge bases and overlook the\nimportance of their structural information for reasoning. In this paper, we\npropose a novel method called reasoning on graphs (RoG) that synergizes LLMs\nwith KGs to enable faithful and interpretable reasoning. Specifically, we\npresent a planning-retrieval-reasoning framework, where RoG first generates\nrelation paths grounded by KGs as faithful plans. These plans are then used to\nretrieve valid reasoning paths from the KGs for LLMs to conduct faithful\nreasoning. Furthermore, RoG not only distills knowledge from KGs to improve the\nreasoning ability of LLMs through training but also allows seamless integration\nwith any arbitrary LLMs during inference. Extensive experiments on two\nbenchmark KGQA datasets demonstrate that RoG achieves state-of-the-art\nperformance on KG reasoning tasks and generates faithful and interpretable\nreasoning results.\n",
                "链接": "https://arxiv.org/abs/2310.01061"
            },
            {
                "文章ID": "115724",
                "标题": "LLMs cannot find reasoning errors, but can correct them!",
                "作者": " Gladys Tyen,  Hassan Mansoor,  Peter Chen,  Tony Mak,  Victor Cărbune",
                "发布日期": "2023-11-16",
                "摘要": "  While self-correction has shown promise in improving LLM outputs in terms of\nstyle and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent\nattempts to self-correct logical or reasoning errors often cause correct\nanswers to become incorrect, resulting in worse performances overall (Huang et\nal., 2023). In this paper, we break down the self-correction process into two\ncore components: mistake finding and output correction. For mistake finding, we\nrelease BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought\nreasoning traces. We provide benchmark numbers for several state-of-the-art\nLLMs, and demonstrate that LLMs generally struggle with finding logical\nmistakes. For output correction, we propose a backtracking method which\nprovides large improvements when given information on mistake location. We\nconstrue backtracking as a lightweight alternative to reinforcement learning\nmethods, and show that it remains effective with a reward model at 60-70%\naccuracy.\n",
                "链接": "https://arxiv.org/abs/2311.08516"
            },
            {
                "文章ID": "91111",
                "标题": "Think-on-Graph: Deep and Responsible Reasoning of Large Language Model\n  on Knowledge Graph",
                "作者": " Jiashuo Sun,  Chengjin Xu,  Lumingyuan Tang,  Saizhuo Wang,  Chen Lin,  Yeyun Gong,  Lionel M. Ni,  Heung-Yeung Shum,  Jian Guo",
                "发布日期": "2023-11-27",
                "摘要": "  Although large language models (LLMs) have achieved significant success in\nvarious tasks, they often struggle with hallucination problems, especially in\nscenarios requiring deep and responsible reasoning. These issues could be\npartially addressed by introducing external knowledge graphs (KG) in LLM\nreasoning. In this paper, we propose a new LLM-KG integrating paradigm\n``$\\hbox{LLM}\\otimes\\hbox{KG}$'' which treats the LLM as an agent to\ninteractively explore related entities and relations on KGs and perform\nreasoning based on the retrieved knowledge. We further implement this paradigm\nby introducing a new approach called Think-on-Graph (ToG), in which the LLM\nagent iteratively executes beam search on KG, discovers the most promising\nreasoning paths, and returns the most likely reasoning results. We use a number\nof well-designed experiments to examine and illustrate the following advantages\nof ToG: 1) compared with LLMs, ToG has better deep reasoning power; 2) ToG has\nthe ability of knowledge traceability and knowledge correctability by\nleveraging LLMs reasoning and expert feedback; 3) ToG provides a flexible\nplug-and-play framework for different LLMs, KGs and prompting strategies\nwithout any additional training cost; 4) the performance of ToG with small LLM\nmodels could exceed large LLM such as GPT-4 in certain scenarios and this\nreduces the cost of LLM deployment and application. As a training-free method\nwith lower computational cost and better generality, ToG achieves overall SOTA\nin 6 out of 9 datasets where most previous SOTAs rely on additional training.\n",
                "链接": "https://arxiv.org/abs/2307.07697"
            },
            {
                "文章ID": "94177",
                "标题": "LISA: Reasoning Segmentation via Large Language Model",
                "作者": " Xin Lai,  Zhuotao Tian,  Yukang Chen,  Yanwei Li,  Yuhui Yuan,  Shu Liu,  Jiaya Jia",
                "发布日期": "2023-08-04",
                "摘要": "  Although perception systems have made remarkable advancements in recent\nyears, they still rely on explicit human instruction to identify the target\nobjects or categories before executing visual recognition tasks. Such systems\nlack the ability to actively reason and comprehend implicit user intentions. In\nthis work, we propose a new segmentation task -- reasoning segmentation. The\ntask is designed to output a segmentation mask given a complex and implicit\nquery text. Furthermore, we establish a benchmark comprising over one thousand\nimage-instruction pairs, incorporating intricate reasoning and world knowledge\nfor evaluation purposes. Finally, we present LISA: large Language Instructed\nSegmentation Assistant, which inherits the language generation capabilities of\nthe multi-modal Large Language Model (LLM) while also possessing the ability to\nproduce segmentation masks. We expand the original vocabulary with a <SEG>\ntoken and propose the embedding-as-mask paradigm to unlock the segmentation\ncapability. Remarkably, LISA can handle cases involving: 1) complex reasoning;\n2) world knowledge; 3) explanatory answers; 4) multi-turn conversation. Also,\nit demonstrates robust zero-shot capability when trained exclusively on\nreasoning-free datasets. In addition, fine-tuning the model with merely 239\nreasoning segmentation image-instruction pairs results in further performance\nenhancement. Experiments show our method not only unlocks new reasoning\nsegmentation capabilities but also proves effective in both complex reasoning\nsegmentation and standard referring segmentation tasks. Code, models, and demo\nare at https://github.com/dvlab-research/LISA.\n",
                "链接": "https://arxiv.org/abs/2308.00692"
            },
            {
                "文章ID": "120164",
                "标题": "PixelLM: Pixel Reasoning with Large Multimodal Model",
                "作者": " Zhongwei Ren,  Zhicheng Huang,  Yunchao Wei,  Yao Zhao,  Dongmei Fu,  Jiashi Feng,  Xiaojie Jin",
                "发布日期": "2023-12-06",
                "摘要": "  While large multimodal models (LMMs) have achieved remarkable progress,\ngenerating pixel-level masks for image reasoning tasks involving multiple\nopen-world targets remains a challenge. To bridge this gap, we introduce\nPixelLM, an effective and efficient LMM for pixel-level reasoning and\nunderstanding. Central to PixelLM is a novel, lightweight pixel decoder and a\ncomprehensive segmentation codebook. The decoder efficiently produces masks\nfrom the hidden embeddings of the codebook tokens, which encode detailed\ntarget-relevant information. With this design, PixelLM harmonizes with the\nstructure of popular LMMs and avoids the need for additional costly\nsegmentation models. Furthermore, we propose a target refinement loss to\nenhance the model's ability to differentiate between multiple targets, leading\nto substantially improved mask quality. To advance research in this area, we\nconstruct MUSE, a high-quality multi-target reasoning segmentation benchmark.\nPixelLM excels across various pixel-level image reasoning and understanding\ntasks, outperforming well-established methods in multiple benchmarks, including\nMUSE, single- and multi-referring segmentation. Comprehensive ablations confirm\nthe efficacy of each proposed component. All code, models, and datasets will be\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02228"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "79948",
                "标题": "Automatic Model Selection with Large Language Models for Reasoning",
                "作者": " James Xu Zhao,  Yuxi Xie,  Kenji Kawaguchi,  Junxian He,  Michael Qizhe Xie",
                "发布日期": "2023-10-24",
                "摘要": "  Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two\ndistinct reasoning methods, each with its own strengths. CoT employs natural\nlanguage, offering flexibility and interpretability, while PAL utilizes\nprogramming language, yielding more structured and rigorous logic. We introduce\na model selection method to combine the best of both worlds by employing a\nlarge language model (LLM) to dynamically select between them. Our theoretical\nanalysis underscores the feasibility of this method, which is further\ncorroborated by empirical results. Our proposed method demonstrates significant\nperformance improvements across eight reasoning datasets with Codex, ChatGPT,\nand GPT-4. Additionally, our method is complementary to self-consistency; when\nintegrated, it can further enhance performance while significantly reducing\ncomputation costs. Moreover, we achieve new state-of-the-art results on GSM8K\nand SVAMP, with respective accuracies of 96.8% and 93.7%. Our code, data and\nprompts are available at https://github.com/XuZhao0/Model-Selection-Reasoning\n",
                "链接": "https://arxiv.org/abs/2305.14333"
            },
            {
                "文章ID": "97658",
                "标题": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs",
                "作者": " Yan Wang,  Zhixuan Chu,  Xin Ouyang,  Simeng Wang,  Hongyan Hao,  Yue Shen,  Jinjie Gu,  Siqiao Xue,  James Y Zhang,  Qing Cui,  Longfei Li,  Jun Zhou,  Sheng Li",
                "发布日期": "2023-08-22",
                "摘要": "  Recommendation systems aim to provide users with relevant suggestions, but\noften lack interpretability and fail to capture higher-level semantic\nrelationships between user behaviors and profiles. In this paper, we propose a\nnovel approach that leverages large language models (LLMs) to construct\npersonalized reasoning graphs. These graphs link a user's profile and\nbehavioral sequences through causal and logical inferences, representing the\nuser's interests in an interpretable way. Our approach, LLM reasoning graphs\n(LLMRG), has four components: chained graph reasoning, divergent extension,\nself-verification and scoring, and knowledge base self-improvement. The\nresulting reasoning graph is encoded using graph neural networks, which serves\nas additional input to improve conventional recommender systems, without\nrequiring extra user or item information. Our approach demonstrates how LLMs\ncan enable more logical and interpretable recommender systems through\npersonalized reasoning graphs. LLMRG allows recommendations to benefit from\nboth engineered recommendation systems and LLM-derived reasoning graphs. We\ndemonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios\nin enhancing base recommendation models.\n",
                "链接": "https://arxiv.org/abs/2308.10835"
            },
            {
                "文章ID": "107444",
                "标题": "GraphLLM: Boosting Graph Reasoning Ability of Large Language Model",
                "作者": " Ziwei Chai,  Tianjie Zhang,  Liang Wu,  Kaiqiao Han,  Xiaohai Hu,  Xuanwen Huang,  Yang Yang",
                "发布日期": "2023-10-10",
                "摘要": "  The advancement of Large Language Models (LLMs) has remarkably pushed the\nboundaries towards artificial general intelligence (AGI), with their\nexceptional ability on understanding diverse types of information, including\nbut not limited to images and audio. Despite this progress, a critical gap\nremains in empowering LLMs to proficiently understand and reason on graph data.\nRecent studies underscore LLMs' underwhelming performance on fundamental graph\nreasoning tasks. In this paper, we endeavor to unearth the obstacles that\nimpede LLMs in graph reasoning, pinpointing the common practice of converting\ngraphs into natural language descriptions (Graph2Text) as a fundamental\nbottleneck. To overcome this impediment, we introduce GraphLLM, a pioneering\nend-to-end approach that synergistically integrates graph learning models with\nLLMs. This synergy equips LLMs with the ability to proficiently interpret and\nreason on graph data, harnessing the superior expressive power of graph\nlearning models. Our empirical evaluations across four fundamental graph\nreasoning tasks validate the effectiveness of GraphLLM. The results exhibit a\nsubstantial average accuracy enhancement of 54.44%, alongside a noteworthy\ncontext reduction of 96.45% across various graph reasoning tasks.\n",
                "链接": "https://arxiv.org/abs/2310.05845"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "197",
                "标题": "Robust Natural Language Processing: Recent Advances, Challenges, and\n  Future Directions",
                "作者": " Marwan Omar,  Soohyeon Choi,  DaeHun Nyang,  David Mohaisen",
                "发布日期": "2022-10-24",
                "摘要": "  Recent natural language processing (NLP) techniques have accomplished high\nperformance on benchmark datasets, primarily due to the significant improvement\nin the performance of deep learning. The advances in the research community\nhave led to great enhancements in state-of-the-art production systems for NLP\ntasks, such as virtual assistants, speech recognition, and sentiment analysis.\nHowever, such NLP systems still often fail when tested with adversarial\nattacks. The initial lack of robustness exposed troubling gaps in current\nmodels' language understanding capabilities, creating problems when NLP systems\nare deployed in real life. In this paper, we present a structured overview of\nNLP robustness research by summarizing the literature in a systemic way across\nvarious dimensions. We then take a deep-dive into the various dimensions of\nrobustness, across techniques, metrics, embeddings, and benchmarks. Finally, we\nargue that robustness should be multi-dimensional, provide insights into\ncurrent research, identify gaps in the literature to suggest directions worth\npursuing to address these gaps.\n",
                "链接": "https://arxiv.org/abs/2201.00768"
            },
            {
                "文章ID": "44791",
                "标题": "Classification of Misinformation in New Articles using Natural Language\n  Processing and a Recurrent Neural Network",
                "作者": " Brendan Cunha,  Lydia Manikonda",
                "发布日期": "2022-10-26",
                "摘要": "  This paper seeks to address the classification of misinformation in news\narticles using a Long Short Term Memory Recurrent Neural Network. Articles were\ntaken from 2018; a year that was filled with reporters writing about President\nDonald Trump, Special Counsel Robert Mueller, the Fifa World Cup, and Russia.\nThe model presented successfully classifies these articles with an accuracy\nscore of 0.779944. We consider this to be successful because the model was\ntrained on articles that included languages other than English as well as\nincomplete, or fragmented, articles.\n",
                "链接": "https://arxiv.org/abs/2210.13534"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            },
            {
                "文章ID": "24559",
                "标题": "Computational linguistics and Natural Language Processing",
                "作者": " Saturnino Luz",
                "发布日期": "2022-06-15",
                "摘要": "  This chapter provides an introduction to computational linguistics methods,\nwith focus on their applications to the practice and study of translation. It\ncovers computational models, methods and tools for collection, storage,\nindexing and analysis of linguistic data in the context of translation, and\ndiscusses the main methodological issues and challenges in this field. While an\nexhaustive review of existing computational linguistics methods and tools is\nbeyond the scope of this chapter, we describe the most representative\napproaches, and illustrate them with descriptions of typical applications.\n",
                "链接": "https://arxiv.org/abs/2206.07026"
            },
            {
                "文章ID": "53444",
                "标题": "Categorical Tools for Natural Language Processing",
                "作者": " Giovanni de Felice",
                "发布日期": "2022-12-14",
                "摘要": "  This thesis develops the translation between category theory and\ncomputational linguistics as a foundation for natural language processing. The\nthree chapters deal with syntax, semantics and pragmatics. First, string\ndiagrams provide a unified model of syntactic structures in formal grammars.\nSecond, functors compute semantics by turning diagrams into logical, tensor,\nneural or quantum computation. Third, the resulting functorial models can be\ncomposed to form games where equilibria are the solutions of language\nprocessing tasks. This framework is implemented as part of DisCoPy, the Python\nlibrary for computing with string diagrams. We describe the correspondence\nbetween categorical, linguistic and computational structures, and demonstrate\ntheir applications in compositional natural language processing.\n",
                "链接": "https://arxiv.org/abs/2212.06636"
            },
            {
                "文章ID": "68255",
                "标题": "Features matching using natural language processing",
                "作者": " Muhammad Danial Khilji",
                "发布日期": "2023-03-24",
                "摘要": "  The feature matching is a basic step in matching different datasets. This\narticle proposes shows a new hybrid model of a pretrained Natural Language\nProcessing (NLP) based model called BERT used in parallel with a statistical\nmodel based on Jaccard similarity to measure the similarity between list of\nfeatures from two different datasets. This reduces the time required to search\nfor correlations or manually match each feature from one dataset to another.\n",
                "链接": "https://arxiv.org/abs/2303.12804"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            },
            {
                "文章ID": "115729",
                "标题": "Natural Language Processing for Financial Regulation",
                "作者": " Ixandra Achitouv,  Dragos Gorduza,  Antoine Jacquier",
                "发布日期": "2023-11-16",
                "摘要": "  This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.\n",
                "链接": "https://arxiv.org/abs/2311.08533"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "72771",
                "标题": "Use of social media and Natural Language Processing (NLP) in natural\n  hazard research",
                "作者": " José Augusto Proença Maia Devienne",
                "发布日期": "2023-04-18",
                "摘要": "  Twitter is a microblogging service for sending short, public text messages\n(tweets) that has recently received more attention in scientific comunity. In\nthe works of Sasaki et al. (2010) and Earle et al., (2011) the authors explored\nthe real-time interaction on Twitter for detecting natural hazards (e.g.,\nearthquakes, typhoons) baed on users' tweets. An inherent challenge for such an\napplication is the natural language processing (NLP), which basically consists\nin converting the words in number (vectors and tensors) in order to\n(mathematically/ computationally) make predictions and classifications.\nRecently advanced computational tools have been made available for dealing with\ntext computationally. In this report we implement a NLP machine learning with\nTensorFlow, an end-to-end open source plataform for machine learning\napplications, to process and classify evenct based on files containing only\ntext.\n",
                "链接": "https://arxiv.org/abs/2304.08341"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "62616",
                "标题": "Time to Embrace Natural Language Processing (NLP)-based Digital\n  Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep\n  Learning Pipelines",
                "作者": " Min Cen,  Xingyu Li,  Bangwei Guo,  Jitendra Jonnagaddala,  Hong Zhang,  Xu Steven Xu",
                "发布日期": "2023-02-22",
                "摘要": "  NLP-based computer vision models, particularly vision transformers, have been\nshown to outperform CNN models in many imaging tasks. However, most digital\npathology artificial-intelligence models are based on CNN architectures,\nprobably owing to a lack of data regarding NLP models for pathology images. In\nthis study, we developed digital pathology pipelines to benchmark the five most\nrecently proposed NLP models (vision transformer (ViT), Swin Transformer,\nMobileViT, CMT, and Sequencer2D) and four popular CNN models (ResNet18,\nResNet50, MobileNetV2, and EfficientNet) to predict biomarkers in colorectal\ncancer (microsatellite instability, CpG island methylator phenotype, and BRAF\nmutation). Hematoxylin and eosin-stained whole-slide images from Molecular and\nCellular Oncology and The Cancer Genome Atlas were used as training and\nexternal validation datasets, respectively. Cross-study external validations\nrevealed that the NLP-based models significantly outperformed the CNN-based\nmodels in biomarker prediction tasks, improving the overall prediction and\nprecision up to approximately 10% and 26%, respectively. Notably, compared with\nexisting models in the current literature using large training datasets, our\nNLP models achieved state-of-the-art predictions for all three biomarkers using\na relatively small training dataset, suggesting that large training datasets\nare not a prerequisite for NLP models or transformers, and NLP may be more\nsuitable for clinical studies in which small training datasets are commonly\ncollected. The superior performance of Sequencer2D suggests that further\nresearch and innovation on both transformer and bidirectional long short-term\nmemory architectures are warranted in the field of digital pathology. NLP\nmodels can replace classic CNN architectures and become the new workhorse\nbackbone in the field of digital pathology.\n",
                "链接": "https://arxiv.org/abs/2302.10406"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            },
            {
                "文章ID": "17641",
                "标题": "Meta Learning for Natural Language Processing: A Survey",
                "作者": " Hung-yi Lee,  Shang-Wen Li,  Ngoc Thang Vu",
                "发布日期": "2022-07-05",
                "摘要": "  Deep learning has been the mainstream technique in natural language\nprocessing (NLP) area. However, the techniques require many labeled data and\nare less generalizable across domains. Meta-learning is an arising field in\nmachine learning studying approaches to learn better learning algorithms.\nApproaches aim at improving algorithms in various aspects, including data\nefficiency and generalizability. Efficacy of approaches has been shown in many\nNLP tasks, but there is no systematic survey of these approaches in NLP, which\nhinders more researchers from joining the field. Our goal with this survey\npaper is to offer researchers pointers to relevant meta-learning works in NLP\nand attract more attention from the NLP community to drive future innovation.\nThis paper first introduces the general concepts of meta-learning and the\ncommon approaches. Then we summarize task construction settings and application\nof meta-learning for various NLP problems and review the development of\nmeta-learning in NLP community.\n",
                "链接": "https://arxiv.org/abs/2205.01500"
            },
            {
                "文章ID": "24559",
                "标题": "Computational linguistics and Natural Language Processing",
                "作者": " Saturnino Luz",
                "发布日期": "2022-06-15",
                "摘要": "  This chapter provides an introduction to computational linguistics methods,\nwith focus on their applications to the practice and study of translation. It\ncovers computational models, methods and tools for collection, storage,\nindexing and analysis of linguistic data in the context of translation, and\ndiscusses the main methodological issues and challenges in this field. While an\nexhaustive review of existing computational linguistics methods and tools is\nbeyond the scope of this chapter, we describe the most representative\napproaches, and illustrate them with descriptions of typical applications.\n",
                "链接": "https://arxiv.org/abs/2206.07026"
            },
            {
                "文章ID": "53444",
                "标题": "Categorical Tools for Natural Language Processing",
                "作者": " Giovanni de Felice",
                "发布日期": "2022-12-14",
                "摘要": "  This thesis develops the translation between category theory and\ncomputational linguistics as a foundation for natural language processing. The\nthree chapters deal with syntax, semantics and pragmatics. First, string\ndiagrams provide a unified model of syntactic structures in formal grammars.\nSecond, functors compute semantics by turning diagrams into logical, tensor,\nneural or quantum computation. Third, the resulting functorial models can be\ncomposed to form games where equilibria are the solutions of language\nprocessing tasks. This framework is implemented as part of DisCoPy, the Python\nlibrary for computing with string diagrams. We describe the correspondence\nbetween categorical, linguistic and computational structures, and demonstrate\ntheir applications in compositional natural language processing.\n",
                "链接": "https://arxiv.org/abs/2212.06636"
            },
            {
                "文章ID": "68255",
                "标题": "Features matching using natural language processing",
                "作者": " Muhammad Danial Khilji",
                "发布日期": "2023-03-24",
                "摘要": "  The feature matching is a basic step in matching different datasets. This\narticle proposes shows a new hybrid model of a pretrained Natural Language\nProcessing (NLP) based model called BERT used in parallel with a statistical\nmodel based on Jaccard similarity to measure the similarity between list of\nfeatures from two different datasets. This reduces the time required to search\nfor correlations or manually match each feature from one dataset to another.\n",
                "链接": "https://arxiv.org/abs/2303.12804"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "72313",
                "标题": "Evaluation of Social Biases in Recent Large Pre-Trained Models",
                "作者": " Swapnil Sharma,  Nikita Anand,  Kranthi Kiran G. V.,  Alind Jain",
                "发布日期": "2023-04-17",
                "摘要": "  Large pre-trained language models are widely used in the community. These\nmodels are usually trained on unmoderated and unfiltered data from open sources\nlike the Internet. Due to this, biases that we see in platforms online which\nare a reflection of those in society are in turn captured and learned by these\nmodels. These models are deployed in applications that affect millions of\npeople and their inherent biases are harmful to the targeted social groups. In\nthis work, we study the general trend in bias reduction as newer pre-trained\nmodels are released. Three recent models ( ELECTRA, DeBERTa, and DistilBERT)\nare chosen and evaluated against two bias benchmarks, StereoSet and\nCrowS-Pairs. They are compared to the baseline of BERT using the associated\nmetrics. We explore whether as advancements are made and newer, faster, lighter\nmodels are released: are they being developed responsibly such that their\ninherent social biases have been reduced compared to their older counterparts?\nThe results are compiled and we find that all the models under study do exhibit\nbiases but have generally improved as compared to BERT.\n",
                "链接": "https://arxiv.org/abs/2304.06861"
            },
            {
                "文章ID": "72848",
                "标题": "An Evaluation on Large Language Model Outputs: Discourse and\n  Memorization",
                "作者": " Adrian de Wynter,  Xun Wang,  Alex Sokolov,  Qilong Gu,  Si-Qing Chen",
                "发布日期": "2023-07-06",
                "摘要": "  We present an empirical evaluation of various outputs generated by nine of\nthe most widely-available large language models (LLMs). Our analysis is done\nwith off-the-shelf, readily-available tools. We find a correlation between\npercentage of memorized text, percentage of unique text, and overall output\nquality, when measured with respect to output pathologies such as\ncounterfactual and logically-flawed statements, and general failures like not\nstaying on topic. Overall, 80.0% of the outputs evaluated contained memorized\ndata, but outputs containing the most memorized content were also more likely\nto be considered of high quality. We discuss and evaluate mitigation\nstrategies, showing that, in the models evaluated, the rate of memorized text\nbeing output is reduced. We conclude with a discussion on potential\nimplications around what it means to learn, to memorize, and to evaluate\nquality text.\n",
                "链接": "https://arxiv.org/abs/2304.08637"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "104015",
                "标题": "EvalLM: Interactive Evaluation of Large Language Model Prompts on\n  User-Defined Criteria",
                "作者": " Tae Soo Kim,  Yoonjoo Lee,  Jamin Shin,  Young-Ho Kim,  Juho Kim",
                "发布日期": "2023-09-26",
                "摘要": "  By simply composing prompts, developers can prototype novel generative\napplications with Large Language Models (LLMs). To refine prototypes into\nproducts, however, developers must iteratively revise prompts by evaluating\noutputs to diagnose weaknesses. Formative interviews (N=8) revealed that\ndevelopers invest significant effort in manually evaluating outputs as they\nassess context-specific and subjective criteria. We present EvalLM, an\ninteractive system for iteratively refining prompts by evaluating multiple\noutputs on user-defined criteria. By describing criteria in natural language,\nusers can employ the system's LLM-based evaluator to get an overview of where\nprompts excel or fail, and improve these based on the evaluator's feedback. A\ncomparative study (N=12) showed that EvalLM, when compared to manual\nevaluation, helped participants compose more diverse criteria, examine twice as\nmany outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond\nprompts, our work can be extended to augment model evaluation and alignment in\nspecific application contexts.\n",
                "链接": "https://arxiv.org/abs/2309.13633"
            },
            {
                "文章ID": "123877",
                "标题": "A Performance Evaluation of a Quantized Large Language Model on Various\n  Smartphones",
                "作者": "Haltia, Inc.  Tolga Çöplü, Haltia, Inc.  Marc Loedi, Haltia, Inc.  Arto Bendiken, Haltia, Inc.  Mykhailo Makohin, Haltia, Inc.  Joshua J. Bouw, Haltia, Inc.  Stephen Cobb",
                "发布日期": "2023-12-21",
                "摘要": "  This paper explores the feasibility and performance of on-device large\nlanguage model (LLM) inference on various Apple iPhone models. Amidst the rapid\nevolution of generative AI, on-device LLMs offer solutions to privacy,\nsecurity, and connectivity challenges inherent in cloud-based models.\nLeveraging existing literature on running multi-billion parameter LLMs on\nresource-limited devices, our study examines the thermal effects and\ninteraction speeds of a high-performing LLM across different smartphone\ngenerations. We present real-world performance results, providing insights into\non-device inference capabilities.\n",
                "链接": "https://arxiv.org/abs/2312.12472"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "97463",
                "标题": "Can Large Language Models Find And Fix Vulnerable Software?",
                "作者": " David Noever",
                "发布日期": "2023-08-22",
                "摘要": "  In this study, we evaluated the capability of Large Language Models (LLMs),\nparticularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing\ntheir performance against traditional static code analyzers like Snyk and\nFortify. Our analysis covered numerous repositories, including those from NASA\nand the Department of Defense. GPT-4 identified approximately four times the\nvulnerabilities than its counterparts. Furthermore, it provided viable fixes\nfor each vulnerability, demonstrating a low rate of false positives. Our tests\nencompassed 129 code samples across eight programming languages, revealing the\nhighest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to\na 90% reduction in vulnerabilities, requiring only an 11% increase in code\nlines. A critical insight was LLMs' ability to self-audit, suggesting fixes for\ntheir identified vulnerabilities and underscoring their precision. Future\nresearch should explore system-level vulnerabilities and integrate multiple\nstatic code analyzers for a holistic perspective on LLMs' potential.\n",
                "链接": "https://arxiv.org/abs/2308.10345"
            },
            {
                "文章ID": "77817",
                "标题": "About Evaluation of F1 Score for RECENT Relation Extraction System",
                "作者": " Michał Olek",
                "发布日期": "2023-05-17",
                "摘要": "  This document contains a discussion of the F1 score evaluation used in the\narticle 'Relation Classification with Entity Type Restriction' by Shengfei Lyu,\nHuanhuan Chen published on Findings of the Association for Computational\nLinguistics: ACL-IJCNLP 2021. The authors created a system named RECENT and\nclaim it achieves (then) a new state-of-the-art result 75.2 (previous 74.8) on\nthe TACRED dataset, while after correcting errors and reevaluation the final\nresult is 65.16\n",
                "链接": "https://arxiv.org/abs/2305.09410"
            },
            {
                "文章ID": "86800",
                "标题": "Comparative Evaluation of Recent Universal Adversarial Perturbations in\n  Image Classification",
                "作者": " Juanjuan Weng,  Zhiming Luo,  Dazhen Lin,  Shaozi Li",
                "发布日期": "2023-06-21",
                "摘要": "  The vulnerability of Convolutional Neural Networks (CNNs) to adversarial\nsamples has recently garnered significant attention in the machine learning\ncommunity. Furthermore, recent studies have unveiled the existence of universal\nadversarial perturbations (UAPs) that are image-agnostic and highly\ntransferable across different CNN models. In this survey, our primary focus\nrevolves around the recent advancements in UAPs specifically within the image\nclassification task. We categorize UAPs into two distinct categories, i.e.,\nnoise-based attacks and generator-based attacks, thereby providing a\ncomprehensive overview of representative methods within each category. By\npresenting the computational details of these methods, we summarize various\nloss functions employed for learning UAPs. Furthermore, we conduct a\ncomprehensive evaluation of different loss functions within consistent training\nframeworks, including noise-based and generator-based. The evaluation covers a\nwide range of attack settings, including black-box and white-box attacks,\ntargeted and untargeted attacks, as well as the examination of defense\nmechanisms.\n  Our quantitative evaluation results yield several important findings\npertaining to the effectiveness of different loss functions, the selection of\nsurrogate CNN models, the impact of training data and data size, and the\ntraining frameworks involved in crafting universal attackers. Finally, to\nfurther promote future research on universal adversarial attacks, we provide\nsome visualizations of the perturbations and discuss the potential research\ndirections.\n",
                "链接": "https://arxiv.org/abs/2306.11261"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "118185",
                "标题": "SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume\n  Registration",
                "作者": " Weixun Luo,  Alexandre Triay Bagur,  Paul Aljabar,  George Ralli,  Sir Michael Brady",
                "发布日期": "2023-11-28",
                "摘要": "  Background and Objective: The lack of benchmark datasets has impeded the\ndevelopment of slice-to-volume registration algorithms. Such datasets are\ndifficult to annotate, primarily due to the dimensional difference within data\nand the dearth of task-specific software. We aim to develop a user-friendly\ntool to streamline dataset annotation for slice-to-volume registration.\n  Methods: The proposed tool, named SVRDA, is an installation-free web\napplication for platform-agnostic collaborative dataset annotation. It enables\nefficient transformation manipulation via keyboard shortcuts and smooth case\ntransitions with auto-saving. SVRDA supports configuration-based data loading\nand adheres to the separation of concerns, offering great flexibility and\nextensibility for future research. Various supplementary features have been\nimplemented to facilitate slice-to-volume registration.\n  Results: We validated the effectiveness of SVRDA by indirectly evaluating the\npost-registration segmentation quality on UK Biobank data, observing a dramatic\noverall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in\nthe 95th percentile Hausdorff distance, respectively) supported by highly\nstatistically significant evidence ($p<0.001$).We further showcased the\nclinical usage of SVRDA by integrating it into test-retest T1 quantification on\nin-house magnetic resonance images, leading to more consistent results after\nregistration.\n  Conclusions: SVRDA can facilitate collaborative annotation of benchmark\ndatasets while being potentially applicable to other pipelines incorporating\nslice-to-volume registration. Full source code and documentation are available\nat https://github.com/Roldbach/SVRDA\n",
                "链接": "https://arxiv.org/abs/2311.15536"
            },
            {
                "文章ID": "122009",
                "标题": "CholecTrack20: A Dataset for Multi-Class Multiple Tool Tracking in\n  Laparoscopic Surgery",
                "作者": " Chinedu Innocent Nwoye,  Kareem Elgohary,  Anvita Srinivas,  Fauzan Zaid,  Joël L. Lavanchy,  Nicolas Padoy",
                "发布日期": "2023-12-13",
                "摘要": "  Tool tracking in surgical videos is vital in computer-assisted intervention\nfor tasks like surgeon skill assessment, safety zone estimation, and\nhuman-machine collaboration during minimally invasive procedures. The lack of\nlarge-scale datasets hampers Artificial Intelligence implementation in this\ndomain. Current datasets exhibit overly generic tracking formalization, often\nlacking surgical context: a deficiency that becomes evident when tools move out\nof the camera's scope, resulting in rigid trajectories that hinder realistic\nsurgical representation. This paper addresses the need for a more precise and\nadaptable tracking formalization tailored to the intricacies of endoscopic\nprocedures by introducing CholecTrack20, an extensive dataset meticulously\nannotated for multi-class multi-tool tracking across three perspectives\nrepresenting the various ways of considering the temporal duration of a tool\ntrajectory: (1) intraoperative, (2) intracorporeal, and (3) visibility within\nthe camera's scope. The dataset comprises 20 laparoscopic videos with over\n35,000 frames and 65,000 annotated tool instances with details on spatial\nlocation, category, identity, operator, phase, and surgical visual conditions.\nThis detailed dataset caters to the evolving assistive requirements within a\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2312.07352"
            },
            {
                "文章ID": "124110",
                "标题": "Position Paper: Bridging the Gap Between Machine Learning and\n  Sensitivity Analysis",
                "作者": " Christian A. Scholbeck,  Julia Moosbauer,  Giuseppe Casalicchio,  Hoshin Gupta,  Bernd Bischl,  Christian Heumann",
                "发布日期": "2023-12-21",
                "摘要": "  We argue that interpretations of machine learning (ML) models or the\nmodel-building process can bee seen as a form of sensitivity analysis (SA), a\ngeneral methodology used to explain complex systems in many fields such as\nenvironmental modeling, engineering, or economics. We address both researchers\nand practitioners, calling attention to the benefits of a unified SA-based view\nof explanations in ML and the necessity to fully credit related work. We bridge\nthe gap between both fields by formally describing how (a) the ML process is a\nsystem suitable for SA, (b) how existing ML interpretation methods relate to\nthis perspective, and (c) how other SA techniques could be applied to ML.\n",
                "链接": "https://arxiv.org/abs/2312.13234"
            },
            {
                "文章ID": "117713",
                "标题": "Brain MRI Screening Tool with Federated Learning",
                "作者": " Roman Stoklasa,  Ioannis Stathopoulos,  Efstratios Karavasilis,  Efstathios Efstathopoulos,  Marek Dostál,  Miloš Keřkovský,  Michal Kozubek,  Luigi Serio",
                "发布日期": "2023-11-27",
                "摘要": "  In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.\n",
                "链接": "https://arxiv.org/abs/2311.14086"
            },
            {
                "文章ID": "123368",
                "标题": "Position Paper on Materials Design -- A Modern Approach",
                "作者": " Willi Grossmann,  Sebastian Eilermann,  Tim Rensmeyer,  Artur Liebert,  Michael Hohmann,  Christian Wittke,  Oliver Niggemann",
                "发布日期": "2023-12-19",
                "摘要": "  Traditional design cycles for new materials and assemblies have two\nfundamental drawbacks. The underlying physical relationships are often too\ncomplex to be precisely calculated and described. Aside from that, many unknown\nuncertainties, such as exact manufacturing parameters or materials composition,\ndominate the real assembly behavior. Machine learning (ML) methods overcome\nthese fundamental limitations through data-driven learning. In addition, modern\napproaches can specifically increase system knowledge. Representation Learning\nallows the physical, and if necessary, even symbolic interpretation of the\nlearned solution. In this way, the most complex physical relationships can be\nconsidered and quickly described. Furthermore, generative ML approaches can\nsynthesize possible morphologies of the materials based on defined conditions\nto visualize the effects of uncertainties. This modern approach accelerates the\ndesign process for new materials and enables the prediction and interpretation\nof realistic materials behavior.\n",
                "链接": "https://arxiv.org/abs/2312.10996"
            },
            {
                "文章ID": "80551",
                "标题": "SPRING: Studying the Paper and Reasoning to Play Games",
                "作者": " Yue Wu,  Shrimai Prabhumoye,  So Yeon Min,  Yonatan Bisk,  Ruslan Salakhutdinov,  Amos Azaria,  Tom Mitchell,  Yuanzhi Li",
                "发布日期": "2023-12-13",
                "摘要": "  Open-world survival games pose significant challenges for AI algorithms due\nto their multi-tasking, deep exploration, and goal prioritization requirements.\nDespite reinforcement learning (RL) being popular for solving games, its high\nsample complexity limits its effectiveness in complex open-world games like\nCrafter or Minecraft. We propose a novel approach, SPRING, to read the game's\noriginal academic paper and use the knowledge learned to reason and play the\ngame through a large language model (LLM). Prompted with the LaTeX source as\ngame context and a description of the agent's current observation, our SPRING\nframework employs a directed acyclic graph (DAG) with game-related questions as\nnodes and dependencies as edges. We identify the optimal action to take in the\nenvironment by traversing the DAG and calculating LLM responses for each node\nin topological order, with the LLM's answer to final node directly translating\nto environment actions. In our experiments, we study the quality of in-context\n\"reasoning\" induced by different forms of prompts under the setting of the\nCrafter open-world environment. Our experiments suggest that LLMs, when\nprompted with consistent chain-of-thought, have great potential in completing\nsophisticated high-level trajectories. Quantitatively, SPRING with GPT-4\noutperforms all state-of-the-art RL baselines, trained for 1M steps, without\nany training. Finally, we show the potential of games as a test bed for LLMs.\n",
                "链接": "https://arxiv.org/abs/2305.15486"
            },
            {
                "文章ID": "116300",
                "标题": "The Song Describer Dataset: a Corpus of Audio Captions for\n  Music-and-Language Evaluation",
                "作者": " Ilaria Manco,  Benno Weck,  SeungHeon Doh,  Minz Won,  Yixiao Zhang,  Dmitry Bogdanov,  Yusong Wu,  Ke Chen,  Philip Tovstogan,  Emmanouil Benetos,  Elio Quinton,  György Fazekas,  Juhan Nam",
                "发布日期": "2023-11-27",
                "摘要": "  We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of\nhigh-quality audio-caption pairs, designed for the evaluation of\nmusic-and-language models. The dataset consists of 1.1k human-written natural\nlanguage descriptions of 706 music recordings, all publicly accessible and\nreleased under Creative Common licenses. To showcase the use of our dataset, we\nbenchmark popular models on three key music-and-language tasks (music\ncaptioning, text-to-music generation and music-language retrieval). Our\nexperiments highlight the importance of cross-dataset evaluation and offer\ninsights into how researchers can use SDD to gain a broader understanding of\nmodel performance.\n",
                "链接": "https://arxiv.org/abs/2311.10057"
            },
            {
                "文章ID": "121559",
                "标题": "MATK: The Meme Analytical Tool Kit",
                "作者": " Ming Shan Hee,  Aditi Kumaresan,  Nguyen Khoi Hoang,  Nirmalendu Prakash,  Rui Cao,  Roy Ka-Wei Lee",
                "发布日期": "2023-12-12",
                "摘要": "  The rise of social media platforms has brought about a new digital culture\ncalled memes. Memes, which combine visuals and text, can strongly influence\npublic opinions on social and cultural issues. As a result, people have become\ninterested in categorizing memes, leading to the development of various\ndatasets and multimodal models that show promising results in this field.\nHowever, there is currently a lack of a single library that allows for the\nreproduction, evaluation, and comparison of these models using fair benchmarks\nand settings. To fill this gap, we introduce the Meme Analytical Tool Kit\n(MATK), an open-source toolkit specifically designed to support existing memes\ndatasets and cutting-edge multimodal models. MATK aims to assist researchers\nand engineers in training and reproducing these multimodal models for meme\nclassification tasks, while also providing analysis techniques to gain insights\ninto their strengths and weaknesses. To access MATK, please visit\n\\url{https://github.com/Social-AI-Studio/MATK}.\n",
                "链接": "https://arxiv.org/abs/2312.06094"
            },
            {
                "文章ID": "123110",
                "标题": "ProTIP: Progressive Tool Retrieval Improves Planning",
                "作者": " Raviteja Anantha,  Bortik Bandyopadhyay,  Anirudh Kashi,  Sayantan Mahinder,  Andrew W Hill,  Srinivas Chappidi",
                "发布日期": "2023-12-19",
                "摘要": "  Large language models (LLMs) are increasingly employed for complex multi-step\nplanning tasks, where the tool retrieval (TR) step is crucial for achieving\nsuccessful outcomes. Two prevalent approaches for TR are single-step retrieval,\nwhich utilizes the complete query, and sequential retrieval using task\ndecomposition (TD), where a full query is segmented into discrete atomic\nsubtasks. While single-step retrieval lacks the flexibility to handle\n\"inter-tool dependency,\" the TD approach necessitates maintaining \"subtask-tool\natomicity alignment,\" as the toolbox can evolve dynamically. To address these\nlimitations, we introduce the Progressive Tool retrieval to Improve Planning\n(ProTIP) framework. ProTIP is a lightweight, contrastive learning-based\nframework that implicitly performs TD without the explicit requirement of\nsubtask labels, while simultaneously maintaining subtask-tool atomicity. On the\nToolBench dataset, ProTIP outperforms the ChatGPT task decomposition-based\napproach by a remarkable margin, achieving a 24% improvement in Recall@K=10 for\nTR and a 41% enhancement in tool accuracy for plan generation.\n",
                "链接": "https://arxiv.org/abs/2312.10332"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "17244",
                "标题": "SciEv: Finding Scientific Evidence Papers for Scientific News",
                "作者": " Md Reshad Ul Hoque,  Jiang Li,  Jian Wu",
                "发布日期": "2022-05-03",
                "摘要": "  In the past decade, many scientific news media that report scientific\nbreakthroughs and discoveries emerged, bringing science and technology closer\nto the general public. However, not all scientific news article cites proper\nsources, such as original scientific papers. A portion of scientific news\narticles contain misinterpreted, exaggerated, or distorted information that\ndeviates from facts asserted in the original papers. Manually identifying\nproper citations is laborious and costly. Therefore, it is necessary to\nautomatically search for pertinent scientific papers that could be used as\nevidence for a given piece of scientific news. We propose a system called SciEv\nthat searches for scientific evidence papers given a scientific news article.\nThe system employs a 2-stage query paradigm with the first stage retrieving\ncandidate papers and the second stage reranking them. The key feature of SciEv\nis it uses domain knowledge entities (DKEs) to find candidates in the first\nstage, which proved to be more effective than regular keyphrases. In the\nreranking stage, we explore different document representations for news\narticles and candidate papers. To evaluate our system, we compiled a pilot\ndataset consisting of 100 manually curated (news,paper) pairs from ScienceAlert\nand similar websites. To our best knowledge, this is the first dataset of this\nkind. Our experiments indicate that the transformer model performs the best for\nDKE extraction. The system achieves a P@1=50%, P@5=71%, and P@10=74% when it\nuses a TFIDF-based text representation. The transformer-based re-ranker\nachieves a comparable performance but costs twice as much time. We will collect\nmore data and test the system for user experience.\n",
                "链接": "https://arxiv.org/abs/2205.00126"
            },
            {
                "文章ID": "86386",
                "标题": "TOBY: A Tool for Exploring Data in Academic Survey Papers",
                "作者": " Tathagata Chakraborti,  Jungkoo Kang,  Christian Muise,  Sarath Sreedharan,  Michael Walker,  Daniel Szafir,  Tom Williams",
                "发布日期": "2023-06-21",
                "摘要": "  This paper describes TOBY, a visualization tool that helps a user explore the\ncontents of an academic survey paper. The visualization consists of four\ncomponents: a hierarchical view of taxonomic data in the survey, a document\nsimilarity view in the space of taxonomic classes, a network view of citations,\nand a new paper recommendation tool. In this paper, we will discuss these\nfeatures in the context of three separate deployments of the tool.\n",
                "链接": "https://arxiv.org/abs/2306.10051"
            },
            {
                "文章ID": "34033",
                "标题": "SimLDA: A tool for topic model evaluation",
                "作者": " Rebecca M. C. Taylor,  Johan A. du Preez",
                "发布日期": "2022-08-22",
                "摘要": "  Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has\nbecome the most popular algorithm for aspect modeling. While sufficiently\nsuccessful in text topic extraction from large corpora, VB is less successful\nin identifying aspects in the presence of limited data. We present a novel\nvariational message passing algorithm as applied to Latent Dirichlet Allocation\n(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In\nsituations where marginalisation leads to non-conjugate messages, we use ideas\nfrom sampling to derive approximate update equations. In cases where conjugacy\nholds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is\nused. Our algorithm, ALBU (approximate LBU), has strong similarities with\nVariational Message Passing (VMP) (which is the message passing variant of VB).\nTo compare the performance of the algorithms in the presence of limited data,\nwe use data sets consisting of tweets and news groups. Using coherence measures\nwe show that ALBU learns latent distributions more accurately than does VB,\nespecially for smaller data sets.\n",
                "链接": "https://arxiv.org/abs/2208.09299"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "25887",
                "标题": "Diagnostic Tool for Out-of-Sample Model Evaluation",
                "作者": " Ludvig Hult,  Dave Zachariah,  Petre Stoica",
                "发布日期": "2023-10-17",
                "摘要": "  Assessment of model fitness is a key part of machine learning. The standard\nparadigm is to learn models by minimizing a chosen loss function averaged over\ntraining data, with the aim of achieving small losses on future data. In this\npaper, we consider the use of a finite calibration data set to characterize the\nfuture, out-of-sample losses of a model. We propose a simple model diagnostic\ntool that provides finite-sample guarantees under weak assumptions. The tool is\nsimple to compute and to interpret. Several numerical experiments are presented\nto show how the proposed method quantifies the impact of distribution shifts,\naids the analysis of regression, and enables model selection as well as\nhyper-parameter tuning.\n",
                "链接": "https://arxiv.org/abs/2206.10982"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "18767",
                "标题": "ALIGNMEET: A Comprehensive Tool for Meeting Annotation, Alignment, and\n  Evaluation",
                "作者": " Peter Polák,  Muskaan Singh,  Anna Nedoluzhko,  Ondřej Bojar",
                "发布日期": "2022-05-12",
                "摘要": "  Summarization is a challenging problem, and even more challenging is to\nmanually create, correct, and evaluate the summaries. The severity of the\nproblem grows when the inputs are multi-party dialogues in a meeting setup. To\nfacilitate the research in this area, we present ALIGNMEET, a comprehensive\ntool for meeting annotation, alignment, and evaluation. The tool aims to\nprovide an efficient and clear interface for fast annotation while mitigating\nthe risk of introducing errors. Moreover, we add an evaluation mode that\nenables a comprehensive quality evaluation of meeting minutes. To the best of\nour knowledge, there is no such tool available. We release the tool as open\nsource. It is also directly installable from PyPI.\n",
                "链接": "https://arxiv.org/abs/2205.05433"
            },
            {
                "文章ID": "88457",
                "标题": "CORAE: A Tool for Intuitive and Continuous Retrospective Evaluation of\n  Interactions",
                "作者": " Michael J. Sack,  Maria Teresa Parreira,  Jenny Fu,  Asher Lipman,  Hifza Javed,  Nawid Jamali,  Malte Jung",
                "发布日期": "2023-06-30",
                "摘要": "  This paper introduces CORAE, a novel web-based open-source tool for\nCOntinuous Retrospective Affect Evaluation, designed to capture continuous\naffect data about interpersonal perceptions in dyadic interactions. Grounded in\nbehavioral ecology perspectives of emotion, this approach replaces valence as\nthe relevant rating dimension with approach and withdrawal, reflecting the\ndegree to which behavior is perceived as increasing or decreasing social\ndistance. We conducted a study to experimentally validate the efficacy of our\nplatform with 24 participants. The tool's effectiveness was tested in the\ncontext of dyadic negotiation, revealing insights about how interpersonal\ndynamics evolve over time. We find that the continuous affect rating method is\nconsistent with individuals' perception of the overall interaction. This paper\ncontributes to the growing body of research on affective computing and offers a\nvaluable tool for researchers interested in investigating the temporal dynamics\nof affect and emotion in social interactions.\n",
                "链接": "https://arxiv.org/abs/2306.16629"
            },
            {
                "文章ID": "5122",
                "标题": "Deep soccer captioning with transformer: dataset, semantics-related\n  losses, and multi-level evaluation",
                "作者": " Ahmad Hammoudeh,  Bastien Vanderplaetse,  Stéphane Dupont",
                "发布日期": "2022-12-01",
                "摘要": "  This work aims at generating captions for soccer videos using deep learning.\nIn this context, this paper introduces a dataset, model, and triple-level\nevaluation. The dataset consists of 22k caption-clip pairs and three visual\nfeatures (images, optical flow, inpainting) for ~500 hours of \\emph{SoccerNet}\nvideos. The model is divided into three parts: a transformer learns language,\nConvNets learn vision, and a fusion of linguistic and visual features generates\ncaptions. The paper suggests evaluating generated captions at three levels:\nsyntax (the commonly used evaluation metrics such as BLEU-score and CIDEr),\nmeaning (the quality of descriptions for a domain expert), and corpus (the\ndiversity of generated captions). The paper shows that the diversity of\ngenerated captions has improved (from 0.07 reaching 0.18) with\nsemantics-related losses that prioritize selected words. Semantics-related\nlosses and the utilization of more visual features (optical flow, inpainting)\nimproved the normalized captioning score by 28\\%. The web page of this work:\nhttps://sites.google.com/view/soccercaptioning}{https://sites.google.com/view/soccercaptioning\n",
                "链接": "https://arxiv.org/abs/2202.05728"
            },
            {
                "文章ID": "33437",
                "标题": "ELEVANT: A Fully Automatic Fine-Grained Entity Linking Evaluation and\n  Analysis Tool",
                "作者": " Hannah Bast,  Matthias Hertel,  Natalie Prange",
                "发布日期": "2022-08-16",
                "摘要": "  We present Elevant, a tool for the fully automatic fine-grained evaluation of\na set of entity linkers on a set of benchmarks. Elevant provides an automatic\nbreakdown of the performance by various error categories and by entity type.\nElevant also provides a rich and compact, yet very intuitive and\nself-explanatory visualization of the results of a linker on a benchmark in\ncomparison to the ground truth. A live demo, the link to the complete code base\non GitHub and a link to a demo video are provided under\nhttps://elevant.cs.uni-freiburg.de .\n",
                "链接": "https://arxiv.org/abs/2208.07193"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "123368",
                "标题": "Position Paper on Materials Design -- A Modern Approach",
                "作者": " Willi Grossmann,  Sebastian Eilermann,  Tim Rensmeyer,  Artur Liebert,  Michael Hohmann,  Christian Wittke,  Oliver Niggemann",
                "发布日期": "2023-12-19",
                "摘要": "  Traditional design cycles for new materials and assemblies have two\nfundamental drawbacks. The underlying physical relationships are often too\ncomplex to be precisely calculated and described. Aside from that, many unknown\nuncertainties, such as exact manufacturing parameters or materials composition,\ndominate the real assembly behavior. Machine learning (ML) methods overcome\nthese fundamental limitations through data-driven learning. In addition, modern\napproaches can specifically increase system knowledge. Representation Learning\nallows the physical, and if necessary, even symbolic interpretation of the\nlearned solution. In this way, the most complex physical relationships can be\nconsidered and quickly described. Furthermore, generative ML approaches can\nsynthesize possible morphologies of the materials based on defined conditions\nto visualize the effects of uncertainties. This modern approach accelerates the\ndesign process for new materials and enables the prediction and interpretation\nof realistic materials behavior.\n",
                "链接": "https://arxiv.org/abs/2312.10996"
            },
            {
                "文章ID": "27917",
                "标题": "A Dataset on Malicious Paper Bidding in Peer Review",
                "作者": " Steven Jecmen,  Minji Yoon,  Vincent Conitzer,  Nihar B. Shah,  Fei Fang",
                "发布日期": "2023-03-14",
                "摘要": "  In conference peer review, reviewers are often asked to provide \"bids\" on\neach submitted paper that express their interest in reviewing that paper. A\npaper assignment algorithm then uses these bids (along with other data) to\ncompute a high-quality assignment of reviewers to papers. However, this process\nhas been exploited by malicious reviewers who strategically bid in order to\nunethically manipulate the paper assignment, crucially undermining the peer\nreview process. For example, these reviewers may aim to get assigned to a\nfriend's paper as part of a quid-pro-quo deal. A critical impediment towards\ncreating and evaluating methods to mitigate this issue is the lack of any\npublicly-available data on malicious paper bidding. In this work, we collect\nand publicly release a novel dataset to fill this gap, collected from a mock\nconference activity where participants were instructed to bid either honestly\nor maliciously. We further provide a descriptive analysis of the bidding\nbehavior, including our categorization of different strategies employed by\nparticipants. Finally, we evaluate the ability of each strategy to manipulate\nthe assignment, and also evaluate the performance of some simple algorithms\nmeant to detect malicious bidding. The performance of these detection\nalgorithms can be taken as a baseline for future research on detecting\nmalicious bidding.\n",
                "链接": "https://arxiv.org/abs/2207.02303"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "81863",
                "标题": "Taming AI Bots: Controllability of Neural States in Large Language\n  Models",
                "作者": " Stefano Soatto,  Paulo Tabuada,  Pratik Chaudhari,  Tian Yu Liu",
                "发布日期": "2023-05-31",
                "摘要": "  We tackle the question of whether an agent can, by suitable choice of\nprompts, control an AI bot to any state. To that end, we first introduce a\nformal definition of ``meaning'' that is amenable to analysis. Then, we\ncharacterize ``meaningful data'' on which large language models (LLMs) are\nostensibly trained, and ``well-trained LLMs'' through conditions that are\nlargely met by today's LLMs. While a well-trained LLM constructs an embedding\nspace of meanings that is Euclidean, meanings themselves do not form a vector\n(linear) subspace, but rather a quotient space within. We then characterize the\nsubset of meanings that can be reached by the state of the LLMs for some input\nprompt, and show that a well-trained bot can reach any meaning albeit with\nsmall probability. We then introduce a stronger notion of controllability as\n{\\em almost certain reachability}, and show that, when restricted to the space\nof meanings, an AI bot is controllable. We do so after introducing a functional\ncharacterization of attentive AI bots, and finally derive necessary and\nsufficient conditions for controllability. The fact that AI bots are\ncontrollable means that an adversary could steer them towards any state.\nHowever, the sampling process can be designed to counteract adverse actions and\navoid reaching undesirable regions of state space before their boundary is\ncrossed.\n",
                "链接": "https://arxiv.org/abs/2305.18449"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "95351",
                "标题": "Auditory Attention Decoding with Task-Related Multi-View Contrastive\n  Learning",
                "作者": " Xiaoyu Chen,  Changde Du,  Qiongyi Zhou,  Huiguang He",
                "发布日期": "2023-08-09",
                "摘要": "  The human brain can easily focus on one speaker and suppress others in\nscenarios such as a cocktail party. Recently, researchers found that auditory\nattention can be decoded from the electroencephalogram (EEG) data. However,\nmost existing deep learning methods are difficult to use prior knowledge of\ndifferent views (that is attended speech and EEG are task-related views) and\nextract an unsatisfactory representation. Inspired by Broadbent's filter model,\nwe decode auditory attention in a multi-view paradigm and extract the most\nrelevant and important information utilizing the missing view. Specifically, we\npropose an auditory attention decoding (AAD) method based on multi-view VAE\nwith task-related multi-view contrastive (TMC) learning. Employing TMC learning\nin multi-view VAE can utilize the missing view to accumulate prior knowledge of\ndifferent views into the fusion of representation, and extract the approximate\ntask-related representation. We examine our method on two popular AAD datasets,\nand demonstrate the superiority of our method by comparing it to the\nstate-of-the-art method.\n",
                "链接": "https://arxiv.org/abs/2308.04244"
            },
            {
                "文章ID": "53554",
                "标题": "Decoding Multi-class Motor-related Intentions with User-optimized and\n  Robust BCI System Based on Multimodal Dataset",
                "作者": " Jeong-Hyun Cho,  Byoung-Hee Kwon,  Byeong-Hoo Lee",
                "发布日期": "2022-12-15",
                "摘要": "  A brain-computer interface (BCI) based on electroencephalography (EEG) can be\nuseful for rehabilitation and the control of external devices. Five grasping\ntasks were decoded for motor execution (ME) and motor imagery (MI). During this\nexperiment, eight healthy subjects were asked to imagine and grasp five\nobjects. Analysis of EEG signals was performed after detecting muscle signals\non electromyograms (EMG) with a time interval selection technique on data taken\nfrom these ME and MI experiments. By refining only data corresponding to the\nexact time when the users performed the motor intention, the proposed method\ncan train the decoding model using only the EEG data generated by various motor\nintentions with strong correlation with a specific class. There was an accuracy\nof 70.73% for ME and 47.95% for MI for the five offline tasks. This method may\nbe applied to future applications, such as controlling robot hands with BCIs.\n",
                "链接": "https://arxiv.org/abs/2212.07083"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "5419",
                "标题": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
                "作者": " Federico Ruggeri,  Mohsen Mesgar,  Iryna Gurevych",
                "发布日期": "2022-10-14",
                "摘要": "  The applications of conversational agents for scientific disciplines (as\nexpert domains) are understudied due to the lack of dialogue data to train such\nagents. While most data collection frameworks, such as Amazon Mechanical Turk,\nfoster data collection for generic domains by connecting crowd workers and task\ndesigners, these frameworks are not much optimized for data collection in\nexpert domains. Scientists are rarely present in these frameworks due to their\nlimited time budget. Therefore, we introduce a novel framework to collect\ndialogues between scientists as domain experts on scientific papers. Our\nframework lets scientists present their scientific papers as groundings for\ndialogues and participate in dialogue they like its paper title. We use our\nframework to collect a novel argumentative dialogue dataset, ArgSciChat. It\nconsists of 498 messages collected from 41 dialogues on 20 scientific papers.\nAlongside extensive analysis on ArgSciChat, we evaluate a recent conversational\nagent on our dataset. Experimental results show that this agent poorly performs\non ArgSciChat, motivating further research on argumentative scientific agents.\nWe release our framework and the dataset.\n",
                "链接": "https://arxiv.org/abs/2202.06690"
            },
            {
                "文章ID": "39109",
                "标题": "Survey on Fairness Notions and Related Tensions",
                "作者": " Guilherme Alves,  Fabien Bernier,  Miguel Couceiro,  Karima Makhlouf,  Catuscia Palamidessi,  Sami Zhioua",
                "发布日期": "2023-06-21",
                "摘要": "  Automated decision systems are increasingly used to take consequential\ndecisions in problems such as job hiring and loan granting with the hope of\nreplacing subjective human decisions with objective machine learning (ML)\nalgorithms. However, ML-based decision systems are prone to bias, which results\nin yet unfair decisions. Several notions of fairness have been defined in the\nliterature to capture the different subtleties of this ethical and social\nconcept (e.g., statistical parity, equal opportunity, etc.). Fairness\nrequirements to be satisfied while learning models created several types of\ntensions among the different notions of fairness and other desirable properties\nsuch as privacy and classification accuracy. This paper surveys the commonly\nused fairness notions and discusses the tensions among them with privacy and\naccuracy. Different methods to address the fairness-accuracy trade-off\n(classified into four approaches, namely, pre-processing, in-processing,\npost-processing, and hybrid) are reviewed. The survey is consolidated with\nexperimental analysis carried out on fairness benchmark datasets to illustrate\nthe relationship between fairness measures and accuracy in real-world\nscenarios.\n",
                "链接": "https://arxiv.org/abs/2209.13012"
            },
            {
                "文章ID": "2627",
                "标题": "A Method to Predict Semantic Relations on Artificial Intelligence Papers",
                "作者": " Francisco Andrades,  Ricardo Ñanculef",
                "发布日期": "2022-01-26",
                "摘要": "  Predicting the emergence of links in large evolving networks is a difficult\ntask with many practical applications. Recently, the Science4cast competition\nhas illustrated this challenge presenting a network of 64.000 AI concepts and\nasking the participants to predict which topics are going to be researched\ntogether in the future. In this paper, we present a solution to this problem\nbased on a new family of deep learning approaches, namely Graph Neural\nNetworks. The results of the challenge show that our solution is competitive\neven if we had to impose severe restrictions to obtain a computationally\nefficient and parsimonious model: ignoring the intrinsic dynamics of the graph\nand using only a small subset of the nodes surrounding a target link.\nPreliminary experiments presented in this paper suggest the model is learning\ntwo related, but different patterns: the absorption of a node by a sub-graph\nand union of more dense sub-graphs. The model seems to excel at recognizing the\nfirst type of pattern.\n",
                "链接": "https://arxiv.org/abs/2201.10518"
            },
            {
                "文章ID": "12396",
                "标题": "On Decoding Strategies for Neural Text Generators",
                "作者": " Gian Wiher,  Clara Meister,  Ryan Cotterell",
                "发布日期": "2022-03-30",
                "摘要": "  When generating text from probabilistic models, the chosen decoding strategy\nhas a profound effect on the resulting text. Yet the properties elicited by\nvarious decoding strategies do not always transfer across natural language\ngeneration tasks. For example, while mode-seeking methods like beam search\nperform remarkably well for machine translation, they have been observed to\nlead to incoherent and repetitive text in story generation. Despite such\nobservations, the effectiveness of decoding strategies is often assessed with\nrespect to only a single task. This work -- in contrast -- provides a\ncomprehensive analysis of the interaction between language generation tasks and\ndecoding strategies. Specifically, we measure changes in attributes of\ngenerated text as a function of both decoding strategy and task using human and\nautomatic evaluation. Our results reveal both previously-observed and\nsurprising findings. For example, the nature of the diversity-quality trade-off\nin language generation is very task-specific; the length bias often attributed\nto beam search is not constant across tasks.\n",
                "链接": "https://arxiv.org/abs/2203.15721"
            },
            {
                "文章ID": "15455",
                "标题": "Research on Domain Information Mining and Theme Evolution of Scientific\n  Papers",
                "作者": " Changwei Zheng,  Zhe Xue,  Meiyu Liang,  Feifei Kou,  Zeli Guan",
                "发布日期": "2022-04-20",
                "摘要": "  In recent years, with the increase of social investment in scientific\nresearch, the number of research results in various fields has increased\nsignificantly. Cross-disciplinary research results have gradually become an\nemerging frontier research direction. There is a certain dependence between a\nlarge number of research results. It is difficult to effectively analyze\ntoday's scientific research results when looking at a single research field in\nisolation. How to effectively use the huge number of scientific papers to help\nresearchers becomes a challenge. This paper introduces the research status at\nhome and abroad in terms of domain information mining and topic evolution law\nof scientific and technological papers from three aspects: the semantic feature\nrepresentation learning of scientific and technological papers, the field\ninformation mining of scientific and technological papers, and the mining and\nprediction of research topic evolution rules of scientific and technological\npapers.\n",
                "链接": "https://arxiv.org/abs/2204.08476"
            },
            {
                "文章ID": "5986",
                "标题": "Mining On Alzheimer's Diseases Related Knowledge Graph to Identity\n  Potential AD-related Semantic Triples for Drug Repurposing",
                "作者": " Yi Nian,  Xinyue Hu,  Rui Zhang,  Jingna Feng,  Jingcheng Du,  Fang Li,  Yong Chen,  Cui Tao",
                "发布日期": "2022-11-30",
                "摘要": "  To date, there are no effective treatments for most neurodegenerative\ndiseases. Knowledge graphs can provide comprehensive and semantic\nrepresentation for heterogeneous data, and have been successfully leveraged in\nmany biomedical applications including drug repurposing. Our objective is to\nconstruct a knowledge graph from literature to study relations between\nAlzheimer's disease (AD) and chemicals, drugs and dietary supplements in order\nto identify opportunities to prevent or delay neurodegenerative progression. We\ncollected biomedical annotations and extracted their relations using SemRep via\nSemMedDB. We used both a BERT-based classifier and rule-based methods during\ndata preprocessing to exclude noise while preserving most AD-related semantic\ntriples. The 1,672,110 filtered triples were used to train with knowledge graph\ncompletion algorithms (i.e., TransE, DistMult, and ComplEx) to predict\ncandidates that might be helpful for AD treatment or prevention. Among three\nknowledge graph completion models, TransE outperformed the other two (MR =\n13.45, Hits@1 = 0.306). We leveraged the time-slicing technique to further\nevaluate the prediction results. We found supporting evidence for most highly\nranked candidates predicted by our model which indicates that our approach can\ninform reliable new knowledge. This paper shows that our graph mining model can\npredict reliable new relationships between AD and other entities (i.e., dietary\nsupplements, chemicals, and drugs). The knowledge graph constructed can\nfacilitate data-driven knowledge discoveries and the generation of novel\nhypotheses.\n",
                "链接": "https://arxiv.org/abs/2202.08712"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "79671",
                "标题": "Mitigating Label Noise through Data Ambiguation",
                "作者": " Julian Lienen,  Eyke Hüllermeier",
                "发布日期": "2023-05-24",
                "摘要": "  Label noise poses an important challenge in machine learning, especially in\ndeep learning, in which large models with high expressive power dominate the\nfield. Models of that kind are prone to memorizing incorrect labels, thereby\nharming generalization performance. Many methods have been proposed to address\nthis problem, including robust loss functions and more complex label correction\napproaches. Robust loss functions are appealing due to their simplicity, but\ntypically lack flexibility, while label correction usually adds substantial\ncomplexity to the training setup. In this paper, we suggest to address the\nshortcomings of both methodologies by \"ambiguating\" the target information,\nadding additional, complementary candidate labels in case the learner is not\nsufficiently convinced of the observed training label. More precisely, we\nleverage the framework of so-called superset learning to construct set-valued\ntargets based on a confidence threshold, which deliver imprecise yet more\nreliable beliefs about the ground-truth, effectively helping the learner to\nsuppress the memorization effect. In an extensive empirical evaluation, our\nmethod demonstrates favorable learning behavior on synthetic and real-world\nnoise, confirming the effectiveness in detecting and correcting erroneous\ntraining labels.\n",
                "链接": "https://arxiv.org/abs/2305.13764"
            },
            {
                "文章ID": "48397",
                "标题": "Quantifying the Impact of Label Noise on Federated Learning",
                "作者": " Shuqi Ke,  Chao Huang,  Xin Liu",
                "发布日期": "2023-04-04",
                "摘要": "  Federated Learning (FL) is a distributed machine learning paradigm where\nclients collaboratively train a model using their local (human-generated)\ndatasets. While existing studies focus on FL algorithm development to tackle\ndata heterogeneity across clients, the important issue of data quality (e.g.,\nlabel noise) in FL is overlooked. This paper aims to fill this gap by providing\na quantitative study on the impact of label noise on FL. We derive an upper\nbound for the generalization error that is linear in the clients' label noise\nlevel. Then we conduct experiments on MNIST and CIFAR-10 datasets using various\nFL algorithms. Our empirical results show that the global model accuracy\nlinearly decreases as the noise level increases, which is consistent with our\ntheoretical analysis. We further find that label noise slows down the\nconvergence of FL training, and the global model tends to overfit when the\nnoise level is high.\n",
                "链接": "https://arxiv.org/abs/2211.07816"
            },
            {
                "文章ID": "52026",
                "标题": "CrossSplit: Mitigating Label Noise Memorization through Data Splitting",
                "作者": " Jihye Kim,  Aristide Baratin,  Yan Zhang,  Simon Lacoste-Julien",
                "发布日期": "2023-04-27",
                "摘要": "  We approach the problem of improving robustness of deep learning algorithms\nin the presence of label noise. Building upon existing label correction and\nco-teaching methods, we propose a novel training procedure to mitigate the\nmemorization of noisy labels, called CrossSplit, which uses a pair of neural\nnetworks trained on two disjoint parts of the labelled dataset. CrossSplit\ncombines two main ingredients: (i) Cross-split label correction. The idea is\nthat, since the model trained on one part of the data cannot memorize\nexample-label pairs from the other part, the training labels presented to each\nnetwork can be smoothly adjusted by using the predictions of its peer network;\n(ii) Cross-split semi-supervised training. A network trained on one part of the\ndata also uses the unlabeled inputs of the other part. Extensive experiments on\nCIFAR-10, CIFAR-100, Tiny-ImageNet and mini-WebVision datasets demonstrate that\nour method can outperform the current state-of-the-art in a wide range of noise\nratios.\n",
                "链接": "https://arxiv.org/abs/2212.01674"
            },
            {
                "文章ID": "106205",
                "标题": "Quantifying and mitigating the impact of label errors on model disparity\n  metrics",
                "作者": " Julius Adebayo,  Melissa Hall,  Bowen Yu,  Bobbie Chern",
                "发布日期": "2023-10-05",
                "摘要": "  Errors in labels obtained via human annotation adversely affect a model's\nperformance. Existing approaches propose ways to mitigate the effect of label\nerror on a model's downstream accuracy, yet little is known about its impact on\na model's disparity metrics. Here we study the effect of label error on a\nmodel's disparity metrics. We empirically characterize how varying levels of\nlabel error, in both training and test data, affect these disparity metrics. We\nfind that group calibration and other metrics are sensitive to train-time and\ntest-time label error -- particularly for minority groups. This disparate\neffect persists even for models trained with noise-aware algorithms. To\nmitigate the impact of training-time label error, we present an approach to\nestimate the influence of a training input's label on a model's group disparity\nmetric. We empirically assess the proposed approach on a variety of datasets\nand find significant improvement, compared to alternative approaches, in\nidentifying training inputs that improve a model's disparity metric. We\ncomplement the approach with an automatic relabel-and-finetune scheme that\nproduces updated models with, provably, improved group calibration error.\n",
                "链接": "https://arxiv.org/abs/2310.02533"
            },
            {
                "文章ID": "105104",
                "标题": "Understanding and Mitigating the Label Noise in Pre-training on\n  Downstream Tasks",
                "作者": " Hao Chen,  Jindong Wang,  Ankit Shah,  Ran Tao,  Hongxin Wei,  Xing Xie,  Masashi Sugiyama,  Bhiksha Raj",
                "发布日期": "2023-10-02",
                "摘要": "  Pre-training on large-scale datasets and then fine-tuning on downstream tasks\nhave become a standard practice in deep learning. However, pre-training data\noften contain label noise that may adversely affect the generalization of the\nmodel. This paper aims to understand the nature of noise in pre-training\ndatasets and to mitigate its impact on downstream tasks. More specifically,\nthrough extensive experiments of supervised pre-training models on synthetic\nnoisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise\nin pre-training can benefit in-domain (ID) transfer performance, where the\ntraining and testing data share the same distribution, it always deteriorates\nout-of-domain (OOD) performance, where training and testing data distribution\nare different. We empirically verify that the reason behind is noise in\npre-training shapes the feature space differently. We then propose a\nlightweight black-box tuning method (NMTune) to affine the feature space to\nmitigate the malignant effect of noise and improve generalization on both ID\nand OOD tasks, considering one may not be able to fully fine-tune or even\naccess the pre-trained models. We conduct practical experiments on popular\nvision and language models that are pre-trained on noisy data for evaluation of\nour approach. Our analysis and results show the importance of this interesting\nand novel research direction, which we term Noisy Model Learning.\n",
                "链接": "https://arxiv.org/abs/2309.17002"
            },
            {
                "文章ID": "88300",
                "标题": "Systematic analysis of the impact of label noise correction on ML\n  Fairness",
                "作者": " I. Oliveira e Silva,  C. Soares,  I. Sousa,  R. Ghani",
                "发布日期": "2023-06-29",
                "摘要": "  Arbitrary, inconsistent, or faulty decision-making raises serious concerns,\nand preventing unfair models is an increasingly important challenge in Machine\nLearning. Data often reflect past discriminatory behavior, and models trained\non such data may reflect bias on sensitive attributes, such as gender, race, or\nage. One approach to developing fair models is to preprocess the training data\nto remove the underlying biases while preserving the relevant information, for\nexample, by correcting biased labels. While multiple label noise correction\nmethods are available, the information about their behavior in identifying\ndiscrimination is very limited. In this work, we develop an empirical\nmethodology to systematically evaluate the effectiveness of label noise\ncorrection techniques in ensuring the fairness of models trained on biased\ndatasets. Our methodology involves manipulating the amount of label noise and\ncan be used with fairness benchmarks but also with standard ML datasets. We\napply the methodology to analyze six label noise correction methods according\nto several fairness metrics on standard OpenML datasets. Our results suggest\nthat the Hybrid Label Noise Correction method achieves the best trade-off\nbetween predictive performance and fairness. Clustering-Based Correction can\nreduce discrimination the most, however, at the cost of lower predictive\nperformance.\n",
                "链接": "https://arxiv.org/abs/2306.15994"
            },
            {
                "文章ID": "33646",
                "标题": "Investigating the Impact of Model Width and Density on Generalization in\n  Presence of Label Noise",
                "作者": " Yihao Xue,  Kyle Whitecross,  Baharan Mirzasoleiman",
                "发布日期": "2023-06-16",
                "摘要": "  Increasing the size of overparameterized neural networks has been a key in\nachieving state-of-the-art performance. This is captured by the double descent\nphenomenon, where the test loss follows a decreasing-increasing-decreasing\npattern as model width increases. However, the effect of label noise on the\ntest loss curve has not been fully explored. In this work, we uncover an\nintriguing phenomenon where label noise leads to a \\textit{final ascent} in the\noriginally observed double descent curve. Specifically, under a sufficiently\nlarge noise-to-sample-size ratio, optimal generalization is achieved at\nintermediate widths. Through theoretical analysis, we attribute this phenomenon\nto the shape transition of test loss variance induced by label noise.\nFurthermore, we extend the final ascent phenomenon to model density and provide\nthe first theoretical characterization showing that reducing density by\nrandomly dropping trainable parameters improves generalization under label\nnoise. We also thoroughly examine the roles of regularization and sample size.\nSurprisingly, we find that larger $\\ell_2$ regularization and robust learning\nmethods against label noise exacerbate the final ascent. We confirm the\nvalidity of our findings through extensive experiments on ReLu networks trained\non MNIST, ResNets trained on CIFAR-10/100, and InceptionResNet-v2 trained on\nStanford Cars with real-world noisy labels.\n",
                "链接": "https://arxiv.org/abs/2208.08003"
            },
            {
                "文章ID": "85700",
                "标题": "Learning on Graphs under Label Noise",
                "作者": " Jingyang Yuan,  Xiao Luo,  Yifang Qin,  Yusheng Zhao,  Wei Ju,  Ming Zhang",
                "发布日期": "2023-06-16",
                "摘要": "  Node classification on graphs is a significant task with a wide range of\napplications, including social analysis and anomaly detection. Even though\ngraph neural networks (GNNs) have produced promising results on this task,\ncurrent techniques often presume that label information of nodes is accurate,\nwhich may not be the case in real-world applications. To tackle this issue, we\ninvestigate the problem of learning on graphs with label noise and develop a\nnovel approach dubbed Consistent Graph Neural Network (CGNN) to solve it.\nSpecifically, we employ graph contrastive learning as a regularization term,\nwhich promotes two views of augmented nodes to have consistent representations.\nSince this regularization term cannot utilize label information, it can enhance\nthe robustness of node representations to label noise. Moreover, to detect\nnoisy labels on the graph, we present a sample selection technique based on the\nhomophily assumption, which identifies noisy nodes by measuring the consistency\nbetween the labels with their neighbors. Finally, we purify these confident\nnoisy labels to permit efficient semantic graph learning. Extensive experiments\non three well-known benchmark datasets demonstrate the superiority of our CGNN\nover competing approaches.\n",
                "链接": "https://arxiv.org/abs/2306.08194"
            },
            {
                "文章ID": "111388",
                "标题": "Label Propagation for Graph Label Noise",
                "作者": " Yao Cheng,  Caihua Shan,  Yifei Shen,  Xiang Li,  Siqiang Luo,  Dongsheng Li",
                "发布日期": "2023-10-26",
                "摘要": "  Label noise is a common challenge in large datasets, as it can significantly\ndegrade the generalization ability of deep neural networks. Most existing\nstudies focus on noisy labels in computer vision; however, graph models\nencompass both node features and graph topology as input, and become more\nsusceptible to label noise through message-passing mechanisms. Recently, only a\nfew works have been proposed to tackle the label noise on graphs. One major\nlimitation is that they assume the graph is homophilous and the labels are\nsmoothly distributed. Nevertheless, real-world graphs may contain varying\ndegrees of heterophily or even be heterophily-dominated, leading to the\ninadequacy of current methods. In this paper, we study graph label noise in the\ncontext of arbitrary heterophily, with the aim of rectifying noisy labels and\nassigning labels to previously unlabeled nodes. We begin by conducting two\nempirical analyses to explore the impact of graph homophily on graph label\nnoise. Following observations, we propose a simple yet efficient algorithm,\ndenoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three\nsteps: (1) reconstruct the graph to recover the homophily property, (2) utilize\nlabel propagation to rectify the noisy labels, (3) select high-confidence\nlabels to retain for the next iteration. By iterating these steps, we obtain a\nset of correct labels, ultimately achieving high accuracy in the node\nclassification task. The theoretical analysis is also provided to demonstrate\nits remarkable denoising \"effect\". Finally, we conduct experiments on 10\nbenchmark datasets under varying graph heterophily levels and noise types,\ncomparing the performance of LP4GLN with 7 typical baselines. Our results\nillustrate the superior performance of the proposed LP4GLN.\n",
                "链接": "https://arxiv.org/abs/2310.16560"
            },
            {
                "文章ID": "88753",
                "标题": "Impact of Noise on Calibration and Generalisation of Neural Networks",
                "作者": " Martin Ferianc,  Ondrej Bohdal,  Timothy Hospedales,  Miguel Rodrigues",
                "发布日期": "2023-07-03",
                "摘要": "  Noise injection and data augmentation strategies have been effective for\nenhancing the generalisation and robustness of neural networks (NNs). Certain\ntypes of noise such as label smoothing and MixUp have also been shown to\nimprove calibration. Since noise can be added in various stages of the NN's\ntraining, it motivates the question of when and where the noise is the most\neffective. We study a variety of noise types to determine how much they improve\ncalibration and generalisation, and under what conditions. More specifically we\nevaluate various noise-injection strategies in both in-distribution (ID) and\nout-of-distribution (OOD) scenarios. The findings highlight that activation\nnoise was the most transferable and effective in improving generalisation,\nwhile input augmentation noise was prominent in improving calibration on OOD\nbut not necessarily ID data.\n",
                "链接": "https://arxiv.org/abs/2306.17630"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "81507",
                "标题": "Reward Collapse in Aligning Large Language Models",
                "作者": " Ziang Song,  Tianle Cai,  Jason D. Lee,  Weijie J. Su",
                "发布日期": "2023-05-30",
                "摘要": "  The extraordinary capabilities of large language models (LLMs) such as\nChatGPT and GPT-4 are in part unleashed by aligning them with reward models\nthat are trained on human preferences, which are often represented as rankings\nof responses to prompts. In this paper, we document the phenomenon of\n\\textit{reward collapse}, an empirical observation where the prevailing\nranking-based approach results in an \\textit{identical} reward distribution\n\\textit{regardless} of the prompts during the terminal phase of training. This\noutcome is undesirable as open-ended prompts like ``write a short story about\nyour best friend'' should yield a continuous range of rewards for their\ncompletions, while specific prompts like ``what is the capital of New Zealand''\nshould generate either high or low rewards. Our theoretical investigation\nreveals that reward collapse is primarily due to the insufficiency of the\nranking-based objective function to incorporate prompt-related information\nduring optimization. This insight allows us to derive closed-form expressions\nfor the reward distribution associated with a set of utility functions in an\nasymptotic regime. To overcome reward collapse, we introduce a prompt-aware\noptimization scheme that provably admits a prompt-dependent reward distribution\nwithin the interpolating regime. Our experimental results suggest that our\nproposed prompt-aware utility functions significantly alleviate reward collapse\nduring the training of reward models.\n",
                "链接": "https://arxiv.org/abs/2305.17608"
            },
            {
                "文章ID": "121795",
                "标题": "Privacy Issues in Large Language Models: A Survey",
                "作者": " Seth Neel,  Peter Chang",
                "发布日期": "2023-12-13",
                "摘要": "  This is the first survey of the active area of AI research that focuses on\nprivacy issues in Large Language Models (LLMs). Specifically, we focus on work\nthat red-teams models to highlight privacy risks, attempts to build privacy\ninto the training or inference process, enables efficient data deletion from\ntrained models to comply with existing privacy regulations, and tries to\nmitigate copyright issues. Our focus is on summarizing technical research that\ndevelops algorithms, proves theorems, and runs empirical evaluations. While\nthere is an extensive body of legal and policy work addressing these challenges\nfrom a different angle, that is not the focus of our survey. Nevertheless,\nthese works, along with recent legal developments do inform how these technical\nproblems are formalized, and so we discuss them briefly in Section 1. While we\nhave made our best effort to include all the relevant work, due to the fast\nmoving nature of this research we may have missed some recent work. If we have\nmissed some of your work please contact us, as we will attempt to keep this\nsurvey relatively up to date. We are maintaining a repository with the list of\npapers covered in this survey and any relevant code that was publicly available\nat https://github.com/safr-ml-lab/survey-llm.\n",
                "链接": "https://arxiv.org/abs/2312.06717"
            },
            {
                "文章ID": "12053",
                "标题": "Image-text Retrieval: A Survey on Recent Research and Development",
                "作者": " Min Cao,  Shiping Li,  Juntao Li,  Liqiang Nie,  Min Zhang",
                "发布日期": "2022-11-21",
                "摘要": "  In the past few years, cross-modal image-text retrieval (ITR) has experienced\nincreased interest in the research community due to its excellent research\nvalue and broad real-world application. It is designed for the scenarios where\nthe queries are from one modality and the retrieval galleries from another\nmodality. This paper presents a comprehensive and up-to-date survey on the ITR\napproaches from four perspectives. By dissecting an ITR system into two\nprocesses: feature extraction and feature alignment, we summarize the recent\nadvance of the ITR approaches from these two perspectives. On top of this, the\nefficiency-focused study on the ITR system is introduced as the third\nperspective. To keep pace with the times, we also provide a pioneering overview\nof the cross-modal pre-training ITR approaches as the fourth perspective.\nFinally, we outline the common benchmark datasets and valuation metric for ITR,\nand conduct the accuracy comparison among the representative ITR approaches.\nSome critical yet less studied issues are discussed at the end of the paper.\n",
                "链接": "https://arxiv.org/abs/2203.14713"
            },
            {
                "文章ID": "106796",
                "标题": "A Comprehensive Evaluation of Large Language Models on Benchmark\n  Biomedical Text Processing Tasks",
                "作者": " Israt Jahan,  Md Tahmid Rahman Laskar,  Chun Peng,  Jimmy Huang",
                "发布日期": "2023-10-11",
                "摘要": "  Recently, Large Language Models (LLM) have demonstrated impressive capability\nto solve a wide range of tasks. However, despite their success across various\ntasks, no prior work has investigated their capability in the biomedical domain\nyet. To this end, this paper aims to evaluate the performance of LLMs on\nbenchmark biomedical tasks. For this purpose, we conduct a comprehensive\nevaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets.\nTo the best of our knowledge, this is the first work that conducts an extensive\nevaluation and comparison of various LLMs in the biomedical domain.\nInterestingly, we find based on our evaluation that in biomedical datasets that\nhave smaller training sets, zero-shot LLMs even outperform the current\nstate-of-the-art fine-tuned biomedical models. This suggests that pretraining\non large text corpora makes LLMs quite specialized even in the biomedical\ndomain. We also find that not a single LLM can outperform other LLMs in all\ntasks, with the performance of different LLMs may vary depending on the task.\nWhile their performance is still quite poor in comparison to the biomedical\nmodels that were fine-tuned on large training sets, our findings demonstrate\nthat LLMs have the potential to be a valuable tool for various biomedical tasks\nthat lack large annotated data.\n",
                "链接": "https://arxiv.org/abs/2310.04270"
            },
            {
                "文章ID": "120739",
                "标题": "Sports Recommender Systems: Overview and Research Issues",
                "作者": " Alexander Felfernig,  Manfred Wundara,  Thi Ngoc Trang Tran,  Viet-Man Le,  Sebastian Lubos,  Seda Polat-Erdeniz",
                "发布日期": "2023-12-08",
                "摘要": "  Sports recommender systems receive an increasing attention due to their\npotential of fostering healthy living, improving personal well-being, and\nincreasing performances in sport. These systems support people in sports, for\nexample, by the recommendation of healthy and performance boosting food items,\nthe recommendation of training practices, talent and team recommendation, and\nthe recommendation of specific tactics in competitions. With applications in\nthe virtual world, for example, the recommendation of maps or opponents in\ne-sports, these systems already transcend conventional sports scenarios where\nphysical presence is needed. On the basis of different working examples, we\npresent an overview of sports recommender systems applications and techniques.\nOverall, we analyze the related state-of-the-art and discuss open research\nissues.\n",
                "链接": "https://arxiv.org/abs/2312.03785"
            },
            {
                "文章ID": "110623",
                "标题": "Evaluating Large Language Models on Controlled Generation Tasks",
                "作者": " Jiao Sun,  Yufei Tian,  Wangchunshu Zhou,  Nan Xu,  Qian Hu,  Rahul Gupta,  John Frederick Wieting,  Nanyun Peng,  Xuezhe Ma",
                "发布日期": "2023-10-24",
                "摘要": "  While recent studies have looked into the abilities of large language models\nin various benchmark tasks, including question generation, reading\ncomprehension, multilingual and etc, there have been few studies looking into\nthe controllability of large language models on generation tasks. We present an\nextensive analysis of various benchmarks including a sentence planning\nbenchmark with different granularities. After comparing large language models\nagainst state-of-the-start finetuned smaller models, we present a spectrum\nshowing large language models falling behind, are comparable, or exceed the\nability of smaller models. We conclude that **large language models struggle at\nmeeting fine-grained hard constraints**.\n",
                "链接": "https://arxiv.org/abs/2310.14542"
            },
            {
                "文章ID": "123365",
                "标题": "Data Contamination Issues in Brain-to-Text Decoding",
                "作者": " Congchi Yin,  Qian Yu,  Zhiwei Fang,  Jie He,  Changping Peng,  Zhangang Lin,  Jingping Shao,  Piji Li",
                "发布日期": "2023-12-27",
                "摘要": "  Decoding non-invasive cognitive signals to natural language has long been the\ngoal of building practical brain-computer interfaces (BCIs). Recent major\nmilestones have successfully decoded cognitive signals like functional Magnetic\nResonance Imaging (fMRI) and electroencephalogram (EEG) into text under open\nvocabulary setting. However, how to split the datasets for training,\nvalidating, and testing in cognitive signal decoding task still remains\ncontroversial. In this paper, we conduct systematic analysis on current dataset\nsplitting methods and find the existence of data contamination largely\nexaggerates model performance. Specifically, first we find the leakage of test\nsubjects' cognitive signals corrupts the training of a robust encoder. Second,\nwe prove the leakage of text stimuli causes the auto-regressive decoder to\nmemorize information in test set. The decoder generates highly accurate text\nnot because it truly understands cognitive signals. To eliminate the influence\nof data contamination and fairly evaluate different models' generalization\nability, we propose a new splitting method for different types of cognitive\ndatasets (e.g. fMRI, EEG). We also test the performance of SOTA Brain-to-Text\ndecoding models under the proposed dataset splitting paradigm as baselines for\nfurther research.\n",
                "链接": "https://arxiv.org/abs/2312.10987"
            },
            {
                "文章ID": "114592",
                "标题": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
                "作者": " James Boyko,  Joseph Cohen,  Nathan Fox,  Maria Han Veiga,  Jennifer I-Hsiu Li,  Jing Liu,  Bernardo Modenesi,  Andreas H. Rauch,  Kenneth N. Reid,  Soumi Tribedi,  Anastasia Visheratina,  Xin Xie",
                "发布日期": "2023-11-10",
                "摘要": "  In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.\n",
                "链接": "https://arxiv.org/abs/2311.04929"
            },
            {
                "文章ID": "108065",
                "标题": "Survey on Factuality in Large Language Models: Knowledge, Retrieval and\n  Domain-Specificity",
                "作者": " Cunxiang Wang,  Xiaoze Liu,  Yuanhao Yue,  Xiangru Tang,  Tianhang Zhang,  Cheng Jiayang,  Yunzhi Yao,  Wenyang Gao,  Xuming Hu,  Zehan Qi,  Yidong Wang,  Linyi Yang,  Jindong Wang,  Xing Xie,  Zheng Zhang,  Yue Zhang",
                "发布日期": "2023-12-19",
                "摘要": "  This survey addresses the crucial issue of factuality in Large Language\nModels (LLMs). As LLMs find applications across diverse domains, the\nreliability and accuracy of their outputs become vital. We define the\nFactuality Issue as the probability of LLMs to produce content inconsistent\nwith established facts. We first delve into the implications of these\ninaccuracies, highlighting the potential consequences and challenges posed by\nfactual errors in LLM outputs. Subsequently, we analyze the mechanisms through\nwhich LLMs store and process facts, seeking the primary causes of factual\nerrors. Our discussion then transitions to methodologies for evaluating LLM\nfactuality, emphasizing key metrics, benchmarks, and studies. We further\nexplore strategies for enhancing LLM factuality, including approaches tailored\nfor specific domains. We focus two primary LLM configurations standalone LLMs\nand Retrieval-Augmented LLMs that utilizes external data, we detail their\nunique challenges and potential enhancements. Our survey offers a structured\nguide for researchers aiming to fortify the factual reliability of LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.07521"
            },
            {
                "文章ID": "34574",
                "标题": "Query-Response Interactions by Multi-tasks in Semantic Search for\n  Chatbot Candidate Retrieval",
                "作者": " Libin Shi,  Kai Zhang,  Wenge Rong",
                "发布日期": "2022-08-24",
                "摘要": "  Semantic search for candidate retrieval is an important yet neglected problem\nin retrieval-based Chatbots, which aims to select a bunch of candidate\nresponses efficiently from a large pool. The existing bottleneck is to ensure\nthe model architecture having two points: 1) rich interactions between a query\nand a response to produce query-relevant responses; 2) ability of separately\nprojecting the query and the response into latent spaces to apply efficiently\nin semantic search during online inference. To tackle this problem, we propose\na novel approach, called Multitask-based Semantic Search Neural Network (MSSNN)\nfor candidate retrieval, which accomplishes query-response interactions through\nmulti-tasks. The method employs a Seq2Seq modeling task to learn a good query\nencoder, and then performs a word prediction task to build response embeddings,\nfinally conducts a simple matching model to form the dot-product scorer.\nExperimental studies have demonstrated the potential of the proposed approach.\n",
                "链接": "https://arxiv.org/abs/2208.11018"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "7152",
                "标题": "The Reality of Multi-Lingual Machine Translation",
                "作者": " Tom Kocmi,  Dominik Macháček,  Ondřej Bojar",
                "发布日期": "2022-02-28",
                "摘要": "  Our book \"The Reality of Multi-Lingual Machine Translation\" discusses the\nbenefits and perils of using more than two languages in machine translation\nsystems. While focused on the particular task of sequence-to-sequence\nprocessing and multi-task learning, the book targets somewhat beyond the area\nof natural language processing. Machine translation is for us a prime example\nof deep learning applications where human skills and learning capabilities are\ntaken as a benchmark that many try to match and surpass. We document that some\nof the gains observed in multi-lingual translation may result from simpler\neffects than the assumed cross-lingual transfer of knowledge.\n  In the first, rather general part, the book will lead you through the\nmotivation for multi-linguality, the versatility of deep neural networks\nespecially in sequence-to-sequence tasks to complications of this learning. We\nconclude the general part with warnings against too optimistic and unjustified\nexplanations of the gains that neural networks demonstrate.\n  In the second part, we fully delve into multi-lingual models, with a\nparticularly careful examination of transfer learning as one of the more\nstraightforward approaches utilizing additional languages. The recent\nmulti-lingual techniques, including massive models, are surveyed and practical\naspects of deploying systems for many languages are discussed. The conclusion\nhighlights the open problem of machine understanding and reminds of two ethical\naspects of building large-scale models: the inclusivity of research and its\necological trace.\n",
                "链接": "https://arxiv.org/abs/2202.12814"
            },
            {
                "文章ID": "77168",
                "标题": "Improving the Quality of Neural Machine Translation Through Proper\n  Translation of Name Entities",
                "作者": " Radhika Sharma,  Pragya Katyayan,  Nisheeth Joshi",
                "发布日期": "2023-05-15",
                "摘要": "  In this paper, we have shown a method of improving the quality of neural\nmachine translation by translating/transliterating name entities as a\npreprocessing step. Through experiments we have shown the performance gain of\nour system. For evaluation we considered three types of name entities viz\nperson names, location names and organization names. The system was able to\ncorrectly translate mostly all the name entities. For person names the accuracy\nwas 99.86%, for location names the accuracy was 99.63% and for organization\nnames the accuracy was 99.05%. Overall, the accuracy of the system was 99.52%\n",
                "链接": "https://arxiv.org/abs/2305.07360"
            },
            {
                "文章ID": "87010",
                "标题": "Evaluation of Chinese-English Machine Translation of Emotion-Loaded\n  Microblog Texts: A Human Annotated Dataset for the Quality Assessment of\n  Emotion Translation",
                "作者": " Shenbin Qian,  Constantin Orasan,  Felix do Carmo,  Qiuliang Li,  Diptesh Kanojia",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we focus on how current Machine Translation (MT) tools perform\non the translation of emotion-loaded texts by evaluating outputs from Google\nTranslate according to a framework proposed in this paper. We propose this\nevaluation framework based on the Multidimensional Quality Metrics (MQM) and\nperform a detailed error analysis of the MT outputs. From our analysis, we\nobserve that about 50% of the MT outputs fail to preserve the original emotion.\nAfter further analysis of the errors, we find that emotion carrying words and\nlinguistic phenomena such as polysemous words, negation, abbreviation etc., are\ncommon causes for these translation errors.\n",
                "链接": "https://arxiv.org/abs/2306.11900"
            },
            {
                "文章ID": "50351",
                "标题": "Competency-Aware Neural Machine Translation: Can Machine Translation\n  Know its Own Translation Quality?",
                "作者": " Pei Zhang,  Baosong Yang,  Haoran Wei,  Dayiheng Liu,  Kai Fan,  Luo Si,  Jun Xie",
                "发布日期": "2022-11-28",
                "摘要": "  Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.\n",
                "链接": "https://arxiv.org/abs/2211.13865"
            },
            {
                "文章ID": "39818",
                "标题": "QUAK: A Synthetic Quality Estimation Dataset for Korean-English Neural\n  Machine Translation",
                "作者": " Sugyeong Eo,  Chanjun Park,  Hyeonseok Moon,  Jaehyung Seo,  Gyeongmin Kim,  Jungseob Lee,  Heuiseok Lim",
                "发布日期": "2022-11-30",
                "摘要": "  With the recent advance in neural machine translation demonstrating its\nimportance, research on quality estimation (QE) has been steadily progressing.\nQE aims to automatically predict the quality of machine translation (MT) output\nwithout reference sentences. Despite its high utility in the real world, there\nremain several limitations concerning manual QE data creation: inevitably\nincurred non-trivial costs due to the need for translation experts, and issues\nwith data scaling and language expansion. To tackle these limitations, we\npresent QUAK, a Korean-English synthetic QE dataset generated in a fully\nautomatic manner. This consists of three sub-QUAK datasets QUAK-M, QUAK-P, and\nQUAK-H, produced through three strategies that are relatively free from\nlanguage constraints. Since each strategy requires no human effort, which\nfacilitates scalability, we scale our data up to 1.58M for QUAK-P, H and 6.58M\nfor QUAK-M. As an experiment, we quantitatively analyze word-level QE results\nin various ways while performing statistical analysis. Moreover, we show that\ndatasets scaled in an efficient way also contribute to performance improvements\nby observing meaningful performance gains in QUAK-M, P when adding data up to\n1.58M.\n",
                "链接": "https://arxiv.org/abs/2209.15285"
            },
            {
                "文章ID": "19807",
                "标题": "PreQuEL: Quality Estimation of Machine Translation Outputs in Advance",
                "作者": " Shachar Don-Yehiya,  Leshem Choshen,  Omri Abend",
                "发布日期": "2022-12-06",
                "摘要": "  We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL\nsystem predicts how well a given sentence will be translated, without recourse\nto the actual translation, thus eschewing unnecessary resource allocation when\ntranslation quality is bound to be low. PreQuEL can be defined relative to a\ngiven MT system (e.g., some industry service) or generally relative to the\nstate-of-the-art. From a theoretical perspective, PreQuEL places the focus on\nthe source text, tracing properties, possibly linguistic features, that make a\nsentence harder to machine translate.\n  We develop a baseline model for the task and analyze its performance. We also\ndevelop a data augmentation method (from parallel corpora), that improves\nresults substantially. We show that this augmentation method can improve the\nperformance of the Quality-Estimation task as well. We investigate the\nproperties of the input text that our model is sensitive to, by testing it on\nchallenge sets and different languages. We conclude that it is aware of\nsyntactic and semantic distinctions, and correlates and even over-emphasizes\nthe importance of standard NLP features.\n",
                "链接": "https://arxiv.org/abs/2205.09178"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            },
            {
                "文章ID": "32341",
                "标题": "Out of the BLEU: how should we assess quality of the Code Generation\n  models?",
                "作者": " Mikhail Evtikhiev,  Egor Bogomolov,  Yaroslav Sokolov,  Timofey Bryksin",
                "发布日期": "2023-05-11",
                "摘要": "  In recent years, researchers have created and introduced a significant number\nof various code generation models. As human evaluation of every new model\nversion is unfeasible, the community adopted automatic evaluation metrics such\nas BLEU to approximate the results of human judgement. These metrics originate\nfrom the machine translation domain and it is unclear whether they are\napplicable for the code generation tasks and how well they agree with the human\nevaluation on this task. There are also other metrics, CodeBLEU and RUBY,\ndeveloped to estimate the similarity of code, that take into account the\nproperties of source code. However, for these metrics there are hardly any\nstudies on their agreement with the human evaluation. Despite all that, minimal\ndifferences in the metric scores have been used in recent papers to claim\nsuperiority of some code generation models over the others.\n  In this paper, we present a study on the applicability of six metrics --\nBLEU, ROUGE-L, METEOR, ChrF, CodeBLEU, and RUBY -- for evaluation of code\ngeneration models. We conduct a study on two different code generation datasets\nand use human annotators to assess the quality of all models run on these\ndatasets. The results indicate that for the CoNaLa dataset of Python\none-liners, none of the metrics can correctly emulate human judgement on which\nmodel is better with >95% certainty if the difference in model scores is less\nthan 5 points. For the HearthStone dataset, which consists of classes of a\nparticular structure, a difference in model scores of at least 2 points is\nenough to claim the superiority of one model over the other. Our findings\nsuggest that the ChrF metric is a better fit for the evaluation of code\ngeneration models than the commonly used BLEU and CodeBLEU. Yet, finding a\nmetric for code generation that closely agrees with humans requires additional\nwork.\n",
                "链接": "https://arxiv.org/abs/2208.03133"
            },
            {
                "文章ID": "72923",
                "标题": "Tailoring Domain Adaptation for Machine Translation Quality Estimation",
                "作者": " Javad Pourmostafa Roshan Sharami,  Dimitar Shterionov,  Frédéric Blain,  Eva Vanmassenhove,  Mirella De Sisto,  Chris Emmery,  Pieter Spronck",
                "发布日期": "2023-05-10",
                "摘要": "  While quality estimation (QE) can play an important role in the translation\nprocess, its effectiveness relies on the availability and quality of training\ndata. For QE in particular, high-quality labeled data is often lacking due to\nthe high cost and effort associated with labeling such data. Aside from the\ndata scarcity challenge, QE models should also be generalizable, i.e., they\nshould be able to handle data from different domains, both generic and\nspecific. To alleviate these two main issues -- data scarcity and domain\nmismatch -- this paper combines domain adaptation and data augmentation within\na robust QE system. Our method first trains a generic QE model and then\nfine-tunes it on a specific domain while retaining generic knowledge. Our\nresults show a significant improvement for all the language pairs investigated,\nbetter cross-lingual inference, and a superior performance in zero-shot\nlearning scenarios as compared to state-of-the-art baselines.\n",
                "链接": "https://arxiv.org/abs/2304.08891"
            },
            {
                "文章ID": "83169",
                "标题": "Evaluating Machine Translation Quality with Conformal Predictive\n  Distributions",
                "作者": " Patrizio Giovannotti",
                "发布日期": "2023-06-05",
                "摘要": "  This paper presents a new approach for assessing uncertainty in machine\ntranslation by simultaneously evaluating translation quality and providing a\nreliable confidence score. Our approach utilizes conformal predictive\ndistributions to produce prediction intervals with guaranteed coverage, meaning\nthat for any given significance level $\\epsilon$, we can expect the true\nquality score of a translation to fall out of the interval at a rate of\n$1-\\epsilon$. In this paper, we demonstrate how our method outperforms a\nsimple, but effective baseline on six different language pairs in terms of\ncoverage and sharpness. Furthermore, we validate that our approach requires the\ndata exchangeability assumption to hold for optimal performance.\n",
                "链接": "https://arxiv.org/abs/2306.01549"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "80051",
                "标题": "Extracting Shopping Interest-Related Product Types from the Web",
                "作者": " Yinghao Li,  Colin Lockard,  Prashant Shiralkar,  Chao Zhang",
                "发布日期": "2023-05-25",
                "摘要": "  Recommending a diversity of product types (PTs) is important for a good\nshopping experience when customers are looking for products around their\nhigh-level shopping interests (SIs) such as hiking. However, the SI-PT\nconnection is typically absent in e-commerce product catalogs and expensive to\nconstruct manually due to the volume of potential SIs, which prevents us from\nestablishing a recommender with easily accessible knowledge systems. To\nestablish such connections, we propose to extract PTs from the Web pages\ncontaining hand-crafted PT recommendations for SIs. The extraction task is\nformulated as binary HTML node classification given the general observation\nthat an HTML node in our target Web pages can present one and only one PT\nphrase. Accordingly, we introduce TrENC, which stands for Tree-Transformer\nEncoders for Node Classification. It improves the inter-node dependency\nmodeling with modified attention mechanisms that preserve the long-term sibling\nand ancestor-descendant relations. TrENC also injects SI into node features for\nbetter semantic representation. Trained on pages regarding limited SIs, TrEnc\nis ready to be applied to other unobserved interests. Experiments on our\nmanually constructed dataset, WebPT, show that TrENC outperforms the best\nbaseline model by 2.37 F1 points in the zero-shot setup. The performance\nindicates the feasibility of constructing SI-PT relations and using them to\npower downstream applications such as search and recommendation.\n",
                "链接": "https://arxiv.org/abs/2305.14549"
            },
            {
                "文章ID": "79369",
                "标题": "Decomposed Prompting for Machine Translation Between Related Languages\n  using Large Language Models",
                "作者": " Ratish Puduppully,  Anoop Kunchukuttan,  Raj Dabre,  Ai Ti Aw,  Nancy F. Chen",
                "发布日期": "2023-10-24",
                "摘要": "  This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share linguistic characteristics such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This procedure requires the model to learn how\nto generate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nautomatic and human evaluation conducted on multiple related language pairs\nacross various language families, we demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple established few-shot baseline\napproaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM\nmodel with an average improvement of 8 chrF++ scores across the examined\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2305.13085"
            },
            {
                "文章ID": "87969",
                "标题": "LLM-Assisted Content Analysis: Using Large Language Models to Support\n  Deductive Coding",
                "作者": " Robert Chew,  John Bollenbacher,  Michael Wenger,  Jessica Speer,  Annice Kim",
                "发布日期": "2023-06-28",
                "摘要": "  Deductive coding is a widely used qualitative research method for determining\nthe prevalence of themes across documents. While useful, deductive coding is\noften burdensome and time consuming since it requires researchers to read,\ninterpret, and reliably categorize a large body of unstructured text documents.\nLarge language models (LLMs), like ChatGPT, are a class of quickly evolving AI\ntools that can perform a range of natural language processing and reasoning\ntasks. In this study, we explore the use of LLMs to reduce the time it takes\nfor deductive coding while retaining the flexibility of a traditional content\nanalysis. We outline the proposed approach, called LLM-assisted content\nanalysis (LACA), along with an in-depth case study using GPT-3.5 for LACA on a\npublicly available deductive coding data set. Additionally, we conduct an\nempirical benchmark using LACA on 4 publicly available data sets to assess the\nbroader question of how well GPT-3.5 performs across a range of deductive\ncoding tasks. Overall, we find that GPT-3.5 can often perform deductive coding\nat levels of agreement comparable to human coders. Additionally, we demonstrate\nthat LACA can help refine prompts for deductive coding, identify codes for\nwhich an LLM is randomly guessing, and help assess when to use LLMs vs. human\ncoders for deductive coding. We conclude with several implications for future\npractice of deductive coding and related research methods.\n",
                "链接": "https://arxiv.org/abs/2306.14924"
            },
            {
                "文章ID": "94049",
                "标题": "The Hitchhiker's Guide to Program Analysis: A Journey with Large\n  Language Models",
                "作者": " Haonan Li,  Yu Hao,  Yizhuo Zhai,  Zhiyun Qian",
                "发布日期": "2023-11-17",
                "摘要": "  Static analysis is a widely used technique in software engineering for\nidentifying and mitigating bugs. However, a significant hurdle lies in\nachieving a delicate balance between precision and scalability. Large Language\nModels (LLMs) offer a promising alternative, as recent advances demonstrate\nremarkable capabilities in comprehending, generating, and even debugging code.\nYet, the logic of bugs can be complex and require sophisticated reasoning and a\nlarge analysis scope spanning multiple functions. Therefore, at this point,\nLLMs are better used in an assistive role to complement static analysis. In\nthis paper, we take a deep dive into the open space of LLM-assisted static\nanalysis, using use-before-initialization (UBI) bugs as a case study. To this\nend, we develop LLift, a fully automated framework that interfaces with both a\nstatic analysis tool and an LLM. By carefully designing the framework and the\nprompts, we are able to overcome a number of challenges, including bug-specific\nmodeling, the large problem scope, the non-deterministic nature of LLMs, etc.\nTested in a real-world scenario analyzing nearly a thousand potential UBI bugs\nproduced by static analysis, LLift demonstrates a potent capability, showcasing\na reasonable precision (50%) and appearing to have no missing bugs. It even\nidentified 13 previously unknown UBI bugs in the Linux kernel. This research\npaves the way for new opportunities and methodologies in using LLMs for bug\ndiscovery in extensive, real-world datasets.\n",
                "链接": "https://arxiv.org/abs/2308.00245"
            },
            {
                "文章ID": "112194",
                "标题": "Using Large Language Models to Support Thematic Analysis in Empirical\n  Legal Studies",
                "作者": " Jakub Drápal,  Hannes Westermann,  Jaromir Savelka",
                "发布日期": "2023-10-31",
                "摘要": "  Thematic analysis and other variants of inductive coding are widely used\nqualitative analytic methods within empirical legal studies (ELS). We propose a\nnovel framework facilitating effective collaboration of a legal expert with a\nlarge language model (LLM) for generating initial codes (phase 2 of thematic\nanalysis), searching for themes (phase 3), and classifying the data in terms of\nthe themes (to kick-start phase 4). We employed the framework for an analysis\nof a dataset (n=785) of facts descriptions from criminal court opinions\nregarding thefts. The goal of the analysis was to discover classes of typical\nthefts. Our results show that the LLM, namely OpenAI's GPT-4, generated\nreasonable initial codes, and it was capable of improving the quality of the\ncodes based on expert feedback. They also suggest that the model performed well\nin zero-shot classification of facts descriptions in terms of the themes.\nFinally, the themes autonomously discovered by the LLM appear to map fairly\nwell to the themes arrived at by legal experts. These findings can be leveraged\nby legal researchers to guide their decisions in integrating LLMs into their\nthematic analyses, as well as other inductive coding projects.\n",
                "链接": "https://arxiv.org/abs/2310.18729"
            },
            {
                "文章ID": "115037",
                "标题": "Distilling Large Language Models using Skill-Occupation Graph Context\n  for HR-Related Tasks",
                "作者": " Pouya Pezeshkpour,  Hayate Iso,  Thom Lake,  Nikita Bhutani,  Estevam Hruschka",
                "发布日期": "2023-11-14",
                "摘要": "  Numerous HR applications are centered around resumes and job descriptions.\nWhile they can benefit from advancements in NLP, particularly large language\nmodels, their real-world adoption faces challenges due to absence of\ncomprehensive benchmarks for various HR tasks, and lack of smaller models with\ncompetitive capabilities. In this paper, we aim to bridge this gap by\nintroducing the Resume-Job Description Benchmark (RJDB). We meticulously craft\nthis benchmark to cater to a wide array of HR tasks, including matching and\nexplaining resumes to job descriptions, extracting skills and experiences from\nresumes, and editing resumes. To create this benchmark, we propose to distill\ndomain-specific knowledge from a large language model (LLM). We rely on a\ncurated skill-occupation graph to ensure diversity and provide context for LLMs\ngeneration. Our benchmark includes over 50 thousand triples of job\ndescriptions, matched resumes and unmatched resumes. Using RJDB, we train\nmultiple smaller student models. Our experiments reveal that the student models\nachieve near/better performance than the teacher model (GPT-4), affirming the\neffectiveness of the benchmark. Additionally, we explore the utility of RJDB on\nout-of-distribution data for skill extraction and resume-job description\nmatching, in zero-shot and weak supervision manner. We release our datasets and\ncode to foster further research and industry applications.\n",
                "链接": "https://arxiv.org/abs/2311.06383"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "69238",
                "标题": "Can Large Language Models assist in Hazard Analysis?",
                "作者": " Simon Diemert,  Jens H Weber",
                "发布日期": "2023-03-29",
                "摘要": "  Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable\nnatural language processing and generation capabilities and have been applied\nto a variety tasks, such as source code generation. This paper explores the\npotential of integrating LLMs in the hazard analysis for safety-critical\nsystems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a\nhuman analyst interacts with an LLM via a context-aware chat session and uses\nthe responses to support elicitation of possible hazard causes. In this\nexperiment, we explore CoHA with three increasingly complex versions of a\nsimple system, using Open AI's ChatGPT service. The quality of ChatGPT's\nresponses were systematically assessed to determine the feasibility of CoHA\ngiven the current state of LLM technology. The results suggest that LLMs may be\nuseful for supporting human analysts performing hazard analysis.\n",
                "链接": "https://arxiv.org/abs/2303.15473"
            }
        ]
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "86386",
                "标题": "TOBY: A Tool for Exploring Data in Academic Survey Papers",
                "作者": " Tathagata Chakraborti,  Jungkoo Kang,  Christian Muise,  Sarath Sreedharan,  Michael Walker,  Daniel Szafir,  Tom Williams",
                "发布日期": "2023-06-21",
                "摘要": "  This paper describes TOBY, a visualization tool that helps a user explore the\ncontents of an academic survey paper. The visualization consists of four\ncomponents: a hierarchical view of taxonomic data in the survey, a document\nsimilarity view in the space of taxonomic classes, a network view of citations,\nand a new paper recommendation tool. In this paper, we will discuss these\nfeatures in the context of three separate deployments of the tool.\n",
                "链接": "https://arxiv.org/abs/2306.10051"
            },
            {
                "文章ID": "79505",
                "标题": "Error-Tolerant Exact Query Learning of Finite Set Partitions with\n  Same-Cluster Oracle",
                "作者": " Adela Frances DePavia,  Olga Medrano Martín del Campo,  Erasmo Tani",
                "发布日期": "2023-06-21",
                "摘要": "  This paper initiates the study of active learning for exact recovery of\npartitions exclusively through access to a same-cluster oracle in the presence\nof bounded adversarial error. We first highlight a novel connection between\nlearning partitions and correlation clustering. Then we use this connection to\nbuild a R\\'enyi-Ulam style analytical framework for this problem, and prove\nupper and lower bounds on its worst-case query complexity. Further, we bound\nthe expected performance of a relevant randomized algorithm. Finally, we study\nthe relationship between adaptivity and query complexity for this problem and\nrelated variants.\n",
                "链接": "https://arxiv.org/abs/2305.13402"
            },
            {
                "文章ID": "93019",
                "标题": "$\\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering\n  beyond Set Operation",
                "作者": " Hang Yin,  Zihao Wang,  Weizhi Fei,  Yangqiu Song",
                "发布日期": "2023-07-27",
                "摘要": "  To answer complex queries on knowledge graphs, logical reasoning over\nincomplete knowledge is required due to the open-world assumption.\nLearning-based methods are essential because they are capable of generalizing\nover unobserved knowledge. Therefore, an appropriate dataset is fundamental to\nboth obtaining and evaluating such methods under this paradigm. In this paper,\nwe propose a comprehensive framework for data generation, model training, and\nmethod evaluation that covers the combinatorial space of Existential\nFirst-order Queries with multiple variables ($\\text{EFO}_{k}$). The\ncombinatorial query space in our framework significantly extends those defined\nby set operations in the existing literature. Additionally, we construct a\ndataset, $\\text{EFO}_{k}$-CQA, with 741 types of query for empirical\nevaluation, and our benchmark results provide new insights into how query\nhardness affects the results. Furthermore, we demonstrate that the existing\ndataset construction process is systematically biased that hinders the\nappropriate development of query-answering methods, highlighting the importance\nof our work. Our code and data are provided\nin~\\url{https://github.com/HKUST-KnowComp/EFOK-CQA}.\n",
                "链接": "https://arxiv.org/abs/2307.13701"
            },
            {
                "文章ID": "79927",
                "标题": "QTSumm: Query-Focused Summarization over Tabular Data",
                "作者": " Yilun Zhao,  Zhenting Qi,  Linyong Nan,  Boyu Mi,  Yixin Liu,  Weijin Zou,  Simeng Han,  Ruizhe Chen,  Xiangru Tang,  Yumo Xu,  Dragomir Radev,  Arman Cohan",
                "发布日期": "2023-11-08",
                "摘要": "  People primarily consult tables to conduct data analysis or answer specific\nquestions. Text generation systems that can provide accurate table summaries\ntailored to users' information needs can facilitate more efficient access to\nrelevant data insights. Motivated by this, we define a new query-focused table\nsummarization task, where text generation models have to perform human-like\nreasoning and analysis over the given table to generate a tailored summary. We\nintroduce a new benchmark named QTSumm for this task, which contains 7,111\nhuman-annotated query-summary pairs over 2,934 tables covering diverse topics.\nWe investigate a set of strong baselines on QTSumm, including text generation,\ntable-to-text generation, and large language models. Experimental results and\nmanual analysis reveal that the new task presents significant challenges in\ntable-to-text generation for future research. Moreover, we propose a new\napproach named ReFactor, to retrieve and reason over query-relevant information\nfrom tabular data to generate several natural language facts. Experimental\nresults demonstrate that ReFactor can bring improvements to baselines by\nconcatenating the generated facts to the model input. Our data and code are\npublicly available at https://github.com/yale-nlp/QTSumm.\n",
                "链接": "https://arxiv.org/abs/2305.14303"
            },
            {
                "文章ID": "86984",
                "标题": "QuOTeS: Query-Oriented Technical Summarization",
                "作者": " Juan Ramirez-Orta,  Eduardo Xamena,  Ana Maguitman,  Axel J. Soto,  Flavia P. Zanoto,  Evangelos Milios",
                "发布日期": "2023-06-22",
                "摘要": "  Abstract. When writing an academic paper, researchers often spend\nconsiderable time reviewing and summarizing papers to extract relevant\ncitations and data to compose the Introduction and Related Work sections. To\naddress this problem, we propose QuOTeS, an interactive system designed to\nretrieve sentences related to a summary of the research from a collection of\npotential references and hence assist in the composition of new papers. QuOTeS\nintegrates techniques from Query-Focused Extractive Summarization and\nHigh-Recall Information Retrieval to provide Interactive Query-Focused\nSummarization of scientific documents. To measure the performance of our\nsystem, we carried out a comprehensive user study where participants uploaded\npapers related to their research and evaluated the system in terms of its\nusability and the quality of the summaries it produces. The results show that\nQuOTeS provides a positive user experience and consistently provides\nquery-focused summaries that are relevant, concise, and complete. We share the\ncode of our system and the novel Query-Focused Summarization dataset collected\nduring our experiments at https://github.com/jarobyte91/quotes.\n",
                "链接": "https://arxiv.org/abs/2306.11832"
            },
            {
                "文章ID": "84446",
                "标题": "Good Data, Large Data, or No Data? Comparing Three Approaches in\n  Developing Research Aspect Classifiers for Biomedical Papers",
                "作者": " Shreya Chandrasekhar,  Chieh-Yang Huang,  Ting-Hao 'Kenneth' Huang",
                "发布日期": "2023-06-09",
                "摘要": "  The rapid growth of scientific publications, particularly during the COVID-19\npandemic, emphasizes the need for tools to help researchers efficiently\ncomprehend the latest advancements. One essential part of understanding\nscientific literature is research aspect classification, which categorizes\nsentences in abstracts to Background, Purpose, Method, and Finding. In this\nstudy, we investigate the impact of different datasets on model performance for\nthe crowd-annotated CODA-19 research aspect classification task. Specifically,\nwe explore the potential benefits of using the large, automatically curated\nPubMed 200K RCT dataset and evaluate the effectiveness of large language models\n(LLMs), such as LLaMA, GPT-3, ChatGPT, and GPT-4. Our results indicate that\nusing the PubMed 200K RCT dataset does not improve performance for the CODA-19\ntask. We also observe that while GPT-4 performs well, it does not outperform\nthe SciBERT model fine-tuned on the CODA-19 dataset, emphasizing the importance\nof a dedicated and task-aligned datasets dataset for the target task. Our code\nis available at https://github.com/Crowd-AI-Lab/CODA-19-exp.\n",
                "链接": "https://arxiv.org/abs/2306.04820"
            },
            {
                "文章ID": "87103",
                "标题": "Adversarial Attacks Neutralization via Data Set Randomization",
                "作者": " Mouna Rabhi,  Roberto Di Pietro",
                "发布日期": "2023-06-22",
                "摘要": "  Adversarial attacks on deep-learning models pose a serious threat to their\nreliability and security. Existing defense mechanisms are narrow addressing a\nspecific type of attack or being vulnerable to sophisticated attacks. We\npropose a new defense mechanism that, while being focused on image-based\nclassifiers, is general with respect to the cited category. It is rooted on\nhyperspace projection. In particular, our solution provides a pseudo-random\nprojection of the original dataset into a new dataset. The proposed defense\nmechanism creates a set of diverse projected datasets, where each projected\ndataset is used to train a specific classifier, resulting in different trained\nclassifiers with different decision boundaries. During testing, it randomly\nselects a classifier to test the input. Our approach does not sacrifice\naccuracy over legitimate input. Other than detailing and providing a thorough\ncharacterization of our defense mechanism, we also provide a proof of concept\nof using four optimization-based adversarial attacks (PGD, FGSM, IGSM, and\nC\\&W) and a generative adversarial attack testing them on the MNIST dataset.\nOur experimental results show that our solution increases the robustness of\ndeep learning models against adversarial attacks and significantly reduces the\nattack success rate by at least 89% for optimization attacks and 78% for\ngenerative attacks. We also analyze the relationship between the number of used\nhyperspaces and the efficacy of the defense mechanism. As expected, the two are\npositively correlated, offering an easy-to-tune parameter to enforce the\ndesired level of security. The generality and scalability of our solution and\nadaptability to different attack scenarios, combined with the excellent\nachieved results, other than providing a robust defense against adversarial\nattacks on deep learning networks, also lay the groundwork for future research\nin the field.\n",
                "链接": "https://arxiv.org/abs/2306.12161"
            },
            {
                "文章ID": "93434",
                "标题": "Set-Membership Inference Attacks using Data Watermarking",
                "作者": " Mike Laszkiewicz,  Denis Lukovnikov,  Johannes Lederer,  Asja Fischer",
                "发布日期": "2023-07-31",
                "摘要": "  In this work, we propose a set-membership inference attack for generative\nmodels using deep image watermarking techniques. In particular, we demonstrate\nhow conditional sampling from a generative model can reveal the watermark that\nwas injected into parts of the training data. Our empirical results demonstrate\nthat the proposed watermarking technique is a principled approach for detecting\nthe non-consensual use of image data in training generative models.\n",
                "链接": "https://arxiv.org/abs/2307.15067"
            },
            {
                "文章ID": "57709",
                "标题": "Hybrid Open-set Segmentation with Synthetic Negative Data",
                "作者": " Matej Grcić,  Siniša Šegvić",
                "发布日期": "2023-07-31",
                "摘要": "  Open-set segmentation is often conceived by complementing closed-set\nclassification with anomaly detection. Existing dense anomaly detectors operate\neither through generative modelling of regular training data or by\ndiscriminating with respect to negative training data. These two approaches\noptimize different objectives and therefore exhibit different failure modes.\nConsequently, we propose the first dense hybrid anomaly score that fuses\ngenerative and discriminative cues. The proposed score can be efficiently\nimplemented by upgrading any semantic segmentation model with dense estimates\nof data likelihood and dataset posterior. Our design is a remarkably good fit\nfor efficient inference on large images due to negligible computational\noverhead over the closed-set baseline. The resulting dense hybrid open-set\nmodels require negative training images that can be sampled from an auxiliary\nnegative dataset, from a jointly trained generative model, or from a mixture of\nboth sources. We evaluate our contributions on benchmarks for dense anomaly\ndetection and open-set segmentation. The experiments reveal strong open-set\nperformance in spite of negligible computational overhead.\n",
                "链接": "https://arxiv.org/abs/2301.08555"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "62305",
                "标题": "RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards\n  Precise Expressions",
                "作者": " Yunlong Wang,  Shuyuan Shen,  Brian Y. Lim",
                "发布日期": "2023-03-21",
                "摘要": "  Generative AI models have shown impressive ability to produce images with\ntext prompts, which could benefit creativity in visual art creation and\nself-expression. However, it is unclear how precisely the generated images\nexpress contexts and emotions from the input texts. We explored the emotional\nexpressiveness of AI-generated images and developed RePrompt, an automatic\nmethod to refine text prompts toward precise expression of the generated\nimages. Inspired by crowdsourced editing strategies, we curated intuitive text\nfeatures, such as the number and concreteness of nouns, and trained a proxy\nmodel to analyze the feature effects on the AI-generated image. With model\nexplanations of the proxy model, we curated a rubric to adjust text prompts to\noptimize image generation for precise emotion expression. We conducted\nsimulation and user studies, which showed that RePrompt significantly improves\nthe emotional expressiveness of AI-generated images, especially for negative\nemotions.\n",
                "链接": "https://arxiv.org/abs/2302.09466"
            },
            {
                "文章ID": "116159",
                "标题": "Do Physicians Know How to Prompt? The Need for Automatic Prompt\n  Optimization Help in Clinical Note Generation",
                "作者": " Zonghai Yao,  Ahmed Jaafar,  Beining Wang,  Yue Zhu,  Zhichao Yang,  Hong Yu",
                "发布日期": "2023-11-17",
                "摘要": "  This study examines the effect of prompt engineering on the performance of\nLarge Language Models (LLMs) in clinical note generation. We introduce an\nAutomatic Prompt Optimization (APO) framework to refine initial prompts and\ncompare the outputs of medical experts, non-medical experts, and APO-enhanced\nGPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in\nstandardizing prompt quality across clinical note sections. A human-in-the-loop\napproach shows that experts maintain content quality post-APO, with a\npreference for their own modifications, suggesting the value of expert\ncustomization. We recommend a two-phase optimization process, leveraging\nAPO-GPT4 for consistency and expert input for personalization.\n",
                "链接": "https://arxiv.org/abs/2311.09684"
            },
            {
                "文章ID": "91013",
                "标题": "AutoHint: Automatic Prompt Optimization with Hint Generation",
                "作者": " Hong Sun,  Xue Li,  Yinchuan Xu,  Youkow Homma,  Qi Cao,  Min Wu,  Jian Jiao,  Denis Charles",
                "发布日期": "2023-08-10",
                "摘要": "  This paper presents AutoHint, a novel framework for automatic prompt\nengineering and optimization for Large Language Models (LLM). While LLMs have\ndemonstrated remarkable ability in achieving high-quality annotation in various\ntasks, the key to applying this ability to specific tasks lies in developing\nhigh-quality prompts. Thus we propose a framework to inherit the merits of both\nin-context learning and zero-shot learning by incorporating enriched\ninstructions derived from input-output demonstrations to optimize original\nprompt. We refer to the enrichment as the hint and propose a framework to\nautomatically generate the hint from labeled data. More concretely, starting\nfrom an initial prompt, our method first instructs a LLM to deduce new hints\nfor selected samples from incorrect predictions, and then summarizes from\nper-sample hints and adds the results back to the initial prompt to form a new,\nenriched instruction. The proposed method is evaluated on the BIG-Bench\nInstruction Induction dataset for both zero-shot and few-short prompts, where\nexperiments demonstrate our method is able to significantly boost accuracy for\nmultiple tasks.\n",
                "链接": "https://arxiv.org/abs/2307.07415"
            },
            {
                "文章ID": "105319",
                "标题": "Automatic Prompt Rewriting for Personalized Text Generation",
                "作者": " Cheng Li,  Mingyang Zhang,  Qiaozhu Mei,  Weize Kong,  Michael Bendersky",
                "发布日期": "2023-10-03",
                "摘要": "  Facilitated by large language models (LLMs), personalized text generation has\nbecome a rapidly growing research direction. Most existing studies focus on\ndesigning specialized models for a particular domain, or they require\nfine-tuning the LLMs to generate personalized text. We consider a typical\nscenario in which the large language model, which generates personalized\noutput, is frozen and can only be accessed through APIs. Under this constraint,\nall one can do is to improve the input text (i.e., text prompts) sent to the\nLLM, a procedure that is usually done manually. In this paper, we propose a\nnovel method to automatically revise prompts for personalized text generation.\nThe proposed method takes the initial prompts generated by a state-of-the-art,\nmultistage framework for personalized generation and rewrites a few critical\ncomponents that summarize and synthesize the personal context. The prompt\nrewriter employs a training paradigm that chains together supervised learning\n(SL) and reinforcement learning (RL), where SL reduces the search space of RL\nand RL facilitates end-to-end training of the rewriter. Using datasets from\nthree representative domains, we demonstrate that the rewritten prompts\noutperform both the original prompts and the prompts optimized via supervised\nlearning or reinforcement learning alone. In-depth analysis of the rewritten\nprompts shows that they are not only human readable, but also able to guide\nmanual revision of prompts when there is limited resource to employ\nreinforcement learning to train the prompt rewriter, or when it is costly to\ndeploy an automatic prompt rewriter for inference.\n",
                "链接": "https://arxiv.org/abs/2310.00152"
            },
            {
                "文章ID": "44385",
                "标题": "Generative Prompt Tuning for Relation Classification",
                "作者": " Jiale Han,  Shuai Zhao,  Bo Cheng,  Shengkun Ma,  Wei Lu",
                "发布日期": "2022-10-25",
                "摘要": "  Using prompts to explore the knowledge contained within pre-trained language\nmodels for downstream tasks has now become an active topic. Current prompt\ntuning methods mostly convert the downstream tasks to masked language modeling\nproblems by adding cloze-style phrases and mapping all labels to verbalizations\nwith fixed length, which has proven effective for tasks with simple label\nspaces. However, when applied to relation classification exhibiting complex\nlabel spaces, vanilla prompt tuning methods may struggle with label\nverbalizations with arbitrary lengths due to rigid prompt restrictions.\nInspired by the text infilling task for pre-training generative models that can\nflexibly predict missing spans, we propose a novel generative prompt tuning\nmethod to reformulate relation classification as an infilling problem, which\nfrees our approach from limitations of current prompt based approaches and thus\nfully exploits rich semantics of entity and relation types. In addition, we\ndesign entity-guided decoding and discriminative relation scoring to generate\nand align relations effectively and efficiently during inference. Extensive\nexperiments under fully supervised settings and low-resource settings\ndemonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2210.12435"
            },
            {
                "文章ID": "85953",
                "标题": "Prompt Performance Prediction for Generative IR",
                "作者": " Nicolas Bizzozzero,  Ihab Bendidi,  Olivier Risser-Maroix",
                "发布日期": "2023-06-16",
                "摘要": "  The ability to predict the performance of a query in Information Retrieval\n(IR) systems has been a longstanding challenge. In this paper, we introduce a\nnovel task called \"Prompt Performance Prediction\" that aims to predict the\nperformance of a query, referred to as a prompt, before obtaining the actual\nsearch results. The context of our task leverages a generative model as an IR\nengine to evaluate the prompts' performance on image retrieval tasks. We\ndemonstrate the plausibility of our task by measuring the correlation\ncoefficient between predicted and actual performance scores across three\ndatasets containing pairs of prompts and generated images. Our results show\npromising performance prediction capabilities, suggesting potential\napplications for optimizing generative IR systems.\n",
                "链接": "https://arxiv.org/abs/2306.08915"
            },
            {
                "文章ID": "95574",
                "标题": "Emotion-Conditioned Text Generation through Automatic Prompt\n  Optimization",
                "作者": " Yarik Menchaca Resendiz,  Roman Klinger",
                "发布日期": "2023-08-10",
                "摘要": "  Conditional natural language generation methods often require either\nexpensive fine-tuning or training a large language model from scratch. Both are\nunlikely to lead to good results without a substantial amount of data and\ncomputational resources. Prompt learning without changing the parameters of a\nlarge language model presents a promising alternative. It is a cost-effective\napproach, while still achieving competitive results. While this procedure is\nnow established for zero- and few-shot text classification and structured\nprediction, it has received limited attention in conditional text generation.\nWe present the first automatic prompt optimization approach for\nemotion-conditioned text generation with instruction-fine-tuned models. Our\nmethod uses an iterative optimization procedure that changes the prompt by\nadding, removing, or replacing tokens. As objective function, we only require a\ntext classifier that measures the realization of the conditional variable in\nthe generated text. We evaluate the method on emotion-conditioned text\ngeneration with a focus on event reports and compare it to manually designed\nprompts that also act as the seed for the optimization procedure. The optimized\nprompts achieve 0.75 macro-average F1 to fulfill the emotion condition in\ncontrast to manually designed seed prompts with only 0.22 macro-average F1.\n",
                "链接": "https://arxiv.org/abs/2308.04857"
            },
            {
                "文章ID": "20988",
                "标题": "Toxicity Detection with Generative Prompt-based Inference",
                "作者": " Yau-Shian Wang,  Yingshan Chang",
                "发布日期": "2022-05-26",
                "摘要": "  Due to the subtleness, implicity, and different possible interpretations\nperceived by different people, detecting undesirable content from text is a\nnuanced difficulty. It is a long-known risk that language models (LMs), once\ntrained on corpus containing undesirable content, have the power to manifest\nbiases and toxicity. However, recent studies imply that, as a remedy, LMs are\nalso capable of identifying toxic content without additional fine-tuning.\nPrompt-methods have been shown to effectively harvest this surprising\nself-diagnosing capability. However, existing prompt-based methods usually\nspecify an instruction to a language model in a discriminative way. In this\nwork, we explore the generative variant of zero-shot prompt-based toxicity\ndetection with comprehensive trials on prompt engineering. We evaluate on three\ndatasets with toxicity labels annotated on social media posts. Our analysis\nhighlights the strengths of our generative classification approach both\nquantitatively and qualitatively. Interesting aspects of self-diagnosis and its\nethical implications are discussed.\n",
                "链接": "https://arxiv.org/abs/2205.12390"
            },
            {
                "文章ID": "32181",
                "标题": "Prompt Tuning for Generative Multimodal Pretrained Models",
                "作者": " Hao Yang,  Junyang Lin,  An Yang,  Peng Wang,  Chang Zhou,  Hongxia Yang",
                "发布日期": "2022-08-05",
                "摘要": "  Prompt tuning has become a new paradigm for model tuning and it has\ndemonstrated success in natural language pretraining and even vision\npretraining. In this work, we explore the transfer of prompt tuning to\nmultimodal pretraining, with a focus on generative multimodal pretrained\nmodels, instead of contrastive ones. Specifically, we implement prompt tuning\non the unified sequence-to-sequence pretrained model adaptive to both\nunderstanding and generation tasks. Experimental results demonstrate that the\nlight-weight prompt tuning can achieve comparable performance with finetuning\nand surpass other light-weight tuning methods. Besides, in comparison with\nfinetuned models, the prompt-tuned models demonstrate improved robustness\nagainst adversarial attacks. We further figure out that experimental factors,\nincluding the prompt length, prompt depth, and reparameteratization, have great\nimpacts on the model performance, and thus we empirically provide a\nrecommendation for the setups of prompt tuning. Despite the observed\nadvantages, we still find some limitations in prompt tuning, and we\ncorrespondingly point out the directions for future studies. Codes are\navailable at \\url{https://github.com/OFA-Sys/OFA}\n",
                "链接": "https://arxiv.org/abs/2208.02532"
            },
            {
                "文章ID": "40278",
                "标题": "Visual Prompt Tuning for Generative Transfer Learning",
                "作者": " Kihyuk Sohn,  Yuan Hao,  José Lezama,  Luisa Polania,  Huiwen Chang,  Han Zhang,  Irfan Essa,  Lu Jiang",
                "发布日期": "2022-10-04",
                "摘要": "  Transferring knowledge from an image synthesis model trained on a large\ndataset is a promising direction for learning generative image models from\nvarious domains efficiently. While previous works have studied GAN models, we\npresent a recipe for learning vision transformers by generative knowledge\ntransfer. We base our framework on state-of-the-art generative vision\ntransformers that represent an image as a sequence of visual tokens to the\nautoregressive or non-autoregressive transformers. To adapt to a new domain, we\nemploy prompt tuning, which prepends learnable tokens called prompt to the\nimage token sequence, and introduce a new prompt design for our task. We study\non a variety of visual domains, including visual task adaptation\nbenchmark~\\cite{zhai2019large}, with varying amount of training images, and\nshow effectiveness of knowledge transfer and a significantly better image\ngeneration quality over existing works.\n",
                "链接": "https://arxiv.org/abs/2210.00990"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "51062",
                "标题": "Instance-Specific Image Goal Navigation: Training Embodied Agents to\n  Find Object Instances",
                "作者": " Jacob Krantz,  Stefan Lee,  Jitendra Malik,  Dhruv Batra,  Devendra Singh Chaplot",
                "发布日期": "2022-11-30",
                "摘要": "  We consider the problem of embodied visual navigation given an image-goal\n(ImageNav) where an agent is initialized in an unfamiliar environment and\ntasked with navigating to a location 'described' by an image. Unlike related\nnavigation tasks, ImageNav does not have a standardized task definition which\nmakes comparison across methods difficult. Further, existing formulations have\ntwo problematic properties; (1) image-goals are sampled from random locations\nwhich can lead to ambiguity (e.g., looking at walls), and (2) image-goals match\nthe camera specification and embodiment of the agent; this rigidity is limiting\nwhen considering user-driven downstream applications. We present the\nInstance-specific ImageNav task (InstanceImageNav) to address these\nlimitations. Specifically, the goal image is 'focused' on some particular\nobject instance in the scene and is taken with camera parameters independent of\nthe agent. We instantiate InstanceImageNav in the Habitat Simulator using\nscenes from the Habitat-Matterport3D dataset (HM3D) and release a standardized\nbenchmark to measure community progress.\n",
                "链接": "https://arxiv.org/abs/2211.15876"
            },
            {
                "文章ID": "63780",
                "标题": "Multimodal Speech Recognition for Language-Guided Embodied Agents",
                "作者": " Allen Chang,  Xiaoyuan Zhu,  Aarav Monga,  Seoho Ahn,  Tejas Srinivasan,  Jesse Thomason",
                "发布日期": "2023-10-11",
                "摘要": "  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr\n",
                "链接": "https://arxiv.org/abs/2302.14030"
            },
            {
                "文章ID": "123652",
                "标题": "Urban Generative Intelligence (UGI): A Foundational Platform for Agents\n  in Embodied City Environment",
                "作者": " Fengli Xu,  Jun Zhang,  Chen Gao,  Jie Feng,  Yong Li",
                "发布日期": "2023-12-20",
                "摘要": "  Urban environments, characterized by their complex, multi-layered networks\nencompassing physical, social, economic, and environmental dimensions, face\nsignificant challenges in the face of rapid urbanization. These challenges,\nranging from traffic congestion and pollution to social inequality, call for\nadvanced technological interventions. Recent developments in big data,\nartificial intelligence, urban computing, and digital twins have laid the\ngroundwork for sophisticated city modeling and simulation. However, a gap\npersists between these technological capabilities and their practical\nimplementation in addressing urban challenges in an systemic-intelligent way.\nThis paper proposes Urban Generative Intelligence (UGI), a novel foundational\nplatform integrating Large Language Models (LLMs) into urban systems to foster\na new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model\ntrained on city-specific multi-source data, to create embodied agents for\nvarious urban tasks. These agents, operating within a textual urban environment\nemulated by city simulator and urban knowledge graph, interact through a\nnatural language interface, offering an open platform for diverse intelligent\nand embodied agent development. This platform not only addresses specific urban\nissues but also simulates complex urban systems, providing a multidisciplinary\napproach to understand and manage urban complexity. This work signifies a\ntransformative step in city science and urban intelligence, harnessing the\npower of LLMs to unravel and address the intricate dynamics of urban systems.\nThe code repository with demonstrations will soon be released here\nhttps://github.com/tsinghua-fib-lab/UGI.\n",
                "链接": "https://arxiv.org/abs/2312.11813"
            },
            {
                "文章ID": "104544",
                "标题": "The Importance of Multimodal Emotion Conditioning and Affect Consistency\n  for Embodied Conversational Agents",
                "作者": " Che-Jui Chang,  Samuel S. Sohn,  Sen Zhang,  Rajath Jayashankar,  Muhammad Usman,  Mubbasir Kapadia",
                "发布日期": "2023-12-08",
                "摘要": "  Previous studies regarding the perception of emotions for embodied virtual\nagents have shown the effectiveness of using virtual characters in conveying\nemotions through interactions with humans. However, creating an autonomous\nembodied conversational agent with expressive behaviors presents two major\nchallenges. The first challenge is the difficulty of synthesizing the\nconversational behaviors for each modality that are as expressive as real human\nbehaviors. The second challenge is that the affects are modeled independently,\nwhich makes it difficult to generate multimodal responses with consistent\nemotions across all modalities. In this work, we propose a conceptual\nframework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims\nto increase the perception of affects by generating multimodal behaviors\nconditioned on a consistent driving affect. We have conducted a user study with\n199 participants to assess how the average person judges the affects perceived\nfrom multimodal behaviors that are consistent and inconsistent with respect to\na driving affect. The result shows that among all model conditions, our\naffect-consistent framework receives the highest Likert scores for the\nperception of driving affects. Our statistical analysis suggests that making a\nmodality affect-inconsistent significantly decreases the perception of driving\naffects. We also observe that multimodal behaviors conditioned on consistent\naffects are more expressive compared to behaviors with inconsistent affects.\nTherefore, we conclude that multimodal emotion conditioning and affect\nconsistency are vital to enhancing the perception of affects for embodied\nconversational agents.\n",
                "链接": "https://arxiv.org/abs/2309.15311"
            },
            {
                "文章ID": "39098",
                "标题": "Dialog Acts for Task-Driven Embodied Agents",
                "作者": " Spandana Gella,  Aishwarya Padmakumar,  Patrick Lange,  Dilek Hakkani-Tur",
                "发布日期": "2022-09-28",
                "摘要": "  Embodied agents need to be able to interact in natural language understanding\ntask descriptions and asking appropriate follow up questions to obtain\nnecessary information to be effective at successfully accomplishing tasks for a\nwide range of users. In this work, we propose a set of dialog acts for\nmodelling such dialogs and annotate the TEACh dataset that includes over 3,000\nsituated, task oriented conversations (consisting of 39.5k utterances in total)\nwith dialog acts. TEACh-DA is one of the first large scale dataset of dialog\nact annotations for embodied task completion. Furthermore, we demonstrate the\nuse of this annotated dataset in training models for tagging the dialog acts of\na given utterance, predicting the dialog act of the next response given a\ndialog history, and use the dialog acts to guide agent's non-dialog behaviour.\nIn particular, our experiments on the TEACh Execution from Dialog History task\nwhere the model predicts the sequence of low level actions to be executed in\nthe environment for embodied task completion, demonstrate that dialog acts can\nimprove end task success rate by up to 2 points compared to the system without\ndialog acts.\n",
                "链接": "https://arxiv.org/abs/2209.12953"
            },
            {
                "文章ID": "102100",
                "标题": "A Data Source for Reasoning Embodied Agents",
                "作者": " Jack Lanchantin,  Sainbayar Sukhbaatar,  Gabriel Synnaeve,  Yuxuan Sun,  Kavya Srinet,  Arthur Szlam",
                "发布日期": "2023-09-18",
                "摘要": "  Recent progress in using machine learning models for reasoning tasks has been\ndriven by novel model architectures, large-scale pre-training protocols, and\ndedicated reasoning datasets for fine-tuning. In this work, to further pursue\nthese advances, we introduce a new data generator for machine reasoning that\nintegrates with an embodied agent. The generated data consists of templated\ntext queries and answers, matched with world-states encoded into a database.\nThe world-states are a result of both world dynamics and the actions of the\nagent. We show the results of several baseline models on instantiations of\ntrain sets. These include pre-trained language models fine-tuned on a\ntext-formatted representation of the database, and graph-structured\nTransformers operating on a knowledge-graph representation of the database. We\nfind that these models can answer some questions about the world-state, but\nstruggle with others. These results hint at new research directions in\ndesigning neural reasoning models and database representations. Code to\ngenerate the data will be released at github.com/facebookresearch/neuralmemory\n",
                "链接": "https://arxiv.org/abs/2309.07974"
            },
            {
                "文章ID": "93062",
                "标题": "MAEA: Multimodal Attribution for Embodied AI",
                "作者": " Vidhi Jain,  Jayant Sravan Tamarapalli,  Sahiti Yerramilli,  Yonatan Bisk",
                "发布日期": "2023-07-27",
                "摘要": "  Understanding multimodal perception for embodied AI is an open question\nbecause such inputs may contain highly complementary as well as redundant\ninformation for the task. A relevant direction for multimodal policies is\nunderstanding the global trends of each modality at the fusion layer. To this\nend, we disentangle the attributions for visual, language, and previous action\ninputs across different policies trained on the ALFRED dataset. Attribution\nanalysis can be utilized to rank and group the failure scenarios, investigate\nmodeling and dataset biases, and critically analyze multimodal EAI policies for\nrobustness and user trust before deployment. We present MAEA, a framework to\ncompute global attributions per modality of any differentiable policy. In\naddition, we show how attributions enable lower-level behavior analysis in EAI\npolicies for language and visual attributions.\n",
                "链接": "https://arxiv.org/abs/2307.13850"
            },
            {
                "文章ID": "7321",
                "标题": "DialFRED: Dialogue-Enabled Agents for Embodied Instruction Following",
                "作者": " Xiaofeng Gao,  Qiaozi Gao,  Ran Gong,  Kaixiang Lin,  Govind Thattai,  Gaurav S. Sukhatme",
                "发布日期": "2022-08-17",
                "摘要": "  Language-guided Embodied AI benchmarks requiring an agent to navigate an\nenvironment and manipulate objects typically allow one-way communication: the\nhuman user gives a natural language command to the agent, and the agent can\nonly follow the command passively. We present DialFRED, a dialogue-enabled\nembodied instruction following benchmark based on the ALFRED benchmark.\nDialFRED allows an agent to actively ask questions to the human user; the\nadditional information in the user's response is used by the agent to better\ncomplete its task. We release a human-annotated dataset with 53K task-relevant\nquestions and answers and an oracle to answer questions. To solve DialFRED, we\npropose a questioner-performer framework wherein the questioner is pre-trained\nwith the human-annotated data and fine-tuned with reinforcement learning. We\nmake DialFRED publicly available and encourage researchers to propose and\nevaluate their solutions to building dialog-enabled embodied agents.\n",
                "链接": "https://arxiv.org/abs/2202.13330"
            },
            {
                "文章ID": "31354",
                "标题": "DoRO: Disambiguation of referred object for embodied agents",
                "作者": " Pradip Pramanick,  Chayan Sarkar,  Sayan Paul,  Ruddra dev Roychoudhury,  Brojeshwar Bhowmick",
                "发布日期": "2022-07-29",
                "摘要": "  Robotic task instructions often involve a referred object that the robot must\nlocate (ground) within the environment. While task intent understanding is an\nessential part of natural language understanding, less effort is made to\nresolve ambiguity that may arise while grounding the task. Existing works use\nvision-based task grounding and ambiguity detection, suitable for a fixed view\nand a static robot. However, the problem magnifies for a mobile robot, where\nthe ideal view is not known beforehand. Moreover, a single view may not be\nsufficient to locate all the object instances in the given area, which leads to\ninaccurate ambiguity detection. Human intervention is helpful only if the robot\ncan convey the kind of ambiguity it is facing. In this article, we present DoRO\n(Disambiguation of Referred Object), a system that can help an embodied agent\nto disambiguate the referred object by raising a suitable query whenever\nrequired. Given an area where the intended object is, DoRO finds all the\ninstances of the object by aggregating observations from multiple views while\nexploring & scanning the area. It then raises a suitable query using the\ninformation from the grounded object instances. Experiments conducted with the\nAI2Thor simulator show that DoRO not only detects the ambiguity more accurately\nbut also raises verbose queries with more accurate information from the\nvisual-language grounding.\n",
                "链接": "https://arxiv.org/abs/2207.14205"
            },
            {
                "文章ID": "51867",
                "标题": "A General Purpose Supervisory Signal for Embodied Agents",
                "作者": " Kunal Pratap Singh,  Jordi Salvador,  Luca Weihs,  Aniruddha Kembhavi",
                "发布日期": "2022-12-05",
                "摘要": "  Training effective embodied AI agents often involves manual reward\nengineering, expert imitation, specialized components such as maps, or\nleveraging additional sensors for depth and localization. Another approach is\nto use neural architectures alongside self-supervised objectives which\nencourage better representation learning. In practice, there are few guarantees\nthat these self-supervised objectives encode task-relevant information. We\npropose the Scene Graph Contrastive (SGC) loss, which uses scene graphs as\ngeneral-purpose, training-only, supervisory signals. The SGC loss does away\nwith explicit graph decoding and instead uses contrastive learning to align an\nagent's representation with a rich graphical encoding of its environment. The\nSGC loss is generally applicable, simple to implement, and encourages\nrepresentations that encode objects' semantics, relationships, and history.\nUsing the SGC loss, we attain significant gains on three embodied tasks: Object\nNavigation, Multi-Object Navigation, and Arm Point Navigation. Finally, we\npresent studies and analyses which demonstrate the ability of our trained\nrepresentation to encode semantic cues about the environment.\n",
                "链接": "https://arxiv.org/abs/2212.01186"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "116872",
                "标题": "Causal Structure Learning Supervised by Large Language Model",
                "作者": " Taiyu Ban,  Lyuzhou Chen,  Derui Lyu,  Xiangyu Wang,  Huanhuan Chen",
                "发布日期": "2023-11-21",
                "摘要": "  Causal discovery from observational data is pivotal for deciphering complex\nrelationships. Causal Structure Learning (CSL), which focuses on deriving\ncausal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast\nDAG spaces and data sparsity. The integration of Large Language Models (LLMs),\nrecognized for their causal reasoning capabilities, offers a promising\ndirection to enhance CSL by infusing it with knowledge-based causal inferences.\nHowever, existing approaches utilizing LLMs for CSL have encountered issues,\nincluding unreliable constraints from imperfect LLM inferences and the\ncomputational intensity of full pairwise variable analyses. In response, we\nintroduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL\ninnovatively integrates LLM-based causal inference with CSL in an iterative\nprocess, refining the causal DAG using feedback from LLMs. This method not only\nutilizes LLM resources more efficiently but also generates more robust and\nhigh-quality structural constraints compared to previous methodologies. Our\ncomprehensive evaluation across eight real-world datasets demonstrates\nILS-CSL's superior performance, setting a new standard in CSL efficacy and\nshowcasing its potential to significantly advance the field of causal\ndiscovery. The codes are available at\n\\url{https://github.com/tyMadara/ILS-CSL}.\n",
                "链接": "https://arxiv.org/abs/2311.11689"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "105692",
                "标题": "Large Language Model-Powered Smart Contract Vulnerability Detection: New\n  Perspectives",
                "作者": " Sihao Hu,  Tiansheng Huang,  Fatih İlhan,  Selim Furkan Tekin,  Ling Liu",
                "发布日期": "2023-10-18",
                "摘要": "  This paper provides a systematic analysis of the opportunities, challenges,\nand potential solutions of harnessing Large Language Models (LLMs) such as\nGPT-4 to dig out vulnerabilities within smart contracts based on our ongoing\nresearch. For the task of smart contract vulnerability detection, achieving\npractical usability hinges on identifying as many true vulnerabilities as\npossible while minimizing the number of false positives. Nonetheless, our\nempirical study reveals contradictory yet interesting findings: generating more\nanswers with higher randomness largely boosts the likelihood of producing a\ncorrect answer but inevitably leads to a higher number of false positives. To\nmitigate this tension, we propose an adversarial framework dubbed GPTLens that\nbreaks the conventional one-stage detection into two synergistic stages $-$\ngeneration and discrimination, for progressive detection and refinement,\nwherein the LLM plays dual roles, i.e., auditor and critic, respectively. The\ngoal of auditor is to yield a broad spectrum of vulnerabilities with the hope\nof encompassing the correct answer, whereas the goal of critic that evaluates\nthe validity of identified vulnerabilities is to minimize the number of false\npositives. Experimental results and illustrative examples demonstrate that\nauditor and critic work together harmoniously to yield pronounced improvements\nover the conventional one-stage detection. GPTLens is intuitive, strategic, and\nentirely LLM-driven without relying on specialist expertise in smart contracts,\nshowcasing its methodical generality and potential to detect a broad spectrum\nof vulnerabilities. Our code is available at:\nhttps://github.com/git-disl/GPTLens.\n",
                "链接": "https://arxiv.org/abs/2310.01152"
            },
            {
                "文章ID": "31631",
                "标题": "Evaluating Table Structure Recognition: A New Perspective",
                "作者": " Tarun Kumar,  Himanshu Sharad Bhatt",
                "发布日期": "2022-08-02",
                "摘要": "  Existing metrics used to evaluate table structure recognition algorithms have\nshortcomings with regard to capturing text and empty cells alignment. In this\npaper, we build on prior work and propose a new metric - TEDS based IOU\nsimilarity (TEDS (IOU)) for table structure recognition which uses bounding\nboxes instead of text while simultaneously being robust against the above\ndisadvantages. We demonstrate the effectiveness of our metric against previous\nmetrics through various examples.\n",
                "链接": "https://arxiv.org/abs/2208.00385"
            },
            {
                "文章ID": "49210",
                "标题": "A Structure-Guided Diffusion Model for Large-Hole Image Completion",
                "作者": " Daichi Horita,  Jiaolong Yang,  Dong Chen,  Yuki Koyama,  Kiyoharu Aizawa,  Nicu Sebe",
                "发布日期": "2023-09-07",
                "摘要": "  Image completion techniques have made significant progress in filling missing\nregions (i.e., holes) in images. However, large-hole completion remains\nchallenging due to limited structural information. In this paper, we address\nthis problem by integrating explicit structural guidance into diffusion-based\nimage completion, forming our structure-guided diffusion model (SGDM). It\nconsists of two cascaded diffusion probabilistic models: structure and texture\ngenerators. The structure generator generates an edge image representing\nplausible structures within the holes, which is then used for guiding the\ntexture generation process. To train both generators jointly, we devise a novel\nstrategy that leverages optimal Bayesian denoising, which denoises the output\nof the structure generator in a single step and thus allows backpropagation.\nOur diffusion-based approach enables a diversity of plausible completions,\nwhile the editable edges allow for editing parts of an image. Our experiments\non natural scene (Places) and face (CelebA-HQ) datasets demonstrate that our\nmethod achieves a superior or comparable visual quality compared to\nstate-of-the-art approaches. The code is available for research purposes at\nhttps://github.com/UdonDa/Structure_Guided_Diffusion_Model.\n",
                "链接": "https://arxiv.org/abs/2211.10437"
            },
            {
                "文章ID": "69949",
                "标题": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language\n  Model Society",
                "作者": " Guohao Li,  Hasan Abed Al Kader Hammoud,  Hani Itani,  Dmitrii Khizbullin,  Bernard Ghanem",
                "发布日期": "2023-11-03",
                "摘要": "  The rapid advancement of chat-based language models has led to remarkable\nprogress in complex task-solving. However, their success heavily relies on\nhuman input to guide the conversation, which can be challenging and\ntime-consuming. This paper explores the potential of building scalable\ntechniques to facilitate autonomous cooperation among communicative agents, and\nprovides insight into their \"cognitive\" processes. To address the challenges of\nachieving autonomous cooperation, we propose a novel communicative agent\nframework named role-playing. Our approach involves using inception prompting\nto guide chat agents toward task completion while maintaining consistency with\nhuman intentions. We showcase how role-playing can be used to generate\nconversational data for studying the behaviors and capabilities of a society of\nagents, providing a valuable resource for investigating conversational language\nmodels. In particular, we conduct comprehensive studies on\ninstruction-following cooperation in multi-agent settings. Our contributions\ninclude introducing a novel communicative agent framework, offering a scalable\napproach for studying the cooperative behaviors and capabilities of multi-agent\nsystems, and open-sourcing our library to support research on communicative\nagents and beyond: https://github.com/camel-ai/camel.\n",
                "链接": "https://arxiv.org/abs/2303.17760"
            },
            {
                "文章ID": "120855",
                "标题": "Using a Large Language Model to generate a Design Structure Matrix",
                "作者": " Edwin C. Y. Koh",
                "发布日期": "2023-12-08",
                "摘要": "  The Design Structure Matrix (DSM) is an established method used in dependency\nmodelling, especially in the design of complex engineering systems. The\ngeneration of DSM is traditionally carried out through manual means and can\ninvolve interviewing experts to elicit critical system elements and the\nrelationships between them. Such manual approaches can be time-consuming and\ncostly. This paper presents a workflow that uses a Large Language Model (LLM)\nto support the generation of DSM and improve productivity. A prototype of the\nworkflow was developed in this work and applied on a diesel engine DSM\npublished previously. It was found that the prototype could reproduce 357 out\nof 462 DSM entries published (i.e. 77.3%), suggesting that the work can aid DSM\ngeneration. A no-code version of the prototype is made available online to\nsupport future research.\n",
                "链接": "https://arxiv.org/abs/2312.04134"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            }
        ]
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "124621",
                "标题": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
                "作者": " Mingyuan Zhang,  Huirong Li,  Zhongang Cai,  Jiawei Ren,  Lei Yang,  Ziwei Liu",
                "发布日期": "2023-12-27",
                "摘要": "  Text-driven motion generation has achieved substantial progress with the\nemergence of diffusion models. However, existing methods still struggle to\ngenerate complex motion sequences that correspond to fine-grained descriptions,\ndepicting detailed and accurate spatio-temporal actions. This lack of fine\ncontrollability limits the usage of motion generation to a larger audience. To\ntackle these challenges, we present FineMoGen, a diffusion-based motion\ngeneration and editing framework that can synthesize fine-grained motions, with\nspatial-temporal composition to the user instructions. Specifically, FineMoGen\nbuilds upon diffusion model with a novel transformer architecture dubbed\nSpatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the\nglobal attention template from two perspectives: 1) explicitly modeling the\nconstraints of spatio-temporal composition; and 2) utilizing sparsely-activated\nmixture-of-experts to adaptively extract fine-grained features. To facilitate a\nlarge-scale study on this new fine-grained motion generation task, we\ncontribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336\nfine-grained spatio-temporal descriptions. Extensive experiments validate that\nFineMoGen exhibits superior motion generation quality over state-of-the-art\nmethods. Notably, FineMoGen further enables zero-shot motion editing\ncapabilities with the aid of modern large language models (LLM), which\nfaithfully manipulates motion sequences with fine-grained instructions. Project\nPage: https://mingyuan-zhang.github.io/projects/FineMoGen.html\n",
                "链接": "https://arxiv.org/abs/2312.15004"
            },
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "123024",
                "标题": "Focus on Your Instruction: Fine-grained and Multi-instruction Image\n  Editing by Attention Modulation",
                "作者": " Qin Guo,  Tianwei Lin",
                "发布日期": "2023-12-19",
                "摘要": "  Recently, diffusion-based methods, like InstructPix2Pix (IP2P), have achieved\neffective instruction-based image editing, requiring only natural language\ninstructions from the user. However, these methods often inadvertently alter\nunintended areas and struggle with multi-instruction editing, resulting in\ncompromised outcomes. To address these issues, we introduce the Focus on Your\nInstruction (FoI), a method designed to ensure precise and harmonious editing\nacross multiple instructions without extra training or test-time optimization.\nIn the FoI, we primarily emphasize two aspects: (1) precisely extracting\nregions of interest for each instruction and (2) guiding the denoising process\nto concentrate within these regions of interest. For the first objective, we\nidentify the implicit grounding capability of IP2P from the cross-attention\nbetween instruction and image, then develop an effective mask extraction\nmethod. For the second objective, we introduce a cross attention modulation\nmodule for rough isolation of target editing regions and unrelated regions.\nAdditionally, we introduce a mask-guided disentangle sampling strategy to\nfurther ensure clear region isolation. Experimental results demonstrate that\nFoI surpasses existing methods in both quantitative and qualitative\nevaluations, especially excelling in multi-instruction editing task.\n",
                "链接": "https://arxiv.org/abs/2312.10113"
            },
            {
                "文章ID": "39047",
                "标题": "Towards Fine-Dining Recipe Generation with Generative Pre-trained\n  Transformers",
                "作者": " Konstantinos Katserelis,  Konstantinos Skianis",
                "发布日期": "2022-09-27",
                "摘要": "  Food is essential to human survival. So much so that we have developed\ndifferent recipes to suit our taste needs. In this work, we propose a novel way\nof creating new, fine-dining recipes from scratch using Transformers,\nspecifically auto-regressive language models. Given a small dataset of food\nrecipes, we try to train models to identify cooking techniques, propose novel\nrecipes, and test the power of fine-tuning with minimal data.\n",
                "链接": "https://arxiv.org/abs/2209.12774"
            },
            {
                "文章ID": "117252",
                "标题": "A Fine-Grained Image Description Generation Method Based on Joint\n  Objectives",
                "作者": " Yifan Zhang,  Chunzhen Lin,  Donglin Cao,  Dazhen Lin",
                "发布日期": "2023-11-23",
                "摘要": "  The goal of fine-grained image description generation techniques is to learn\ndetailed information from images and simulate human-like descriptions that\nprovide coherent and comprehensive textual details about the image content.\nCurrently, most of these methods face two main challenges: description\nrepetition and omission. Moreover, the existing evaluation metrics cannot\nclearly reflect the performance of models on these two issues. To address these\nchallenges, we propose an innovative Fine-grained Image Description Generation\nmodel based on Joint Objectives. Furthermore, we introduce new object-based\nevaluation metrics to more intuitively assess the model's performance in\nhandling description repetition and omission. This novel approach combines\nvisual features at both the image level and object level to maximize their\nadvantages and incorporates an object penalty mechanism to reduce description\nrepetition. Experimental results demonstrate that our proposed method\nsignificantly improves the CIDEr evaluation metric, indicating its excellent\nperformance in addressing description repetition and omission issues.\n",
                "链接": "https://arxiv.org/abs/2311.12799"
            },
            {
                "文章ID": "52126",
                "标题": "Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models",
                "作者": " Naoki Matsunaga,  Masato Ishii,  Akio Hayakawa,  Kenji Suzuki,  Takuya Narihira",
                "发布日期": "2023-06-01",
                "摘要": "  Our goal is to develop fine-grained real-image editing methods suitable for\nreal-world applications. In this paper, we first summarize four requirements\nfor these methods and propose a novel diffusion-based image editing framework\nwith pixel-wise guidance that satisfies these requirements. Specifically, we\ntrain pixel-classifiers with a few annotated data and then infer the\nsegmentation map of a target image. Users then manipulate the map to instruct\nhow the image will be edited. We utilize a pre-trained diffusion model to\ngenerate edited images aligned with the user's intention with pixel-wise\nguidance. The effective combination of proposed guidance and other techniques\nenables highly controllable editing with preserving the outside of the edited\narea, which results in meeting our requirements. The experimental results\ndemonstrate that our proposal outperforms the GAN-based method for editing\nquality and speed.\n",
                "链接": "https://arxiv.org/abs/2212.02024"
            },
            {
                "文章ID": "30268",
                "标题": "A Survey on Leveraging Pre-trained Generative Adversarial Networks for\n  Image Editing and Restoration",
                "作者": " Ming Liu,  Yuxiang Wei,  Xiaohe Wu,  Wangmeng Zuo,  Lei Zhang",
                "发布日期": "2022-07-22",
                "摘要": "  Generative adversarial networks (GANs) have drawn enormous attention due to\nthe simple yet effective training mechanism and superior image generation\nquality. With the ability to generate photo-realistic high-resolution (e.g.,\n$1024\\times1024$) images, recent GAN models have greatly narrowed the gaps\nbetween the generated images and the real ones. Therefore, many recent works\nshow emerging interest to take advantage of pre-trained GAN models by\nexploiting the well-disentangled latent space and the learned GAN priors. In\nthis paper, we briefly review recent progress on leveraging pre-trained\nlarge-scale GAN models from three aspects, i.e., 1) the training of large-scale\ngenerative adversarial networks, 2) exploring and understanding the pre-trained\nGAN models, and 3) leveraging these models for subsequent tasks like image\nrestoration and editing. More information about relevant methods and\nrepositories can be found at https://github.com/csmliu/pretrained-GANs.\n",
                "链接": "https://arxiv.org/abs/2207.10309"
            },
            {
                "文章ID": "124901",
                "标题": "SERF: Fine-Grained Interactive 3D Segmentation and Editing with Radiance\n  Fields",
                "作者": " Kaichen Zhou,  Lanqing Hong,  Enze Xie,  Yongxin Yang,  Zhenguo Li,  Wei Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Although significant progress has been made in the field of 2D-based\ninteractive editing, fine-grained 3D-based interactive editing remains\nrelatively unexplored. This limitation can be attributed to two main\nchallenges: the lack of an efficient 3D representation robust to different\nmodifications and the absence of an effective 3D interactive segmentation\nmethod. In this paper, we introduce a novel fine-grained interactive 3D\nsegmentation and editing algorithm with radiance fields, which we refer to as\nSERF. Our method entails creating a neural mesh representation by integrating\nmulti-view algorithms with pre-trained 2D models. Building upon this\nrepresentation, we introduce a novel surface rendering technique that preserves\nlocal information and is robust to deformation. Moreover, this representation\nforms the basis for achieving accurate and interactive 3D segmentation without\nrequiring 3D supervision. Harnessing this representation facilitates a range of\ninteractive 3D editing operations, encompassing tasks such as interactive\ngeometry editing and texture painting. Extensive experiments and visualization\nexamples of editing on both real and synthetic data demonstrate the superiority\nof our method on representation quality and editing ability.\n",
                "链接": "https://arxiv.org/abs/2312.15856"
            },
            {
                "文章ID": "29583",
                "标题": "Effect of Instance Normalization on Fine-Grained Control for\n  Sketch-Based Face Image Generation",
                "作者": " Zhihua Cheng,  Xuejin Chen",
                "发布日期": "2022-07-19",
                "摘要": "  Sketching is an intuitive and effective way for content creation. While\nsignificant progress has been made for photorealistic image generation by using\ngenerative adversarial networks, it remains challenging to take a fine-grained\ncontrol on synthetic content. The instance normalization layer, which is widely\nadopted in existing image translation networks, washes away details in the\ninput sketch and leads to loss of precise control on the desired shape of the\ngenerated face images. In this paper, we comprehensively investigate the effect\nof instance normalization on generating photorealistic face images from\nhand-drawn sketches. We first introduce a visualization approach to analyze the\nfeature embedding for sketches with a group of specific changes. Based on the\nvisual analysis, we modify the instance normalization layers in the baseline\nimage translation model. We elaborate a new set of hand-drawn sketches with 11\ncategories of specially designed changes and conduct extensive experimental\nanalysis. The results and user studies demonstrate that our method markedly\nimprove the quality of synthesized images and the conformance with user\nintention.\n",
                "链接": "https://arxiv.org/abs/2207.08072"
            },
            {
                "文章ID": "96626",
                "标题": "DragNUWA: Fine-grained Control in Video Generation by Integrating Text,\n  Image, and Trajectory",
                "作者": " Shengming Yin,  Chenfei Wu,  Jian Liang,  Jie Shi,  Houqiang Li,  Gong Ming,  Nan Duan",
                "发布日期": "2023-08-17",
                "摘要": "  Controllable video generation has gained significant attention in recent\nyears. However, two main limitations persist: Firstly, most existing works\nfocus on either text, image, or trajectory-based control, leading to an\ninability to achieve fine-grained control in videos. Secondly, trajectory\ncontrol research is still in its early stages, with most experiments being\nconducted on simple datasets like Human3.6M. This constraint limits the models'\ncapability to process open-domain images and effectively handle complex curved\ntrajectories. In this paper, we propose DragNUWA, an open-domain\ndiffusion-based video generation model. To tackle the issue of insufficient\ncontrol granularity in existing works, we simultaneously introduce text, image,\nand trajectory information to provide fine-grained control over video content\nfrom semantic, spatial, and temporal perspectives. To resolve the problem of\nlimited open-domain trajectory control in current research, We propose\ntrajectory modeling with three aspects: a Trajectory Sampler (TS) to enable\nopen-domain control of arbitrary trajectories, a Multiscale Fusion (MF) to\ncontrol trajectories in different granularities, and an Adaptive Training (AT)\nstrategy to generate consistent videos following trajectories. Our experiments\nvalidate the effectiveness of DragNUWA, demonstrating its superior performance\nin fine-grained control in video generation. The homepage link is\n\\url{https://www.microsoft.com/en-us/research/project/dragnuwa/}\n",
                "链接": "https://arxiv.org/abs/2308.08089"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83081",
                "标题": "Text Style Transfer Back-Translation",
                "作者": " Daimeng Wei,  Zhanglin Wu,  Hengchao Shang,  Zongyao Li,  Minghan Wang,  Jiaxin Guo,  Xiaoyu Chen,  Zhengzhe Yu,  Hao Yang",
                "发布日期": "2023-06-05",
                "摘要": "  Back Translation (BT) is widely used in the field of machine translation, as\nit has been proved effective for enhancing translation quality. However, BT\nmainly improves the translation of inputs that share a similar style (to be\nmore specific, translation-like inputs), since the source side of BT data is\nmachine-translated. For natural inputs, BT brings only slight improvements and\nsometimes even adverse effects. To address this issue, we propose Text Style\nTransfer Back Translation (TST BT), which uses a style transfer model to modify\nthe source side of BT data. By making the style of source-side text more\nnatural, we aim to improve the translation of natural inputs. Our experiments\non various language pairs, including both high-resource and low-resource ones,\ndemonstrate that TST BT significantly improves translation performance against\npopular BT benchmarks. In addition, TST BT is proved to be effective in domain\nadaptation so this strategy can be regarded as a general data augmentation\nmethod. Our training code and text style transfer model are open-sourced.\n",
                "链接": "https://arxiv.org/abs/2306.01318"
            },
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "119453",
                "标题": "Relevance-guided Neural Machine Translation",
                "作者": " Isidora Chara Tourni,  Derry Wijaya",
                "发布日期": "2023-12-04",
                "摘要": "  With the advent of the Transformer architecture, Neural Machine Translation\n(NMT) results have shown great improvement lately. However, results in\nlow-resource conditions still lag behind in both bilingual and multilingual\nsetups, due to the limited amount of available monolingual and/or parallel\ndata; hence, the need for methods addressing data scarcity in an efficient, and\nexplainable way, is eminent. We propose an explainability-based training\napproach for NMT, applied in Unsupervised and Supervised model training, for\ntranslation of three languages of varying resources, French, Gujarati, Kazakh,\nto and from English. Our results show our method can be promising, particularly\nwhen training in low-resource conditions, outperforming simple training\nbaselines; though the improvement is marginal, it sets the ground for further\nexploration of the approach and the parameters, and its extension to other\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2312.00214"
            },
            {
                "文章ID": "101979",
                "标题": "Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer",
                "作者": " Yongqi Wang,  Jionghao Bai,  Rongjie Huang,  Ruiqi Li,  Zhiqing Hong,  Zhou Zhao",
                "发布日期": "2023-09-15",
                "摘要": "  Direct speech-to-speech translation (S2ST) with discrete self-supervised\nrepresentations has achieved remarkable accuracy, but is unable to preserve the\nspeaker timbre of the source speech during translation. Meanwhile, the scarcity\nof high-quality speaker-parallel data poses a challenge for learning style\ntransfer between source and target speech. We propose an S2ST framework with an\nacoustic language model based on discrete units from a self-supervised model\nand a neural codec for style transfer. The acoustic language model leverages\nself-supervised in-context learning, acquiring the ability for style transfer\nwithout relying on any speaker-parallel data, thereby overcoming the issue of\ndata scarcity. By using extensive training data, our model achieves zero-shot\ncross-lingual style transfer on previously unseen source languages. Experiments\nshow that our model generates translated speeches with high fidelity and style\nsimilarity. Audio samples are available at http://stylelm.github.io/ .\n",
                "链接": "https://arxiv.org/abs/2309.07566"
            },
            {
                "文章ID": "7091",
                "标题": "Screening Gender Transfer in Neural Machine Translation",
                "作者": " Guillaume Wisniewski,  Lichao Zhu,  Nicolas Ballier,  François Yvon",
                "发布日期": "2022-02-28",
                "摘要": "  This paper aims at identifying the information flow in state-of-the-art\nmachine translation systems, taking as example the transfer of gender when\ntranslating from French into English. Using a controlled set of examples, we\nexperiment several ways to investigate how gender information circulates in a\nencoder-decoder architecture considering both probing techniques as well as\ninterventions on the internal representations used in the MT system. Our\nresults show that gender information can be found in all token representations\nbuilt by the encoder and the decoder and lead us to conclude that there are\nmultiple pathways for gender transfer.\n",
                "链接": "https://arxiv.org/abs/2202.12568"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "521",
                "标题": "Consistent Style Transfer",
                "作者": " Xuan Luo,  Zhen Han,  Lingkang Yang,  Lingling Zhang",
                "发布日期": "2022-01-10",
                "摘要": "  Recently, attentional arbitrary style transfer methods have been proposed to\nachieve fine-grained results, which manipulates the point-wise similarity\nbetween content and style features for stylization. However, the attention\nmechanism based on feature points ignores the feature multi-manifold\ndistribution, where each feature manifold corresponds to a semantic region in\nthe image. Consequently, a uniform content semantic region is rendered by\nhighly different patterns from various style semantic regions, producing\ninconsistent stylization results with visual artifacts. We proposed the\nprogressive attentional manifold alignment (PAMA) to alleviate this problem,\nwhich repeatedly applies attention operations and space-aware interpolations.\nThe attention operation rearranges style features dynamically according to the\nspatial distribution of content features. This makes the content and style\nmanifolds correspond on the feature map. Then the space-aware interpolation\nadaptively interpolates between the corresponding content and style manifolds\nto increase their similarity. By gradually aligning the content manifolds to\nstyle manifolds, the proposed PAMA achieves state-of-the-art performance while\navoiding the inconsistency of semantic regions. Codes are available at\nhttps://github.com/computer-vision2022/PAMA.\n",
                "链接": "https://arxiv.org/abs/2201.02233"
            },
            {
                "文章ID": "75710",
                "标题": "Learning Language-Specific Layers for Multilingual Machine Translation",
                "作者": " Telmo Pessoa Pires,  Robin M. Schmidt,  Yi-Hsiu Liao,  Stephan Peitz",
                "发布日期": "2023-05-05",
                "摘要": "  Multilingual Machine Translation promises to improve translation quality\nbetween non-English languages. This is advantageous for several reasons, namely\nlower latency (no need to translate twice), and reduced error cascades (e.g.,\navoiding losing gender and formality information when translating through\nEnglish). On the downside, adding more languages reduces model capacity per\nlanguage, which is usually countered by increasing the overall model size,\nmaking training harder and inference slower. In this work, we introduce\nLanguage-Specific Transformer Layers (LSLs), which allow us to increase model\ncapacity, while keeping the amount of computation and the number of parameters\nused in the forward pass constant. The key idea is to have some layers of the\nencoder be source or target language-specific, while keeping the remaining\nlayers shared. We study the best way to place these layers using a neural\narchitecture search inspired approach, and achieve an improvement of 1.3 chrF\n(1.5 spBLEU) points over not using LSLs on a separate decoder architecture, and\n1.9 chrF (2.2 spBLEU) on a shared decoder one.\n",
                "链接": "https://arxiv.org/abs/2305.02665"
            },
            {
                "文章ID": "113724",
                "标题": "Narrowing the Gap between Zero- and Few-shot Machine Translation by\n  Matching Styles",
                "作者": " Weiting Tan,  Haoran Xu,  Lingfeng Shen,  Shuyue Stella Li,  Kenton Murray,  Philipp Koehn,  Benjamin Van Durme,  Yunmo Chen",
                "发布日期": "2023-11-07",
                "摘要": "  Large language models trained primarily in a monolingual setting have\ndemonstrated their ability to generalize to machine translation using zero- and\nfew-shot examples with in-context learning. However, even though zero-shot\ntranslations are relatively good, there remains a discernible gap comparing\ntheir performance with the few-shot setting. In this paper, we investigate the\nfactors contributing to this gap and find that this gap can largely be closed\n(for about 70%) by matching the writing styles of the target corpus.\nAdditionally, we explore potential approaches to enhance zero-shot baselines\nwithout the need for parallel demonstration examples, providing valuable\ninsights into how these methods contribute to improving translation metrics.\n",
                "链接": "https://arxiv.org/abs/2311.02310"
            },
            {
                "文章ID": "10215",
                "标题": "Triangular Transfer: Freezing the Pivot for Triangular Machine\n  Translation",
                "作者": " Meng Zhang,  Liangyou Li,  Qun Liu",
                "发布日期": "2022-03-18",
                "摘要": "  Triangular machine translation is a special case of low-resource machine\ntranslation where the language pair of interest has limited parallel data, but\nboth languages have abundant parallel data with a pivot language. Naturally,\nthe key to triangular machine translation is the successful exploitation of\nsuch auxiliary data. In this work, we propose a transfer-learning-based\napproach that utilizes all types of auxiliary data. As we train auxiliary\nsource-pivot and pivot-target translation models, we initialize some parameters\nof the pivot side with a pre-trained language model and freeze them to\nencourage both translation models to work in the same pivot language space, so\nthat they can be smoothly transferred to the source-target translation model.\nExperiments show that our approach can outperform previous ones.\n",
                "链接": "https://arxiv.org/abs/2203.09027"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "124014",
                "标题": "CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks\n  for Chinese Large Language Models",
                "作者": " Dan Shi,  Chaobin You,  Jiantao Huang,  Taihao Li,  Deyi Xiong",
                "发布日期": "2023-12-21",
                "摘要": "  As an indispensable ingredient of intelligence, commonsense reasoning is\ncrucial for large language models (LLMs) in real-world scenarios. In this\npaper, we propose CORECODE, a dataset that contains abundant commonsense\nknowledge manually annotated on dyadic dialogues, to evaluate the commonsense\nreasoning and commonsense conflict detection capabilities of Chinese LLMs. We\ncategorize commonsense knowledge in everyday conversations into three\ndimensions: entity, event, and social interaction. For easy and consistent\nannotation, we standardize the form of commonsense knowledge annotation in\nopen-domain dialogues as \"domain: slot = value\". A total of 9 domains and 37\nslots are defined to capture diverse commonsense knowledge. With these\npre-defined domains and slots, we collect 76,787 commonsense knowledge\nannotations from 19,700 dialogues through crowdsourcing. To evaluate and\nenhance the commonsense reasoning capability for LLMs on the curated dataset,\nwe establish a series of dialogue-level reasoning and detection tasks,\nincluding commonsense knowledge filling, commonsense knowledge generation,\ncommonsense conflict phrase detection, domain identification, slot\nidentification, and event causal inference. A wide variety of existing\nopen-source Chinese LLMs are evaluated with these tasks on our dataset.\nExperimental results demonstrate that these models are not competent to predict\nCORECODE's plentiful reasoning content, and even ChatGPT could only achieve\n0.275 and 0.084 accuracy on the domain identification and slot identification\ntasks under the zero-shot setting. We release the data and codes of CORECODE at\nhttps://github.com/danshi777/CORECODE to promote commonsense reasoning\nevaluation and study of LLMs in the context of daily conversations.\n",
                "链接": "https://arxiv.org/abs/2312.12853"
            },
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "27917",
                "标题": "A Dataset on Malicious Paper Bidding in Peer Review",
                "作者": " Steven Jecmen,  Minji Yoon,  Vincent Conitzer,  Nihar B. Shah,  Fei Fang",
                "发布日期": "2023-03-14",
                "摘要": "  In conference peer review, reviewers are often asked to provide \"bids\" on\neach submitted paper that express their interest in reviewing that paper. A\npaper assignment algorithm then uses these bids (along with other data) to\ncompute a high-quality assignment of reviewers to papers. However, this process\nhas been exploited by malicious reviewers who strategically bid in order to\nunethically manipulate the paper assignment, crucially undermining the peer\nreview process. For example, these reviewers may aim to get assigned to a\nfriend's paper as part of a quid-pro-quo deal. A critical impediment towards\ncreating and evaluating methods to mitigate this issue is the lack of any\npublicly-available data on malicious paper bidding. In this work, we collect\nand publicly release a novel dataset to fill this gap, collected from a mock\nconference activity where participants were instructed to bid either honestly\nor maliciously. We further provide a descriptive analysis of the bidding\nbehavior, including our categorization of different strategies employed by\nparticipants. Finally, we evaluate the ability of each strategy to manipulate\nthe assignment, and also evaluate the performance of some simple algorithms\nmeant to detect malicious bidding. The performance of these detection\nalgorithms can be taken as a baseline for future research on detecting\nmalicious bidding.\n",
                "链接": "https://arxiv.org/abs/2207.02303"
            },
            {
                "文章ID": "84049",
                "标题": "Some voices are too common: Building fair speech recognition systems\n  using the Common Voice dataset",
                "作者": " Lucas Maison,  Yannick Estève",
                "发布日期": "2023-06-07",
                "摘要": "  Automatic speech recognition (ASR) systems become increasingly efficient\nthanks to new advances in neural network training like self-supervised\nlearning. However, they are known to be unfair toward certain groups, for\ninstance, people speaking with an accent. In this work, we use the French\nCommon Voice dataset to quantify the biases of a pre-trained wav2vec~2.0 model\ntoward several demographic groups. By fine-tuning the pre-trained model on a\nvariety of fixed-size, carefully crafted training sets, we demonstrate the\nimportance of speaker diversity. We also run an in-depth analysis of the Common\nVoice corpus and identify important shortcomings that should be taken into\naccount by users of this dataset.\n",
                "链接": "https://arxiv.org/abs/2306.03773"
            },
            {
                "文章ID": "100573",
                "标题": "A Critical Review of Common Log Data Sets Used for Evaluation of\n  Sequence-based Anomaly Detection Techniques",
                "作者": " Max Landauer,  Florian Skopik,  Markus Wurzenberger",
                "发布日期": "2023-09-07",
                "摘要": "  Log data store event execution patterns that correspond to underlying\nworkflows of systems or applications. While most logs are informative, log data\nalso include artifacts that indicate failures or incidents. Accordingly, log\ndata are often used to evaluate anomaly detection techniques that aim to\nautomatically disclose unexpected or otherwise relevant system behavior\npatterns. Recently, detection approaches leveraging deep learning have\nincreasingly focused on anomalies that manifest as changes of sequential\npatterns within otherwise normal event traces. Several publicly available data\nsets, such as HDFS, BGL, Thunderbird, OpenStack, and Hadoop, have since become\nstandards for evaluating these anomaly detection techniques, however, the\nappropriateness of these data sets has not been closely investigated in the\npast. In this paper we therefore analyze six publicly available log data sets\nwith focus on the manifestations of anomalies and simple techniques for their\ndetection. Our findings suggest that most anomalies are not directly related to\nsequential manifestations and that advanced detection techniques are not\nrequired to achieve high detection rates on these data sets.\n",
                "链接": "https://arxiv.org/abs/2309.02854"
            },
            {
                "文章ID": "76534",
                "标题": "VCSUM: A Versatile Chinese Meeting Summarization Dataset",
                "作者": " Han Wu,  Mingjie Zhan,  Haochen Tan,  Zhaohui Hou,  Ding Liang,  Linqi Song",
                "发布日期": "2023-05-16",
                "摘要": "  Compared to news and chat summarization, the development of meeting\nsummarization is hugely decelerated by the limited data. To this end, we\nintroduce a versatile Chinese meeting summarization dataset, dubbed VCSum,\nconsisting of 239 real-life meetings, with a total duration of over 230 hours.\nWe claim our dataset is versatile because we provide the annotations of topic\nsegmentation, headlines, segmentation summaries, overall meeting summaries, and\nsalient sentences for each meeting transcript. As such, the dataset can adapt\nto various summarization tasks or methods, including segmentation-based\nsummarization, multi-granularity summarization and retrieval-then-generate\nsummarization. Our analysis confirms the effectiveness and robustness of VCSum.\nWe also provide a set of benchmark models regarding different downstream\nsummarization tasks on VCSum to facilitate further research. The dataset and\ncode will be released at https://github.com/hahahawu/VCSum.\n",
                "链接": "https://arxiv.org/abs/2305.05280"
            },
            {
                "文章ID": "85346",
                "标题": "LTCR: Long-Text Chinese Rumor Detection Dataset",
                "作者": " Ziyang Ma,  Mengsha Liu,  Guian Fang,  Ying Shen",
                "发布日期": "2023-06-14",
                "摘要": "  False information can spread quickly on social media, negatively influencing\nthe citizens' behaviors and responses to social events. To better detect all of\nthe fake news, especially long texts which are harder to find completely, a\nLong-Text Chinese Rumor detection dataset named LTCR is proposed. The LTCR\ndataset provides a valuable resource for accurately detecting misinformation,\nespecially in the context of complex fake news related to COVID-19. The dataset\nconsists of 1,729 and 500 pieces of real and fake news, respectively. The\naverage lengths of real and fake news are approximately 230 and 152 characters.\nWe also propose \\method, Salience-aware Fake News Detection Model, which\nachieves the highest accuracy (95.85%), fake news recall (90.91%) and F-score\n(90.60%) on the dataset. (https://github.com/Enderfga/DoubleCheck)\n",
                "链接": "https://arxiv.org/abs/2306.07201"
            },
            {
                "文章ID": "1409",
                "标题": "Common Phone: A Multilingual Dataset for Robust Acoustic Modelling",
                "作者": " Philipp Klumpp,  Tomás Arias-Vergara,  Paula Andrea Pérez-Toro,  Elmar Nöth,  Juan Rafael Orozco-Arroyave",
                "发布日期": "2022-02-01",
                "摘要": "  Current state of the art acoustic models can easily comprise more than 100\nmillion parameters. This growing complexity demands larger training datasets to\nmaintain a decent generalization of the final decision function. An ideal\ndataset is not necessarily large in size, but large with respect to the amount\nof unique speakers, utilized hardware and varying recording conditions. This\nenables a machine learning model to explore as much of the domain-specific\ninput space as possible during parameter estimation. This work introduces\nCommon Phone, a gender-balanced, multilingual corpus recorded from more than\n11.000 contributors via Mozilla's Common Voice project. It comprises around 116\nhours of speech enriched with automatically generated phonetic segmentation. A\nWav2Vec 2.0 acoustic model was trained with the Common Phone to perform\nphonetic symbol recognition and validate the quality of the generated phonetic\nannotation. The architecture achieved a PER of 18.1 % on the entire test set,\ncomputed with all 101 unique phonetic symbols, showing slight differences\nbetween the individual languages. We conclude that Common Phone provides\nsufficient variability and reliable phonetic annotation to help bridging the\ngap between research and application of acoustic models.\n",
                "链接": "https://arxiv.org/abs/2201.05912"
            },
            {
                "文章ID": "26793",
                "标题": "Bengali Common Voice Speech Dataset for Automatic Speech Recognition",
                "作者": " Samiul Alam,  Asif Sushmit,  Zaowad Abdullah,  Shahrin Nakkhatra,  MD. Nazmuddoha Ansary,  Syed Mobassir Hossen,  Sazia Morshed Mehnaz,  Tahsin Reasat,  Ahmed Imtiaz Humayun",
                "发布日期": "2022-06-30",
                "摘要": "  Bengali is one of the most spoken languages in the world with over 300\nmillion speakers globally. Despite its popularity, research into the\ndevelopment of Bengali speech recognition systems is hindered due to the lack\nof diverse open-source datasets. As a way forward, we have crowdsourced the\nBengali Common Voice Speech Dataset, which is a sentence-level automatic speech\nrecognition corpus. Collected on the Mozilla Common Voice platform, the dataset\nis part of an ongoing campaign that has led to the collection of over 400 hours\nof data in 2 months and is growing rapidly. Our analysis shows that this\ndataset has more speaker, phoneme, and environmental diversity compared to the\nOpenSLR Bengali ASR dataset, the largest existing open-source Bengali speech\ndataset. We present insights obtained from the dataset and discuss key\nlinguistic challenges that need to be addressed in future versions.\nAdditionally, we report the current performance of a few Automatic Speech\nRecognition (ASR) algorithms and set a benchmark for future research.\n",
                "链接": "https://arxiv.org/abs/2206.14053"
            },
            {
                "文章ID": "67515",
                "标题": "Right the docs: Characterising voice dataset documentation practices\n  used in machine learning",
                "作者": " Kathy Reid,  Elizabeth T. Williams",
                "发布日期": "2023-03-21",
                "摘要": "  Voice-enabled technology is quickly becoming ubiquitous, and is constituted\nfrom machine learning (ML)-enabled components such as speech recognition and\nvoice activity detection. However, these systems don't yet work well for\neveryone. They exhibit bias - the systematic and unfair discrimination against\nindividuals or cohorts of individuals in favour of others (Friedman &\nNissembaum, 1996) - across axes such as age, gender and accent.\n  ML is reliant on large datasets for training. Dataset documentation is\ndesigned to give ML Practitioners (MLPs) a better understanding of a dataset's\ncharacteristics. However, there is a lack of empirical research on voice\ndataset documentation specifically. Additionally, while MLPs are frequent\nparticipants in fairness research, little work focuses on those who work with\nvoice data. Our work makes an empirical contribution to this gap.\n  Here, we combine two methods to form an exploratory study. First, we\nundertake 13 semi-structured interviews, exploring multiple perspectives of\nvoice dataset documentation practice. Using open and axial coding methods, we\nexplore MLPs' practices through the lenses of roles and tradeoffs. Drawing from\nthis work, we then purposively sample voice dataset documents (VDDs) for 9\nvoice datasets. Our findings then triangulate these two methods, using the\nlenses of MLP roles and trade-offs. We find that current VDD practices are\ninchoate, inadequate and incommensurate. The characteristics of voice datasets\nare codified in fragmented, disjoint ways that often do not meet the needs of\nMLPs. Moreover, they cannot be readily compared, presenting a barrier to\npractitioners' bias reduction efforts.\n  We then discuss the implications of these findings for bias practices in\nvoice data and speech technologies. We conclude by setting out a program of\nfuture work to address these findings -- that is, how we may \"right the docs\".\n",
                "链接": "https://arxiv.org/abs/2303.10721"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "34843",
                "标题": "Data Augmentation for Graph Data: Recent Advancements",
                "作者": " Maria Marrium,  Arif Mahmood",
                "发布日期": "2022-08-26",
                "摘要": "  Graph Neural Network (GNNs) based methods have recently become a popular tool\nto deal with graph data because of their ability to incorporate structural\ninformation. The only hurdle in the performance of GNNs is the lack of labeled\ndata. Data Augmentation techniques for images and text data can not be used for\ngraph data because of the complex and non-euclidean structure of graph data.\nThis gap has forced researchers to shift their focus towards the development of\ndata augmentation techniques for graph data. Most of the proposed Graph Data\nAugmentation (GDA) techniques are task-specific. In this paper, we survey the\nexisting GDA techniques based on different graph tasks. This survey not only\nprovides a reference to the research community of GDA but also provides the\nnecessary information to the researchers of other domains.\n",
                "链接": "https://arxiv.org/abs/2208.11973"
            },
            {
                "文章ID": "3131",
                "标题": "Adversarial Examples for Good: Adversarial Examples Guided Imbalanced\n  Learning",
                "作者": " Jie Zhang,  Lei Zhang,  Gang Li,  Chao Wu",
                "发布日期": "2022-08-31",
                "摘要": "  Adversarial examples are inputs for machine learning models that have been\ndesigned by attackers to cause the model to make mistakes. In this paper, we\ndemonstrate that adversarial examples can also be utilized for good to improve\nthe performance of imbalanced learning. We provide a new perspective on how to\ndeal with imbalanced data: adjust the biased decision boundary by training with\nGuiding Adversarial Examples (GAEs). Our method can effectively increase the\naccuracy of minority classes while sacrificing little accuracy on majority\nclasses. We empirically show, on several benchmark datasets, our proposed\nmethod is comparable to the state-of-the-art method. To our best knowledge, we\nare the first to deal with imbalanced learning with adversarial examples.\n",
                "链接": "https://arxiv.org/abs/2201.12356"
            },
            {
                "文章ID": "104776",
                "标题": "Adversarial Examples Might be Avoidable: The Role of Data Concentration\n  in Adversarial Robustness",
                "作者": " Ambar Pal,  Jeremias Sulam,  René Vidal",
                "发布日期": "2023-09-29",
                "摘要": "  The susceptibility of modern machine learning classifiers to adversarial\nexamples has motivated theoretical results suggesting that these might be\nunavoidable. However, these results can be too general to be applicable to\nnatural data distributions. Indeed, humans are quite robust for tasks involving\nvision. This apparent conflict motivates a deeper dive into the question: Are\nadversarial examples truly unavoidable? In this work, we theoretically\ndemonstrate that a key property of the data distribution -- concentration on\nsmall-volume subsets of the input space -- determines whether a robust\nclassifier exists. We further demonstrate that, for a data distribution\nconcentrated on a union of low-dimensional linear subspaces, exploiting data\nstructure naturally leads to classifiers that enjoy good robustness guarantees,\nimproving upon methods for provable certification in certain regimes.\n",
                "链接": "https://arxiv.org/abs/2309.16096"
            },
            {
                "文章ID": "83372",
                "标题": "Generative Adversarial Networks for Data Augmentation",
                "作者": " Angona Biswas,  MD Abdullah Al Nasim,  Al Imran,  Anika Tabassum Sejuty,  Fabliha Fairooz,  Sai Puppala,  Sajedul Talukder",
                "发布日期": "2023-06-09",
                "摘要": "  One way to expand the available dataset for training AI models in the medical\nfield is through the use of Generative Adversarial Networks (GANs) for data\naugmentation. GANs work by employing a generator network to create new data\nsamples that are then assessed by a discriminator network to determine their\nsimilarity to real samples. The discriminator network is taught to\ndifferentiate between actual and synthetic samples, while the generator system\nis trained to generate data that closely resemble real ones. The process is\nrepeated until the generator network can produce synthetic data that is\nindistinguishable from genuine data. GANs have been utilized in medical image\nanalysis for various tasks, including data augmentation, image creation, and\ndomain adaptation. They can generate synthetic samples that can be used to\nincrease the available dataset, especially in cases where obtaining large\namounts of genuine data is difficult or unethical. However, it is essential to\nnote that the use of GANs in medical imaging is still an active area of\nresearch to ensure that the produced images are of high quality and suitable\nfor use in clinical settings.\n",
                "链接": "https://arxiv.org/abs/2306.02019"
            },
            {
                "文章ID": "11996",
                "标题": "Robust Unlearnable Examples: Protecting Data Against Adversarial\n  Learning",
                "作者": " Shaopeng Fu,  Fengxiang He,  Yang Liu,  Li Shen,  Dacheng Tao",
                "发布日期": "2022-03-29",
                "摘要": "  The tremendous amount of accessible data in cyberspace face the risk of being\nunauthorized used for training deep learning models. To address this concern,\nmethods are proposed to make data unlearnable for deep learning models by\nadding a type of error-minimizing noise. However, such conferred unlearnability\nis found fragile to adversarial training. In this paper, we design new methods\nto generate robust unlearnable examples that are protected from adversarial\ntraining. We first find that the vanilla error-minimizing noise, which\nsuppresses the informative knowledge of data via minimizing the corresponding\ntraining loss, could not effectively minimize the adversarial training loss.\nThis explains the vulnerability of error-minimizing noise in adversarial\ntraining. Based on the observation, robust error-minimizing noise is then\nintroduced to reduce the adversarial training loss. Experiments show that the\nunlearnability brought by robust error-minimizing noise can effectively protect\ndata from adversarial training in various scenarios. The code is available at\n\\url{https://github.com/fshp971/robust-unlearnable-examples}.\n",
                "链接": "https://arxiv.org/abs/2203.14533"
            },
            {
                "文章ID": "43317",
                "标题": "Towards Generating Adversarial Examples on Mixed-type Data",
                "作者": " Han Xu,  Menghai Pan,  Zhimeng Jiang,  Huiyuan Chen,  Xiaoting Li,  Mahashweta Das,  Hao Yang",
                "发布日期": "2022-10-19",
                "摘要": "  The existence of adversarial attacks (or adversarial examples) brings huge\nconcern about the machine learning (ML) model's safety issues. For many\nsafety-critical ML tasks, such as financial forecasting, fraudulent detection,\nand anomaly detection, the data samples are usually mixed-type, which contain\nplenty of numerical and categorical features at the same time. However, how to\ngenerate adversarial examples with mixed-type data is still seldom studied. In\nthis paper, we propose a novel attack algorithm M-Attack, which can effectively\ngenerate adversarial examples in mixed-type data. Based on M-Attack, attackers\ncan attempt to mislead the targeted classification model's prediction, by only\nslightly perturbing both the numerical and categorical features in the given\ndata samples. More importantly, by adding designed regularizations, our\ngenerated adversarial examples can evade potential detection models, which\nmakes the attack indeed insidious. Through extensive empirical studies, we\nvalidate the effectiveness and efficiency of our attack method and evaluate the\nrobustness of existing classification models against our proposed attack. The\nexperimental results highlight the feasibility of generating adversarial\nexamples toward machine learning models in real-world applications.\n",
                "链接": "https://arxiv.org/abs/2210.09405"
            },
            {
                "文章ID": "68099",
                "标题": "Wasserstein Adversarial Examples on Univariant Time Series Data",
                "作者": " Wenjie Wang,  Li Xiong,  Jian Lou",
                "发布日期": "2023-03-23",
                "摘要": "  Adversarial examples are crafted by adding indistinguishable perturbations to\nnormal examples in order to fool a well-trained deep learning model to\nmisclassify. In the context of computer vision, this notion of\nindistinguishability is typically bounded by $L_{\\infty}$ or other norms.\nHowever, these norms are not appropriate for measuring indistinguishiability\nfor time series data. In this work, we propose adversarial examples in the\nWasserstein space for time series data for the first time and utilize\nWasserstein distance to bound the perturbation between normal examples and\nadversarial examples. We introduce Wasserstein projected gradient descent\n(WPGD), an adversarial attack method for perturbing univariant time series\ndata. We leverage the closed-form solution of Wasserstein distance in the 1D\nspace to calculate the projection step of WPGD efficiently with the gradient\ndescent method. We further propose a two-step projection so that the search of\nadversarial examples in the Wasserstein space is guided and constrained by\nEuclidean norms to yield more effective and imperceptible perturbations. We\nempirically evaluate the proposed attack on several time series datasets in the\nhealthcare domain. Extensive results demonstrate that the Wasserstein attack is\npowerful and can successfully attack most of the target classifiers with a high\nattack success rate. To better study the nature of Wasserstein adversarial\nexample, we evaluate a strong defense mechanism named Wasserstein smoothing for\npotential certified robustness defense. Although the defense can achieve some\naccuracy gain, it still has limitations in many cases and leaves space for\ndeveloping a stronger certified robustness method to Wasserstein adversarial\nexamples on univariant time series data.\n",
                "链接": "https://arxiv.org/abs/2303.12357"
            },
            {
                "文章ID": "73820",
                "标题": "StyLess: Boosting the Transferability of Adversarial Examples",
                "作者": " Kaisheng Liang,  Bin Xiao",
                "发布日期": "2023-04-25",
                "摘要": "  Adversarial attacks can mislead deep neural networks (DNNs) by adding\nimperceptible perturbations to benign examples. The attack transferability\nenables adversarial examples to attack black-box DNNs with unknown\narchitectures or parameters, which poses threats to many real-world\napplications. We find that existing transferable attacks do not distinguish\nbetween style and content features during optimization, limiting their attack\ntransferability. To improve attack transferability, we propose a novel attack\nmethod called style-less perturbation (StyLess). Specifically, instead of using\na vanilla network as the surrogate model, we advocate using stylized networks,\nwhich encode different style features by perturbing an adaptive instance\nnormalization. Our method can prevent adversarial examples from using\nnon-robust style features and help generate transferable perturbations.\nComprehensive experiments show that our method can significantly improve the\ntransferability of adversarial examples. Furthermore, our approach is generic\nand can outperform state-of-the-art transferable attacks when combined with\nother attack techniques.\n",
                "链接": "https://arxiv.org/abs/2304.11579"
            },
            {
                "文章ID": "103155",
                "标题": "AttentionMix: Data augmentation method that relies on BERT attention\n  mechanism",
                "作者": " Dominik Lewy,  Jacek Mańdziuk",
                "发布日期": "2023-09-21",
                "摘要": "  The Mixup method has proven to be a powerful data augmentation technique in\nComputer Vision, with many successors that perform image mixing in a guided\nmanner. One of the interesting research directions is transferring the\nunderlying Mixup idea to other domains, e.g. Natural Language Processing (NLP).\nEven though there already exist several methods that apply Mixup to textual\ndata, there is still room for new, improved approaches. In this work, we\nintroduce AttentionMix, a novel mixing method that relies on attention-based\ninformation. While the paper focuses on the BERT attention mechanism, the\nproposed approach can be applied to generally any attention-based model.\nAttentionMix is evaluated on 3 standard sentiment classification datasets and\nin all three cases outperforms two benchmark approaches that utilize Mixup\nmechanism, as well as the vanilla BERT method. The results confirm that the\nattention-based information can be effectively used for data augmentation in\nthe NLP domain.\n",
                "链接": "https://arxiv.org/abs/2309.11104"
            },
            {
                "文章ID": "64448",
                "标题": "Rethinking the Effect of Data Augmentation in Adversarial Contrastive\n  Learning",
                "作者": " Rundong Luo,  Yifei Wang,  Yisen Wang",
                "发布日期": "2023-03-06",
                "摘要": "  Recent works have shown that self-supervised learning can achieve remarkable\nrobustness when integrated with adversarial training (AT). However, the\nrobustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT)\nremains significant. Motivated by this observation, we revisit existing self-AT\nmethods and discover an inherent dilemma that affects self-AT robustness:\neither strong or weak data augmentations are harmful to self-AT, and a medium\nstrength is insufficient to bridge the gap. To resolve this dilemma, we propose\na simple remedy named DYNACL (Dynamic Adversarial Contrastive Learning). In\nparticular, we propose an augmentation schedule that gradually anneals from a\nstrong augmentation to a weak one to benefit from both extreme cases. Besides,\nwe adopt a fast post-processing stage for adapting it to downstream tasks.\nThrough extensive experiments, we show that DYNACL can improve state-of-the-art\nself-AT robustness by 8.84% under Auto-Attack on the CIFAR-10 dataset, and can\neven outperform vanilla supervised adversarial training for the first time. Our\ncode is available at \\url{https://github.com/PKU-ML/DYNACL}.\n",
                "链接": "https://arxiv.org/abs/2303.01289"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54835",
                "标题": "Feature Acquisition using Monte Carlo Tree Search",
                "作者": " Sungsoo Lim,  Diego Klabjan,  Mark Shapiro",
                "发布日期": "2022-12-23",
                "摘要": "  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n",
                "链接": "https://arxiv.org/abs/2212.11360"
            },
            {
                "文章ID": "3914",
                "标题": "On Monte Carlo Tree Search for Weighted Vertex Coloring",
                "作者": " Cyril Grelier,  Olivier Goudet,  Jin-Kao Hao",
                "发布日期": "2022-04-08",
                "摘要": "  This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.\n",
                "链接": "https://arxiv.org/abs/2202.01665"
            },
            {
                "文章ID": "53055",
                "标题": "Lookahead Pathology in Monte-Carlo Tree Search",
                "作者": " Khoi P. N. Nguyen,  Raghuram Ramanujan",
                "发布日期": "2022-12-13",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is an adversarial search paradigm that first\nfound prominence with its success in the domain of computer Go. Early\ntheoretical work established the game-theoretic soundness and convergence\nbounds for Upper Confidence bounds applied to Trees (UCT), the most popular\ninstantiation of MCTS; however, there remain notable gaps in our understanding\nof how UCT behaves in practice. In this work, we address one such gap by\nconsidering the question of whether UCT can exhibit lookahead pathology -- a\nparadoxical phenomenon first observed in Minimax search where greater search\neffort leads to worse decision-making. We introduce a novel family of synthetic\ngames that offer rich modeling possibilities while remaining amenable to\nmathematical analysis. Our theoretical and experimental results suggest that\nUCT is indeed susceptible to pathological behavior in a range of games drawn\nfrom this family.\n",
                "链接": "https://arxiv.org/abs/2212.05208"
            },
            {
                "文章ID": "67092",
                "标题": "Proof Number Based Monte-Carlo Tree Search",
                "作者": " Jakub Kowalski,  Elliot Doe,  Mark H. M. Winands,  Daniel Górski,  Dennis J. N. J. Soemers",
                "发布日期": "2023-12-22",
                "摘要": "  This paper proposes a new game-search algorithm, PN-MCTS, which combines\nMonte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two\nalgorithms have been successfully applied for decision making in a range of\ndomains. We define three areas where the additional knowledge provided by the\nproof and disproof numbers gathered in MCTS trees might be used: final move\nselection, solving subtrees, and the UCB1 selection mechanism. We test all\npossible combinations on different time settings, playing against vanilla UCT\non several games: Lines of Action ($7$$\\times$$7$ and $8$$\\times$$8$ board\nsizes), MiniShogi, Knightthrough, and Awari. Furthermore, we extend this new\nalgorithm to properly address games with draws, like Awari, by adding an\nadditional layer of PNS on top of the MCTS tree. The experiments show that\nPN-MCTS confidently outperforms MCTS in all tested game domains, achieving win\nrates up to 96.2\\% for Lines of Action.\n",
                "链接": "https://arxiv.org/abs/2303.09449"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "116381",
                "标题": "Graph Sparsifications using Neural Network Assisted Monte Carlo Tree\n  Search",
                "作者": " Alvin Chiu,  Mithun Ghosh,  Reyan Ahmed,  Kwang-Sung Jun,  Stephen Kobourov,  Michael T. Goodrich",
                "发布日期": "2023-11-20",
                "摘要": "  Graph neural networks have been successful for machine learning, as well as\nfor combinatorial and graph problems such as the Subgraph Isomorphism Problem\nand the Traveling Salesman Problem. We describe an approach for computing graph\nsparsifiers by combining a graph neural network and Monte Carlo Tree Search. We\nfirst train a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a sparsifier. The proposed method consistently\noutperforms several standard approximation algorithms on different types of\ngraphs and often finds the optimal solution.\n",
                "链接": "https://arxiv.org/abs/2311.10316"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "107708",
                "标题": "Accelerating Monte Carlo Tree Search with Probability Tree State\n  Abstraction",
                "作者": " Yangqing Fu,  Ming Sun,  Buqing Nie,  Yue Gao",
                "发布日期": "2023-10-11",
                "摘要": "  Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have\nachieved superhuman performance in many challenging tasks. However, the\ncomputational complexity of MCTS-based algorithms is influenced by the size of\nthe search space. To address this issue, we propose a novel probability tree\nstate abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A\ngeneral tree state abstraction with path transitivity is defined. In addition,\nthe probability tree state abstraction is proposed for fewer mistakes during\nthe aggregation step. Furthermore, the theoretical guarantees of the\ntransitivity and aggregation error bound are justified. To evaluate the\neffectiveness of the PTSA algorithm, we integrate it with state-of-the-art\nMCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental\nresults on different tasks demonstrate that our method can accelerate the\ntraining process of state-of-the-art algorithms with 10%-45% search space\nreduction.\n",
                "链接": "https://arxiv.org/abs/2310.06513"
            },
            {
                "文章ID": "7216",
                "标题": "Decision Making in Non-Stationary Environments with Policy-Augmented\n  Monte Carlo Tree Search",
                "作者": " Geoffrey Pettet,  Ayan Mukhopadhyay,  Abhishek Dubey",
                "发布日期": "2022-03-01",
                "摘要": "  Decision-making under uncertainty (DMU) is present in many important\nproblems. An open challenge is DMU in non-stationary environments, where the\ndynamics of the environment can change over time. Reinforcement Learning (RL),\na popular approach for DMU problems, learns a policy by interacting with a\nmodel of the environment offline. Unfortunately, if the environment changes the\npolicy can become stale and take sub-optimal actions, and relearning the policy\nfor the updated environment takes time and computational effort. An alternative\nis online planning approaches such as Monte Carlo Tree Search (MCTS), which\nperform their computation at decision time. Given the current environment, MCTS\nplans using high-fidelity models to determine promising action trajectories.\nThese models can be updated as soon as environmental changes are detected to\nimmediately incorporate them into decision making. However, MCTS's convergence\ncan be slow for domains with large state-action spaces. In this paper, we\npresent a novel hybrid decision-making approach that combines the strengths of\nRL and planning while mitigating their weaknesses. Our approach, called Policy\nAugmented MCTS (PA-MCTS), integrates a policy's actin-value estimates into\nMCTS, using the estimates to seed the action trajectories favored by the\nsearch. We hypothesize that PA-MCTS will converge more quickly than standard\nMCTS while making better decisions than the policy can make on its own when\nfaced with nonstationary environments. We test our hypothesis by comparing\nPA-MCTS with pure MCTS and an RL agent applied to the classical CartPole\nenvironment. We find that PC-MCTS can achieve higher cumulative rewards than\nthe policy in isolation under several environmental shifts while converging in\nsignificantly fewer iterations than pure MCTS.\n",
                "链接": "https://arxiv.org/abs/2202.13003"
            },
            {
                "文章ID": "22592",
                "标题": "Policy Gradient Algorithms with Monte-Carlo Tree Search for Non-Markov\n  Decision Processes",
                "作者": " Tetsuro Morimura,  Kazuhiro Ota,  Kenshi Abe,  Peinan Zhang",
                "发布日期": "2022-06-03",
                "摘要": "  Policy gradient (PG) is a reinforcement learning (RL) approach that optimizes\na parameterized policy model for an expected return using gradient ascent.\nGiven a well-parameterized policy model, such as a neural network model, with\nappropriate initial parameters, the PG algorithms work well even when\nenvironment does not have the Markov property. Otherwise, they can be trapped\non a plateau or suffer from peakiness effects. As another successful RL\napproach, algorithms based on Monte-Carlo Tree Search (MCTS), which include\nAlphaZero, have obtained groundbreaking results especially on the board game\nplaying domain. They are also suitable to be applied to non-Markov decision\nprocesses. However, since the standard MCTS does not have the ability to learn\nstate representation, the size of the tree-search space can be too large to\nsearch. In this work, we examine a mixture policy of PG and MCTS to complement\neach other's difficulties and take advantage of them. We derive conditions for\nasymptotic convergence with results of a two-timescale stochastic approximation\nand propose an algorithm that satisfies these conditions. The effectivity of\nthe proposed methods is verified through numerical experiments on non-Markov\ndecision processes.\n",
                "链接": "https://arxiv.org/abs/2206.01011"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "57762",
                "标题": "Robot Skill Learning Via Classical Robotics-Based Generated Datasets:\n  Advantages, Disadvantages, and Future Improvement",
                "作者": " Batu Kaan Oezen",
                "发布日期": "2023-01-24",
                "摘要": "  Why do we not profit from our long-existing classical robotics knowledge and\nlook for some alternative way for data collection? The situation ignoring all\nexisting methods might be such a waste. This article argues that a dataset\ncreated using a classical robotics algorithm is a crucial part of future\ndevelopment. This developed classic algorithm has a perfect domain adaptation\nand generalization property, and most importantly, collecting datasets based on\nthem is quite easy. It is well known that current robot skill-learning\napproaches perform exceptionally badly in the unseen domain, and their\nperformance against adversarial attacks is quite limited as long as they do not\nhave a very exclusive big dataset. Our experiment is the initial steps of using\na dataset created by classical robotics codes. Our experiment investigated\npossible trajectory collection based on classical robotics. It addressed some\nadvantages and disadvantages and pointed out other future development ideas.\n",
                "链接": "https://arxiv.org/abs/2301.08794"
            },
            {
                "文章ID": "19675",
                "标题": "The Solvability of Interpretability Evaluation Metrics",
                "作者": " Yilun Zhou,  Julie Shah",
                "发布日期": "2023-02-06",
                "摘要": "  Feature attribution methods are popular for explaining neural network\npredictions, and they are often evaluated on metrics such as comprehensiveness\nand sufficiency. In this paper, we highlight an intriguing property of these\nmetrics: their solvability. Concretely, we can define the problem of optimizing\nan explanation for a metric, which can be solved by beam search. This\nobservation leads to the obvious yet unaddressed question: why do we use\nexplainers (e.g., LIME) not based on solving the target metric, if the metric\nvalue represents explanation quality? We present a series of investigations\nshowing strong performance of this beam search explainer and discuss its\nbroader implication: a definition-evaluation duality of interpretability\nconcepts. We implement the explainer and release the Python solvex package for\nmodels of text, image and tabular domains.\n",
                "链接": "https://arxiv.org/abs/2205.08696"
            },
            {
                "文章ID": "5926",
                "标题": "On the Evaluation Metrics for Paraphrase Generation",
                "作者": " Lingfeng Shen,  Lemao Liu,  Haiyun Jiang,  Shuming Shi",
                "发布日期": "2022-10-11",
                "摘要": "  In this paper we revisit automatic metrics for paraphrase evaluation and\nobtain two findings that disobey conventional wisdom: (1) Reference-free\nmetrics achieve better performance than their reference-based counterparts. (2)\nMost commonly used metrics do not align well with human annotation. Underlying\nreasons behind the above findings are explored through additional experiments\nand in-depth analyses. Based on the experiments and analyses, we propose\nParaScore, a new evaluation metric for paraphrase generation. It possesses the\nmerits of reference-based and reference-free metrics and explicitly models\nlexical divergence. Experimental results demonstrate that ParaScore\nsignificantly outperforms existing metrics.\n",
                "链接": "https://arxiv.org/abs/2202.08479"
            },
            {
                "文章ID": "22986",
                "标题": "Never mind the metrics -- what about the uncertainty? Visualising\n  confusion matrix metric distributions",
                "作者": " David Lovell,  Dimity Miller,  Jaiden Capra,  Andrew Bradley",
                "发布日期": "2022-06-07",
                "摘要": "  There are strong incentives to build models that demonstrate outstanding\npredictive performance on various datasets and benchmarks. We believe these\nincentives risk a narrow focus on models and on the performance metrics used to\nevaluate and compare them -- resulting in a growing body of literature to\nevaluate and compare metrics. This paper strives for a more balanced\nperspective on classifier performance metrics by highlighting their\ndistributions under different models of uncertainty and showing how this\nuncertainty can easily eclipse differences in the empirical performance of\nclassifiers. We begin by emphasising the fundamentally discrete nature of\nempirical confusion matrices and show how binary matrices can be meaningfully\nrepresented in a three dimensional compositional lattice, whose cross-sections\nform the basis of the space of receiver operating characteristic (ROC) curves.\nWe develop equations, animations and interactive visualisations of the contours\nof performance metrics within (and beyond) this ROC space, showing how some are\naffected by class imbalance. We provide interactive visualisations that show\nthe discrete posterior predictive probability mass functions of true and false\npositive rates in ROC space, and how these relate to uncertainty in performance\nmetrics such as Balanced Accuracy (BA) and the Matthews Correlation Coefficient\n(MCC). Our hope is that these insights and visualisations will raise greater\nawareness of the substantial uncertainty in performance metric estimates that\ncan arise when classifiers are evaluated on empirical datasets and benchmarks,\nand that classification model performance claims should be tempered by this\nunderstanding.\n",
                "链接": "https://arxiv.org/abs/2206.02157"
            },
            {
                "文章ID": "80263",
                "标题": "Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation\n  Metrics using Measurement Theory",
                "作者": " Ziang Xiao,  Susu Zhang,  Vivian Lai,  Q. Vera Liao",
                "发布日期": "2023-10-24",
                "摘要": "  We address a fundamental challenge in Natural Language Generation (NLG) model\nevaluation -- the design and evaluation of evaluation metrics. Recognizing the\nlimitations of existing automatic metrics and noises from how current human\nevaluation was conducted, we propose MetricEval, a framework informed by\nmeasurement theory, the foundation of educational test design, for\nconceptualizing and evaluating the reliability and validity of NLG evaluation\nmetrics. The framework formalizes the source of measurement error and offers\nstatistical tools for evaluating evaluation metrics based on empirical data.\nWith our framework, one can quantify the uncertainty of the metrics to better\ninterpret the result. To exemplify the use of our framework in practice, we\nanalyzed a set of evaluation metrics for summarization and identified issues\nrelated to conflated validity structure in human-eval and reliability in\nLLM-based metrics. Through MetricEval, we aim to promote the design,\nevaluation, and interpretation of valid and reliable metrics to advance robust\nand effective NLG models.\n",
                "链接": "https://arxiv.org/abs/2305.14889"
            },
            {
                "文章ID": "11789",
                "标题": "On the Intrinsic and Extrinsic Fairness Evaluation Metrics for\n  Contextualized Language Representations",
                "作者": " Yang Trista Cao,  Yada Pruksachatkun,  Kai-Wei Chang,  Rahul Gupta,  Varun Kumar,  Jwala Dhamala,  Aram Galstyan",
                "发布日期": "2022-03-29",
                "摘要": "  Multiple metrics have been introduced to measure fairness in various natural\nlanguage processing tasks. These metrics can be roughly categorized into two\ncategories: 1) \\emph{extrinsic metrics} for evaluating fairness in downstream\napplications and 2) \\emph{intrinsic metrics} for estimating fairness in\nupstream contextualized language representation models. In this paper, we\nconduct an extensive correlation study between intrinsic and extrinsic metrics\nacross bias notions using 19 contextualized language models. We find that\nintrinsic and extrinsic metrics do not necessarily correlate in their original\nsetting, even when correcting for metric misalignments, noise in evaluation\ndatasets, and confounding factors such as experiment configuration for\nextrinsic metrics. %al\n",
                "链接": "https://arxiv.org/abs/2203.13928"
            },
            {
                "文章ID": "98603",
                "标题": "Training and Meta-Evaluating Machine Translation Evaluation Metrics at\n  the Paragraph Level",
                "作者": " Daniel Deutsch,  Juraj Juraska,  Mara Finkelstein,  Markus Freitag",
                "发布日期": "2023-08-29",
                "摘要": "  As research on machine translation moves to translating text beyond the\nsentence level, it remains unclear how effective automatic evaluation metrics\nare at scoring longer translations. In this work, we first propose a method for\ncreating paragraph-level data for training and meta-evaluating metrics from\nexisting sentence-level data. Then, we use these new datasets to benchmark\nexisting sentence-level metrics as well as train learned metrics at the\nparagraph level. Interestingly, our experimental results demonstrate that using\nsentence-level metrics to score entire paragraphs is equally as effective as\nusing a metric designed to work at the paragraph level. We speculate this\nresult can be attributed to properties of the task of reference-based\nevaluation as well as limitations of our datasets with respect to capturing all\ntypes of phenomena that occur in paragraph-level translations.\n",
                "链接": "https://arxiv.org/abs/2308.13506"
            },
            {
                "文章ID": "23650",
                "标题": "Abstraction not Memory: BERT and the English Article System",
                "作者": " Harish Tayyar Madabushi,  Dagmar Divjak,  Petar Milin",
                "发布日期": "2022-06-10",
                "摘要": "  Article prediction is a task that has long defied accurate linguistic\ndescription. As such, this task is ideally suited to evaluate models on their\nability to emulate native-speaker intuition. To this end, we compare the\nperformance of native English speakers and pre-trained models on the task of\narticle prediction set up as a three way choice (a/an, the, zero). Our\nexperiments with BERT show that BERT outperforms humans on this task across all\narticles. In particular, BERT is far superior to humans at detecting the zero\narticle, possibly because we insert them using rules that the deep neural model\ncan easily pick up. More interestingly, we find that BERT tends to agree more\nwith annotators than with the corpus when inter-annotator agreement is high but\nswitches to agreeing more with the corpus as inter-annotator agreement drops.\nWe contend that this alignment with annotators, despite being trained on the\ncorpus, suggests that BERT is not memorising article use, but captures a high\nlevel generalisation of article use akin to human intuition.\n",
                "链接": "https://arxiv.org/abs/2206.04184"
            },
            {
                "文章ID": "36945",
                "标题": "Large-scale Evaluation of Transformer-based Article Encoders on the Task\n  of Citation Recommendation",
                "作者": " Zoran Medić,  Jan Šnajder",
                "发布日期": "2022-09-13",
                "摘要": "  Recently introduced transformer-based article encoders (TAEs) designed to\nproduce similar vector representations for mutually related scientific articles\nhave demonstrated strong performance on benchmark datasets for scientific\narticle recommendation. However, the existing benchmark datasets are\npredominantly focused on single domains and, in some cases, contain easy\nnegatives in small candidate pools. Evaluating representations on such\nbenchmarks might obscure the realistic performance of TAEs in setups with\nthousands of articles in candidate pools. In this work, we evaluate TAEs on\nlarge benchmarks with more challenging candidate pools. We compare the\nperformance of TAEs with a lexical retrieval baseline model BM25 on the task of\ncitation recommendation, where the model produces a list of recommendations for\nciting in a given input article. We find out that BM25 is still very\ncompetitive with the state-of-the-art neural retrievers, a finding which is\nsurprising given the strong performance of TAEs on small benchmarks. As a\nremedy for the limitations of the existing benchmarks, we propose a new\nbenchmark dataset for evaluating scientific article representations:\nMulti-Domain Citation Recommendation dataset (MDCR), which covers different\nscientific fields and contains challenging candidate pools.\n",
                "链接": "https://arxiv.org/abs/2209.05452"
            },
            {
                "文章ID": "27574",
                "标题": "On the Effect of Ranking Axioms on IR Evaluation Metrics",
                "作者": " Fernando Giner",
                "发布日期": "2022-07-05",
                "摘要": "  The study of IR evaluation metrics through axiomatic analysis enables a\nbetter understanding of their numerical properties. Some works have modelled\nthe effectiveness of retrieval metrics with axioms that capture desirable\nproperties on the set of rankings of documents. This paper formally explores\nthe effect of these ranking axioms on the numerical values of some IR\nevaluation metrics. It focuses on the set of ranked lists of documents with\nmultigrade relevance. The possible orderings in this set are derived from three\ncommonly accepted ranking axioms on retrieval metrics; then, they are\nclassified by their latticial properties. When relevant documents are\nprioritised, a subset of document rankings are identified: the join-irreducible\nelements, which have some resemblance to the concept of basis in vector space.\nIt is possible to compute the precision, recall, RBP or DCG values of any\nranking from their values in the join-irreducible elements. However this is not\nthe case when the swapping of documents is considered.\n",
                "链接": "https://arxiv.org/abs/2207.01201"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "66852",
                "标题": "GPT-4 Technical Report",
                "作者": "Rai   OpenAI, Rai   :, Rai  Josh Achiam, Rai  Steven Adler, Rai  Sandhini Agarwal, Rai  Lama Ahmad, Rai  Ilge Akkaya, Rai  Florencia Leoni Aleman, Rai  Diogo Almeida, Rai  Janko Altenschmidt, Rai  Sam Altman, Rai  Shyamal Anadkat, Rai  Red Avila, Rai  Igor Babuschkin, Rai  Suchir Balaji, Rai  Valerie Balcom, Rai  Paul Baltescu, Rai  Haiming Bao, Rai  Mo Bavarian, Rai  Jeff Belgum, Rai  Irwan Bello, Rai  Jake Berdine, Rai  Gabriel Bernadett-Shapiro, Rai  Christopher Berner, Rai  Lenny Bogdonoff, Rai  Oleg Boiko, Rai  Madelaine Boyd, Rai  Anna-Luisa Brakman, Rai  Greg Brockman, Rai  Tim Brooks, Rai  Miles Brundage, Rai  Kevin Button, Rai  Trevor Cai, Rai  Rosie Campbell, Rai  Andrew Cann, Rai  Brittany Carey, Rai  Chelsea Carlson, Rai  Rory Carmichael, Rai  Brooke Chan, Rai  Che Chang, Rai  Fotis Chantzis, Rai  Derek Chen, Rai  Sully Chen, Rai  Ruby Chen, Rai  Jason Chen, Rai  Mark Chen, Rai  Ben Chess, Rai  Chester Cho, Rai  Casey Chu, Rai  Hyung Won Chung, Rai  Dave Cummings, Rai  Jeremiah Currier, Rai  Yunxing Dai, Rai  Cory Decareaux, Rai  Thomas Degry, Rai  Noah Deutsch, Rai  Damien Deville, Rai  Arka Dhar, Rai  David Dohan, Rai  Steve Dowling, Rai  Sheila Dunning, Rai  Adrien Ecoffet, Rai  Atty Eleti, Rai  Tyna Eloundou, Rai  David Farhi, Rai  Liam Fedus, Rai  Niko Felix, Rai  Simón Posada Fishman, Rai  Juston Forte, Rai  Isabella Fulford, Rai  Leo Gao, Rai  Elie Georges, Rai  Christian Gibson, Rai  Vik Goel, Rai  Tarun Gogineni, Rai  Gabriel Goh, Rai  Rapha Gontijo-Lopes, Rai  Jonathan Gordon, Rai  Morgan Grafstein, Rai  Scott Gray, Rai  Ryan Greene, Rai  Joshua Gross, Rai  Shixiang Shane Gu, Rai  Yufei Guo, Rai  Chris Hallacy, Rai  Jesse Han, Rai  Jeff Harris, Rai  Yuchen He, Rai  Mike Heaton, Rai  Johannes Heidecke, Rai  Chris Hesse, Rai  Alan Hickey, Rai  Wade Hickey, Rai  Peter Hoeschele, Rai  Brandon Houghton, Rai  Kenny Hsu, Rai  Shengli Hu, Rai  Xin Hu, Rai  Joost Huizinga, Rai  Shantanu Jain, Rai  Shawn Jain, Rai  Joanne Jang, Rai  Angela Jiang, Rai  Roger Jiang, Rai  Haozhun Jin, Rai  Denny Jin, Rai  Shino Jomoto, Rai  Billie Jonn, Rai  Heewoo Jun, Rai  Tomer Kaftan, Rai  Łukasz Kaiser, Rai  Ali Kamali, Rai  Ingmar Kanitscheider, Rai  Nitish Shirish Keskar, Rai  Tabarak Khan, Rai  Logan Kilpatrick, Rai  Jong Wook Kim, Rai  Christina Kim, Rai  Yongjik Kim, Rai  Hendrik Kirchner, Rai  Jamie Kiros, Rai  Matt Knight, Rai  Daniel Kokotajlo, Rai  Łukasz Kondraciuk, Rai  Andrew Kondrich, Rai  Aris Konstantinidis, Rai  Kyle Kosic, Rai  Gretchen Krueger, Rai  Vishal Kuo, Rai  Michael Lampe, Rai  Ikai Lan, Rai  Teddy Lee, Rai  Jan Leike, Rai  Jade Leung, Rai  Daniel Levy, Rai  Chak Ming Li, Rai  Rachel Lim, Rai  Molly Lin, Rai  Stephanie Lin, Rai  Mateusz Litwin, Rai  Theresa Lopez, Rai  Ryan Lowe, Rai  Patricia Lue, Rai  Anna Makanju, Rai  Kim Malfacini, Rai  Sam Manning, Rai  Todor Markov, Rai  Yaniv Markovski, Rai  Bianca Martin, Rai  Katie Mayer, Rai  Andrew Mayne, Rai  Bob McGrew, Rai  Scott Mayer McKinney, Rai  Christine McLeavey, Rai  Paul McMillan, Rai  Jake McNeil, Rai  David Medina, Rai  Aalok Mehta, Rai  Jacob Menick, Rai  Luke Metz, Rai  Andrey Mishchenko, Rai  Pamela Mishkin, Rai  Vinnie Monaco, Rai  Evan Morikawa, Rai  Daniel Mossing, Rai  Tong Mu, Rai  Mira Murati, Rai  Oleg Murk, Rai  David Mély, Rai  Ashvin Nair, Rai  Reiichiro Nakano, Rai  Rajeev Nayak, Rai  Arvind Neelakantan, Rai  Richard Ngo, Rai  Hyeonwoo Noh, Rai  Long Ouyang, Rai  Cullen O'Keefe, Rai  Jakub Pachocki, Rai  Alex Paino, Rai  Joe Palermo, Rai  Ashley Pantuliano, Rai  Giambattista Parascandolo, Rai  Joel Parish, Rai  Emy Parparita, Rai  Alex Passos, Rai  Mikhail Pavlov, Rai  Andrew Peng, Rai  Adam Perelman, Rai  Filipe de Avila Belbute Peres, Rai  Michael Petrov, Rai  Henrique Ponde de Oliveira Pinto, Rai   Michael,   Pokorny,  Michelle Pokrass,  Vitchyr Pong,  Tolly Powell,  Alethea Power,  Boris Power,  Elizabeth Proehl,  Raul Puri,  Alec Radford,  Jack Rae,  Aditya Ramesh,  Cameron Raymond,  Francis Real,  Kendra Rimbach,  Carl Ross,  Bob Rotsted,  Henri Roussez,  Nick Ryder,  Mario Saltarelli,  Ted Sanders,  Shibani Santurkar,  Girish Sastry,  Heather Schmidt,  David Schnurr,  John Schulman,  Daniel Selsam,  Kyla Sheppard,  Toki Sherbakov,  Jessica Shieh,  Sarah Shoker,  Pranav Shyam,  Szymon Sidor,  Eric Sigler,  Maddie Simens,  Jordan Sitkin,  Katarina Slama,  Ian Sohl,  Benjamin Sokolowsky,  Yang Song,  Natalie Staudacher,  Felipe Petroski Such,  Natalie Summers,  Ilya Sutskever,  Jie Tang,  Nikolas Tezak,  Madeleine Thompson,  Phil Tillet,  Amin Tootoonchian,  Elizabeth Tseng,  Preston Tuggle,  Nick Turley,  Jerry Tworek,  Juan Felipe Cerón Uribe,  Andrea Vallone,  Arun Vijayvergiya,  Chelsea Voss,  Carroll Wainwright,  Justin Jay Wang,  Alvin Wang,  Ben Wang,  Jonathan Ward,  Jason Wei,  CJ Weinmann,  Akila Welihinda,  Peter Welinder,  Jiayi Weng,  Lilian Weng,  Matt Wiethoff,  Dave Willner,  Clemens Winter,  Samuel Wolrich,  Hannah Wong,  Lauren Workman,  Sherwin Wu,  Jeff Wu,  Michael Wu,  Kai Xiao,  Tao Xu,  Sarah Yoo,  Kevin Yu,  Qiming Yuan,  Wojciech Zaremba,  Rowan Zellers,  Chong Zhang,  Marvin Zhang,  Shengjia Zhao,  Tianhao Zheng,  Juntang Zhuang,  William Zhuk,  Barret Zoph",
                "发布日期": "2023-12-20",
                "摘要": "  We report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance on\nvarious professional and academic benchmarks, including passing a simulated bar\nexam with a score around the top 10% of test takers. GPT-4 is a\nTransformer-based model pre-trained to predict the next token in a document.\nThe post-training alignment process results in improved performance on measures\nof factuality and adherence to desired behavior. A core component of this\nproject was developing infrastructure and optimization methods that behave\npredictably across a wide range of scales. This allowed us to accurately\npredict some aspects of GPT-4's performance based on models trained with no\nmore than 1/1,000th the compute of GPT-4.\n",
                "链接": "https://arxiv.org/abs/2303.08774"
            },
            {
                "文章ID": "95177",
                "标题": "GPT-4 Can't Reason",
                "作者": " Konstantine Arkoudas",
                "发布日期": "2023-08-11",
                "摘要": "  GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\nimprovement across the board over GPT-3.5 (OpenAI's previously best model,\nwhich had powered the initial release of ChatGPT). However, despite the\ngenuinely impressive improvement, there are good reasons to be highly skeptical\nof GPT-4's ability to reason. This position paper discusses the nature of\nreasoning; criticizes the current formulation of reasoning problems in the NLP\ncommunity, as well as the way in which LLM reasoning performance is currently\nevaluated; introduces a small collection of 21 diverse reasoning problems; and\nperforms a detailed qualitative evaluation of GPT-4's performance on those\nproblems. Based on this analysis, the paper concludes that, despite its\noccasional flashes of analytical brilliance, GPT-4 at present is utterly\nincapable of reasoning.\n",
                "链接": "https://arxiv.org/abs/2308.03762"
            },
            {
                "文章ID": "94757",
                "标题": "Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings",
                "作者": " Veronika Hackl,  Alexandra Elena Müller,  Michael Granitzer,  Maximilian Sailer",
                "发布日期": "2023-08-08",
                "摘要": "  This study investigates the consistency of feedback ratings generated by\nOpenAI's GPT-4, a state-of-the-art artificial intelligence language model,\nacross multiple iterations, time spans and stylistic variations. The model\nrated responses to tasks within the Higher Education (HE) subject domain of\nmacroeconomics in terms of their content and style. Statistical analysis was\nconducted in order to learn more about the interrater reliability, consistency\nof the ratings across iterations and the correlation between ratings in terms\nof content and style. The results revealed a high interrater reliability with\nICC scores ranging between 0.94 and 0.99 for different timespans, suggesting\nthat GPT-4 is capable of generating consistent ratings across repetitions with\na clear prompt. Style and content ratings show a high correlation of 0.87. When\napplying a non-adequate style the average content ratings remained constant,\nwhile style ratings decreased, which indicates that the large language model\n(LLM) effectively distinguishes between these two criteria during evaluation.\nThe prompt used in this study is furthermore presented and explained. Further\nresearch is necessary to assess the robustness and reliability of AI models in\nvarious use cases.\n",
                "链接": "https://arxiv.org/abs/2308.02575"
            },
            {
                "文章ID": "124407",
                "标题": "Exploiting Novel GPT-4 APIs",
                "作者": " Kellin Pelrine,  Mohammad Taufeeque,  Michał Zając,  Euan McLean,  Adam Gleave",
                "发布日期": "2023-12-25",
                "摘要": "  Language model attacks typically assume one of two extreme threat models:\nfull white-box access to model weights, or black-box access limited to a text\ngeneration API. However, real-world APIs are often more flexible than just text\ngeneration: these APIs expose ``gray-box'' access leading to new threat\nvectors. To explore this, we red-team three new functionalities exposed in the\nGPT-4 APIs: fine-tuning, function calling and knowledge retrieval. We find that\nfine-tuning a model on as few as 15 harmful examples or 100 benign examples can\nremove core safeguards from GPT-4, enabling a range of harmful outputs.\nFurthermore, we find that GPT-4 Assistants readily divulge the function call\nschema and can be made to execute arbitrary function calls. Finally, we find\nthat knowledge retrieval can be hijacked by injecting instructions into\nretrieval documents. These vulnerabilities highlight that any additions to the\nfunctionality exposed by an API can create new vulnerabilities.\n",
                "链接": "https://arxiv.org/abs/2312.14302"
            },
            {
                "文章ID": "105208",
                "标题": "Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind\n  Aware GPT-4",
                "作者": " Jiaxian Guo,  Bo Yang,  Paul Yoo,  Bill Yuchen Lin,  Yusuke Iwasawa,  Yutaka Matsuo",
                "发布日期": "2023-10-09",
                "摘要": "  Unlike perfect information games, where all elements are known to every\nplayer, imperfect information games emulate the real-world complexities of\ndecision-making under uncertain or incomplete information. GPT-4, the recent\nbreakthrough in large language models (LLMs) trained on massive passive data,\nis notable for its knowledge retrieval and reasoning abilities. This paper\ndelves into the applicability of GPT-4's learned knowledge for imperfect\ninformation games. To achieve this, we introduce \\textbf{Suspicion-Agent}, an\ninnovative agent that leverages GPT-4's capabilities for performing in\nimperfect information games. With proper prompt engineering to achieve\ndifferent functions, Suspicion-Agent based on GPT-4 demonstrates remarkable\nadaptability across a range of imperfect information card games. Importantly,\nGPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it\ncan understand others and intentionally impact others' behavior. Leveraging\nthis, we design a planning strategy that enables GPT-4 to competently play\nagainst different opponents, adapting its gameplay style as needed, while\nrequiring only the game rules and descriptions of observations as input. In the\nexperiments, we qualitatively showcase the capabilities of Suspicion-Agent\nacross three different imperfect information games and then quantitatively\nevaluate it in Leduc Hold'em. The results show that Suspicion-Agent can\npotentially outperform traditional algorithms designed for imperfect\ninformation games, without any specialized training or examples. In order to\nencourage and foster deeper insights within the community, we make our\ngame-related data publicly available.\n",
                "链接": "https://arxiv.org/abs/2309.17277"
            },
            {
                "文章ID": "106172",
                "标题": "Low-Resource Languages Jailbreak GPT-4",
                "作者": " Zheng-Xin Yong,  Cristina Menghini,  Stephen H. Bach",
                "发布日期": "2023-10-05",
                "摘要": "  AI safety training and red-teaming of large language models (LLMs) are\nmeasures to mitigate the generation of unsafe content. Our work exposes the\ninherent cross-lingual vulnerability of these safety mechanisms, resulting from\nthe linguistic inequality of safety training data, by successfully\ncircumventing GPT-4's safeguard through translating unsafe English inputs into\nlow-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe\ntranslated inputs and provides actionable items that can get the users towards\ntheir harmful goals 79% of the time, which is on par with or even surpassing\nstate-of-the-art jailbreaking attacks. Other high-/mid-resource languages have\nsignificantly lower attack success rate, which suggests that the cross-lingual\nvulnerability mainly applies to low-resource languages. Previously, limited\ntraining on low-resource languages primarily affects speakers of those\nlanguages, causing technological disparities. However, our work highlights a\ncrucial shift: this deficiency now poses a risk to all LLMs users. Publicly\navailable translation APIs enable anyone to exploit LLMs' safety\nvulnerabilities. Therefore, our work calls for a more holistic red-teaming\nefforts to develop robust multilingual safeguards with wide language coverage.\n",
                "链接": "https://arxiv.org/abs/2310.02446"
            },
            {
                "文章ID": "73599",
                "标题": "Can GPT-4 Perform Neural Architecture Search?",
                "作者": " Mingkai Zheng,  Xiu Su,  Shan You,  Fei Wang,  Chen Qian,  Chang Xu,  Samuel Albanie",
                "发布日期": "2023-08-03",
                "摘要": "  We investigate the potential of GPT-4~\\cite{gpt4} to perform Neural\nArchitecture Search (NAS) -- the task of designing effective neural\narchitectures. Our proposed approach, \\textbf{G}PT-4 \\textbf{E}nhanced\n\\textbf{N}eural arch\\textbf{I}tect\\textbf{U}re \\textbf{S}earch (GENIUS),\nleverages the generative capabilities of GPT-4 as a black-box optimiser to\nquickly navigate the architecture search space, pinpoint promising candidates,\nand iteratively refine these candidates to improve performance. We assess\nGENIUS across several benchmarks, comparing it with existing state-of-the-art\nNAS techniques to illustrate its effectiveness. Rather than targeting\nstate-of-the-art performance, our objective is to highlight GPT-4's potential\nto assist research on a challenging technical problem through a simple\nprompting scheme that requires relatively limited domain\nexpertise\\footnote{Code available at\n\\href{https://github.com/mingkai-zheng/GENIUS}{https://github.com/mingkai-zheng/GENIUS}.}.\nMore broadly, we believe our preliminary results point to future research that\nharnesses general purpose language models for diverse optimisation tasks. We\nalso highlight important limitations to our study, and note implications for AI\nsafety.\n",
                "链接": "https://arxiv.org/abs/2304.10970"
            },
            {
                "文章ID": "80356",
                "标题": "Is GPT-4 a Good Data Analyst?",
                "作者": " Liying Cheng,  Xingxuan Li,  Lidong Bing",
                "发布日期": "2023-10-24",
                "摘要": "  As large language models (LLMs) have demonstrated their powerful capabilities\nin plenty of domains and tasks, including context understanding, code\ngeneration, language generation, data storytelling, etc., many data analysts\nmay raise concerns if their jobs will be replaced by artificial intelligence\n(AI). This controversial topic has drawn great attention in public. However, we\nare still at a stage of divergent opinions without any definitive conclusion.\nMotivated by this, we raise the research question of \"is GPT-4 a good data\nanalyst?\" in this work and aim to answer it by conducting head-to-head\ncomparative studies. In detail, we regard GPT-4 as a data analyst to perform\nend-to-end data analysis with databases from a wide range of domains. We\npropose a framework to tackle the problems by carefully designing the prompts\nfor GPT-4 to conduct experiments. We also design several task-specific\nevaluation metrics to systematically compare the performance between several\nprofessional human data analysts and GPT-4. Experimental results show that\nGPT-4 can achieve comparable performance to humans. We also provide in-depth\ndiscussions about our results to shed light on further studies before reaching\nthe conclusion that GPT-4 can replace data analysts.\n",
                "链接": "https://arxiv.org/abs/2305.15038"
            },
            {
                "文章ID": "93923",
                "标题": "LLMediator: GPT-4 Assisted Online Dispute Resolution",
                "作者": " Hannes Westermann,  Jaromir Savelka,  Karim Benyekhlef",
                "发布日期": "2023-08-01",
                "摘要": "  In this article, we introduce LLMediator, an experimental platform designed\nto enhance online dispute resolution (ODR) by utilizing capabilities of\nstate-of-the-art large language models (LLMs) such as GPT-4. In the context of\nhigh-volume, low-intensity legal disputes, alternative dispute resolution\nmethods such as negotiation and mediation offer accessible and cooperative\nsolutions for laypeople. These approaches can be carried out online on ODR\nplatforms. LLMediator aims to improve the efficacy of such processes by\nleveraging GPT-4 to reformulate user messages, draft mediator responses, and\npotentially autonomously engage in the discussions. We present and discuss\nseveral features of LLMediator and conduct initial qualitative evaluations,\ndemonstrating the potential for LLMs to support ODR and facilitate amicable\nsettlements. The initial proof of concept is promising and opens up avenues for\nfurther research in AI-assisted negotiation and mediation.\n",
                "链接": "https://arxiv.org/abs/2307.16732"
            },
            {
                "文章ID": "105803",
                "标题": "Graph Neural Architecture Search with GPT-4",
                "作者": " Haishuai Wang,  Yang Gao,  Xin Zheng,  Peng Zhang,  Hongyang Chen,  Jiajun Bu",
                "发布日期": "2023-10-04",
                "摘要": "  Graph Neural Architecture Search (GNAS) has shown promising results in\nautomatically designing graph neural networks. However, GNAS still requires\nintensive human labor with rich domain knowledge to design the search space and\nsearch strategy. In this paper, we integrate GPT-4 into GNAS and propose a new\nGPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The\nbasic idea of our method is to design a new class of prompts for GPT-4 to guide\nGPT-4 toward the generative task of graph neural architectures. The prompts\nconsist of descriptions of the search space, search strategy, and search\nfeedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS\ngenerates more accurate graph neural networks with fast convergence.\nExperimental results show that embedding GPT-4 into GNAS outperforms the\nstate-of-the-art GNAS methods.\n",
                "链接": "https://arxiv.org/abs/2310.01436"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "11176",
                "标题": "4D-OR: Semantic Scene Graphs for OR Domain Modeling",
                "作者": " Ege Özsoy,  Evin Pınar Örnek,  Ulrich Eck,  Tobias Czempiel,  Federico Tombari,  Nassir Navab",
                "发布日期": "2022-03-23",
                "摘要": "  Surgical procedures are conducted in highly complex operating rooms (OR),\ncomprising different actors, devices, and interactions. To date, only medically\ntrained human experts are capable of understanding all the links and\ninteractions in such a demanding environment. This paper aims to bring the\ncommunity one step closer to automated, holistic and semantic understanding and\nmodeling of OR domain. Towards this goal, for the first time, we propose using\nsemantic scene graphs (SSG) to describe and summarize the surgical scene. The\nnodes of the scene graphs represent different actors and objects in the room,\nsuch as medical staff, patients, and medical equipment, whereas edges are the\nrelationships between them. To validate the possibilities of the proposed\nrepresentation, we create the first publicly available 4D surgical SSG dataset,\n4D-OR, containing ten simulated total knee replacement surgeries recorded with\nsix RGB-D sensors in a realistic OR simulation center. 4D-OR includes 6734\nframes and is richly annotated with SSGs, human and object poses, and clinical\nroles. We propose an end-to-end neural network-based SSG generation pipeline,\nwith a rate of success of 0.75 macro F1, indeed being able to infer semantic\nreasoning in the OR. We further demonstrate the representation power of our\nscene graphs by using it for the problem of clinical role prediction, where we\nachieve 0.85 macro F1. The code and dataset will be made available upon\nacceptance.\n",
                "链接": "https://arxiv.org/abs/2203.11937"
            },
            {
                "文章ID": "44611",
                "标题": "Composition, Attention, or Both?",
                "作者": " Ryo Yoshida,  Yohei Oseki",
                "发布日期": "2023-05-12",
                "摘要": "  In this paper, we propose a novel architecture called Composition Attention\nGrammars (CAGs) that recursively compose subtrees into a single vector\nrepresentation with a composition function, and selectively attend to previous\nstructural information with a self-attention mechanism. We investigate whether\nthese components -- the composition function and the self-attention mechanism\n-- can both induce human-like syntactic generalization. Specifically, we train\nlanguage models (LMs) with and without these two components with the model\nsizes carefully controlled, and evaluate their syntactic generalization\nperformance against six test circuits on the SyntaxGym benchmark. The results\ndemonstrated that the composition function and the self-attention mechanism\nboth play an important role to make LMs more human-like, and closer inspection\nof linguistic phenomenon implied that the composition function allowed\nsyntactic features, but not semantic features, to percolate into subtree\nrepresentations.\n",
                "链接": "https://arxiv.org/abs/2210.12958"
            },
            {
                "文章ID": "112268",
                "标题": "Topological, or Non-topological? A Deep Learning Based Prediction",
                "作者": " Ashiqur Rasul,  Md Shafayat Hossain,  Ankan Ghosh Dastider,  Himaddri Roy,  M. Zahid Hasan,  Quazi D. M. Khosru",
                "发布日期": "2023-10-31",
                "摘要": "  Prediction and discovery of new materials with desired properties are at the\nforefront of quantum science and technology research. A major bottleneck in\nthis field is the computational resources and time complexity related to\nfinding new materials from ab initio calculations. In this work, an effective\nand robust deep learning-based model is proposed by incorporating persistent\nhomology and graph neural network which offers an accuracy of 91.4% and an F1\nscore of 88.5% in classifying topological vs. non-topological materials,\noutperforming the other state-of-the-art classifier models. The incorporation\nof the graph neural network encodes the underlying relation between the atoms\ninto the model based on their own crystalline structures and thus proved to be\nan effective method to represent and process non-euclidean data like molecules\nwith a relatively shallow network. The persistent homology pipeline in the\nsuggested neural network is capable of integrating the atom-specific\ntopological information into the deep learning model, increasing robustness,\nand gain in performance. It is believed that the presented work will be an\nefficacious tool for predicting the topological class and therefore enable the\nhigh-throughput search for novel materials in this field.\n",
                "链接": "https://arxiv.org/abs/2310.18907"
            },
            {
                "文章ID": "118340",
                "标题": "Should We Learn Most Likely Functions or Parameters?",
                "作者": " Shikai Qiu,  Tim G. J. Rudner,  Sanyam Kapoor,  Andrew Gordon Wilson",
                "发布日期": "2023-11-28",
                "摘要": "  Standard regularized training procedures correspond to maximizing a posterior\ndistribution over parameters, known as maximum a posteriori (MAP) estimation.\nHowever, model parameters are of interest only insomuch as they combine with\nthe functional form of a model to provide a function that can make good\npredictions. Moreover, the most likely parameters under the parameter posterior\ndo not generally correspond to the most likely function induced by the\nparameter posterior. In fact, we can re-parametrize a model such that any\nsetting of parameters can maximize the parameter posterior. As an alternative,\nwe investigate the benefits and drawbacks of directly estimating the most\nlikely function implied by the model and the data. We show that this procedure\nleads to pathological solutions when using neural networks and prove conditions\nunder which the procedure is well-behaved, as well as a scalable approximation.\nUnder these conditions, we find that function-space MAP estimation can lead to\nflatter minima, better generalization, and improved robustness to overfitting.\n",
                "链接": "https://arxiv.org/abs/2311.15990"
            },
            {
                "文章ID": "118191",
                "标题": "Move or Push? Studying Pseudo-Haptic Perceptions Obtained with Motion or\n  Force Input",
                "作者": " Yutaro Hirao,  Takuji Narumi,  Ferran Argelaguet,  Anatole Lecuyer",
                "发布日期": "2023-11-28",
                "摘要": "  Pseudo-haptics techniques are interesting alternatives for generating haptic\nperceptions, which entails the manipulation of haptic perception through the\nappropriate alteration of primarily visual feedback in response to body\nmovements. However, the use of pseudo-haptics techniques with a motion-input\nsystem can sometimes be limited. This paper investigates a novel approach for\nextending the potential of pseudo-haptics techniques in virtual reality (VR).\nThe proposed approach utilizes a reaction force from force-input as a\nsubstitution of haptic cue for the pseudo-haptic perception. The paper\nintroduced a manipulation method in which the vertical acceleration of the\nvirtual hand is controlled by the extent of push-in of a force sensor. Such a\nforce-input manipulation of a virtual body can not only present pseudo-haptics\nwith less physical spaces and be used by more various users including\nphysically handicapped people, but also can present the reaction force\nproportional to the user's input to the user. We hypothesized that such a\nhaptic force cue would contribute to the pseudo-haptic perception. Therefore,\nthe paper endeavors to investigate the force-input pseudo-haptic perception in\na comparison with the motion-input pseudo-haptics. The paper compared\nforce-input and motion-input manipulation in a point of achievable range and\nresolution of pseudo-haptic weight. The experimental results suggest that the\nforce-input manipulation successfully extends the range of perceptible\npseudo-weight by 80\\% in comparison to the motion-input manipulation. On the\nother hand, it is revealed that the motion-input manipulation has 1 step larger\nnumber of distinguishable weight levels and is easier to operate than the\nforce-input manipulation.\n",
                "链接": "https://arxiv.org/abs/2311.15546"
            },
            {
                "文章ID": "46387",
                "标题": "More Speaking or More Speakers?",
                "作者": " Dan Berrebbi,  Ronan Collobert,  Navdeep Jaitly,  Tatiana Likhomanenko",
                "发布日期": "2023-03-03",
                "摘要": "  Self-training (ST) and self-supervised learning (SSL) methods have\ndemonstrated strong improvements in automatic speech recognition (ASR). In\nspite of these advances, to the best of our knowledge, there is no analysis of\nhow the composition of the labelled and unlabelled datasets used in these\nmethods affects the results. In this work we aim to analyse the effect of\nnumber of speakers in the training data on a recent SSL algorithm (wav2vec\n2.0), and a recent ST algorithm (slimIPL). We perform a systematic analysis on\nboth labeled and unlabeled data by varying the number of speakers while keeping\nthe number of hours fixed and vice versa. Our findings suggest that SSL\nrequires a large amount of unlabeled data to produce high accuracy results,\nwhile ST requires a sufficient number of speakers in the labelled data,\nespecially in the low-regime setting. In this manner these two approaches\nimprove supervised learning in different regimes of data composition.\n",
                "链接": "https://arxiv.org/abs/2211.00854"
            },
            {
                "文章ID": "102947",
                "标题": "Love or Hate? Share or Split? Privacy-Preserving Training Using Split\n  Learning and Homomorphic Encryption",
                "作者": " Tanveer Khan,  Khoa Nguyen,  Antonis Michalas,  Alexandros Bakas",
                "发布日期": "2023-09-20",
                "摘要": "  Split learning (SL) is a new collaborative learning technique that allows\nparticipants, e.g. a client and a server, to train machine learning models\nwithout the client sharing raw data. In this setting, the client initially\napplies its part of the machine learning model on the raw data to generate\nactivation maps and then sends them to the server to continue the training\nprocess. Previous works in the field demonstrated that reconstructing\nactivation maps could result in privacy leakage of client data. In addition to\nthat, existing mitigation techniques that overcome the privacy leakage of SL\nprove to be significantly worse in terms of accuracy. In this paper, we improve\nupon previous works by constructing a protocol based on U-shaped SL that can\noperate on homomorphically encrypted data. More precisely, in our approach, the\nclient applies homomorphic encryption on the activation maps before sending\nthem to the server, thus protecting user privacy. This is an important\nimprovement that reduces privacy leakage in comparison to other SL-based works.\nFinally, our results show that, with the optimum set of parameters, training\nwith HE data in the U-shaped SL setting only reduces accuracy by 2.65% compared\nto training on plaintext. In addition, raw training data privacy is preserved.\n",
                "链接": "https://arxiv.org/abs/2309.10517"
            },
            {
                "文章ID": "7760",
                "标题": "Hierarchical team structure and multidimensional localization (or\n  siloing) on networks",
                "作者": " Laurent Hébert-Dufresne,  Guillaume St-Onge,  John Meluso,  James Bagrow,  Antoine Allard",
                "发布日期": "2022-03-03",
                "摘要": "  Knowledge silos emerge when structural properties of organizational\ninteraction networks limit the diffusion of information. These structural\nbarriers are known to take many forms at different scales - hubs in otherwise\nsparse organisations, large dense teams, or global core-periphery structure -\nbut we lack an understanding of how these different structures interact. Here\nwe bridge the gap between the mathematical literature on localization of\nspreading dynamics and the more applied literature on knowledge silos in\norganizational interaction networks. To do so, we introduce a new model that\nconsiders a layered structure of teams to unveil a new form of hierarchical\nlocalization (i.e., the localization of information at the top or center of an\norganization) and study its interplay with known phenomena of mesoscopic\nlocalization (i.e., the localization of information in large groups), $k$-core\nlocalization (i.e., around denser $k$-cores) and hub localization (i.e., around\nhigh degree stars). We also include a complex contagion mechanism by\nconsidering a general infection kernel which can depend on hierarchical level\n(influence), degree (popularity), infectious neighbors (social reinforcement)\nor team size (importance). This general model allows us to study the\nmultifaceted phenomenon of information siloing in complex organizational\ninteraction networks and opens the door to new optimization problems to promote\nor hinder the emergence of different localization regimes.\n",
                "链接": "https://arxiv.org/abs/2203.00745"
            },
            {
                "文章ID": "100919",
                "标题": "Noisy Computing of the $\\mathsf{OR}$ and $\\mathsf{MAX}$ Functions",
                "作者": " Banghua Zhu,  Ziao Wang,  Nadim Ghaddar,  Jiantao Jiao,  Lele Wang",
                "发布日期": "2023-09-11",
                "摘要": "  We consider the problem of computing a function of $n$ variables using noisy\nqueries, where each query is incorrect with some fixed and known probability $p\n\\in (0,1/2)$. Specifically, we consider the computation of the $\\mathsf{OR}$\nfunction of $n$ bits (where queries correspond to noisy readings of the bits)\nand the $\\mathsf{MAX}$ function of $n$ real numbers (where queries correspond\nto noisy pairwise comparisons). We show that an expected number of queries of\n\\[ (1 \\pm o(1)) \\frac{n\\log \\frac{1}{\\delta}}{D_{\\mathsf{KL}}(p \\| 1-p)} \\] is\nboth sufficient and necessary to compute both functions with a vanishing error\nprobability $\\delta = o(1)$, where $D_{\\mathsf{KL}}(p \\| 1-p)$ denotes the\nKullback-Leibler divergence between $\\mathsf{Bern}(p)$ and $\\mathsf{Bern}(1-p)$\ndistributions. Compared to previous work, our results tighten the dependence on\n$p$ in both the upper and lower bounds for the two functions.\n",
                "链接": "https://arxiv.org/abs/2309.03986"
            },
            {
                "文章ID": "38820",
                "标题": "Dead or Murdered? Predicting Responsibility Perception in Femicide News\n  Reports",
                "作者": " Gosse Minnema,  Sara Gemelli,  Chiara Zanchi,  Tommaso Caselli,  Malvina Nissim",
                "发布日期": "2022-09-27",
                "摘要": "  Different linguistic expressions can conceptualize the same event from\ndifferent viewpoints by emphasizing certain participants over others. Here, we\ninvestigate a case where this has social consequences: how do linguistic\nexpressions of gender-based violence (GBV) influence who we perceive as\nresponsible? We build on previous psycholinguistic research in this area and\nconduct a large-scale perception survey of GBV descriptions automatically\nextracted from a corpus of Italian newspapers. We then train regression models\nthat predict the salience of GBV participants with respect to different\ndimensions of perceived responsibility. Our best model (fine-tuned BERT) shows\nsolid overall performance, with large differences between dimensions and\nparticipants: salient _focus_ is more predictable than salient _blame_, and\nperpetrators' salience is more predictable than victims' salience. Experiments\nwith ridge regression models using different representations show that features\nbased on linguistic theory similarly to word-based features. Overall, we show\nthat different linguistic choices do trigger different perceptions of\nresponsibility, and that such perceptions can be modelled automatically. This\nwork can be a core instrument to raise awareness of the consequences of\ndifferent perspectivizations in the general public and in news producers alike.\n",
                "链接": "https://arxiv.org/abs/2209.12030"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "824",
                "标题": "BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives",
                "作者": " Frederico Souza,  João Filho",
                "发布日期": "2022-01-11",
                "摘要": "  BERT has revolutionized the NLP field by enabling transfer learning with\nlarge language models that can capture complex textual patterns, reaching the\nstate-of-the-art for an expressive number of NLP applications. For text\nclassification tasks, BERT has already been extensively explored. However,\naspects like how to better cope with the different embeddings provided by the\nBERT output layer and the usage of language-specific instead of multilingual\nmodels are not well studied in the literature, especially for the Brazilian\nPortuguese language. The purpose of this article is to conduct an extensive\nexperimental study regarding different strategies for aggregating the features\nproduced in the BERT output layer, with a focus on the sentiment analysis task.\nThe experiments include BERT models trained with Brazilian Portuguese corpora\nand the multilingual version, contemplating multiple aggregation strategies and\nopen-source datasets with predefined training, validation, and test partitions\nto facilitate the reproducibility of the results. BERT achieved the highest\nROC-AUC values for the majority of cases as compared to TF-IDF. Nonetheless,\nTF-IDF represents a good trade-off between the predictive performance and\ncomputational cost.\n",
                "链接": "https://arxiv.org/abs/2201.03382"
            },
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "102384",
                "标题": "Has Sentiment Returned to the Pre-pandemic Level? A Sentiment Analysis\n  Using U.S. College Subreddit Data from 2019 to 2022",
                "作者": " Tian Yan,  Fang Liu",
                "发布日期": "2023-09-19",
                "摘要": "  As impact of COVID-19 pandemic winds down, both individuals and society\ngradually return to pre-pandemic activities. This study aims to explore how\npeople's emotions have changed from the pre-pandemic during the pandemic to\npost-emergency period and whether it has returned to pre-pandemic level. We\ncollected Reddit data in 2019 (pre-pandemic), 2020 (peak pandemic), 2021, and\n2022 (late stages of pandemic, transitioning period to post-emergency period)\nfrom subreddits in 128 universities/colleges in the U.S., and a set of\nschool-level characteristics. We predicted two sets of sentiments from a\npre-trained Robustly Optimized BERT pre-training approach (RoBERTa) and graph\nattention network (GAT) that leverages both rich semantic and relational\ninformation among posted messages and then applied a logistic stacking method\nto obtain the final sentiment classification. After obtaining sentiment label\nfor each message, we used a generalized linear mixed-effects model to estimate\ntemporal trend in sentiment from 2019 to 2022 and how school-level factors may\naffect sentiment. Compared to the year 2019, the odds of negative sentiment in\nyears 2020, 2021, and 2022 are 24%, 4.3%, and 10.3% higher, respectively, which\nare all statistically significant(adjusted $p$<0.05). Our study findings\nsuggest a partial recovery in the sentiment composition in the\npost-pandemic-emergency era. The results align with common expectations and\nprovide a detailed quantification of how sentiments have evolved from 2019 to\n2022.\n",
                "链接": "https://arxiv.org/abs/2309.08845"
            },
            {
                "文章ID": "75893",
                "标题": "LLM-RM at SemEval-2023 Task 2: Multilingual Complex NER using\n  XLM-RoBERTa",
                "作者": " Rahul Mehta,  Vasudeva Varma",
                "发布日期": "2023-05-08",
                "摘要": "  Named Entity Recognition(NER) is a task of recognizing entities at a token\nlevel in a sentence. This paper focuses on solving NER tasks in a multilingual\nsetting for complex named entities. Our team, LLM-RM participated in the\nrecently organized SemEval 2023 task, Task 2: MultiCoNER II,Multilingual\nComplex Named Entity Recognition. We approach the problem by leveraging\ncross-lingual representation provided by fine-tuning XLM-Roberta base model on\ndatasets of all of the 12 languages provided -- Bangla, Chinese, English,\nFarsi, French, German, Hindi, Italian, Portuguese, Spanish, Swedish and\nUkrainian\n",
                "链接": "https://arxiv.org/abs/2305.03300"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "78993",
                "标题": "SEntFiN 1.0: Entity-Aware Sentiment Analysis for Financial News",
                "作者": " Ankur Sinha,  Satishwar Kedas,  Rishu Kumar,  Pekka Malo",
                "发布日期": "2023-05-23",
                "摘要": "  Fine-grained financial sentiment analysis on news headlines is a challenging\ntask requiring human-annotated datasets to achieve high performance. Limited\nstudies have tried to address the sentiment extraction task in a setting where\nmultiple entities are present in a news headline. In an effort to further\nresearch in this area, we make publicly available SEntFiN 1.0, a\nhuman-annotated dataset of 10,753 news headlines with entity-sentiment\nannotations, of which 2,847 headlines contain multiple entities, often with\nconflicting sentiments. We augment our dataset with a database of over 1,000\nfinancial entities and their various representations in news media amounting to\nover 5,000 phrases. We propose a framework that enables the extraction of\nentity-relevant sentiments using a feature-based approach rather than an\nexpression-based approach. For sentiment extraction, we utilize 12 different\nlearning schemes utilizing lexicon-based and pre-trained sentence\nrepresentations and five classification approaches. Our experiments indicate\nthat lexicon-based n-gram ensembles are above par with pre-trained word\nembedding schemes such as GloVe. Overall, RoBERTa and finBERT (domain-specific\nBERT) achieve the highest average accuracy of 94.29% and F1-score of 93.27%.\nFurther, using over 210,000 entity-sentiment predictions, we validate the\neconomic effect of sentiments on aggregate market movements over a long\nduration.\n",
                "链接": "https://arxiv.org/abs/2305.12257"
            },
            {
                "文章ID": "14627",
                "标题": "Forecasting Cryptocurrency Returns from Sentiment Signals: An Analysis\n  of BERT Classifiers and Weak Supervision",
                "作者": " Duygu Ider,  Stefan Lessmann",
                "发布日期": "2023-03-21",
                "摘要": "  Anticipating price developments in financial markets is a topic of continued\ninterest in forecasting. Funneled by advancements in deep learning and natural\nlanguage processing (NLP) together with the availability of vast amounts of\ntextual data in form of news articles, social media postings, etc., an\nincreasing number of studies incorporate text-based predictors in forecasting\nmodels. We contribute to this literature by introducing weak learning, a\nrecently proposed NLP approach to address the problem that text data is\nunlabeled. Without a dependent variable, it is not possible to finetune\npretrained NLP models on a custom corpus. We confirm that finetuning using weak\nlabels enhances the predictive value of text-based features and raises forecast\naccuracy in the context of predicting cryptocurrency returns. More\nfundamentally, the modeling paradigm we present, weak labeling domain-specific\ntext and finetuning pretrained NLP models, is universally applicable in\n(financial) forecasting and unlocks new ways to leverage text data.\n",
                "链接": "https://arxiv.org/abs/2204.05781"
            },
            {
                "文章ID": "51506",
                "标题": "Location analysis of players in UEFA EURO 2020 and 2022 using\n  generalized valuation of defense by estimating probabilities",
                "作者": " Rikuhei Umemoto,  Kazushi Tsutsui,  Keisuke Fujii",
                "发布日期": "2022-12-02",
                "摘要": "  Analyzing defenses in team sports is generally challenging because of the\nlimited event data. Researchers have previously proposed methods to evaluate\nfootball team defense by predicting the events of ball gain and being attacked\nusing locations of all players and the ball. However, they did not consider the\nimportance of the events, assumed the perfect observation of all 22 players,\nand did not fully investigated the influence of the diversity (e.g.,\nnationality and sex). Here, we propose a generalized valuation method of\ndefensive teams by score-scaling the predicted probabilities of the events.\nUsing the open-source location data of all players in broadcast video frames in\nfootball games of men's Euro 2020 and women's Euro 2022, we investigated the\neffect of the number of players on the prediction and validated our approach by\nanalyzing the games. Results show that for the predictions of being attacked,\nscoring, and conceding, all players' information was not necessary, while that\nof ball gain required information on three to four offensive and defensive\nplayers. With game analyses we explained the excellence in defense of finalist\nteams in Euro 2020. Our approach might be applicable to location data from\nbroadcast video frames in football games.\n",
                "链接": "https://arxiv.org/abs/2212.00021"
            },
            {
                "文章ID": "95613",
                "标题": "Performance Analysis of Transformer Based Models (BERT, ALBERT and\n  RoBERTa) in Fake News Detection",
                "作者": " Shafna Fitria Nur Azizah,  Hasan Dwi Cahyono,  Sari Widya Sihwi,  Wisnu Widiarto",
                "发布日期": "2023-08-10",
                "摘要": "  Fake news is fake material in a news media format but is not processed\nproperly by news agencies. The fake material can provoke or defame significant\nentities or individuals or potentially even for the personal interests of the\ncreators, causing problems for society. Distinguishing fake news and real news\nis challenging due to limited of domain knowledge and time constraints.\nAccording to the survey, the top three areas most exposed to hoaxes and\nmisinformation by residents are in Banten, DKI Jakarta and West Java. The model\nof transformers is referring to an approach in the field of artificial\nintelligence (AI) in natural language processing utilizing the deep learning\narchitectures. Transformers exercise a powerful attention mechanism to process\ntext in parallel and produce rich and contextual word representations. A\nprevious study indicates a superior performance of a transformer model known as\nBERT over and above non transformer approach. However, some studies suggest the\nperformance can be improved with the use of improved BERT models known as\nALBERT and RoBERTa. However, the modified BERT models are not well explored for\ndetecting fake news in Bahasa Indonesia. In this research, we explore those\ntransformer models and found that ALBERT outperformed other models with 87.6%\naccuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)\nrespectively. Source code available at:\nhttps://github.com/Shafna81/fakenewsdetection.git\n",
                "链接": "https://arxiv.org/abs/2308.04950"
            },
            {
                "文章ID": "18471",
                "标题": "A Dataset and BERT-based Models for Targeted Sentiment Analysis on\n  Turkish Texts",
                "作者": " M. Melih Mutlu,  Arzucan Özgür",
                "发布日期": "2022-05-10",
                "摘要": "  Targeted Sentiment Analysis aims to extract sentiment towards a particular\ntarget from a given text. It is a field that is attracting attention due to the\nincreasing accessibility of the Internet, which leads people to generate an\nenormous amount of data. Sentiment analysis, which in general requires\nannotated data for training, is a well-researched area for widely studied\nlanguages such as English. For low-resource languages such as Turkish, there is\na lack of such annotated data. We present an annotated Turkish dataset suitable\nfor targeted sentiment analysis. We also propose BERT-based models with\ndifferent architectures to accomplish the task of targeted sentiment analysis.\nThe results demonstrate that the proposed models outperform the traditional\nsentiment analysis models for the targeted sentiment analysis task.\n",
                "链接": "https://arxiv.org/abs/2205.04185"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "85504",
                "标题": "Modality Adaption or Regularization? A Case Study on End-to-End Speech\n  Translation",
                "作者": " Yuchen Han,  Chen Xu,  Tong Xiao,  Jingbo Zhu",
                "发布日期": "2023-06-14",
                "摘要": "  Pre-training and fine-tuning is a paradigm for alleviating the data scarcity\nproblem in end-to-end speech translation (E2E ST). The commonplace \"modality\ngap\" between speech and text data often leads to inconsistent inputs between\npre-training and fine-tuning. However, we observe that this gap occurs in the\nearly stages of fine-tuning, but does not have a major impact on the final\nperformance. On the other hand, we find that there has another gap, which we\ncall the \"capacity gap\": high resource tasks (such as ASR and MT) always\nrequire a large model to fit, when the model is reused for a low resource task\n(E2E ST), it will get a sub-optimal performance due to the over-fitting. In a\ncase study, we find that the regularization plays a more important role than\nthe well-designed modality adaption method, which achieves 29.0 for en-de and\n40.3 for en-fr on the MuST-C dataset. Code and models are available at\nhttps://github.com/hannlp/TAB.\n",
                "链接": "https://arxiv.org/abs/2306.07650"
            },
            {
                "文章ID": "89528",
                "标题": "To be or not to be: a translation reception study of a literary text\n  translated into Dutch and Catalan using machine translation",
                "作者": " Ana Guerberof Arenas,  Antonio Toral",
                "发布日期": "2023-07-06",
                "摘要": "  This article presents the results of a study involving the reception of a\nfictional story by Kurt Vonnegut translated from English into Catalan and Dutch\nin three conditions: machine-translated (MT), post-edited (PE) and translated\nfrom scratch (HT). 223 participants were recruited who rated the reading\nconditions using three scales: Narrative Engagement, Enjoyment and Translation\nReception. The results show that HT presented a higher engagement, enjoyment\nand translation reception in Catalan if compared to PE and MT. However, the\nDutch readers show higher scores in PE than in both HT and MT, and the highest\nengagement and enjoyments scores are reported when reading the original English\nversion. We hypothesize that when reading a fictional story in translation, not\nonly the condition and the quality of the translations is key to understand its\nreception, but also the participants reading patterns, reading language, and,\nperhaps language status in their own societies.\n",
                "链接": "https://arxiv.org/abs/2307.02358"
            },
            {
                "文章ID": "17416",
                "标题": "Jam or Cream First? Modeling Ambiguity in Neural Machine Translation\n  with SCONES",
                "作者": " Felix Stahlberg,  Shankar Kumar",
                "发布日期": "2022-05-03",
                "摘要": "  The softmax layer in neural machine translation is designed to model the\ndistribution over mutually exclusive tokens. Machine translation, however, is\nintrinsically uncertain: the same source sentence can have multiple\nsemantically equivalent translations. Therefore, we propose to replace the\nsoftmax activation with a multi-label classification layer that can model\nambiguity more effectively. We call our loss function Single-label Contrastive\nObjective for Non-Exclusive Sequences (SCONES). We show that the multi-label\noutput layer can still be trained on single reference training data using the\nSCONES loss function. SCONES yields consistent BLEU score gains across six\ntranslation directions, particularly for medium-resource language pairs and\nsmall beam sizes. By using smaller beam sizes we can speed up inference by a\nfactor of 3.9x and still match or improve the BLEU score obtained using\nsoftmax. Furthermore, we demonstrate that SCONES can be used to train NMT\nmodels that assign the highest probability to adequate translations, thus\nmitigating the \"beam search curse\". Additional experiments on synthetic\nlanguage pairs with varying levels of uncertainty suggest that the improvements\nfrom SCONES can be attributed to better handling of ambiguity.\n",
                "链接": "https://arxiv.org/abs/2205.00704"
            },
            {
                "文章ID": "84278",
                "标题": "Multilingual Clinical NER: Translation or Cross-lingual Transfer?",
                "作者": " Xavier Fontaine,  Félix Gaschi,  Parisa Rastin,  Yannick Toussaint",
                "发布日期": "2023-06-08",
                "摘要": "  Natural language tasks like Named Entity Recognition (NER) in the clinical\ndomain on non-English texts can be very time-consuming and expensive due to the\nlack of annotated data. Cross-lingual transfer (CLT) is a way to circumvent\nthis issue thanks to the ability of multilingual large language models to be\nfine-tuned on a specific task in one language and to provide high accuracy for\nthe same task in another language. However, other methods leveraging\ntranslation models can be used to perform NER without annotated data in the\ntarget language, by either translating the training set or test set. This paper\ncompares cross-lingual transfer with these two alternative methods, to perform\nclinical NER in French and in German without any training data in those\nlanguages. To this end, we release MedNERF a medical NER test set extracted\nfrom French drug prescriptions and annotated with the same guidelines as an\nEnglish dataset. Through extensive experiments on this dataset and on a German\nmedical dataset (Frei and Kramer, 2021), we show that translation-based methods\ncan achieve similar performance to CLT but require more care in their design.\nAnd while they can take advantage of monolingual clinical language models,\nthose do not guarantee better results than large general-purpose multilingual\nmodels, whether with cross-lingual transfer or translation.\n",
                "链接": "https://arxiv.org/abs/2306.04384"
            },
            {
                "文章ID": "22038",
                "标题": "Payday loans -- blessing or growth suppressor? Machine Learning Analysis",
                "作者": " Rohith Mahadevan,  Sam Richard,  Kishore Harshan Kumar,  Jeevitha Murugan,  Santhosh Kannan,   Saaisri,   Tarun,  Raja CSP Raman",
                "发布日期": "2022-06-01",
                "摘要": "  The upsurge of real estate involves a variety of factors that have got\ninfluenced by many domains. Indeed, the unrecognized sector that would affect\nthe economy for which regulatory proposals are being drafted to keep this in\ncontrol is the payday loans. This research paper revolves around the impact of\npayday loans in the real estate market. The research paper draws a first-hand\nexperience of obtaining the index for the concentration of real estate in an\narea of reference by virtue of payday loans in Toronto, Ontario in particular,\nwhich sets out an ideology to create, evaluate and demonstrate the scenario\nthrough research analysis. The purpose of this indexing via payday loans is the\nbasic - debt: income ratio which states that when the income of the person\nbound to pay the interest of payday loans increases, his debt goes down\nmarginally which hence infers that the person invests in fixed assets like real\nestate which hikes up its growth.\n",
                "链接": "https://arxiv.org/abs/2205.15320"
            },
            {
                "文章ID": "50110",
                "标题": "Human or Machine? Turing Tests for Vision and Language",
                "作者": " Mengmi Zhang,  Giorgia Dellaferrera,  Ankur Sikarwar,  Marcelo Armendariz,  Noga Mudrik,  Prachi Agrawal,  Spandan Madan,  Andrei Barbu,  Haochen Yang,  Tanishq Kumar,  Meghna Sadwani,  Stella Dellaferrera,  Michele Pizzochero,  Hanspeter Pfister,  Gabriel Kreiman",
                "发布日期": "2022-11-24",
                "摘要": "  As AI algorithms increasingly participate in daily activities that used to be\nthe sole province of humans, we are inevitably called upon to consider how much\nmachines are really like us. To address this question, we turn to the Turing\ntest and systematically benchmark current AIs in their abilities to imitate\nhumans. We establish a methodology to evaluate humans versus machines in\nTuring-like tests and systematically evaluate a representative set of selected\ndomains, parameters, and variables. The experiments involved testing 769 human\nagents, 24 state-of-the-art AI agents, 896 human judges, and 8 AI judges, in\n21,570 Turing tests across 6 tasks encompassing vision and language modalities.\nSurprisingly, the results reveal that current AIs are not far from being able\nto impersonate human judges across different ages, genders, and educational\nlevels in complex visual and language challenges. In contrast, simple AI judges\noutperform human judges in distinguishing human answers versus machine answers.\nThe curated large-scale Turing test datasets introduced here and their\nevaluation metrics provide valuable insights to assess whether an agent is\nhuman or not. The proposed formulation to benchmark human imitation ability in\ncurrent AIs paves a way for the research community to expand Turing tests to\nother research areas and conditions. All of source code and data are publicly\navailable at https://tinyurl.com/8x8nha7p\n",
                "链接": "https://arxiv.org/abs/2211.13087"
            },
            {
                "文章ID": "81365",
                "标题": "Moral Machine or Tyranny of the Majority?",
                "作者": " Michael Feffer,  Hoda Heidari,  Zachary C. Lipton",
                "发布日期": "2023-05-30",
                "摘要": "  With Artificial Intelligence systems increasingly applied in consequential\ndomains, researchers have begun to ask how these systems ought to act in\nethically charged situations where even humans lack consensus. In the Moral\nMachine project, researchers crowdsourced answers to \"Trolley Problems\"\nconcerning autonomous vehicles. Subsequently, Noothigattu et al. (2018)\nproposed inferring linear functions that approximate each individual's\npreferences and aggregating these linear models by averaging parameters across\nthe population. In this paper, we examine this averaging mechanism, focusing on\nfairness concerns in the presence of strategic effects. We investigate a simple\nsetting where the population consists of two groups, with the minority\nconstituting an {\\alpha} < 0.5 share of the population. To simplify the\nanalysis, we consider the extreme case in which within-group preferences are\nhomogeneous. Focusing on the fraction of contested cases where the minority\ngroup prevails, we make the following observations: (a) even when all parties\nreport their preferences truthfully, the fraction of disputes where the\nminority prevails is less than proportionate in {\\alpha}; (b) the degree of\nsub-proportionality grows more severe as the level of disagreement between the\ngroups increases; (c) when parties report preferences strategically, pure\nstrategy equilibria do not always exist; and (d) whenever a pure strategy\nequilibrium exists, the majority group prevails 100% of the time. These\nfindings raise concerns about stability and fairness of preference vector\naveraging as a mechanism for aggregating diverging voices. Finally, we discuss\nalternatives, including randomized dictatorship and median-based mechanisms.\n",
                "链接": "https://arxiv.org/abs/2305.17319"
            },
            {
                "文章ID": "107237",
                "标题": "Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation\n  with the GeNTE Corpus",
                "作者": " Andrea Piergentili,  Beatrice Savoldi,  Dennis Fucci,  Matteo Negri,  Luisa Bentivogli",
                "发布日期": "2023-10-10",
                "摘要": "  Gender inequality is embedded in our communication practices and perpetuated\nin translation technologies. This becomes particularly apparent when\ntranslating into grammatical gender languages, where machine translation (MT)\noften defaults to masculine and stereotypical representations by making undue\nbinary gender assumptions. Our work addresses the rising demand for inclusive\nlanguage by focusing head-on on gender-neutral translation from English to\nItalian. We start from the essentials: proposing a dedicated benchmark and\nexploring automated evaluation methods. First, we introduce GeNTE, a natural,\nbilingual test set for gender-neutral translation, whose creation was informed\nby a survey on the perception and use of neutral language. Based on GeNTE, we\nthen overview existing reference-based evaluation approaches, highlight their\nlimits, and propose a reference-free method more suitable to assess\ngender-neutral translation.\n",
                "链接": "https://arxiv.org/abs/2310.05294"
            },
            {
                "文章ID": "17900",
                "标题": "Original or Translated? A Causal Analysis of the Impact of\n  Translationese on Machine Translation Performance",
                "作者": " Jingwei Ni,  Zhijing Jin,  Markus Freitag,  Mrinmaya Sachan,  Bernhard Schölkopf",
                "发布日期": "2022-06-10",
                "摘要": "  Human-translated text displays distinct features from naturally written text\nin the same language. This phenomena, known as translationese, has been argued\nto confound the machine translation (MT) evaluation. Yet, we find that existing\nwork on translationese neglects some important factors and the conclusions are\nmostly correlational but not causal. In this work, we collect CausalMT, a\ndataset where the MT training data are also labeled with the human translation\ndirections. We inspect two critical factors, the train-test direction match\n(whether the human translation directions in the training and test sets are\naligned), and data-model direction match (whether the model learns in the same\ndirection as the human translation direction in the dataset). We show that\nthese two factors have a large causal effect on the MT performance, in addition\nto the test-model direction mismatch highlighted by existing work on the impact\nof translationese. In light of our findings, we provide a set of suggestions\nfor MT training and evaluation. Our code and data are at\nhttps://github.com/EdisonNi-hku/CausalMT\n",
                "链接": "https://arxiv.org/abs/2205.02293"
            },
            {
                "文章ID": "102947",
                "标题": "Love or Hate? Share or Split? Privacy-Preserving Training Using Split\n  Learning and Homomorphic Encryption",
                "作者": " Tanveer Khan,  Khoa Nguyen,  Antonis Michalas,  Alexandros Bakas",
                "发布日期": "2023-09-20",
                "摘要": "  Split learning (SL) is a new collaborative learning technique that allows\nparticipants, e.g. a client and a server, to train machine learning models\nwithout the client sharing raw data. In this setting, the client initially\napplies its part of the machine learning model on the raw data to generate\nactivation maps and then sends them to the server to continue the training\nprocess. Previous works in the field demonstrated that reconstructing\nactivation maps could result in privacy leakage of client data. In addition to\nthat, existing mitigation techniques that overcome the privacy leakage of SL\nprove to be significantly worse in terms of accuracy. In this paper, we improve\nupon previous works by constructing a protocol based on U-shaped SL that can\noperate on homomorphically encrypted data. More precisely, in our approach, the\nclient applies homomorphic encryption on the activation maps before sending\nthem to the server, thus protecting user privacy. This is an important\nimprovement that reduces privacy leakage in comparison to other SL-based works.\nFinally, our results show that, with the optimum set of parameters, training\nwith HE data in the U-shaped SL setting only reduces accuracy by 2.65% compared\nto training on plaintext. In addition, raw training data privacy is preserved.\n",
                "链接": "https://arxiv.org/abs/2309.10517"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "113210",
                "标题": "Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in\n  Transformer Models",
                "作者": " Steve Yadlowsky,  Lyric Doshi,  Nilesh Tripuraneni",
                "发布日期": "2023-11-03",
                "摘要": "  Transformer models, notably large language models (LLMs), have the remarkable\nability to perform in-context learning (ICL) -- to perform new tasks when\nprompted with unseen input-output examples without any explicit model training.\nIn this work, we study how effectively transformers can bridge between their\npretraining data mixture, comprised of multiple distinct task families, to\nidentify and learn new tasks in-context which are both inside and outside the\npretraining distribution. Building on previous work, we investigate this\nquestion in a controlled setting, where we study transformer models trained on\nsequences of $(x, f(x))$ pairs rather than natural language. Our empirical\nresults show transformers demonstrate near-optimal unsupervised model selection\ncapabilities, in their ability to first in-context identify different task\nfamilies and in-context learn within them when the task families are\nwell-represented in their pretraining data. However when presented with tasks\nor functions which are out-of-domain of their pretraining data, we demonstrate\nvarious failure modes of transformers and degradation of their generalization\nfor even simple extrapolation tasks. Together our results highlight that the\nimpressive ICL abilities of high-capacity sequence models may be more closely\ntied to the coverage of their pretraining data mixtures than inductive biases\nthat create fundamental generalization capabilities.\n",
                "链接": "https://arxiv.org/abs/2311.00871"
            },
            {
                "文章ID": "111481",
                "标题": "Detecting Pretraining Data from Large Language Models",
                "作者": " Weijia Shi,  Anirudh Ajith,  Mengzhou Xia,  Yangsibo Huang,  Daogao Liu,  Terra Blevins,  Danqi Chen,  Luke Zettlemoyer",
                "发布日期": "2023-11-06",
                "摘要": "  Although large language models (LLMs) are widely deployed, the data used to\ntrain them is rarely disclosed. Given the incredible scale of this data, up to\ntrillions of tokens, it is all but certain that it includes potentially\nproblematic text such as copyrighted materials, personally identifiable\ninformation, and test data for widely reported reference benchmarks. However,\nwe currently have no way to know which data of these types is included or in\nwhat proportions. In this paper, we study the pretraining data detection\nproblem: given a piece of text and black-box access to an LLM without knowing\nthe pretraining data, can we determine if the model was trained on the provided\ntext? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that\nuses data created before and after model training to support gold truth\ndetection. We also introduce a new detection method Min-K% Prob based on a\nsimple hypothesis: an unseen example is likely to contain a few outlier words\nwith low probabilities under the LLM, while a seen example is less likely to\nhave words with such low probabilities. Min-K% Prob can be applied without any\nknowledge about the pretraining corpus or any additional training, departing\nfrom previous detection methods that require training a reference model on data\nthat is similar to the pretraining data. Moreover, our experiments demonstrate\nthat Min-K% Prob achieves a 7.4% improvement on WIKIMIA over these previous\nmethods. We apply Min-K% Prob to three real-world scenarios, copyrighted book\ndetection, contaminated downstream example detection and privacy auditing of\nmachine unlearning, and find it a consistently effective solution.\n",
                "链接": "https://arxiv.org/abs/2310.16789"
            },
            {
                "文章ID": "72773",
                "标题": "VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and\n  Dataset",
                "作者": " Sihan Chen,  Xingjian He,  Longteng Guo,  Xinxin Zhu,  Weining Wang,  Jinhui Tang,  Jing Liu",
                "发布日期": "2023-04-18",
                "摘要": "  In this paper, we propose a Vision-Audio-Language Omni-peRception pretraining\nmodel (VALOR) for multi-modal understanding and generation. Different from\nwidely-studied vision-language pretraining models, VALOR jointly models\nrelationships of vision, audio and language in an end-to-end manner. It\ncontains three separate encoders for single modality representations, and a\ndecoder for multimodal conditional text generation. We design two pretext tasks\nto pretrain VALOR model, including Multimodal Grouping Alignment (MGA) and\nMultimodal Grouping Captioning (MGC). MGA projects vision, language and audio\nto the same common space, building vision-language, audio-language and\naudiovisual-language alignment simultaneously. MGC learns how to generate text\ntokens in conditions of vision, audio or their both. To promote\nvision-audio-language pretraining research, we construct a large-scale\nhigh-quality tri-modality dataset named VALOR-1M, which contains 1M audiable\nvideos with human annotated audiovisual captions. Extensive experiments show\nthat VALOR can learn strong multimodal correlations and be generalized to\nvarious downstream tasks (e.g., retrieval, captioning and question answering),\nwith different input modalities (e.g., vision-language, audio-language and\naudiovisual-language). VALOR achieves new state-of-the-art performances on\nseries of public cross-modality benchmarks. Code and data are available at\nproject page https://casia-iva-group.github.io/projects/VALOR.\n",
                "链接": "https://arxiv.org/abs/2304.08345"
            },
            {
                "文章ID": "70577",
                "标题": "Blockwise Compression of Transformer-based Models without Retraining",
                "作者": " Gaochen Dong,  Wei Chen",
                "发布日期": "2023-09-19",
                "摘要": "  Transformer-based models, exemplified by GPT-3, ChatGPT, and GPT-4, have\nrecently garnered considerable attention in both academia and industry due to\ntheir promising performance in general language tasks. Nevertheless, these\nmodels typically involve computationally encoding processes, and in some cases,\ndecoding processes as well, both of which are fundamentally large-scale matrix\nmultiplication. These operations bring the inevitable challenges of massive\ncomputation resources and huge memory footprint, usually requiring at least\n10^23 FLOPs and hundreds of gigabytes, respectively. A common method to address\nthis issue is to reduce the computational and memory requirements by applying\nlayerwise quantization to the transformer, replacing the usual fp32 data type\nwith a low-bit equivalent. Unfortunately, this method often leads to decreased\nmodel accuracy and necessitates time-consuming retraining. Such retraining not\nonly requires fine-tuning skills but also substantial computational resources,\nposing challenges for users. To specifically tackle these issues, we propose\nBCT, a framework of blockwise compression for transformers without retraining,\naiming to facilitate model deployment. Unlike layerwise compression methods,\nBCT achieves finer compression of the entire transformer by operating\nblockwise. This method mitigates data distribution deviation caused by\nquantization, eliminating the requirement for retraining. BCT effectively\ncompresses all components of the model, including but not limited to the\nembedding, matrix multiplication, GELU, Softmax, layer normalization, and\nintermediate results. In a case study, an efficient model is compressed by BCT\nachieving up to 7.988x compression. Subsequently, we also evaluate it on\nseveral General Language Understanding Evaluation (GLUE) datasets.\n",
                "链接": "https://arxiv.org/abs/2304.01483"
            },
            {
                "文章ID": "22225",
                "标题": "CogVideo: Large-scale Pretraining for Text-to-Video Generation via\n  Transformers",
                "作者": " Wenyi Hong,  Ming Ding,  Wendi Zheng,  Xinghan Liu,  Jie Tang",
                "发布日期": "2022-06-01",
                "摘要": "  Large-scale pretrained transformers have created milestones in text (GPT-3)\nand text-to-image (DALL-E and CogView) generation. Its application to video\ngeneration is still facing many challenges: The potential huge computation cost\nmakes the training from scratch unaffordable; The scarcity and weak relevance\nof text-video datasets hinder the model understanding complex movement\nsemantics. In this work, we present 9B-parameter transformer CogVideo, trained\nby inheriting a pretrained text-to-image model, CogView2. We also propose\nmulti-frame-rate hierarchical training strategy to better align text and video\nclips. As (probably) the first open-source large-scale pretrained text-to-video\nmodel, CogVideo outperforms all publicly available models at a large margin in\nmachine and human evaluations.\n",
                "链接": "https://arxiv.org/abs/2205.15868"
            },
            {
                "文章ID": "61474",
                "标题": "Guiding Pretraining in Reinforcement Learning with Large Language Models",
                "作者": " Yuqing Du,  Olivia Watkins,  Zihan Wang,  Cédric Colas,  Trevor Darrell,  Pieter Abbeel,  Abhishek Gupta,  Jacob Andreas",
                "发布日期": "2023-09-18",
                "摘要": "  Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.\n",
                "链接": "https://arxiv.org/abs/2302.06692"
            },
            {
                "文章ID": "118367",
                "标题": "MEDITRON-70B: Scaling Medical Pretraining for Large Language Models",
                "作者": " Zeming Chen,  Alejandro Hernández Cano,  Angelika Romanou,  Antoine Bonnet,  Kyle Matoba,  Francesco Salvi,  Matteo Pagliardini,  Simin Fan,  Andreas Köpf,  Amirkeivan Mohtashami,  Alexandre Sallinen,  Alireza Sakhaeirad,  Vinitra Swamy,  Igor Krawczuk,  Deniz Bayazit,  Axel Marmet,  Syrielle Montariol,  Mary-Anne Hartley,  Martin Jaggi,  Antoine Bosselut",
                "发布日期": "2023-11-28",
                "摘要": "  Large language models (LLMs) can potentially democratize access to medical\nknowledge. While many efforts have been made to harness and improve LLMs'\nmedical knowledge and reasoning capacities, the resulting models are either\nclosed-source (e.g., PaLM, GPT-4) or limited in scale (<= 13B parameters),\nwhich restricts their abilities. In this work, we improve access to large-scale\nmedical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B\nparameters adapted to the medical domain. MEDITRON builds on Llama-2 (through\nour adaptation of Nvidia's Megatron-LM distributed trainer), and extends\npretraining on a comprehensively curated medical corpus, including selected\nPubMed articles, abstracts, and internationally-recognized medical guidelines.\nEvaluations using four major medical benchmarks show significant performance\ngains over several state-of-the-art baselines before and after task-specific\nfinetuning. Overall, MEDITRON achieves a 6% absolute performance gain over the\nbest public baseline in its parameter class and 3% over the strongest baseline\nwe finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70B\noutperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of\nMed-PaLM-2. We release our code for curating the medical pretraining corpus and\nthe MEDITRON model weights to drive open-source development of more capable\nmedical LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.16079"
            },
            {
                "文章ID": "14842",
                "标题": "METRO: Efficient Denoising Pretraining of Large Scale Autoencoding\n  Language Models with Model Generated Signals",
                "作者": " Payal Bajaj,  Chenyan Xiong,  Guolin Ke,  Xiaodong Liu,  Di He,  Saurabh Tiwary,  Tie-Yan Liu,  Paul Bennett,  Xia Song,  Jianfeng Gao",
                "发布日期": "2022-04-19",
                "摘要": "  We present an efficient method of pretraining large-scale autoencoding\nlanguage models using training signals generated by an auxiliary model.\nOriginated in ELECTRA, this training strategy has demonstrated\nsample-efficiency to pretrain models at the scale of hundreds of millions of\nparameters. In this work, we conduct a comprehensive empirical study, and\npropose a recipe, namely \"Model generated dEnoising TRaining Objective\"\n(METRO), which incorporates some of the best modeling techniques developed\nrecently to speed up, stabilize, and enhance pretrained language models without\ncompromising model effectiveness. The resultant models, METRO-LM, consisting of\nup to 5.4 billion parameters, achieve new state-of-the-art on the GLUE,\nSuperGLUE, and SQuAD benchmarks. More importantly, METRO-LM are efficient in\nthat they often outperform previous large models with significantly smaller\nmodel sizes and lower pretraining cost.\n",
                "链接": "https://arxiv.org/abs/2204.06644"
            },
            {
                "文章ID": "111908",
                "标题": "FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model\n  for Fault Recognition",
                "作者": " Zeren Zhang,  Ran Chen,  Jinwen Ma",
                "发布日期": "2023-10-30",
                "摘要": "  This paper introduces an approach to enhance seismic fault recognition\nthrough self-supervised pretraining. Seismic fault interpretation holds great\nsignificance in the fields of geophysics and geology. However, conventional\nmethods for seismic fault recognition encounter various issues, including\ndependence on data quality and quantity, as well as susceptibility to\ninterpreter subjectivity. Currently, automated fault recognition methods\nproposed based on small synthetic datasets experience performance degradation\nwhen applied to actual seismic data. To address these challenges, we have\nintroduced the concept of self-supervised learning, utilizing a substantial\namount of relatively easily obtainable unlabeled seismic data for pretraining.\nSpecifically, we have employed the Swin Transformer model as the core network\nand employed the SimMIM pretraining task to capture unique features related to\ndiscontinuities in seismic data. During the fine-tuning phase, inspired by edge\ndetection techniques, we have also refined the structure of the Swin-UNETR\nmodel, enabling multiscale decoding and fusion for more effective fault\ndetection. Experimental results demonstrate that our proposed method attains\nstate-of-the-art performance on the Thebe dataset, as measured by the OIS and\nODS metrics.\n",
                "链接": "https://arxiv.org/abs/2310.17974"
            },
            {
                "文章ID": "102081",
                "标题": "Large-Vocabulary 3D Diffusion Model with Transformer",
                "作者": " Ziang Cao,  Fangzhou Hong,  Tong Wu,  Liang Pan,  Ziwei Liu",
                "发布日期": "2023-09-18",
                "摘要": "  Creating diverse and high-quality 3D assets with an automatic generative\nmodel is highly desirable. Despite extensive efforts on 3D generation, most\nexisting works focus on the generation of a single category or a few\ncategories. In this paper, we introduce a diffusion-based feed-forward\nframework for synthesizing massive categories of real-world 3D objects with a\nsingle generative model. Notably, there are three major challenges for this\nlarge-vocabulary 3D generation: a) the need for expressive yet efficient 3D\nrepresentation; b) large diversity in geometry and texture across categories;\nc) complexity in the appearances of real-world objects. To this end, we propose\na novel triplane-based 3D-aware Diffusion model with TransFormer, DiffTF, for\nhandling challenges via three aspects. 1) Considering efficiency and\nrobustness, we adopt a revised triplane representation and improve the fitting\nspeed and accuracy. 2) To handle the drastic variations in geometry and\ntexture, we regard the features of all 3D objects as a combination of\ngeneralized 3D knowledge and specialized 3D features. To extract generalized 3D\nknowledge from diverse categories, we propose a novel 3D-aware transformer with\nshared cross-plane attention. It learns the cross-plane relations across\ndifferent planes and aggregates the generalized 3D knowledge with specialized\n3D features. 3) In addition, we devise the 3D-aware encoder/decoder to enhance\nthe generalized 3D knowledge in the encoded triplanes for handling categories\nwith complex appearances. Extensive experiments on ShapeNet and OmniObject3D\n(over 200 diverse real-world categories) convincingly demonstrate that a single\nDiffTF model achieves state-of-the-art large-vocabulary 3D object generation\nperformance with large diversity, rich semantics, and high quality.\n",
                "链接": "https://arxiv.org/abs/2309.07920"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "64359",
                "标题": "Reinforcement Learning Guided Multi-Objective Exam Paper Generation",
                "作者": " Yuhu Shang,  Xuexiong Luo,  Lihong Wang,  Hao Peng,  Xiankun Zhang,  Yimeng Ren,  Kun Liang",
                "发布日期": "2023-03-03",
                "摘要": "  To reduce the repetitive and complex work of instructors, exam paper\ngeneration (EPG) technique has become a salient topic in the intelligent\neducation field, which targets at generating high-quality exam paper\nautomatically according to instructor-specified assessment criteria. The\ncurrent advances utilize the ability of heuristic algorithms to optimize\nseveral well-known objective constraints, such as difficulty degree, number of\nquestions, etc., for producing optimal solutions. However, in real scenarios,\nconsidering other equally relevant objectives (e.g., distribution of exam\nscores, skill coverage) is extremely important. Besides, how to develop an\nautomatic multi-objective solution that finds an optimal subset of questions\nfrom a huge search space of large-sized question datasets and thus composes a\nhigh-quality exam paper is urgent but non-trivial. To this end, we skillfully\ndesign a reinforcement learning guided Multi-Objective Exam Paper Generation\nframework, termed MOEPG, to simultaneously optimize three exam domain-specific\nobjectives including difficulty degree, distribution of exam scores, and skill\ncoverage. Specifically, to accurately measure the skill proficiency of the\nexaminee group, we first employ deep knowledge tracing to model the interaction\ninformation between examinees and response logs. We then design the flexible\nExam Q-Network, a function approximator, which automatically selects the\nappropriate question to update the exam paper composition process. Later, MOEPG\ndivides the decision space into multiple subspaces to better guide the updated\ndirection of the exam paper. Through extensive experiments on two real-world\ndatasets, we demonstrate that MOEPG is feasible in addressing the multiple\ndilemmas of exam paper generation scenario.\n",
                "链接": "https://arxiv.org/abs/2303.01042"
            },
            {
                "文章ID": "30296",
                "标题": "CodeT: Code Generation with Generated Tests",
                "作者": " Bei Chen,  Fengji Zhang,  Anh Nguyen,  Daoguang Zan,  Zeqi Lin,  Jian-Guang Lou,  Weizhu Chen",
                "发布日期": "2022-11-24",
                "摘要": "  The task of generating code solutions for a given programming problem can\nbenefit from the use of pre-trained language models such as Codex, which can\nproduce multiple diverse samples. However, a major challenge for this task is\nto select the most appropriate solution from the multiple samples generated by\nthe pre-trained language models. A natural way to evaluate the quality and\ncorrectness of a code solution is to run it against a set of test cases, but\nthe manual creation of such test cases is often costly and time-consuming. In\nthis paper, we propose a novel method, CodeT, that leverages the same\npre-trained language models to automatically generate test cases for the code\nsamples, thus reducing the human effort and increasing the coverage of the test\nscenarios. CodeT then executes the code samples using the generated test cases,\nand performs a dual execution agreement, which considers both the consistency\nof the outputs against the generated test cases and the agreement of the\noutputs with other code samples. We conduct comprehensive experiments on four\nbenchmarks, HumanEval, MBPP, APPS and CodeContests, using five different\npre-trained language models with varying sizes and capabilities. Our results\nshow that CodeT can significantly improve the performance of code solution\nselection over previous methods, achieving remarkable and consistent gains\nacross different models and benchmarks. For instance, CodeT improves the pass@1\nmetric on HumanEval to 65.8%, which represents an absolute improvement of 18.8%\nover the code-davinci-002 model, and an absolute improvement of more than 20%\nover the previous state-of-the-art results.\n",
                "链接": "https://arxiv.org/abs/2207.10397"
            },
            {
                "文章ID": "51256",
                "标题": "Coder Reviewer Reranking for Code Generation",
                "作者": " Tianyi Zhang,  Tao Yu,  Tatsunori B. Hashimoto,  Mike Lewis,  Wen-tau Yih,  Daniel Fried,  Sida I. Wang",
                "发布日期": "2022-11-30",
                "摘要": "  Sampling diverse programs from a code language model and reranking with model\nlikelihood is a popular method for code generation but it is prone to\npreferring degenerate solutions. Inspired by collaborative programming, we\npropose Coder-Reviewer reranking. We augment Coder language models from past\nwork, which generate programs given language instructions, with Reviewer\nmodels, which evaluate the likelihood of the instruction given the generated\nprograms. We perform an extensive study across six datasets with eight models\nfrom three model families. Experimental results show that Coder-Reviewer\nreranking leads to consistent and significant improvement (up to 17% absolute\naccuracy gain) over reranking with the Coder model only. When combined with\nexecutability filtering, Coder-Reviewer reranking can often outperform the\nminimum Bayes risk method. Coder-Reviewer reranking is easy to implement by\nprompting, can generalize to different programming languages, and works well\nwith off-the-shelf hyperparameters.\n",
                "链接": "https://arxiv.org/abs/2211.16490"
            },
            {
                "文章ID": "48407",
                "标题": "Evaluating How Fine-tuning on Bimodal Data Effects Code Generation",
                "作者": " Gabriel Orlanski,  Seonhye Yang,  Michael Healy",
                "发布日期": "2022-11-16",
                "摘要": "  Despite the increase in popularity of language models for code generation, it\nis still unknown how training on bimodal coding forums affects a model's code\ngeneration performance and reliability. We, therefore, collect a dataset of\nover 2.2M StackOverflow questions with answers for finetuning. These fine-tuned\nmodels have average $pass@k$ improvements of 54.64% and 85.35% on the HumanEval\n(Chen et al., 2021) and Mostly Basic Program Problems (Austin et al., 2021)\ntasks, respectively. This regime further decreases the number of generated\nprograms with both syntax and runtime errors. However, we find that at higher\ntemperatures, there are significant decreases to the model's ability to\ngenerate runnable programs despite higher $pass@k$ scores, underscoring the\nneed for better methods of incorporating such data that mitigate these side\neffects. The code can be found\nhttps://github.com/gabeorlanski/bimodalcode-generation\n",
                "链接": "https://arxiv.org/abs/2211.07842"
            },
            {
                "文章ID": "15595",
                "标题": "CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex",
                "作者": " Immanuel Trummer",
                "发布日期": "2022-04-20",
                "摘要": "  CodexDB is an SQL processing engine whose internals can be customized via\nnatural language instructions. CodexDB is based on OpenAI's GPT-3 Codex model\nwhich translates text into code. It is a framework on top of GPT-3 Codex that\ndecomposes complex SQL queries into a series of simple processing steps,\ndescribed in natural language. Processing steps are enriched with user-provided\ninstructions and descriptions of database properties. Codex translates the\nresulting text into query processing code. An early prototype of CodexDB is\nable to generate correct code for a majority of queries of the WikiSQL\nbenchmark and can be customized in various ways.\n",
                "链接": "https://arxiv.org/abs/2204.08941"
            },
            {
                "文章ID": "61747",
                "标题": "Generation of Highlights from Research Papers Using Pointer-Generator\n  Networks and SciBERT Embeddings",
                "作者": " Tohida Rehman,  Debarshi Kumar Sanyal,  Samiran Chattopadhyay,  Plaban Kumar Bhowmick,  Partha Pratim Das",
                "发布日期": "2023-09-19",
                "摘要": "  Nowadays many research articles are prefaced with research highlights to\nsummarize the main findings of the paper. Highlights not only help researchers\nprecisely and quickly identify the contributions of a paper, they also enhance\nthe discoverability of the article via search engines. We aim to automatically\nconstruct research highlights given certain segments of a research paper. We\nuse a pointer-generator network with coverage mechanism and a contextual\nembedding layer at the input that encodes the input tokens into SciBERT\nembeddings. We test our model on a benchmark dataset, CSPubSum, and also\npresent MixSub, a new multi-disciplinary corpus of papers for automatic\nresearch highlight generation. For both CSPubSum and MixSub, we have observed\nthat the proposed model achieves the best performance compared to related\nvariants and other models proposed in the literature. On the CSPubSum dataset,\nour model achieves the best performance when the input is only the abstract of\na paper as opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2\nand ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR score of\n32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On the\nnew MixSub dataset, where only the abstract is the input, our proposed model\n(when trained on the whole training corpus without distinguishing between the\nsubject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,\n9.76 and 29.3, respectively, METEOR score of 24.00, and BERTScore F1 of 85.25.\n",
                "链接": "https://arxiv.org/abs/2302.07729"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "79847",
                "标题": "GrACE: Generation using Associated Code Edits",
                "作者": " Priyanshu Gupta,  Avishree Khare,  Yasharth Bajpai,  Saikat Chakraborty,  Sumit Gulwani,  Aditya Kanade,  Arjun Radhakrishna,  Gustavo Soares,  Ashish Tiwari",
                "发布日期": "2023-09-22",
                "摘要": "  Developers expend a significant amount of time in editing code for a variety\nof reasons such as bug fixing or adding new features. Designing effective\nmethods to predict code edits has been an active yet challenging area of\nresearch due to the diversity of code edits and the difficulty of capturing the\ndeveloper intent. In this work, we address these challenges by endowing\npre-trained large language models (LLMs) of code with the knowledge of prior,\nrelevant edits. The generative capability of the LLMs helps address the\ndiversity in code changes and conditioning code generation on prior edits helps\ncapture the latent developer intent. We evaluate two well-known LLMs, Codex and\nCodeT5, in zero-shot and fine-tuning settings respectively. In our experiments\nwith two datasets, the knowledge of prior edits boosts the performance of the\nLLMs significantly and enables them to generate 29% and 54% more correctly\nedited code in top-1 suggestions relative to the current state-of-the-art\nsymbolic and neural approaches, respectively.\n",
                "链接": "https://arxiv.org/abs/2305.14129"
            },
            {
                "文章ID": "27761",
                "标题": "CodeRL: Mastering Code Generation through Pretrained Models and Deep\n  Reinforcement Learning",
                "作者": " Hung Le,  Yue Wang,  Akhilesh Deepak Gotmare,  Silvio Savarese,  Steven C. H. Hoi",
                "发布日期": "2022-11-04",
                "摘要": "  Program synthesis or code generation aims to generate a program that\nsatisfies a problem specification. Recent approaches using large-scale\npretrained language models (LMs) have shown promising results, yet they have\nsome critical limitations. In particular, they often follow a standard\nsupervised fine-tuning procedure to train a code generation model only from the\npairs of natural-language problem descriptions and ground-truth programs. Such\nparadigm largely ignores some important but potentially useful signals in the\nproblem specification such as unit tests, which thus often results in poor\nperformance when solving complex unseen coding tasks. To address the\nlimitations, we propose \"CodeRL\", a new framework for program synthesis tasks\nthrough pretrained LMs and deep reinforcement learning (RL). Specifically,\nduring training, we treat the code-generating LM as an actor network, and\nintroduce a critic network that is trained to predict the functional\ncorrectness of generated programs and provide dense feedback signals to the\nactor. During inference, we introduce a new generation procedure with a\ncritical sampling strategy that allows a model to automatically regenerate\nprograms based on feedback from example unit tests and critic scores. For the\nmodel backbones, we extended the encoder-decoder architecture of CodeT5 with\nenhanced learning objectives, larger model sizes, and better pretraining data.\nOur method not only achieves new SOTA results on the challenging APPS\nbenchmark, but also shows strong zero-shot transfer capability with new SOTA\nresults on the simpler MBPP benchmark.\n",
                "链接": "https://arxiv.org/abs/2207.01780"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "11850",
                "标题": "Human-centred home network security",
                "作者": " Derek McAuley,  Jiahong Chen,  Tom Lodge,  Richard Mortier,  Stanislaw Piasecki,  Diana Andreea Popescu,  Lachlan Urquhart",
                "发布日期": "2022-03-29",
                "摘要": "  This chapter draws from across the foregoing chapters discussing many core\nHDI approaches and disciplinary perspectives to consider the specific\napplication of HDI in home network security. While much work has considered the\nchallenges of securing in home IoT devices and their communications, especially\nfor those with limited power or computational capacity, scant attention has\nbeen paid by the research community to home network security, and its\nacceptability and usability, from the viewpoint of ordinary citizens. It will\nbe clear that we need a radical transformation in our approach to designing\ndomestic networking infrastructure to guard against widespread cyber-attacks\nthat threaten to counter the benefits of the IoT. Our aim has to be to defend\nagainst enemies inside the walls, to protect critical functionality in the home\nagainst rogue devices and prevent the proliferation of disruptive wide-scale\nIoT DDOS attacks that are already occurring [1].\n",
                "链接": "https://arxiv.org/abs/2203.14109"
            },
            {
                "文章ID": "94111",
                "标题": "Structural Embeddings of Tools for Large Language Models",
                "作者": " Eren Unlu",
                "发布日期": "2023-08-02",
                "摘要": "  It is evident that the current state of Large Language Models (LLMs)\nnecessitates the incorporation of external tools. The lack of straightforward\nalgebraic and logical reasoning is well documented and prompted researchers to\ndevelop frameworks which allow LLMs to operate via external tools. The\nontological nature of tool utilization for a specific task can be well\nformulated with a Directed Acyclic Graph (DAG). The central aim of the paper is\nto highlight the importance of graph based approaches to LLM-tool interaction\nin near future. We propose an exemplary framework to guide the orchestration of\nexponentially increasing numbers of external tools with LLMs,where objectives\nand functionalities of tools are graph encoded hierarchically. Assuming that\ntextual segments of a Chain-of-Thought (CoT) can be imagined as a tool as\ndefined here, the graph based framework can pave new avenues in that particular\ndirection as well.\n",
                "链接": "https://arxiv.org/abs/2308.00447"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "95590",
                "标题": "An Empirical Study on Using Large Language Models to Analyze Software\n  Supply Chain Security Failures",
                "作者": " Tanmay Singla,  Dharun Anandayuvaraj,  Kelechi G. Kalu,  Taylor R. Schorlemmer,  James C. Davis",
                "发布日期": "2023-08-10",
                "摘要": "  As we increasingly depend on software systems, the consequences of breaches\nin the software supply chain become more severe. High-profile cyber attacks\nlike those on SolarWinds and ShadowHammer have resulted in significant\nfinancial and data losses, underlining the need for stronger cybersecurity. One\nway to prevent future breaches is by studying past failures. However,\ntraditional methods of analyzing these failures require manually reading and\nsummarizing reports about them. Automated support could reduce costs and allow\nanalysis of more failures. Natural Language Processing (NLP) techniques such as\nLarge Language Models (LLMs) could be leveraged to assist the analysis of\nfailures. In this study, we assessed the ability of Large Language Models\n(LLMs) to analyze historical software supply chain breaches. We used LLMs to\nreplicate the manual analysis of 69 software supply chain security failures\nperformed by members of the Cloud Native Computing Foundation (CNCF). We\ndeveloped prompts for LLMs to categorize these by four dimensions: type of\ncompromise, intent, nature, and impact. GPT 3.5s categorizations had an average\naccuracy of 68% and Bard had an accuracy of 58% over these dimensions. We\nreport that LLMs effectively characterize software supply chain failures when\nthe source articles are detailed enough for consensus among manual analysts,\nbut cannot yet replace human analysts. Future work can improve LLM performance\nin this context, and study a broader range of articles and failures.\n",
                "链接": "https://arxiv.org/abs/2308.04898"
            },
            {
                "文章ID": "102250",
                "标题": "On some limitations of data-driven weather forecasting models",
                "作者": " Massimo Bonavita",
                "发布日期": "2023-11-06",
                "摘要": "  As in many other areas of engineering and applied science, Machine Learning\n(ML) is having a profound impact in the domain of Weather and Climate\nPrediction. A very recent development in this area has been the emergence of\nfully data-driven ML prediction models which routinely claim superior\nperformance to that of traditional physics-based models. In this work, we\nexamine some aspects of the forecasts produced by an exemplar of the current\ngeneration of ML models, Pangu-Weather, with a focus on the fidelity and\nphysical consistency of those forecasts and how these characteristics relate to\nperceived forecast performance. The main conclusion is that Pangu-Weather\nforecasts, and possibly those of similar ML models, do not have the fidelity\nand physical consistency of physics-based models and their advantage in\naccuracy on traditional deterministic metrics of forecast skill can be at least\npartly attributed to these peculiarities. Balancing forecast skill and physical\nconsistency of ML-driven predictions will be an important consideration for\nfuture ML models. However, and similarly to other modern post-processing\ntechnologies, the current ML models appear to be already able to add value to\nstandard NWP output for specific forecast applications and combined with their\nextremely low computational cost during deployment, are set to provide an\nadditional, useful source of forecast information. .\n",
                "链接": "https://arxiv.org/abs/2309.08473"
            },
            {
                "文章ID": "98955",
                "标题": "Using ChatGPT as a Static Application Security Testing Tool",
                "作者": " Atieh Bakhshandeh,  Abdalsamad Keramatfar,  Amir Norouzi,  Mohammad Mahdi Chekidehkhoun",
                "发布日期": "2023-08-29",
                "摘要": "  In recent years, artificial intelligence has had a conspicuous growth in\nalmost every aspect of life. One of the most applicable areas is security code\nreview, in which a lot of AI-based tools and approaches have been proposed.\nRecently, ChatGPT has caught a huge amount of attention with its remarkable\nperformance in following instructions and providing a detailed response.\nRegarding the similarities between natural language and code, in this paper, we\nstudy the feasibility of using ChatGPT for vulnerability detection in Python\nsource code. Toward this goal, we feed an appropriate prompt along with\nvulnerable data to ChatGPT and compare its results on two datasets with the\nresults of three widely used Static Application Security Testing tools (Bandit,\nSemgrep and SonarQube). We implement different kinds of experiments with\nChatGPT and the results indicate that ChatGPT reduces the false positive and\nfalse negative rates and has the potential to be used for Python source code\nvulnerability detection.\n",
                "链接": "https://arxiv.org/abs/2308.14434"
            },
            {
                "文章ID": "103416",
                "标题": "On the Definition of Appropriate Trust and the Tools that Come with it",
                "作者": " Helena Löfström",
                "发布日期": "2023-09-22",
                "摘要": "  Evaluating the efficiency of human-AI interactions is challenging, including\nsubjective and objective quality aspects. With the focus on the human\nexperience of the explanations, evaluations of explanation methods have become\nmostly subjective, making comparative evaluations almost impossible and highly\nlinked to the individual user. However, it is commonly agreed that one aspect\nof explanation quality is how effectively the user can detect if the\npredictions are trustworthy and correct, i.e., if the explanations can increase\nthe user's appropriate trust in the model. This paper starts with the\ndefinitions of appropriate trust from the literature. It compares the\ndefinitions with model performance evaluation, showing the strong similarities\nbetween appropriate trust and model performance evaluation. The paper's main\ncontribution is a novel approach to evaluating appropriate trust by taking\nadvantage of the likenesses between definitions. The paper offers several\nstraightforward evaluation methods for different aspects of user performance,\nincluding suggesting a method for measuring uncertainty and appropriate trust\nin regression.\n",
                "链接": "https://arxiv.org/abs/2309.11937"
            },
            {
                "文章ID": "49428",
                "标题": "Semantic Similarity-Based Clustering of Findings From Security Testing\n  Tools",
                "作者": " Phillip Schneider,  Markus Voggenreiter,  Abdullah Gulraiz,  Florian Matthes",
                "发布日期": "2022-11-22",
                "摘要": "  Over the last years, software development in domains with high security\ndemands transitioned from traditional methodologies to uniting modern\napproaches from software development and operations (DevOps). Key principles of\nDevOps gained more importance and are now applied to security aspects of\nsoftware development, resulting in the automation of security-enhancing\nactivities. In particular, it is common practice to use automated security\ntesting tools that generate reports after inspecting a software artifact from\nmultiple perspectives. However, this raises the challenge of generating\nduplicate security findings. To identify these duplicate findings manually, a\nsecurity expert has to invest resources like time, effort, and knowledge. A\npartial automation of this process could reduce the analysis effort, encourage\nDevOps principles, and diminish the chance of human error. In this study, we\ninvestigated the potential of applying Natural Language Processing for\nclustering semantically similar security findings to support the identification\nof problem-specific duplicate findings. Towards this goal, we developed a web\napplication for annotating and assessing security testing tool reports and\npublished a human-annotated corpus of clustered security findings. In addition,\nwe performed a comparison of different semantic similarity techniques for\nautomatically grouping security findings. Finally, we assess the resulting\nclusters using both quantitative and qualitative evaluation methods.\n",
                "链接": "https://arxiv.org/abs/2211.11057"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "82796",
                "标题": "Unfair Utilities and First Steps Towards Improving Them",
                "作者": " Frederik Hytting Jørgensen,  Sebastian Weichwald,  Jonas Peters",
                "发布日期": "2023-06-02",
                "摘要": "  Many fairness criteria constrain the policy or choice of predictors. In this\nwork, we propose a different framework for thinking about fairness: Instead of\nconstraining the policy or choice of predictors, we consider which utility a\npolicy is optimizing for. We define value of information fairness and propose\nto not use utilities that do not satisfy this criterion. We describe how to\nmodify a utility to satisfy this fairness criterion and discuss the\nconsequences this might have on the corresponding optimal policies.\n",
                "链接": "https://arxiv.org/abs/2306.00636"
            },
            {
                "文章ID": "111530",
                "标题": "Break it, Imitate it, Fix it: Robustness by Generating Human-Like\n  Attacks",
                "作者": " Aradhana Sinha,  Ananth Balashankar,  Ahmad Beirami,  Thi Avrahami,  Jilin Chen,  Alex Beutel",
                "发布日期": "2023-10-27",
                "摘要": "  Real-world natural language processing systems need to be robust to human\nadversaries. Collecting examples of human adversaries for training is an\neffective but expensive solution. On the other hand, training on synthetic\nattacks with small perturbations - such as word-substitution - does not\nactually improve robustness to human adversaries. In this paper, we propose an\nadversarial training framework that uses limited human adversarial examples to\ngenerate more useful adversarial examples at scale. We demonstrate the\nadvantages of this system on the ANLI and hate speech detection benchmark\ndatasets - both collected via an iterative, adversarial\nhuman-and-model-in-the-loop procedure. Compared to training only on observed\nhuman attacks, also training on our synthetic adversarial examples improves\nmodel robustness to future rounds. In ANLI, we see accuracy gains on the\ncurrent set of attacks (44.1%$\\,\\to\\,$50.1%) and on two future unseen rounds of\nhuman generated attacks (32.5%$\\,\\to\\,$43.4%, and 29.4%$\\,\\to\\,$40.2%). In hate\nspeech detection, we see AUC gains on current attacks (0.76 $\\to$ 0.84) and a\nfuture round (0.77 $\\to$ 0.79). Attacks from methods that do not learn the\ndistribution of existing human adversaries, meanwhile, degrade robustness.\n",
                "链接": "https://arxiv.org/abs/2310.16955"
            },
            {
                "文章ID": "20498",
                "标题": "Improving Short Text Classification With Augmented Data Using GPT-3",
                "作者": " Salvador Balkus,  Donghui Yan",
                "发布日期": "2023-08-29",
                "摘要": "  GPT-3 is a large-scale natural language model developed by OpenAI that can\nperform many different tasks, including topic classification. Although\nresearchers claim that it requires only a small number of in-context examples\nto learn a task, in practice GPT-3 requires these training examples to be\neither of exceptional quality or a higher quantity than easily created by hand.\nTo address this issue, this study teaches GPT-3 to classify whether a question\nis related to data science by augmenting a small training set with additional\nexamples generated by GPT-3 itself. This study compares two classifiers: the\nGPT-3 Classification Endpoint with augmented examples, and the GPT-3 Completion\nEndpoint with an optimal training set chosen using a genetic algorithm. We find\nthat while the augmented Completion Endpoint achieves upwards of 80 percent\nvalidation accuracy, using the augmented Classification Endpoint yields more\nconsistent accuracy on unseen examples. In this way, giving large-scale machine\nlearning models like GPT-3 the ability to propose their own additional training\nexamples can result in improved classification performance.\n",
                "链接": "https://arxiv.org/abs/2205.10981"
            },
            {
                "文章ID": "96585",
                "标题": "Generating Individual Trajectories Using GPT-2 Trained from Scratch on\n  Encoded Spatiotemporal Data",
                "作者": " Taizo Horikomi,  Shouji Fujimoto,  Atushi Ishikawa,  Takayuki Mizuno",
                "发布日期": "2023-08-17",
                "摘要": "  Following Mizuno, Fujimoto, and Ishikawa's research (Front. Phys. 2022), we\ntranspose geographical coordinates expressed in latitude and longitude into\ndistinctive location tokens that embody positions across varied spatial scales.\nWe encapsulate an individual daily trajectory as a sequence of tokens by adding\nunique time interval tokens to the location tokens. Using the architecture of\nan autoregressive language model, GPT-2, this sequence of tokens is trained\nfrom scratch, allowing us to construct a deep learning model that sequentially\ngenerates an individual daily trajectory. Environmental factors such as\nmeteorological conditions and individual attributes such as gender and age are\nsymbolized by unique special tokens, and by training these tokens and\ntrajectories on the GPT-2 architecture, we can generate trajectories that are\ninfluenced by both environmental factors and individual attributes.\n",
                "链接": "https://arxiv.org/abs/2308.07940"
            },
            {
                "文章ID": "83635",
                "标题": "Efficient GPT Model Pre-training using Tensor Train Matrix\n  Representation",
                "作者": " Viktoriia Chekalina,  Georgii Novikov,  Julia Gusak,  Ivan Oseledets,  Alexander Panchenko",
                "发布日期": "2023-06-06",
                "摘要": "  Large-scale transformer models have shown remarkable performance in language\nmodelling tasks. However, such models feature billions of parameters, leading\nto difficulties in their deployment and prohibitive training costs from\nscratch. To reduce the number of the parameters in the GPT-2 architecture, we\nreplace the matrices of fully-connected layers with the corresponding Tensor\nTrain Matrix~(TTM) structure. Finally, we customize forward and backward\noperations through the TTM-based layer for simplicity and the stableness of\nfurther training. % The resulting GPT-2-based model stores up to 40% fewer\nparameters, showing the perplexity comparable to the original model. On the\ndownstream tasks, including language understanding and text summarization, the\nmodel performs similarly to the original GPT-2 model. The proposed tensorized\nlayers could be used to efficiently pre-training other Transformer models.\n",
                "链接": "https://arxiv.org/abs/2306.02697"
            },
            {
                "文章ID": "102920",
                "标题": "AutoDiffusion: Training-Free Optimization of Time Steps and\n  Architectures for Automated Diffusion Model Acceleration",
                "作者": " Lijiang Li,  Huixia Li,  Xiawu Zheng,  Jie Wu,  Xuefeng Xiao,  Rui Wang,  Min Zheng,  Xin Pan,  Fei Chao,  Rongrong Ji",
                "发布日期": "2023-09-26",
                "摘要": "  Diffusion models are emerging expressive generative models, in which a large\nnumber of time steps (inference steps) are required for a single image\ngeneration. To accelerate such tedious process, reducing steps uniformly is\nconsidered as an undisputed principle of diffusion models. We consider that\nsuch a uniform assumption is not the optimal solution in practice; i.e., we can\nfind different optimal time steps for different models. Therefore, we propose\nto search the optimal time steps sequence and compressed model architecture in\na unified framework to achieve effective image generation for diffusion models\nwithout any further training. Specifically, we first design a unified search\nspace that consists of all possible time steps and various architectures. Then,\na two stage evolutionary algorithm is introduced to find the optimal solution\nin the designed search space. To further accelerate the search process, we\nemploy FID score between generated and real samples to estimate the performance\nof the sampled examples. As a result, the proposed method is (i).training-free,\nobtaining the optimal time steps and model architecture without any training\nprocess; (ii). orthogonal to most advanced diffusion samplers and can be\nintegrated to gain better sample quality. (iii). generalized, where the\nsearched time steps and architectures can be directly applied on different\ndiffusion models with the same guidance scale. Experimental results show that\nour method achieves excellent performance by using only a few time steps, e.g.\n17.86 FID score on ImageNet 64 $\\times$ 64 with only four steps, compared to\n138.66 with DDIM. The code is available at\nhttps://github.com/lilijiangg/AutoDiffusion.\n",
                "链接": "https://arxiv.org/abs/2309.10438"
            },
            {
                "文章ID": "80324",
                "标题": "RefGPT: Dialogue Generation of GPT, by GPT, and for GPT",
                "作者": " Dongjie Yang,  Ruifeng Yuan,  Yuantao Fan,  Yifei Yang,  Zili Wang,  Shusen Wang,  Hai Zhao",
                "发布日期": "2023-10-20",
                "摘要": "  Large Language Models (LLMs) have attained the impressive capability to\nresolve a wide range of NLP tasks by fine-tuning high-quality instruction data.\nHowever, collecting human-written data of high quality, especially multi-turn\ndialogues, is expensive and unattainable for most people. Though previous\nstudies have used powerful LLMs to generate the dialogues automatically, they\nall suffer from generating untruthful dialogues because of the model\nhallucination. Therefore, we propose a method called RefGPT to generate\nenormous truthful and customized dialogues without worrying about factual\nerrors caused by the model hallucination. RefGPT solves the model hallucination\nin dialogue generation by restricting the LLMs to leverage the given reference\ninstead of reciting their own knowledge to generate dialogues. Additionally,\nRefGPT adds detailed controls on every utterance to enable high customization\ncapability, which previous studies have ignored. On the basis of RefGPT, we\nalso propose two high-quality dialogue datasets generated by GPT-4, namely\nRefGPT-Fact and RefGPT-Code. RefGPT-Fact is a dataset with 100k multi-turn\ndialogues based on factual knowledge and RefGPT-Code has 76k multi-turn\ndialogues covering a wide range of coding scenarios. Our code and datasets are\nreleased in https://github.com/mutonix/RefGPT.\n",
                "链接": "https://arxiv.org/abs/2305.14994"
            },
            {
                "文章ID": "83723",
                "标题": "Beyond Generating Code: Evaluating GPT on a Data Visualization Course",
                "作者": " Chen Zhu-Tian,  Chenyang Zhang,  Qianwen Wang,  Jakob Troidl,  Simon Warchol,  Johanna Beyer,  Nils Gehlenborg,  Hanspeter Pfister",
                "发布日期": "2023-10-10",
                "摘要": "  This paper presents an empirical evaluation of the performance of the\nGenerative Pre-trained Transformer (GPT) model in Harvard's CS171 data\nvisualization course. While previous studies have focused on GPT's ability to\ngenerate code for visualizations, this study goes beyond code generation to\nevaluate GPT's abilities in various visualization tasks, such as data\ninterpretation, visualization design, visual data exploration, and insight\ncommunication. The evaluation utilized GPT-3.5 and GPT-4 to complete\nassignments of CS171, and included a quantitative assessment based on the\nestablished course rubrics, a qualitative analysis informed by the feedback of\nthree experienced graders, and an exploratory study of GPT's capabilities in\ncompleting border visualization tasks. Findings show that GPT-4 scored 80% on\nquizzes and homework, and TFs could distinguish between GPT- and\nhuman-generated homework with 70% accuracy. The study also demonstrates GPT's\npotential in completing various visualization tasks, such as data cleanup,\ninteraction with visualizations, and insight communication. The paper concludes\nby discussing the strengths and limitations of GPT in data visualization,\npotential avenues for incorporating GPT in broader visualization tasks, and the\nneed to redesign visualization education.\n",
                "链接": "https://arxiv.org/abs/2306.02914"
            },
            {
                "文章ID": "117290",
                "标题": "Meticulously Selecting 1% of the Dataset for Pre-training! Generating\n  Differentially Private Images Data with Semantics Query",
                "作者": " Kecen Li,  Chen Gong,  Zhixiang Li,  Yuzhong Zhao,  Xinwen Hou,  Tianhao Wang",
                "发布日期": "2023-11-27",
                "摘要": "  Differential Privacy (DP) image data synthesis, which leverages the DP\ntechnique to generate synthetic data to replace the sensitive data, allowing\norganizations to share and utilize synthetic images without privacy concerns.\nPrevious methods incorporate the advanced techniques of generative models and\npre-training on a public dataset to produce exceptional DP image data, but\nsuffer from problems of unstable training and massive computational resource\ndemands. This paper proposes a novel DP image synthesis method, termed\nPRIVIMAGE, which meticulously selects pre-training data, promoting the\nefficient creation of DP datasets with high fidelity and utility. PRIVIMAGE\nfirst establishes a semantic query function using a public dataset. Then, this\nfunction assists in querying the semantic distribution of the sensitive\ndataset, facilitating the selection of data from the public dataset with\nanalogous semantics for pre-training. Finally, we pre-train an image generative\nmodel using the selected data and then fine-tune this model on the sensitive\ndataset using Differentially Private Stochastic Gradient Descent (DP-SGD).\nPRIVIMAGE allows us to train a lightly parameterized generative model, reducing\nthe noise in the gradient during DP-SGD training and enhancing training\nstability. Extensive experiments demonstrate that PRIVIMAGE uses only 1% of the\npublic dataset for pre-training and 7.6% of the parameters in the generative\nmodel compared to the state-of-the-art method, whereas achieves superior\nsynthetic performance and conserves more computational resources. On average,\nPRIVIMAGE achieves 30.1% lower FID and 12.6% higher Classification Accuracy\nthan the state-of-the-art method. The replication package and datasets can be\naccessed online.\n",
                "链接": "https://arxiv.org/abs/2311.12850"
            },
            {
                "文章ID": "81391",
                "标题": "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of\n  GPT-Generated Text",
                "作者": " Xianjun Yang,  Wei Cheng,  Yue Wu,  Linda Petzold,  William Yang Wang,  Haifeng Chen",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have notably enhanced the fluency and diversity\nof machine-generated text. However, this progress also presents a significant\nchallenge in detecting the origin of a given text, and current research on\ndetection methods lags behind the rapid evolution of LLMs. Conventional\ntraining-based methods have limitations in flexibility, particularly when\nadapting to new domains, and they often lack explanatory power. To address this\ngap, we propose a novel training-free detection strategy called Divergent\nN-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and\nthen use only the preceding portion as input to the LLMs to regenerate the new\nremaining parts. By analyzing the differences between the original and new\nremaining parts through N-gram analysis in black-box or probability divergence\nin white-box, we unveil significant discrepancies between the distribution of\nmachine-generated text and the distribution of human-written text. We conducted\nextensive experiments on the most advanced LLMs from OpenAI, including\ntext-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such\nas GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach\nexhibits state-of-the-art performance in distinguishing between human and\nGPT-generated text on four English and one German dataset, outperforming\nOpenAI's own classifier, which is trained on millions of text. Additionally,\nour methods provide reasonable explanations and evidence to support our claim,\nwhich is a unique feature of explainable detection. Our method is also robust\nunder the revised text attack and can additionally solve model sourcing. Codes\nare available at https://github.com/Xianjun-Yang/DNA-GPT.\n",
                "链接": "https://arxiv.org/abs/2305.17359"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "104220",
                "标题": "CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic\n  Segmentation For-Free",
                "作者": " Monika Wysoczańska,  Michaël Ramamonjisoa,  Tomasz Trzciński,  Oriane Siméoni",
                "发布日期": "2023-11-29",
                "摘要": "  The emergence of CLIP has opened the way for open-world image perception. The\nzero-shot classification capabilities of the model are impressive but are\nharder to use for dense tasks such as image segmentation. Several methods have\nproposed different modifications and learning schemes to produce dense output.\nInstead, we propose in this work an open-vocabulary semantic segmentation\nmethod, dubbed CLIP-DIY, which does not require any additional training or\nannotations, but instead leverages existing unsupervised object localization\napproaches. In particular, CLIP-DIY is a multi-scale approach that directly\nexploits CLIP classification abilities on patches of different sizes and\naggregates the decision in a single map. We further guide the segmentation\nusing foreground/background scores obtained using unsupervised object\nlocalization methods. With our method, we obtain state-of-the-art zero-shot\nsemantic segmentation results on PASCAL VOC and perform on par with the best\nmethods on COCO. The code is available at\nhttp://github.com/wysoczanska/clip-diy\n",
                "链接": "https://arxiv.org/abs/2309.14289"
            },
            {
                "文章ID": "41351",
                "标题": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP",
                "作者": " Feng Liang,  Bichen Wu,  Xiaoliang Dai,  Kunpeng Li,  Yinan Zhao,  Hang Zhang,  Peizhao Zhang,  Peter Vajda,  Diana Marculescu",
                "发布日期": "2023-04-04",
                "摘要": "  Open-vocabulary semantic segmentation aims to segment an image into semantic\nregions according to text descriptions, which may not have been seen during\ntraining. Recent two-stage methods first generate class-agnostic mask proposals\nand then leverage pre-trained vision-language models, e.g., CLIP, to classify\nmasked regions. We identify the performance bottleneck of this paradigm to be\nthe pre-trained CLIP model, since it does not perform well on masked images. To\naddress this, we propose to finetune CLIP on a collection of masked image\nregions and their corresponding text descriptions. We collect training data by\nmining an existing image-caption dataset (e.g., COCO Captions), using CLIP to\nmatch masked image regions to nouns in the image captions. Compared with the\nmore precise and manually annotated segmentation labels with fixed classes\n(e.g., COCO-Stuff), we find our noisy but diverse dataset can better retain\nCLIP's generalization ability. Along with finetuning the entire model, we\nutilize the \"blank\" areas in masked images using a method we dub mask prompt\ntuning. Experiments demonstrate mask prompt tuning brings significant\nimprovement without modifying any weights of CLIP, and it can further improve a\nfully finetuned model. In particular, when trained on COCO and evaluated on\nADE20K-150, our best model achieves 29.6% mIoU, which is +8.5% higher than the\nprevious state-of-the-art. For the first time, open-vocabulary generalist\nmodels match the performance of supervised specialist models in 2017 without\ndataset-specific adaptations.\n",
                "链接": "https://arxiv.org/abs/2210.04150"
            },
            {
                "文章ID": "1976",
                "标题": "Why Did You Not Compare With That? Identifying Papers for Use as\n  Baselines",
                "作者": " Manjot Bedi,  Tanisha Pandey,  Sumit Bhatia,  Tanmoy Chakraborty",
                "发布日期": "2022-01-21",
                "摘要": "  We propose the task of automatically identifying papers used as baselines in\na scientific article. We frame the problem as a binary classification task\nwhere all the references in a paper are to be classified as either baselines or\nnon-baselines. This is a challenging problem due to the numerous ways in which\na baseline reference can appear in a paper. We develop a dataset of $2,075$\npapers from ACL anthology corpus with all their references manually annotated\nas one of the two classes. We develop a multi-module attention-based neural\nclassifier for the baseline classification task that outperforms four\nstate-of-the-art citation role classification methods when applied to the\nbaseline classification task. We also present an analysis of the errors made by\nthe proposed classifier, eliciting the challenges that make baseline\nidentification a challenging problem.\n",
                "链接": "https://arxiv.org/abs/2201.08089"
            },
            {
                "文章ID": "50058",
                "标题": "Open-vocabulary Attribute Detection",
                "作者": " María A. Bravo,  Sudhanshu Mittal,  Simon Ging,  Thomas Brox",
                "发布日期": "2023-03-10",
                "摘要": "  Vision-language modeling has enabled open-vocabulary tasks where predictions\ncan be queried using any text prompt in a zero-shot manner. Existing\nopen-vocabulary tasks focus on object classes, whereas research on object\nattributes is limited due to the lack of a reliable attribute-focused\nevaluation benchmark. This paper introduces the Open-Vocabulary Attribute\nDetection (OVAD) task and the corresponding OVAD benchmark. The objective of\nthe novel task and benchmark is to probe object-level attribute information\nlearned by vision-language models. To this end, we created a clean and densely\nannotated test set covering 117 attribute classes on the 80 object classes of\nMS COCO. It includes positive and negative annotations, which enables\nopen-vocabulary evaluation. Overall, the benchmark consists of 1.4 million\nannotations. For reference, we provide a first baseline method for\nopen-vocabulary attribute detection. Moreover, we demonstrate the benchmark's\nvalue by studying the attribute detection performance of several foundation\nmodels. Project page https://ovad-benchmark.github.io\n",
                "链接": "https://arxiv.org/abs/2211.12914"
            },
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "71939",
                "标题": "CLIP Surgery for Better Explainability with Enhancement in\n  Open-Vocabulary Tasks",
                "作者": " Yi Li,  Hualiang Wang,  Yiqun Duan,  Xiaomeng Li",
                "发布日期": "2023-04-13",
                "摘要": "  Contrastive Language-Image Pre-training (CLIP) is a powerful multimodal large\nvision model that has demonstrated significant benefits for downstream tasks,\nincluding many zero-shot learning and text-guided vision tasks. However, we\nnotice some severe problems regarding the model's explainability, which\nundermines its credibility and impedes related tasks. Specifically, we find\nCLIP prefers the background regions than the foregrounds according to the\npredicted similarity map, which contradicts human understanding. Besides, there\nare obvious noisy activations on the visualization results at irrelevant\npositions. To address these two issues, we conduct in-depth analyses and reveal\nthe reasons with new findings and evidences. Based on these insights, we\npropose the CLIP Surgery, a method that enables surgery-like modifications for\nthe inference architecture and features, for better explainability and\nenhancement in multiple open-vocabulary tasks. The proposed method has\nsignificantly improved the explainability of CLIP for both convolutional\nnetworks and vision transformers, surpassing existing methods by large margins.\nBesides, our approach also demonstrates remarkable improvements in\nopen-vocabulary segmentation and multi-label recognition tasks. For examples,\nthe mAP improvement on NUS-Wide multi-label recognition is 4.41% without any\nadditional training, and our CLIP Surgery surpasses the state-of-the-art method\nby 8.74% at mIoU on Cityscapes open-vocabulary semantic segmentation.\nFurthermore, our method benefits other tasks including multimodal visualization\nand interactive segmentation like Segment Anything Model (SAM). The code is\navailable at https://github.com/xmed-lab/CLIP_Surgery\n",
                "链接": "https://arxiv.org/abs/2304.05653"
            },
            {
                "文章ID": "86253",
                "标题": "Scaling Open-Vocabulary Object Detection",
                "作者": " Matthias Minderer,  Alexey Gritsenko,  Neil Houlsby",
                "发布日期": "2023-07-21",
                "摘要": "  Open-vocabulary object detection has benefited greatly from pretrained\nvision-language models, but is still limited by the amount of available\ndetection training data. While detection training data can be expanded by using\nWeb image-text pairs as weak supervision, this has not been done at scales\ncomparable to image-level pretraining. Here, we scale up detection data with\nself-training, which uses an existing detector to generate pseudo-box\nannotations on image-text pairs. Major challenges in scaling self-training are\nthe choice of label space, pseudo-annotation filtering, and training\nefficiency. We present the OWLv2 model and OWL-ST self-training recipe, which\naddress these challenges. OWLv2 surpasses the performance of previous\nstate-of-the-art open-vocabulary detectors already at comparable training\nscales (~10M examples). However, with OWL-ST, we can scale to over 1B examples,\nyielding further large improvement: With an L/14 architecture, OWL-ST improves\nAP on LVIS rare classes, for which the model has seen no human box annotations,\nfrom 31.2% to 44.6% (43% relative improvement). OWL-ST unlocks Web-scale\ntraining for open-world localization, similar to what has been seen for image\nclassification and language modelling.\n",
                "链接": "https://arxiv.org/abs/2306.09683"
            },
            {
                "文章ID": "115237",
                "标题": "Open-Vocabulary Video Anomaly Detection",
                "作者": " Peng Wu,  Xuerong Zhou,  Guansong Pang,  Yujia Sun,  Jing Liu,  Peng Wang,  Yanning Zhang",
                "发布日期": "2023-11-16",
                "摘要": "  Video anomaly detection (VAD) with weak supervision has achieved remarkable\nperformance in utilizing video-level labels to discriminate whether a video\nframe is normal or abnormal. However, current approaches are inherently limited\nto a closed-set setting and may struggle in open-world applications where there\ncan be anomaly categories in the test data unseen during training. A few recent\nstudies attempt to tackle a more realistic setting, open-set VAD, which aims to\ndetect unseen anomalies given seen anomalies and normal videos. However, such a\nsetting focuses on predicting frame anomaly scores, having no ability to\nrecognize the specific categories of anomalies, despite the fact that this\nability is essential for building more informed video surveillance systems.\nThis paper takes a step further and explores open-vocabulary video anomaly\ndetection (OVVAD), in which we aim to leverage pre-trained large models to\ndetect and categorize seen and unseen anomalies. To this end, we propose a\nmodel that decouples OVVAD into two mutually complementary tasks --\nclass-agnostic detection and class-specific classification -- and jointly\noptimizes both tasks. Particularly, we devise a semantic knowledge injection\nmodule to introduce semantic knowledge from large language models for the\ndetection task, and design a novel anomaly synthesis module to generate pseudo\nunseen anomaly videos with the help of large vision generation models for the\nclassification task. These semantic knowledge and synthesis anomalies\nsubstantially extend our model's capability in detecting and categorizing a\nvariety of seen and unseen anomalies. Extensive experiments on three\nwidely-used benchmarks demonstrate our model achieves state-of-the-art\nperformance on OVVAD task.\n",
                "链接": "https://arxiv.org/abs/2311.07042"
            },
            {
                "文章ID": "119030",
                "标题": "Active Open-Vocabulary Recognition: Let Intelligent Moving Mitigate CLIP\n  Limitations",
                "作者": " Lei Fan,  Jianxiong Zhou,  Xiaoying Xing,  Ying Wu",
                "发布日期": "2023-12-01",
                "摘要": "  Active recognition, which allows intelligent agents to explore observations\nfor better recognition performance, serves as a prerequisite for various\nembodied AI tasks, such as grasping, navigation and room arrangements. Given\nthe evolving environment and the multitude of object classes, it is impractical\nto include all possible classes during the training stage. In this paper, we\naim at advancing active open-vocabulary recognition, empowering embodied agents\nto actively perceive and classify arbitrary objects. However, directly adopting\nrecent open-vocabulary classification models, like Contrastive Language Image\nPretraining (CLIP), poses its unique challenges. Specifically, we observe that\nCLIP's performance is heavily affected by the viewpoint and occlusions,\ncompromising its reliability in unconstrained embodied perception scenarios.\nFurther, the sequential nature of observations in agent-environment\ninteractions necessitates an effective method for integrating features that\nmaintains discriminative strength for open-vocabulary classification. To\naddress these issues, we introduce a novel agent for active open-vocabulary\nrecognition. The proposed method leverages inter-frame and inter-concept\nsimilarities to navigate agent movements and to fuse features, without relying\non class-specific knowledge. Compared to baseline CLIP model with 29.6%\naccuracy on ShapeNet dataset, the proposed agent could achieve 53.3% accuracy\nfor open-vocabulary recognition, without any fine-tuning to the equipped CLIP\nmodel. Additional experiments conducted with the Habitat simulator further\naffirm the efficacy of our method.\n",
                "链接": "https://arxiv.org/abs/2311.17938"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "10152",
                "标题": "Self-Supervised Deep Learning to Enhance Breast Cancer Detection on\n  Screening Mammography",
                "作者": " John D. Miller,  Vignesh A. Arasu,  Albert X. Pu,  Laurie R. Margolies,  Weiva Sieh,  Li Shen",
                "发布日期": "2022-03-18",
                "摘要": "  A major limitation in applying deep learning to artificial intelligence (AI)\nsystems is the scarcity of high-quality curated datasets. We investigate strong\naugmentation based self-supervised learning (SSL) techniques to address this\nproblem. Using breast cancer detection as an example, we first identify a\nmammogram-specific transformation paradigm and then systematically compare four\nrecent SSL methods representing a diversity of approaches. We develop a method\nto convert a pretrained model from making predictions on uniformly tiled\npatches to whole images, and an attention-based pooling method that improves\nthe classification performance. We found that the best SSL model substantially\noutperformed the baseline supervised model. The best SSL model also improved\nthe data efficiency of sample labeling by nearly 4-fold and was highly\ntransferrable from one dataset to another. SSL represents a major breakthrough\nin computer vision and may help the AI for medical imaging field to shift away\nfrom supervised learning and dependency on scarce labels.\n",
                "链接": "https://arxiv.org/abs/2203.08812"
            },
            {
                "文章ID": "52882",
                "标题": "Contrastive View Design Strategies to Enhance Robustness to Domain\n  Shifts in Downstream Object Detection",
                "作者": " Kyle Buettner,  Adriana Kovashka",
                "发布日期": "2022-12-12",
                "摘要": "  Contrastive learning has emerged as a competitive pretraining method for\nobject detection. Despite this progress, there has been minimal investigation\ninto the robustness of contrastively pretrained detectors when faced with\ndomain shifts. To address this gap, we conduct an empirical study of\ncontrastive learning and out-of-domain object detection, studying how\ncontrastive view design affects robustness. In particular, we perform a case\nstudy of the detection-focused pretext task Instance Localization (InsLoc) and\npropose strategies to augment views and enhance robustness in\nappearance-shifted and context-shifted scenarios. Amongst these strategies, we\npropose changes to cropping such as altering the percentage used, adding IoU\nconstraints, and integrating saliency based object priors. We also explore the\naddition of shortcut-reducing augmentations such as Poisson blending, texture\nflattening, and elastic deformation. We benchmark these strategies on abstract,\nweather, and context domain shifts and illustrate robust ways to combine them,\nin both pretraining on single-object and multi-object image datasets. Overall,\nour results and insights show how to ensure robustness through the choice of\nviews in contrastive learning.\n",
                "链接": "https://arxiv.org/abs/2212.04613"
            },
            {
                "文章ID": "8526",
                "标题": "Enhance Language Identification using Dual-mode Model with Knowledge\n  Distillation",
                "作者": " Hexin Liu,  Leibny Paola Garcia Perera,  Andy W. H. Khong,  Justin Dauwels,  Suzy J. Styles,  Sanjeev Khudanpur",
                "发布日期": "2022-03-08",
                "摘要": "  In this paper, we propose to employ a dual-mode framework on the x-vector\nself-attention (XSA-LID) model with knowledge distillation (KD) to enhance its\nlanguage identification (LID) performance for both long and short utterances.\nThe dual-mode XSA-LID model is trained by jointly optimizing both the full and\nshort modes with their respective inputs being the full-length speech and its\nshort clip extracted by a specific Boolean mask, and KD is applied to further\nboost the performance on short utterances. In addition, we investigate the\nimpact of clip-wise linguistic variability and lexical integrity for LID by\nanalyzing the variation of LID performance in terms of the lengths and\npositions of the mimicked speech clips. We evaluated our approach on the MLS14\ndata from the NIST 2017 LRE. With the 3~s random-location Boolean mask, our\nproposed method achieved 19.23%, 21.52% and 8.37% relative improvement in\naverage cost compared with the XSA-LID model on 3s, 10s, and 30s speech,\nrespectively.\n",
                "链接": "https://arxiv.org/abs/2203.03218"
            },
            {
                "文章ID": "14674",
                "标题": "Localization Distillation for Object Detection",
                "作者": " Zhaohui Zheng,  Rongguang Ye,  Qibin Hou,  Dongwei Ren,  Ping Wang,  Wangmeng Zuo,  Ming-Ming Cheng",
                "发布日期": "2022-12-09",
                "摘要": "  Previous knowledge distillation (KD) methods for object detection mostly\nfocus on feature imitation instead of mimicking the prediction logits due to\nits inefficiency in distilling the localization information. In this paper, we\ninvestigate whether logit mimicking always lags behind feature imitation.\nTowards this goal, we first present a novel localization distillation (LD)\nmethod which can efficiently transfer the localization knowledge from the\nteacher to the student. Second, we introduce the concept of valuable\nlocalization region that can aid to selectively distill the classification and\nlocalization knowledge for a certain region. Combining these two new\ncomponents, for the first time, we show that logit mimicking can outperform\nfeature imitation and the absence of localization distillation is a critical\nreason for why logit mimicking underperforms for years. The thorough studies\nexhibit the great potential of logit mimicking that can significantly alleviate\nthe localization ambiguity, learn robust feature representation, and ease the\ntraining difficulty in the early stage. We also provide the theoretical\nconnection between the proposed LD and the classification KD, that they share\nthe equivalent optimization effect. Our distillation scheme is simple as well\nas effective and can be easily applied to both dense horizontal object\ndetectors and rotated object detectors. Extensive experiments on the MS COCO,\nPASCAL VOC, and DOTA benchmarks demonstrate that our method can achieve\nconsiderable AP improvement without any sacrifice on the inference speed. Our\nsource code and pretrained models are publicly available at\nhttps://github.com/HikariTJU/LD.\n",
                "链接": "https://arxiv.org/abs/2204.05957"
            },
            {
                "文章ID": "98993",
                "标题": "Neural Network Training Strategy to Enhance Anomaly Detection\n  Performance: A Perspective on Reconstruction Loss Amplification",
                "作者": " YeongHyeon Park,  Sungho Kang,  Myung Jin Kim,  Hyeonho Jeong,  Hyunkyu Park,  Hyeong Seok Kim,  Juneho Yi",
                "发布日期": "2023-08-29",
                "摘要": "  Unsupervised anomaly detection (UAD) is a widely adopted approach in industry\ndue to rare anomaly occurrences and data imbalance. A desirable characteristic\nof an UAD model is contained generalization ability which excels in the\nreconstruction of seen normal patterns but struggles with unseen anomalies.\nRecent studies have pursued to contain the generalization capability of their\nUAD models in reconstruction from different perspectives, such as design of\nneural network (NN) structure and training strategy. In contrast, we note that\ncontaining of generalization ability in reconstruction can also be obtained\nsimply from steep-shaped loss landscape. Motivated by this, we propose a loss\nlandscape sharpening method by amplifying the reconstruction loss, dubbed Loss\nAMPlification (LAMP). LAMP deforms the loss landscape into a steep shape so the\nreconstruction error on unseen anomalies becomes greater. Accordingly, the\nanomaly detection performance is improved without any change of the NN\narchitecture. Our findings suggest that LAMP can be easily applied to any\nreconstruction error metrics in UAD settings where the reconstruction model is\ntrained with anomaly-free samples only.\n",
                "链接": "https://arxiv.org/abs/2308.14595"
            },
            {
                "文章ID": "97940",
                "标题": "Aggregating Intrinsic Information to Enhance BCI Performance through\n  Federated Learning",
                "作者": " Rui Liu,  Yuanyuan Chen,  Anran Li,  Yi Ding,  Han Yu,  Cuntai Guan",
                "发布日期": "2023-08-24",
                "摘要": "  Insufficient data is a long-standing challenge for Brain-Computer Interface\n(BCI) to build a high-performance deep learning model. Though numerous research\ngroups and institutes collect a multitude of EEG datasets for the same BCI\ntask, sharing EEG data from multiple sites is still challenging due to the\nheterogeneity of devices. The significance of this challenge cannot be\noverstated, given the critical role of data diversity in fostering model\nrobustness. However, existing works rarely discuss this issue, predominantly\ncentering their attention on model training within a single dataset, often in\nthe context of inter-subject or inter-session settings. In this work, we\npropose a hierarchical personalized Federated Learning EEG decoding (FLEEG)\nframework to surmount this challenge. This innovative framework heralds a new\nlearning paradigm for BCI, enabling datasets with disparate data formats to\ncollaborate in the model training process. Each client is assigned a specific\ndataset and trains a hierarchical personalized model to manage diverse data\nformats and facilitate information exchange. Meanwhile, the server coordinates\nthe training procedure to harness knowledge gleaned from all datasets, thus\nelevating overall performance. The framework has been evaluated in Motor\nImagery (MI) classification with nine EEG datasets collected by different\ndevices but implementing the same MI task. Results demonstrate that the\nproposed frame can boost classification performance up to 16.7% by enabling\nknowledge sharing between multiple datasets, especially for smaller datasets.\nVisualization results also indicate that the proposed framework can empower the\nlocal models to put a stable focus on task-related areas, yielding better\nperformance. To the best of our knowledge, this is the first end-to-end\nsolution to address this important challenge.\n",
                "链接": "https://arxiv.org/abs/2308.11636"
            },
            {
                "文章ID": "14912",
                "标题": "Spatial Likelihood Voting with Self-Knowledge Distillation for Weakly\n  Supervised Object Detection",
                "作者": " Ze Chen,  Zhihang Fu,  Jianqiang Huang,  Mingyuan Tao,  Rongxin Jiang,  Xiang Tian,  Yaowu Chen,  Xian-sheng Hua",
                "发布日期": "2022-04-15",
                "摘要": "  Weakly supervised object detection (WSOD), which is an effective way to train\nan object detection model using only image-level annotations, has attracted\nconsiderable attention from researchers. However, most of the existing methods,\nwhich are based on multiple instance learning (MIL), tend to localize instances\nto the discriminative parts of salient objects instead of the entire content of\nall objects. In this paper, we propose a WSOD framework called the Spatial\nLikelihood Voting with Self-knowledge Distillation Network (SLV-SD Net). In\nthis framework, we introduce a spatial likelihood voting (SLV) module to\nconverge region proposal localization without bounding box annotations.\nSpecifically, in every iteration during training, all the region proposals in a\ngiven image act as voters voting for the likelihood of each category in the\nspatial dimensions. After dilating the alignment on the area with large\nlikelihood values, the voting results are regularized as bounding boxes, which\nare then used for the final classification and localization. Based on SLV, we\nfurther propose a self-knowledge distillation (SD) module to refine the feature\nrepresentations of the given image. The likelihood maps generated by the SLV\nmodule are used to supervise the feature learning of the backbone network,\nencouraging the network to attend to wider and more diverse areas of the image.\nExtensive experiments on the PASCAL VOC 2007/2012 and MS-COCO datasets\ndemonstrate the excellent performance of SLV-SD Net. In addition, SLV-SD Net\nproduces new state-of-the-art results on these benchmarks.\n",
                "链接": "https://arxiv.org/abs/2204.06899"
            },
            {
                "文章ID": "8799",
                "标题": "Semantic Distillation Guided Salient Object Detection",
                "作者": " Bo Xu,  Guanze Liu,  Han Huang,  Cheng Lu,  Yandong Guo",
                "发布日期": "2022-03-09",
                "摘要": "  Most existing CNN-based salient object detection methods can identify local\nsegmentation details like hair and animal fur, but often misinterpret the real\nsaliency due to the lack of global contextual information caused by the\nsubjectiveness of the SOD task and the locality of convolution layers.\nMoreover, due to the unrealistically expensive labeling costs, the current\nexisting SOD datasets are insufficient to cover the real data distribution. The\nlimitation and bias of the training data add additional difficulty to fully\nexploring the semantic association between object-to-object and\nobject-to-environment in a given image. In this paper, we propose a semantic\ndistillation guided SOD (SDG-SOD) method that produces accurate results by\nfusing semantically distilled knowledge from generated image captioning into\nthe Vision-Transformer-based SOD framework. SDG-SOD can better uncover\ninter-objects and object-to-environment saliency and cover the gap between the\nsubjective nature of SOD and its expensive labeling. Comprehensive experiments\non five benchmark datasets demonstrate that the SDG-SOD outperforms the\nstate-of-the-art approaches on four evaluation metrics, and largely improves\nthe model performance on DUTS, ECSSD, DUT, HKU-IS, and PASCAL-S datasets.\n",
                "链接": "https://arxiv.org/abs/2203.04076"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46217",
                "标题": "Recognizing Nested Entities from Flat Supervision: A New NER Subtask,\n  Feasibility and Challenges",
                "作者": " Enwei Zhu,  Yiyang Liu,  Ming Jin,  Jinpeng Li",
                "发布日期": "2022-11-02",
                "摘要": "  Many recent named entity recognition (NER) studies criticize flat NER for its\nnon-overlapping assumption, and switch to investigating nested NER. However,\nexisting nested NER models heavily rely on training data annotated with nested\nentities, while labeling such data is costly. This study proposes a new\nsubtask, nested-from-flat NER, which corresponds to a realistic application\nscenario: given data annotated with flat entities only, one may still desire\nthe trained model capable of recognizing nested entities. To address this task,\nwe train span-based models and deliberately ignore the spans nested inside\nlabeled entities, since these spans are possibly unlabeled entities. With\nnested entities removed from the training data, our model achieves 54.8%, 54.2%\nand 41.1% F1 scores on the subset of spans within entities on ACE 2004, ACE\n2005 and GENIA, respectively. This suggests the effectiveness of our approach\nand the feasibility of the task. In addition, the model's performance on flat\nentities is entirely unaffected. We further manually annotate the nested\nentities in the test set of CoNLL 2003, creating a nested-from-flat NER\nbenchmark. Analysis results show that the main challenges stem from the data\nand annotation inconsistencies between the flat and nested entities.\n",
                "链接": "https://arxiv.org/abs/2211.00301"
            },
            {
                "文章ID": "82089",
                "标题": "A Multilingual Evaluation of NER Robustness to Adversarial Inputs",
                "作者": " Akshay Srinivasan,  Sowmya Vajjala",
                "发布日期": "2023-05-31",
                "摘要": "  Adversarial evaluations of language models typically focus on English alone.\nIn this paper, we performed a multilingual evaluation of Named Entity\nRecognition (NER) in terms of its robustness to small perturbations in the\ninput. Our results showed the NER models we explored across three languages\n(English, German and Hindi) are not very robust to such changes, as indicated\nby the fluctuations in the overall F1 score as well as in a more fine-grained\nevaluation. With that knowledge, we further explored whether it is possible to\nimprove the existing NER models using a part of the generated adversarial data\nsets as augmented training data to train a new NER model or as fine-tuning data\nto adapt an existing NER model. Our results showed that both these approaches\nimprove performance on the original as well as adversarial test sets. While\nthere is no significant difference between the two approaches for English,\nre-training is significantly better than fine-tuning for German and Hindi.\n",
                "链接": "https://arxiv.org/abs/2305.18933"
            },
            {
                "文章ID": "111254",
                "标题": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
                "作者": " Susanna Rücker,  Alan Akbik",
                "发布日期": "2023-10-26",
                "摘要": "  The CoNLL-03 corpus is arguably the most well-known and utilized benchmark\ndataset for named entity recognition (NER). However, prior works found\nsignificant numbers of annotation errors, incompleteness, and inconsistencies\nin the data. This poses challenges to objectively comparing NER approaches and\nanalyzing their errors, as current state-of-the-art models achieve F1-scores\nthat are comparable to or even exceed the estimated noise level in CoNLL-03. To\naddress this issue, we present a comprehensive relabeling effort assisted by\nautomatic consistency checking that corrects 7.0% of all labels in the English\nCoNLL-03. Our effort adds a layer of entity linking annotation both for better\nexplainability of NER labels and as additional safeguard of annotation quality.\nOur experimental evaluation finds not only that state-of-the-art approaches\nreach significantly higher F1-scores (97.1%) on our data, but crucially that\nthe share of correct predictions falsely counted as errors due to annotation\nnoise drops from 47% to 6%. This indicates that our resource is well suited to\nanalyze the remaining errors made by state-of-the-art models, and that the\ntheoretical upper bound even on high resource, coarse-grained NER is not yet\nreached. To facilitate such analysis, we make CleanCoNLL publicly available to\nthe research community.\n",
                "链接": "https://arxiv.org/abs/2310.16225"
            },
            {
                "文章ID": "54351",
                "标题": "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?",
                "作者": " Shuheng Liu,  Alan Ritter",
                "发布日期": "2023-07-13",
                "摘要": "  The CoNLL-2003 English named entity recognition (NER) dataset has been widely\nused to train and evaluate NER models for almost 20 years. However, it is\nunclear how well models that are trained on this 20-year-old data and developed\nover a period of decades using the same test set will perform when applied on\nmodern data. In this paper, we evaluate the generalization of over 20 different\nmodels trained on CoNLL-2003, and show that NER models have very different\ngeneralization. Surprisingly, we find no evidence of performance degradation in\npre-trained Transformers, such as RoBERTa and T5, even when fine-tuned using\ndecades-old data. We investigate why some models generalize well to new data\nwhile others do not, and attempt to disentangle the effects of temporal drift\nand overfitting due to test reuse. Our analysis suggests that most\ndeterioration is due to temporal mismatch between the pre-training corpora and\nthe downstream test sets. We found that four factors are important for good\ngeneralization: model architecture, number of parameters, time period of the\npre-training corpus, in addition to the amount of fine-tuning data. We suggest\ncurrent evaluation methods have, in some sense, underestimated progress on NER\nover the past 20 years, as NER models have not only improved on the original\nCoNLL-2003 test set, but improved even more on modern data. Our datasets can be\nfound at https://github.com/ShuhengL/acl2023_conllpp.\n",
                "链接": "https://arxiv.org/abs/2212.09747"
            },
            {
                "文章ID": "39331",
                "标题": "mRobust04: A Multilingual Version of the TREC Robust 2004 Benchmark",
                "作者": " Vitor Jeronymo,  Mauricio Nascimento,  Roberto Lotufo,  Rodrigo Nogueira",
                "发布日期": "2022-09-29",
                "摘要": "  Robust 2004 is an information retrieval benchmark whose large number of\njudgments per query make it a reliable evaluation dataset. In this paper, we\npresent mRobust04, a multilingual version of Robust04 that was translated to 8\nlanguages using Google Translate. We also provide results of three different\nmultilingual retrievers on this dataset. The dataset is available at\nhttps://huggingface.co/datasets/unicamp-dl/mrobust\n",
                "链接": "https://arxiv.org/abs/2209.13738"
            },
            {
                "文章ID": "12159",
                "标题": "Federated Named Entity Recognition",
                "作者": " Joel Mathew,  Dimitris Stripelis,  José Luis Ambite",
                "发布日期": "2022-03-30",
                "摘要": "  We present an analysis of the performance of Federated Learning in a\nparadigmatic natural-language processing task: Named-Entity Recognition (NER).\nFor our evaluation, we use the language-independent CoNLL-2003 dataset as our\nbenchmark dataset and a Bi-LSTM-CRF model as our benchmark NER model. We show\nthat federated training reaches almost the same performance as the centralized\nmodel, though with some performance degradation as the learning environments\nbecome more heterogeneous. We also show the convergence rate of federated\nmodels for NER. Finally, we discuss existing challenges of Federated Learning\nfor NLP applications that can foster future research directions.\n",
                "链接": "https://arxiv.org/abs/2203.15101"
            },
            {
                "文章ID": "10782",
                "标题": "Leveraging Expert Guided Adversarial Augmentation For Improving\n  Generalization in Named Entity Recognition",
                "作者": " Aaron Reich,  Jiaao Chen,  Aastha Agrawal,  Yanzhe Zhang,  Diyi Yang",
                "发布日期": "2022-03-22",
                "摘要": "  Named Entity Recognition (NER) systems often demonstrate great performance on\nin-distribution data, but perform poorly on examples drawn from a shifted\ndistribution. One way to evaluate the generalization ability of NER models is\nto use adversarial examples, on which the specific variations associated with\nnamed entities are rarely considered. To this end, we propose leveraging\nexpert-guided heuristics to change the entity tokens and their surrounding\ncontexts thereby altering their entity types as adversarial attacks. Using\nexpert-guided heuristics, we augmented the CoNLL 2003 test set and manually\nannotated it to construct a high-quality challenging set. We found that\nstate-of-the-art NER systems trained on CoNLL 2003 training data drop\nperformance dramatically on our challenging set. By training on adversarial\naugmented training examples and using mixup for regularization, we were able to\nsignificantly improve the performance on the challenging set as well as improve\nout-of-domain generalization which we evaluated by using OntoNotes data. We\nhave publicly released our dataset and code at\nhttps://github.com/GT-SALT/Guided-Adversarial-Augmentation.\n",
                "链接": "https://arxiv.org/abs/2203.10693"
            },
            {
                "文章ID": "54218",
                "标题": "E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text",
                "作者": " Ting Wai Terence Au,  Ingemar J. Cox,  Vasileios Lampos",
                "发布日期": "2022-12-20",
                "摘要": "  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n",
                "链接": "https://arxiv.org/abs/2212.09306"
            },
            {
                "文章ID": "50504",
                "标题": "Finetuning BERT on Partially Annotated NER Corpora",
                "作者": " Viktor Scherbakov,  Vladimir Mayorov",
                "发布日期": "2022-11-29",
                "摘要": "  Most Named Entity Recognition (NER) models operate under the assumption that\ntraining datasets are fully labelled. While it is valid for established\ndatasets like CoNLL 2003 and OntoNotes, sometimes it is not feasible to obtain\nthe complete dataset annotation. These situations may occur, for instance,\nafter selective annotation of entities for cost reduction. This work presents\nan approach to finetuning BERT on such partially labelled datasets using\nself-supervision and label preprocessing. Our approach outperforms the previous\nLSTM-based label preprocessing baseline, significantly improving the\nperformance on poorly labelled datasets. We demonstrate that following our\napproach while finetuning RoBERTa on CoNLL 2003 dataset with only 10% of total\nentities labelled is enough to reach the performance of the baseline trained on\nthe same dataset with 50% of the entities labelled.\n",
                "链接": "https://arxiv.org/abs/2211.14360"
            },
            {
                "文章ID": "73488",
                "标题": "IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named\n  Entity Recognition using Knowledge Bases",
                "作者": " Iker García-Ferrero,  Jon Ander Campos,  Oscar Sainz,  Ander Salaberria,  Dan Roth",
                "发布日期": "2023-05-01",
                "摘要": "  Named Entity Recognition (NER) is a core natural language processing task in\nwhich pre-trained language models have shown remarkable performance. However,\nstandard benchmarks like CoNLL 2003 do not address many of the challenges that\ndeployed NER systems face, such as having to classify emerging or complex\nentities in a fine-grained way. In this paper we present a novel NER cascade\napproach comprising three steps: first, identifying candidate entities in the\ninput sentence; second, linking the each candidate to an existing knowledge\nbase; third, predicting the fine-grained category for each entity candidate. We\nempirically demonstrate the significance of external knowledge bases in\naccurately classifying fine-grained and emerging entities. Our system exhibits\nrobust performance in the MultiCoNER2 shared task, even in the low-resource\nlanguage setting where we leverage knowledge bases of high-resource languages.\n",
                "链接": "https://arxiv.org/abs/2304.10637"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "45137",
                "标题": "Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with\n  User Simulator",
                "作者": " Qinyuan Cheng,  Linyang Li,  Guofeng Quan,  Feng Gao,  Xiaofeng Mou,  Xipeng Qiu",
                "发布日期": "2022-10-27",
                "摘要": "  Task-Oriented Dialogue (TOD) systems are drawing more and more attention in\nrecent studies. Current methods focus on constructing pre-trained models or\nfine-tuning strategies while the evaluation of TOD is limited by a policy\nmismatch problem. That is, during evaluation, the user utterances are from the\nannotated dataset while these utterances should interact with previous\nresponses which can have many alternatives besides annotated texts. Therefore,\nin this work, we propose an interactive evaluation framework for TOD. We first\nbuild a goal-oriented user simulator based on pre-trained models and then use\nthe user simulator to interact with the dialogue system to generate dialogues.\nBesides, we introduce a sentence-level and a session-level score to measure the\nsentence fluency and session coherence in the interactive evaluation.\nExperimental results show that RL-based TOD systems trained by our proposed\nuser simulator can achieve nearly 98% inform and success rates in the\ninteractive evaluation of MultiWOZ dataset and the proposed scores measure the\nresponse quality besides the inform and success rates. We are hoping that our\nwork will encourage simulator-based interactive evaluations in the TOD task.\n",
                "链接": "https://arxiv.org/abs/2210.14529"
            },
            {
                "文章ID": "5419",
                "标题": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
                "作者": " Federico Ruggeri,  Mohsen Mesgar,  Iryna Gurevych",
                "发布日期": "2022-10-14",
                "摘要": "  The applications of conversational agents for scientific disciplines (as\nexpert domains) are understudied due to the lack of dialogue data to train such\nagents. While most data collection frameworks, such as Amazon Mechanical Turk,\nfoster data collection for generic domains by connecting crowd workers and task\ndesigners, these frameworks are not much optimized for data collection in\nexpert domains. Scientists are rarely present in these frameworks due to their\nlimited time budget. Therefore, we introduce a novel framework to collect\ndialogues between scientists as domain experts on scientific papers. Our\nframework lets scientists present their scientific papers as groundings for\ndialogues and participate in dialogue they like its paper title. We use our\nframework to collect a novel argumentative dialogue dataset, ArgSciChat. It\nconsists of 498 messages collected from 41 dialogues on 20 scientific papers.\nAlongside extensive analysis on ArgSciChat, we evaluate a recent conversational\nagent on our dataset. Experimental results show that this agent poorly performs\non ArgSciChat, motivating further research on argumentative scientific agents.\nWe release our framework and the dataset.\n",
                "链接": "https://arxiv.org/abs/2202.06690"
            },
            {
                "文章ID": "40726",
                "标题": "Schema Encoding for Transferable Dialogue State Tracking",
                "作者": " Hyunmin Jeon,  Gary Geunbae Lee",
                "发布日期": "2022-10-06",
                "摘要": "  Dialogue state tracking (DST) is an essential sub-task for task-oriented\ndialogue systems. Recent work has focused on deep neural models for DST.\nHowever, the neural models require a large dataset for training. Furthermore,\napplying them to another domain needs a new dataset because the neural models\nare generally trained to imitate the given dataset. In this paper, we propose\nSchema Encoding for Transferable Dialogue State Tracking (SETDST), which is a\nneural DST method for effective transfer to new domains. Transferable DST could\nassist developments of dialogue systems even with few dataset on target\ndomains. We use a schema encoder not just to imitate the dataset but to\ncomprehend the schema of the dataset. We aim to transfer the model to new\ndomains by encoding new schemas and using them for DST on multi-domain\nsettings. As a result, SET-DST improved the joint accuracy by 1.46 points on\nMultiWOZ 2.1.\n",
                "链接": "https://arxiv.org/abs/2210.02351"
            },
            {
                "文章ID": "60862",
                "标题": "Find a witness or shatter: the landscape of computable PAC learning",
                "作者": " Valentino Delle Rose,  Alexander Kozachinskiy,  Cristobal Rojas,  Tomasz Steifer",
                "发布日期": "2023-02-24",
                "摘要": "  This paper contributes to the study of CPAC learnability -- a computable\nversion of PAC learning -- by solving three open questions from recent papers.\nFirstly, we prove that every improperly CPAC learnable class is contained in a\nclass which is properly CPAC learnable with polynomial sample complexity. This\nconfirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that\nthere exists a decidable class of hypothesis which is properly CPAC learnable,\nbut only with uncomputably fast growing sample complexity. This solves a\nquestion from Sterkenburg (COLT 2022). Finally, we construct a decidable class\nof finite Littlestone dimension which is not improperly CPAC learnable,\nstrengthening a recent result of Sterkenburg (2022) and answering a question\nposed by Hasrati and Ben-David (ALT 2023). Together with previous work, our\nresults provide a complete landscape for the learnability problem in the CPAC\nsetting.\n",
                "链接": "https://arxiv.org/abs/2302.04731"
            },
            {
                "文章ID": "48889",
                "标题": "Self-Training with Purpose Preserving Augmentation Improves Few-shot\n  Generative Dialogue State Tracking",
                "作者": " Jihyun Lee,  Chaebin Lee,  Yunsu Kim,  Gary Geunbae Lee",
                "发布日期": "2022-11-18",
                "摘要": "  In dialogue state tracking (DST), labeling the dataset involves considerable\nhuman labor. We propose a new self-training framework for few-shot generative\nDST that utilize unlabeled data. Our self-training method iteratively improves\nthe model by pseudo labeling and employs Purpose Preserving Augmentation\n(PPAug) to prevent overfitting. We increaese the few-shot 10% performance by\napproximately 4% on MultiWOZ 2.1 and enhances the slot-recall 8.34% for unseen\nvalues compared to baseline.\n",
                "链接": "https://arxiv.org/abs/2211.09379"
            },
            {
                "文章ID": "8498",
                "标题": "Mismatch between Multi-turn Dialogue and its Evaluation Metric in\n  Dialogue State Tracking",
                "作者": " Takyoung Kim,  Hoonsang Yoon,  Yukyung Lee,  Pilsung Kang,  Misuk Kim",
                "发布日期": "2022-04-01",
                "摘要": "  Dialogue state tracking (DST) aims to extract essential information from\nmulti-turn dialogue situations and take appropriate actions. A belief state,\none of the core pieces of information, refers to the subject and its specific\ncontent, and appears in the form of domain-slot-value. The trained model\npredicts \"accumulated\" belief states in every turn, and joint goal accuracy and\nslot accuracy are mainly used to evaluate the prediction; however, we specify\nthat the current evaluation metrics have a critical limitation when evaluating\nbelief states accumulated as the dialogue proceeds, especially in the most used\nMultiWOZ dataset. Additionally, we propose relative slot accuracy to complement\nexisting metrics. Relative slot accuracy does not depend on the number of\npredefined slots, and allows intuitive evaluation by assigning relative scores\naccording to the turn of each dialogue. This study also encourages not solely\nthe reporting of joint goal accuracy, but also various complementary metrics in\nDST tasks for the sake of a realistic evaluation.\n",
                "链接": "https://arxiv.org/abs/2203.03123"
            },
            {
                "文章ID": "41702",
                "标题": "CSS: Combining Self-training and Self-supervised Learning for Few-shot\n  Dialogue State Tracking",
                "作者": " Haoning Zhang,  Junwei Bao,  Haipeng Sun,  Huaishao Luo,  Wenye Li,  Shuguang Cui",
                "发布日期": "2022-10-12",
                "摘要": "  Few-shot dialogue state tracking (DST) is a realistic problem that trains the\nDST model with limited labeled data. Existing few-shot methods mainly transfer\nknowledge learned from external labeled dialogue data (e.g., from question\nanswering, dialogue summarization, machine reading comprehension tasks, etc.)\ninto DST, whereas collecting a large amount of external labeled data is\nlaborious, and the external data may not effectively contribute to the\nDST-specific task. In this paper, we propose a few-shot DST framework called\nCSS, which Combines Self-training and Self-supervised learning methods. The\nunlabeled data of the DST task is incorporated into the self-training\niterations, where the pseudo labels are predicted by a DST model trained on\nlimited labeled data in advance. Besides, a contrastive self-supervised method\nis used to learn better representations, where the data is augmented by the\ndropout operation to train the model. Experimental results on the MultiWOZ\ndataset show that our proposed CSS achieves competitive performance in several\nfew-shot scenarios.\n",
                "链接": "https://arxiv.org/abs/2210.05146"
            },
            {
                "文章ID": "111434",
                "标题": "In the user's eyes we find trust: Using gaze data as a predictor or\n  trust in an artifical intelligence",
                "作者": " Martin Johannes Dechant,  Olga Lukashova-Sanz,  Siegfried Wahl",
                "发布日期": "2023-10-26",
                "摘要": "  Trust is essential for our interactions with others but also with artificial\nintelligence (AI) based systems. To understand whether a user trusts an AI,\nresearchers need reliable measurement tools. However, currently discussed\nmarkers mostly rely on expensive and invasive sensors, like\nelectroencephalograms, which may cause discomfort. The analysis of gaze data\nhas been suggested as a convenient tool for trust assessment. However, the\nrelationship between trust and several aspects of the gaze behaviour is not yet\nfully understood. To provide more insights into this relationship, we propose a\nexploration study in virtual reality where participants have to perform a\nsorting task together with a simulated AI in a simulated robotic arm embedded\nin a gaming. We discuss the potential benefits of this approach and outline our\nstudy design in this submission.\n",
                "链接": "https://arxiv.org/abs/2310.16672"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59883",
                "标题": "LIQUID: A Framework for List Question Answering Dataset Generation",
                "作者": " Seongyun Lee,  Hyunjae Kim,  Jaewoo Kang",
                "发布日期": "2023-02-07",
                "摘要": "  Question answering (QA) models often rely on large-scale training datasets,\nwhich necessitates the development of a data generation framework to reduce the\ncost of manual annotations. Although several recent studies have aimed to\ngenerate synthetic questions with single-span answers, no study has been\nconducted on the creation of list questions with multiple, non-contiguous spans\nas answers. To address this gap, we propose LIQUID, an automated framework for\ngenerating list QA datasets from unlabeled corpora. We first convert a passage\nfrom Wikipedia or PubMed into a summary and extract named entities from the\nsummarized text as candidate answers. This allows us to select answers that are\nsemantically correlated in context and is, therefore, suitable for constructing\nlist questions. We then create questions using an off-the-shelf question\ngenerator with the extracted entities and original passage. Finally, iterative\nfiltering and answer expansion are performed to ensure the accuracy and\ncompleteness of the answers. Using our synthetic data, we significantly improve\nthe performance of the previous best list QA models by exact-match F1 scores of\n5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ\nbenchmarks.\n",
                "链接": "https://arxiv.org/abs/2302.01691"
            },
            {
                "文章ID": "48802",
                "标题": "A Creative Industry Image Generation Dataset Based on Captions",
                "作者": " Xiang Yuejia,  Lv Chuanhao,  Liu Qingdazhu,  Yang Xiaocui,  Liu Bo,  Ju Meizhi",
                "发布日期": "2022-11-17",
                "摘要": "  Most image generation methods are difficult to precisely control the\nproperties of the generated images, such as structure, scale, shape, etc.,\nwhich limits its large-scale application in creative industries such as\nconceptual design and graphic design, and so on. Using the prompt and the\nsketch is a practical solution for controllability. Existing datasets lack\neither prompt or sketch and are not designed for the creative industry. Here is\nthe main contribution of our work. a) This is the first dataset that covers the\n4 most important areas of creative industry domains and is labeled with prompt\nand sketch. b) We provide multiple reference images in the test set and\nfine-grained scores for each reference which are useful for measurement. c) We\napply two state-of-the-art models to our dataset and then find some\nshortcomings, such as the prompt is more highly valued than the sketch.\n",
                "链接": "https://arxiv.org/abs/2211.09035"
            },
            {
                "文章ID": "17220",
                "标题": "End-to-end Spoken Conversational Question Answering: Task, Dataset and\n  Model",
                "作者": " Chenyu You,  Nuo Chen,  Fenglin Liu,  Shen Ge,  Xian Wu,  Yuexian Zou",
                "发布日期": "2022-05-02",
                "摘要": "  In spoken question answering, the systems are designed to answer questions\nfrom contiguous text spans within the related speech transcripts. However, the\nmost natural way that human seek or test their knowledge is via human\nconversations. Therefore, we propose a new Spoken Conversational Question\nAnswering task (SCQA), aiming at enabling the systems to model complex dialogue\nflows given the speech documents. In this task, our main objective is to build\nthe system to deal with conversational questions based on the audio recordings,\nand to explore the plausibility of providing more cues from different\nmodalities with systems in information gathering. To this end, instead of\ndirectly adopting automatically generated speech transcripts with highly noisy\ndata, we propose a novel unified data distillation approach, DDNet, which\neffectively ingests cross-modal information to achieve fine-grained\nrepresentations of the speech and language modalities. Moreover, we propose a\nsimple and novel mechanism, termed Dual Attention, by encouraging better\nalignments between audio and text to ease the process of knowledge transfer. To\nevaluate the capacity of SCQA systems in a dialogue-style interaction, we\nassemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with\nmore than 40k question-answer pairs from 4k conversations. The performance of\nthe existing state-of-the-art methods significantly degrade on our dataset,\nhence demonstrating the necessity of cross-modal information integration. Our\nexperimental results demonstrate that our proposed method achieves superior\nperformance in spoken conversational question answering tasks.\n",
                "链接": "https://arxiv.org/abs/2204.14272"
            },
            {
                "文章ID": "2758",
                "标题": "SCAI-QReCC Shared Task on Conversational Question Answering",
                "作者": " Svitlana Vakulenko,  Johannes Kiesel,  Maik Fröbe",
                "发布日期": "2022-01-27",
                "摘要": "  Search-Oriented Conversational AI (SCAI) is an established venue that\nregularly puts a spotlight upon the recent work advancing the field of\nconversational search. SCAI'21 was organised as an independent on-line event\nand featured a shared task on conversational question answering. Since all of\nthe participant teams experimented with answer generation models for this task,\nwe identified evaluation of answer correctness in this settings as the major\nchallenge and a current research gap. Alongside the automatic evaluation, we\nconducted two crowdsourcing experiments to collect annotations for answer\nplausibility and faithfulness. As a result of this shared task, the original\nconversational QA dataset used for evaluation was further extended with\nalternative correct answers produced by the participant systems.\n",
                "链接": "https://arxiv.org/abs/2201.11094"
            },
            {
                "文章ID": "111378",
                "标题": "CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task\n  Information Retrieval",
                "作者": " Jindřich Helcl,  Jindřich Libovický",
                "发布日期": "2023-10-26",
                "摘要": "  We present the Charles University system for the MRL~2023 Shared Task on\nMulti-lingual Multi-task Information Retrieval. The goal of the shared task was\nto develop systems for named entity recognition and question answering in\nseveral under-represented languages. Our solutions to both subtasks rely on the\ntranslate-test approach. We first translate the unlabeled examples into English\nusing a multilingual machine translation model. Then, we run inference on the\ntranslated data using a strong task-specific model. Finally, we project the\nlabeled data back into the original language. To keep the inferred tags on the\ncorrect positions in the original language, we propose a method based on\nscoring the candidate positions using a label-sensitive translation model. In\nboth settings, we experiment with finetuning the classification models on the\ntranslated data. However, due to a domain mismatch between the development data\nand the shared task validation and test sets, the finetuned models could not\noutperform our baselines.\n",
                "链接": "https://arxiv.org/abs/2310.16528"
            },
            {
                "文章ID": "23951",
                "标题": "Explanation as Question Answering based on a Task Model of the Agent's\n  Design",
                "作者": " Ashok Goel,  Harshvardhan Sikka,  Vrinda Nandan,  Jeonghyun Lee,  Matt Lisle,  Spencer Rugaber",
                "发布日期": "2022-06-13",
                "摘要": "  We describe a stance towards the generation of explanations in AI agents that\nis both human-centered and design-based. We collect questions about the working\nof an AI agent through participatory design by focus groups. We capture an\nagent's design through a Task-Method-Knowledge model that explicitly specifies\nthe agent's tasks and goals, as well as the mechanisms, knowledge and\nvocabulary it uses for accomplishing the tasks. We illustrate our approach\nthrough the generation of explanations in Skillsync, an AI agent that links\ncompanies and colleges for worker upskilling and reskilling. In particular, we\nembed a question-answering agent called AskJill in Skillsync, where AskJill\ncontains a TMK model of Skillsync's design. AskJill presently answers\nhuman-generated questions about Skillsync's tasks and vocabulary, and thereby\nhelps explain how it produces its recommendations.\n",
                "链接": "https://arxiv.org/abs/2206.05030"
            },
            {
                "文章ID": "29902",
                "标题": "On the Usability of Transformers-based models for a French\n  Question-Answering task",
                "作者": " Oralie Cattan,  Christophe Servan,  Sophie Rosset",
                "发布日期": "2022-07-20",
                "摘要": "  For many tasks, state-of-the-art results have been achieved with\nTransformer-based architectures, resulting in a paradigmatic shift in practices\nfrom the use of task-specific architectures to the fine-tuning of pre-trained\nlanguage models. The ongoing trend consists in training models with an\never-increasing amount of data and parameters, which requires considerable\nresources. It leads to a strong search to improve resource efficiency based on\nalgorithmic and hardware improvements evaluated only for English. This raises\nquestions about their usability when applied to small-scale learning problems,\nfor which a limited amount of training data is available, especially for\nunder-resourced languages tasks. The lack of appropriately sized corpora is a\nhindrance to applying data-driven and transfer learning-based approaches with\nstrong instability cases. In this paper, we establish a state-of-the-art of the\nefforts dedicated to the usability of Transformer-based models and propose to\nevaluate these improvements on the question-answering performances of French\nlanguage which have few resources. We address the instability relating to data\nscarcity by investigating various training strategies with data augmentation,\nhyperparameters optimization and cross-lingual transfer. We also introduce a\nnew compact model for French FrALBERT which proves to be competitive in\nlow-resource settings.\n",
                "链接": "https://arxiv.org/abs/2207.09150"
            },
            {
                "文章ID": "21182",
                "标题": "Automatic question generation based on sentence structure analysis using\n  machine learning approach",
                "作者": " Miroslav Blšták,  Viera Rozinajová",
                "发布日期": "2022-05-26",
                "摘要": "  Automatic question generation is one of the most challenging tasks of Natural\nLanguage Processing. It requires \"bidirectional\" language processing: firstly,\nthe system has to understand the input text (Natural Language Understanding)\nand it then has to generate questions also in the form of text (Natural\nLanguage Generation). In this article, we introduce our framework for\ngenerating the factual questions from unstructured text in the English\nlanguage. It uses a combination of traditional linguistic approaches based on\nsentence patterns with several machine learning methods. We firstly obtain\nlexical, syntactic and semantic information from an input text and we then\nconstruct a hierarchical set of patterns for each sentence. The set of features\nis extracted from the patterns and it is then used for automated learning of\nnew transformation rules. Our learning process is totally data-driven because\nthe transformation rules are obtained from a set of initial sentence-question\npairs. The advantages of this approach lie in a simple expansion of new\ntransformation rules which allows us to generate various types of questions and\nalso in the continuous improvement of the system by reinforcement learning. The\nframework also includes a question evaluation module which estimates the\nquality of generated questions. It serves as a filter for selecting the best\nquestions and eliminating incorrect ones or duplicates. We have performed\nseveral experiments to evaluate the correctness of generated questions and we\nhave also compared our system with several state-of-the-art systems. Our\nresults indicate that the quality of generated questions outperforms the\nstate-of-the-art systems and our questions are also comparable to questions\ncreated by humans. We have also created and published an interface with all\ncreated datasets and evaluated questions, so it is possible to follow up on our\nwork.\n",
                "链接": "https://arxiv.org/abs/2205.12811"
            },
            {
                "文章ID": "111240",
                "标题": "BLP 2023 Task 2: Sentiment Analysis",
                "作者": " Md. Arid Hasan,  Firoj Alam,  Anika Anjum,  Shudipta Das,  Afiyat Anjum",
                "发布日期": "2023-10-26",
                "摘要": "  We present an overview of the BLP Sentiment Shared Task, organized as part of\nthe inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is\ndefined as the detection of sentiment in a given piece of social media text.\nThis task attracted interest from 71 participants, among whom 29 and 30 teams\nsubmitted systems during the development and evaluation phases, respectively.\nIn total, participants submitted 597 runs. However, a total of 15 teams\nsubmitted system description papers. The range of approaches in the submitted\nsystems spans from classical machine learning models, fine-tuning pre-trained\nmodels, to leveraging Large Language Model (LLMs) in zero- and few-shot\nsettings. In this paper, we provide a detailed account of the task setup,\nincluding dataset development and evaluation setup. Additionally, we provide a\nbrief overview of the systems submitted by the participants. All datasets and\nevaluation scripts from the shared task have been made publicly available for\nthe research community, to foster further research in this domain\n",
                "链接": "https://arxiv.org/abs/2310.16183"
            },
            {
                "文章ID": "17721",
                "标题": "Quiz Design Task: Helping Teachers Create Quizzes with Automated\n  Question Generation",
                "作者": " Philippe Laban,  Chien-Sheng Wu,  Lidiya Murakhovs'ka,  Wenhao Liu,  Caiming Xiong",
                "发布日期": "2022-05-05",
                "摘要": "  Question generation (QGen) models are often evaluated with standardized NLG\nmetrics that are based on n-gram overlap. In this paper, we measure whether\nthese metric improvements translate to gains in a practical setting, focusing\non the use case of helping teachers automate the generation of reading\ncomprehension quizzes. In our study, teachers building a quiz receive question\nsuggestions, which they can either accept or refuse with a reason. Even though\nwe find that recent progress in QGen leads to a significant increase in\nquestion acceptance rates, there is still large room for improvement, with the\nbest model having only 68.4% of its questions accepted by the ten teachers who\nparticipated in our study. We then leverage the annotations we collected to\nanalyze standard NLG metrics and find that model performance has reached\nprojected upper-bounds, suggesting new automatic metrics are needed to guide\nQGen research forward.\n",
                "链接": "https://arxiv.org/abs/2205.01730"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "1976",
                "标题": "Why Did You Not Compare With That? Identifying Papers for Use as\n  Baselines",
                "作者": " Manjot Bedi,  Tanisha Pandey,  Sumit Bhatia,  Tanmoy Chakraborty",
                "发布日期": "2022-01-21",
                "摘要": "  We propose the task of automatically identifying papers used as baselines in\na scientific article. We frame the problem as a binary classification task\nwhere all the references in a paper are to be classified as either baselines or\nnon-baselines. This is a challenging problem due to the numerous ways in which\na baseline reference can appear in a paper. We develop a dataset of $2,075$\npapers from ACL anthology corpus with all their references manually annotated\nas one of the two classes. We develop a multi-module attention-based neural\nclassifier for the baseline classification task that outperforms four\nstate-of-the-art citation role classification methods when applied to the\nbaseline classification task. We also present an analysis of the errors made by\nthe proposed classifier, eliciting the challenges that make baseline\nidentification a challenging problem.\n",
                "链接": "https://arxiv.org/abs/2201.08089"
            },
            {
                "文章ID": "22134",
                "标题": "Individual health-disease phase diagrams for disease prevention based on\n  machine learning",
                "作者": " Kazuki Nakamura,  Eiichiro Uchino,  Noriaki Sato,  Ayano Araki,  Kei Terayama,  Ryosuke Kojima,  Koichi Murashita,  Ken Itoh,  Tatsuya Mikami,  Yoshinori Tamada,  Yasushi Okuno",
                "发布日期": "2022-07-08",
                "摘要": "  Early disease detection and prevention methods based on effective\ninterventions are gaining attention. Machine learning technology has enabled\nprecise disease prediction by capturing individual differences in multivariate\ndata. Progress in precision medicine has revealed that substantial\nheterogeneity exists in health data at the individual level and that complex\nhealth factors are involved in the development of chronic diseases. However, it\nremains a challenge to identify individual physiological state changes in\ncross-disease onset processes because of the complex relationships among\nmultiple biomarkers. Here, we present the health-disease phase diagram (HDPD),\nwhich represents a personal health state by visualizing the boundary values of\nmultiple biomarkers that fluctuate early in the disease progression process. In\nHDPDs, future onset predictions are represented by perturbing multiple\nbiomarker values while accounting for dependencies among variables. We\nconstructed HDPDs for 11 non-communicable diseases (NCDs) from a longitudinal\nhealth checkup cohort of 3,238 individuals, comprising 3,215 measurement items\nand genetic data. Improvement of biomarker values to the non-onset region in\nHDPD significantly prevented future disease onset in 7 out of 11 NCDs. Our\nresults demonstrate that HDPDs can represent individual physiological states in\nthe onset process and be used as intervention goals for disease prevention.\n",
                "链接": "https://arxiv.org/abs/2205.15598"
            },
            {
                "文章ID": "21978",
                "标题": "Machine Learning Methods for Health-Index Prediction in Coating Chambers",
                "作者": " Clemens Heistracher,  Anahid Jalali,  Jürgen Schneeweiss,  Klaudia Kovacs,  Catherine Laflamme,  Bernhard Haslhofer",
                "发布日期": "2022-05-31",
                "摘要": "  Coating chambers create thin layers that improve the mechanical and optical\nsurface properties in jewelry production using physical vapor deposition. In\nsuch a process, evaporated material condensates on the walls of such chambers\nand, over time, causes mechanical defects and unstable processes. As a result,\nmanufacturers perform extensive maintenance procedures to reduce production\nloss. Current rule-based maintenance strategies neglect the impact of specific\nrecipes and the actual condition of the vacuum chamber. Our overall goal is to\npredict the future condition of the coating chamber to allow cost and quality\noptimized maintenance of the equipment. This paper describes the derivation of\na novel health indicator that serves as a step toward condition-based\nmaintenance for coating chambers. We indirectly use gas emissions of the\nchamber's contamination to evaluate the machine's condition. Our approach\nrelies on process data and does not require additional hardware installation.\nFurther, we evaluated multiple machine learning algorithms for a\ncondition-based forecast of the health indicator that also reflects production\nplanning. Our results show that models based on decision trees are the most\neffective and outperform all three benchmarks, improving at least $0.22$ in the\nmean average error. Our work paves the way for cost and quality optimized\nmaintenance of coating applications.\n",
                "链接": "https://arxiv.org/abs/2205.15145"
            },
            {
                "文章ID": "113411",
                "标题": "Identifying Alzheimer Disease Dementia Levels Using Machine Learning\n  Methods",
                "作者": " Md Gulzar Hussain,  Ye Shiren",
                "发布日期": "2023-11-06",
                "摘要": "  Dementia, a prevalent neurodegenerative condition, is a major manifestation\nof Alzheimer's disease (AD). As the condition progresses from mild to severe,\nit significantly impairs the individual's ability to perform daily tasks\nindependently, necessitating the need for timely and accurate AD\nclassification. Machine learning or deep learning models have emerged as\neffective tools for this purpose. In this study, we suggested an approach for\nclassifying the four stages of dementia using RF, SVM, and CNN algorithms,\naugmented with watershed segmentation for feature extraction from MRI images.\nOur results reveal that SVM with watershed features achieves an impressive\naccuracy of 96.25%, surpassing other classification methods. The ADNI dataset\nis utilized to evaluate the effectiveness of our method, and we observed that\nthe inclusion of watershed segmentation contributes to the enhanced performance\nof the models.\n",
                "链接": "https://arxiv.org/abs/2311.01428"
            },
            {
                "文章ID": "91950",
                "标题": "Important Clues that Facilitate Visual Emergence: Three Psychological\n  Experiments",
                "作者": " Jingmeng Li,  Hui Wei",
                "发布日期": "2023-07-21",
                "摘要": "  Visual emergence is the phenomenon in which the visual system obtains a\nholistic perception after grouping and reorganizing local signals. The picture\nDalmatian dog is known for its use in explaining visual emergence. This type of\nimage, which consists of a set of discrete black speckles (speckles), is called\nan emerging image. Not everyone can find the dog in Dalmatian dog, and among\nthose who can, the time spent varies greatly. Although Gestalt theory\nsummarizes perceptual organization into several principles, it remains\nambiguous how these principles affect the perception of emerging images. This\nstudy, therefore, designed three psychological experiments to explore the\nfactors that influence the perception of emerging images. In the first, we\nfound that the density of speckles in the local area and the arrangements of\nsome key speckles played a key role in the perception of an emerging case. We\nset parameters in the algorithm to characterize these two factors. We then\nautomatically generated diversified emerging-test images (ETIs) through the\nalgorithm and verified their effectiveness in two subsequent experiments.\n",
                "链接": "https://arxiv.org/abs/2307.10194"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "32669",
                "标题": "An example of use of Variational Methods in Quantum Machine Learning",
                "作者": " Marco Simonetti,  Damiano Perri,  Osvaldo Gervasi",
                "发布日期": "2022-08-10",
                "摘要": "  This paper introduces a deep learning system based on a quantum neural\nnetwork for the binary classification of points of a specific geometric pattern\n(Two-Moons Classification problem) on a plane. We believe that the use of\nhybrid deep learning systems (classical + quantum) can reasonably bring\nbenefits, not only in terms of computational acceleration but in understanding\nthe underlying phenomena and mechanisms; that will lead to the creation of new\nforms of machine learning, as well as to a strong development in the world of\nquantum computation. The chosen dataset is based on a 2D binary classification\ngenerator, which helps test the effectiveness of specific algorithms; it is a\nset of 2D points forming two interspersed semicircles. It displays two\ndisjointed data sets in a two-dimensional representation space: the features\nare, therefore, the individual points' two coordinates, $x_1$ and $x_2$. The\nintention was to produce a quantum deep neural network with the minimum number\nof trainable parameters capable of correctly recognising and classifying\npoints.\n",
                "链接": "https://arxiv.org/abs/2208.04316"
            },
            {
                "文章ID": "46928",
                "标题": "Towards Alzheimer's Disease Progression Assessment: A Review of Machine\n  Learning Methods",
                "作者": " Zibin Zhao",
                "发布日期": "2022-11-14",
                "摘要": "  Alzheimer's Disease (AD), as the most devastating neurodegenerative disease\nworldwide, has reached nearly 10 million new cases annually. Current technology\nprovides unprecedented opportunities to study the progression and etiology of\nthis disease with the advanced in imaging techniques. With the recent emergence\nof a society driven by big data and machine learning (ML), researchers have\nexerted considerable effort to summarize recent advances in ML-based AD\ndiagnosis. Here, we outline some of the most prevalent and recent ML models for\nassessing the progression of AD and provide insights on the challenges,\nopportunities, and future directions that could be advantageous to future\nresearch in AD using ML.\n",
                "链接": "https://arxiv.org/abs/2211.02636"
            },
            {
                "文章ID": "116611",
                "标题": "Classification Methods Based on Machine Learning for the Analysis of\n  Fetal Health Data",
                "作者": " Binod Regmi,  Chiranjibi Shah",
                "发布日期": "2023-11-21",
                "摘要": "  The persistent battle to decrease childhood mortality serves as a commonly\nemployed benchmark for gauging advancements in the field of medicine. Globally,\nthe under-5 mortality rate stands at approximately 5 million, with a\nsignificant portion of these deaths being avoidable. Given the significance of\nthis problem, Machine learning-based techniques have emerged as a prominent\ntool for assessing fetal health. In this work, we have analyzed the\nclassification performance of various machine learning models for fetal health\nanalysis. Classification performance of various machine learning models, such\nas support vector machine (SVM), random forest(RF), and attentive interpretable\ntabular learning (TabNet) have been assessed on fetal health. Moreover,\ndimensionality reduction techniques, such as Principal component analysis (PCA)\nand Linear discriminant analysis (LDA) have been implemented to obtain better\nclassification performance with less number of features. A TabNet model on a\nfetal health dataset provides a classification accuracy of 94.36%. In general,\nthis technology empowers doctors and healthcare experts to achieve precise\nfetal health classification and identify the most influential features in the\nprocess.\n",
                "链接": "https://arxiv.org/abs/2311.10962"
            },
            {
                "文章ID": "11999",
                "标题": "Specialized Document Embeddings for Aspect-based Similarity of Research\n  Papers",
                "作者": " Malte Ostendorff,  Till Blume,  Terry Ruas,  Bela Gipp,  Georg Rehm",
                "发布日期": "2022-03-29",
                "摘要": "  Document embeddings and similarity measures underpin content-based\nrecommender systems, whereby a document is commonly represented as a single\ngeneric embedding. However, similarity computed on single vector\nrepresentations provides only one perspective on document similarity that\nignores which aspects make two documents alike. To address this limitation,\naspect-based similarity measures have been developed using document\nsegmentation or pairwise multi-class document classification. While\nsegmentation harms the document coherence, the pairwise classification approach\nscales poorly to large scale corpora. In this paper, we treat aspect-based\nsimilarity as a classical vector similarity problem in aspect-specific\nembedding spaces. We represent a document not as a single generic embedding but\nas multiple specialized embeddings. Our approach avoids document segmentation\nand scales linearly w.r.t.the corpus size. In an empirical study, we use the\nPapers with Code corpus containing 157,606 research papers and consider the\ntask, method, and dataset of the respective research papers as their aspects.\nWe compare and analyze three generic document embeddings, six specialized\ndocument embeddings and a pairwise classification baseline in the context of\nresearch paper recommendations. As generic document embeddings, we consider\nFastText, SciBERT, and SPECTER. To compute the specialized document embeddings,\nwe compare three alternative methods inspired by retrofitting, fine-tuning, and\nSiamese networks. In our experiments, Siamese SciBERT achieved the highest\nscores. Additional analyses indicate an implicit bias of the generic document\nembeddings towards the dataset aspect and against the method aspect of each\nresearch paper. Our approach of aspect-based document embeddings mitigates\npotential risks arising from implicit biases by making them explicit.\n",
                "链接": "https://arxiv.org/abs/2203.14541"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "11766",
                "标题": "Intelligent Masking: Deep Q-Learning for Context Encoding in Medical\n  Image Analysis",
                "作者": " Mojtaba Bahrami,  Mahsa Ghorbani,  Nassir Navab",
                "发布日期": "2022-04-06",
                "摘要": "  The need for a large amount of labeled data in the supervised setting has led\nrecent studies to utilize self-supervised learning to pre-train deep neural\nnetworks using unlabeled data. Many self-supervised training strategies have\nbeen investigated especially for medical datasets to leverage the information\navailable in the much fewer unlabeled data. One of the fundamental strategies\nin image-based self-supervision is context prediction. In this approach, a\nmodel is trained to reconstruct the contents of an arbitrary missing region of\nan image based on its surroundings. However, the existing methods adopt a\nrandom and blind masking approach by focusing uniformly on all regions of the\nimages. This approach results in a lot of unnecessary network updates that\ncause the model to forget the rich extracted features. In this work, we develop\na novel self-supervised approach that occludes targeted regions to improve the\npre-training procedure. To this end, we propose a reinforcement learning-based\nagent which learns to intelligently mask input images through deep Q-learning.\nWe show that training the agent against the prediction model can significantly\nimprove the semantic features extracted for downstream classification tasks. We\nperform our experiments on two public datasets for diagnosing breast cancer in\nthe ultrasound images and detecting lower-grade glioma with MR images. In our\nexperiments, we show that our novel masking strategy advances the learned\nfeatures according to the performance on the classification task in terms of\naccuracy, macro F1, and AUROC.\n",
                "链接": "https://arxiv.org/abs/2203.13865"
            },
            {
                "文章ID": "65067",
                "标题": "Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis",
                "作者": " Raghav Mehta,  Changjian Shui,  Tal Arbel",
                "发布日期": "2023-03-07",
                "摘要": "  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2303.03242"
            },
            {
                "文章ID": "68134",
                "标题": "Label-Efficient Deep Learning in Medical Image Analysis: Challenges and\n  Future Directions",
                "作者": " Cheng Jin,  Zhengrui Guo,  Yi Lin,  Luyang Luo,  Hao Chen",
                "发布日期": "2023-12-21",
                "摘要": "  Deep learning has seen rapid growth in recent years and achieved\nstate-of-the-art performance in a wide range of applications. However, training\nmodels typically requires expensive and time-consuming collection of large\nquantities of labeled data. This is particularly true within the scope of\nmedical imaging analysis (MIA), where data are limited and labels are expensive\nto be acquired. Thus, label-efficient deep learning methods are developed to\nmake comprehensive use of the labeled data as well as the abundance of\nunlabeled and weak-labeled data. In this survey, we extensively investigated\nover 300 recent papers to provide a comprehensive overview of recent progress\non label-efficient learning strategies in MIA. We first present the background\nof label-efficient learning and categorize the approaches into different\nschemes. Next, we examine the current state-of-the-art methods in detail\nthrough each scheme. Specifically, we provide an in-depth investigation,\ncovering not only canonical semi-supervised, self-supervised, and\nmulti-instance learning schemes, but also recently emerged active and\nannotation-efficient learning strategies. Moreover, as a comprehensive\ncontribution to the field, this survey not only elucidates the commonalities\nand unique features of the surveyed methods but also presents a detailed\nanalysis of the current challenges in the field and suggests potential avenues\nfor future research.\n",
                "链接": "https://arxiv.org/abs/2303.12484"
            },
            {
                "文章ID": "2860",
                "标题": "An Analysis on Ensemble Learning optimized Medical Image Classification\n  with Deep Convolutional Neural Networks",
                "作者": " Dominik Müller,  Iñaki Soto-Rey,  Frank Kramer",
                "发布日期": "2022-04-14",
                "摘要": "  Novel and high-performance medical image classification pipelines are heavily\nutilizing ensemble learning strategies. The idea of ensemble learning is to\nassemble diverse models or multiple predictions and, thus, boost prediction\nperformance. However, it is still an open question to what extent as well as\nwhich ensemble learning strategies are beneficial in deep learning based\nmedical image classification pipelines. In this work, we proposed a\nreproducible medical image classification pipeline for analyzing the\nperformance impact of the following ensemble learning techniques: Augmenting,\nStacking, and Bagging. The pipeline consists of state-of-the-art preprocessing\nand image augmentation methods as well as 9 deep convolution neural network\narchitectures. It was applied on four popular medical imaging datasets with\nvarying complexity. Furthermore, 12 pooling functions for combining multiple\npredictions were analyzed, ranging from simple statistical functions like\nunweighted averaging up to more complex learning-based functions like support\nvector machines. Our results revealed that Stacking achieved the largest\nperformance gain of up to 13% F1-score increase. Augmenting showed consistent\nimprovement capabilities by up to 4% and is also applicable to single model\nbased pipelines. Cross-validation based Bagging demonstrated significant\nperformance gain close to Stacking, which resulted in an F1-score increase up\nto +11%. Furthermore, we demonstrated that simple statistical pooling functions\nare equal or often even better than more complex pooling functions. We\nconcluded that the integration of ensemble learning techniques is a powerful\nmethod for any medical image classification pipeline to improve robustness and\nboost performance.\n",
                "链接": "https://arxiv.org/abs/2201.11440"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "107726",
                "标题": "Data efficient deep learning for medical image analysis: A survey",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-10-11",
                "摘要": "  The rapid evolution of deep learning has significantly advanced the field of\nmedical image analysis. However, despite these achievements, the further\nenhancement of deep learning models for medical image analysis faces a\nsignificant challenge due to the scarcity of large, well-annotated datasets. To\naddress this issue, recent years have witnessed a growing emphasis on the\ndevelopment of data-efficient deep learning methods. This paper conducts a\nthorough review of data-efficient deep learning methods for medical image\nanalysis. To this end, we categorize these methods based on the level of\nsupervision they rely on, encompassing categories such as no supervision,\ninexact supervision, incomplete supervision, inaccurate supervision, and only\nlimited supervision. We further divide these categories into finer\nsubcategories. For example, we categorize inexact supervision into multiple\ninstance learning and learning with weak annotations. Similarly, we categorize\nincomplete supervision into semi-supervised learning, active learning, and\ndomain-adaptive learning and so on. Furthermore, we systematically summarize\ncommonly used datasets for data efficient deep learning in medical image\nanalysis and investigate future research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2310.06557"
            },
            {
                "文章ID": "56274",
                "标题": "Deep-learning models in medical image analysis: Detection of esophagitis\n  from the Kvasir Dataset",
                "作者": " Kyoka Yoshiok,  Kensuke Tanioka,  Satoru Hiwa,  Tomoyuki Hiroyasu",
                "发布日期": "2023-01-09",
                "摘要": "  Early detection of esophagitis is important because this condition can\nprogress to cancer if left untreated. However, the accuracies of different deep\nlearning models in detecting esophagitis have yet to be compared. Thus, this\nstudy aimed to compare the accuracies of convolutional neural network models\n(GoogLeNet, ResNet-50, MobileNet V2, and MobileNet V3) in detecting esophagitis\nfrom the open Kvasir dataset of endoscopic images. Results showed that among\nthe models, GoogLeNet achieved the highest F1-scores. Based on the average of\ntrue positive rate, MobileNet V3 predicted esophagitis more confidently than\nthe other models. The results obtained using the models were also compared with\nthose obtained using SHapley Additive exPlanations and Gradient-weighted Class\nActivation Mapping.\n",
                "链接": "https://arxiv.org/abs/2301.02390"
            },
            {
                "文章ID": "6957",
                "标题": "Transformers in Medical Image Analysis: A Review",
                "作者": " Kelei He,  Chen Gan,  Zhuoyuan Li,  Islem Rekik,  Zihao Yin,  Wen Ji,  Yang Gao,  Qian Wang,  Junfeng Zhang,  Dinggang Shen",
                "发布日期": "2022-08-22",
                "摘要": "  Transformers have dominated the field of natural language processing, and\nrecently impacted the computer vision area. In the field of medical image\nanalysis, Transformers have also been successfully applied to full-stack\nclinical applications, including image synthesis/reconstruction, registration,\nsegmentation, detection, and diagnosis. Our paper aims to promote awareness and\napplication of Transformers in the field of medical image analysis.\nSpecifically, we first overview the core concepts of the attention mechanism\nbuilt into Transformers and other basic components. Second, we review various\nTransformer architectures tailored for medical image applications and discuss\ntheir limitations. Within this review, we investigate key challenges revolving\naround the use of Transformers in different learning paradigms, improving the\nmodel efficiency, and their coupling with other techniques. We hope this review\ncan give a comprehensive picture of Transformers to the readers in the field of\nmedical image analysis.\n",
                "链接": "https://arxiv.org/abs/2202.12165"
            }
        ]
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "30292",
                "标题": "On the Implementation of a Reinforcement Learning-based Capacity Sharing\n  Algorithm in O-RAN",
                "作者": " Irene Vilà,  Oriol Sallent,  Jordi Pérez-Romero",
                "发布日期": "2022-07-22",
                "摘要": "  The capacity sharing problem in Radio Access Network (RAN) slicing deals with\nthe distribution of the capacity available in each RAN node among various RAN\nslices to satisfy their traffic demands and efficiently use the radio\nresources. While several capacity sharing algorithmic solutions have been\nproposed in the literature, their practical implementation still remains as a\ngap. In this paper, the implementation of a Reinforcement Learning-based\ncapacity sharing algorithm over the O-RAN architecture is discussed, providing\ninsights into the operation of the involved interfaces and the containerization\nof the solution. Moreover, the description of the testbed implemented to\nvalidate the solution is included and some performance and validation results\nare presented.\n",
                "链接": "https://arxiv.org/abs/2207.10390"
            },
            {
                "文章ID": "21198",
                "标题": "Robust Reinforcement Learning on Graphs for Logistics optimization",
                "作者": " Zangir Iklassov,  Dmitrii Medvedev",
                "发布日期": "2022-05-26",
                "摘要": "  Logistics optimization nowadays is becoming one of the hottest areas in the\nAI community. In the past year, significant advancements in the domain were\nachieved by representing the problem in a form of graph. Another promising area\nof research was to apply reinforcement learning algorithms to the above task.\nIn our work, we made advantage of using both approaches and apply reinforcement\nlearning on a graph. To do that, we have analyzed the most recent results in\nboth fields and selected SOTA algorithms both from graph neural networks and\nreinforcement learning. Then, we combined selected models on the problem of\nAMOD systems optimization for the transportation network of New York city. Our\nteam compared three algorithms - GAT, Pro-CNN and PTDNet - to bring to the fore\nthe important nodes on a graph representation. Finally, we achieved SOTA\nresults on AMOD systems optimization problem employing PTDNet with GNN and\ntraining them in reinforcement fashion.\n  Keywords: Graph Neural Network (GNN), Logistics optimization, Reinforcement\nLearning\n",
                "链接": "https://arxiv.org/abs/2205.12888"
            },
            {
                "文章ID": "74214",
                "标题": "A optimization framework for herbal prescription planning based on deep\n  reinforcement learning",
                "作者": " Kuo Yang,  Zecong Yu,  Xin Su,  Xiong He,  Ning Wang,  Qiguang Zheng,  Feidie Yu,  Zhuang Liu,  Tiancai Wen,  Xuezhong Zhou",
                "发布日期": "2023-04-26",
                "摘要": "  Treatment planning for chronic diseases is a critical task in medical\nartificial intelligence, particularly in traditional Chinese medicine (TCM).\nHowever, generating optimized sequential treatment strategies for patients with\nchronic diseases in different clinical encounters remains a challenging issue\nthat requires further exploration. In this study, we proposed a TCM herbal\nprescription planning framework based on deep reinforcement learning for\nchronic disease treatment (PrescDRL). PrescDRL is a sequential herbal\nprescription optimization model that focuses on long-term effectiveness rather\nthan achieving maximum reward at every step, thereby ensuring better patient\noutcomes. We constructed a high-quality benchmark dataset for sequential\ndiagnosis and treatment of diabetes and evaluated PrescDRL against this\nbenchmark. Our results showed that PrescDRL achieved a higher curative effect,\nwith the single-step reward improving by 117% and 153% compared to doctors.\nFurthermore, PrescDRL outperformed the benchmark in prescription prediction,\nwith precision improving by 40.5% and recall improving by 63%. Overall, our\nstudy demonstrates the potential of using artificial intelligence to improve\nclinical intelligent diagnosis and treatment in TCM.\n",
                "链接": "https://arxiv.org/abs/2304.12828"
            },
            {
                "文章ID": "71243",
                "标题": "On Efficient Training of Large-Scale Deep Learning Models: A Literature\n  Review",
                "作者": " Li Shen,  Yan Sun,  Zhiyuan Yu,  Liang Ding,  Xinmei Tian,  Dacheng Tao",
                "发布日期": "2023-04-10",
                "摘要": "  The field of deep learning has witnessed significant progress, particularly\nin computer vision (CV), natural language processing (NLP), and speech. The use\nof large-scale models trained on vast amounts of data holds immense promise for\npractical applications, enhancing industrial productivity and facilitating\nsocial development. With the increasing demands on computational capacity,\nthough numerous studies have explored the efficient training, a comprehensive\nsummarization on acceleration techniques of training deep learning models is\nstill much anticipated. In this survey, we present a detailed review for\ntraining acceleration. We consider the fundamental update formulation and split\nits basic components into five main perspectives: (1) data-centric: including\ndataset regularization, data sampling, and data-centric curriculum learning\ntechniques, which can significantly reduce the computational complexity of the\ndata samples; (2) model-centric, including acceleration of basic modules,\ncompression training, model initialization and model-centric curriculum\nlearning techniques, which focus on accelerating the training via reducing the\ncalculations on parameters; (3) optimization-centric, including the selection\nof learning rate, the employment of large batchsize, the designs of efficient\nobjectives, and model average techniques, which pay attention to the training\npolicy and improving the generality for the large-scale models; (4) budgeted\ntraining, including some distinctive acceleration methods on source-constrained\nsituations; (5) system-centric, including some efficient open-source\ndistributed libraries/systems which provide adequate hardware support for the\nimplementation of acceleration algorithms. By presenting this comprehensive\ntaxonomy, our survey presents a comprehensive review to understand the general\nmechanisms within each component and their joint interaction.\n",
                "链接": "https://arxiv.org/abs/2304.03589"
            },
            {
                "文章ID": "27272",
                "标题": "Literature on Hand GESTURE Recognition using Graph based methods",
                "作者": " Neha Baranwal,  Varun Sharma",
                "发布日期": "2022-07-04",
                "摘要": "  Skeleton based recognition systems are gaining popularity and machine\nlearning models focusing on points or joints in a skeleton have proved to be\ncomputationally effective and application in many areas like Robotics. It is\neasy to track points and thereby preserving spatial and temporal information,\nwhich plays an important role in abstracting the required information,\nclassification becomes an easy task. In this paper, we aim to study these\npoints but using a cloud mechanism, where we define a cloud as collection of\npoints. However, when we add temporal information, it may not be possible to\nretrieve the coordinates of a point in each frame and hence instead of focusing\non a single point, we can use k-neighbors to retrieve the state of the point\nunder discussion. Our focus is to gather such information using weight sharing\nbut making sure that when we try to retrieve the information from neighbors, we\ndo not carry noise with it. LSTM which has capability of long-term modelling\nand can carry both temporal and spatial information. In this article we tried\nto summarise graph based gesture recognition method.\n",
                "链接": "https://arxiv.org/abs/2207.00329"
            },
            {
                "文章ID": "25398",
                "标题": "A Survey on Model-based Reinforcement Learning",
                "作者": " Fan-Ming Luo,  Tian Xu,  Hang Lai,  Xiong-Hui Chen,  Weinan Zhang,  Yang Yu",
                "发布日期": "2022-06-22",
                "摘要": "  Reinforcement learning (RL) solves sequential decision-making problems via a\ntrial-and-error process interacting with the environment. While RL achieves\noutstanding success in playing complex video games that allow huge\ntrial-and-error, making errors is always undesired in the real world. To\nimprove the sample efficiency and thus reduce the errors, model-based\nreinforcement learning (MBRL) is believed to be a promising direction, which\nbuilds environment models in which the trial-and-errors can take place without\nreal costs. In this survey, we take a review of MBRL with a focus on the recent\nprogress in deep RL. For non-tabular environments, there is always a\ngeneralization error between the learned environment model and the real\nenvironment. As such, it is of great importance to analyze the discrepancy\nbetween policy training in the environment model and that in the real\nenvironment, which in turn guides the algorithm design for better model\nlearning, model usage, and policy training. Besides, we also discuss the recent\nadvances of model-based techniques in other forms of RL, including offline RL,\ngoal-conditioned RL, multi-agent RL, and meta-RL. Moreover, we discuss the\napplicability and advantages of MBRL in real-world tasks. Finally, we end this\nsurvey by discussing the promising prospects for the future development of\nMBRL. We think that MBRL has great potential and advantages in real-world\napplications that were overlooked, and we hope this survey could attract more\nresearch on MBRL.\n",
                "链接": "https://arxiv.org/abs/2206.09328"
            },
            {
                "文章ID": "53627",
                "标题": "Quantum Control based on Deep Reinforcement Learning",
                "作者": " Zhikang Wang",
                "发布日期": "2022-12-15",
                "摘要": "  In this thesis, we consider two simple but typical control problems and apply\ndeep reinforcement learning to them, i.e., to cool and control a particle which\nis subject to continuous position measurement in a one-dimensional quadratic\npotential or in a quartic potential. We compare the performance of\nreinforcement learning control and conventional control strategies on the two\nproblems, and show that the reinforcement learning achieves a performance\ncomparable to the optimal control for the quadratic case, and outperforms\nconventional control strategies for the quartic case for which the optimal\ncontrol strategy is unknown. To our knowledge, this is the first time deep\nreinforcement learning is applied to quantum control problems in continuous\nreal space. Our research demonstrates that deep reinforcement learning can be\nused to control a stochastic quantum system in real space effectively as a\nmeasurement-feedback closed-loop controller, and our research also shows the\nability of AI to discover new control strategies and properties of the quantum\nsystems that are not well understood, and we can gain insights into these\nproblems by learning from the AI, which opens up a new regime for scientific\nresearch.\n",
                "链接": "https://arxiv.org/abs/2212.07385"
            },
            {
                "文章ID": "54131",
                "标题": "Neural Coreference Resolution based on Reinforcement Learning",
                "作者": " Yu Wang,  Hongxia Jin",
                "发布日期": "2022-12-20",
                "摘要": "  The target of a coreference resolution system is to cluster all mentions that\nrefer to the same entity in a given context. All coreference resolution systems\nneed to solve two subtasks; one task is to detect all of the potential\nmentions, and the other is to learn the linking of an antecedent for each\npossible mention. In this paper, we propose a reinforcement learning\nactor-critic-based neural coreference resolution system, which can achieve both\nmention detection and mention clustering by leveraging an actor-critic deep\nreinforcement learning technique and a joint training algorithm. We experiment\non the BERT model to generate different input span representations. Our model\nwith the BERT span representation achieves the state-of-the-art performance\namong the models on the CoNLL-2012 Shared Task English Test Set.\n",
                "链接": "https://arxiv.org/abs/2212.09028"
            },
            {
                "文章ID": "113240",
                "标题": "Dynamic Fair Federated Learning Based on Reinforcement Learning",
                "作者": " Weikang Chen,  Junping Du,  Yingxia Shao,  Jia Wang,  Yangxi Zhou",
                "发布日期": "2023-11-03",
                "摘要": "  Federated learning enables a collaborative training and optimization of\nglobal models among a group of devices without sharing local data samples.\nHowever, the heterogeneity of data in federated learning can lead to unfair\nrepresentation of the global model across different devices. To address the\nfairness issue in federated learning, we propose a dynamic q fairness federated\nlearning algorithm with reinforcement learning, called DQFFL. DQFFL aims to\nmitigate the discrepancies in device aggregation and enhance the fairness of\ntreatment for all groups involved in federated learning. To quantify fairness,\nDQFFL leverages the performance of the global federated model on each device\nand incorporates {\\alpha}-fairness to transform the preservation of fairness\nduring federated aggregation into the distribution of client weights in the\naggregation process. Considering the sensitivity of parameters in measuring\nfairness, we propose to utilize reinforcement learning for dynamic parameters\nduring aggregation. Experimental results demonstrate that our DQFFL outperforms\nthe state-of-the-art methods in terms of overall performance, fairness and\nconvergence speed.\n",
                "链接": "https://arxiv.org/abs/2311.00959"
            },
            {
                "文章ID": "42360",
                "标题": "Efficient circuit implementation for coined quantum walks on binary\n  trees and application to reinforcement learning",
                "作者": " Thomas Mullor,  David Vigouroux,  Louis Bethune",
                "发布日期": "2022-10-17",
                "摘要": "  Quantum walks on binary trees are used in many quantum algorithms to achieve\nimportant speedup over classical algorithms. The formulation of this kind of\nalgorithms as quantum circuit presents the advantage of being easily readable,\nexecutable on circuit based quantum computers and simulators and optimal on the\nusage of resources. We propose a strategy to compose quantum circuit that\nperforms quantum walk on binary trees following universal gate model quantum\ncomputation principles. We give a particular attention to NAND formula\nevaluation algorithm as it could have many applications in game theory and\nreinforcement learning. We therefore propose an application of this algorithm\nand show how it can be used to train a quantum reinforcement learning agent in\na two player game environment.\n",
                "链接": "https://arxiv.org/abs/2210.06784"
            }
        ]
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "91355",
                "标题": "On the application of Large Language Models for language teaching and\n  assessment technology",
                "作者": " Andrew Caines,  Luca Benedetto,  Shiva Taslimipoor,  Christopher Davis,  Yuan Gao,  Oeistein Andersen,  Zheng Yuan,  Mark Elliott,  Russell Moore,  Christopher Bryant,  Marek Rei,  Helen Yannakoudakis,  Andrew Mullooly,  Diane Nicholls,  Paula Buttery",
                "发布日期": "2023-07-18",
                "摘要": "  The recent release of very large language models such as PaLM and GPT-4 has\nmade an unprecedented impact in the popular media and public consciousness,\ngiving rise to a mixture of excitement and fear as to their capabilities and\npotential uses, and shining a light on natural language processing research\nwhich had not previously received so much attention. The developments offer\ngreat promise for education technology, and in this paper we look specifically\nat the potential for incorporating large language models in AI-driven language\nteaching and assessment systems. We consider several research areas and also\ndiscuss the risks and ethical considerations surrounding generative AI in\neducation technology for language learners. Overall we find that larger\nlanguage models offer improvements over previous models in text generation,\nopening up routes toward content generation which had not previously been\nplausible. For text generation they must be prompted carefully and their\noutputs may need to be reshaped before they are ready for use. For automated\ngrading and grammatical error correction, tasks whose progress is checked on\nwell-known benchmarks, early investigations indicate that large language models\non their own do not improve on state-of-the-art results according to standard\nevaluation metrics. For grading it appears that linguistic features established\nin the literature should still be used for best performance, and for error\ncorrection it may be that the models can offer alternative feedback styles\nwhich are not measured sensitively with existing methods. In all cases, there\nis work to be done to experiment with the inclusion of large language models in\neducation technology for language learners, in order to properly understand and\nreport on their capacities and limitations, and to ensure that foreseeable\nrisks such as misinformation and harmful bias are mitigated.\n",
                "链接": "https://arxiv.org/abs/2307.08393"
            },
            {
                "文章ID": "61474",
                "标题": "Guiding Pretraining in Reinforcement Learning with Large Language Models",
                "作者": " Yuqing Du,  Olivia Watkins,  Zihan Wang,  Cédric Colas,  Trevor Darrell,  Pieter Abbeel,  Abhishek Gupta,  Jacob Andreas",
                "发布日期": "2023-09-18",
                "摘要": "  Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.\n",
                "链接": "https://arxiv.org/abs/2302.06692"
            },
            {
                "文章ID": "77204",
                "标题": "Systematic Review on Reinforcement Learning in the Field of Fintech",
                "作者": " Nadeem Malibari,  Iyad Katib,  Rashid Mehmood",
                "发布日期": "2023-05-15",
                "摘要": "  Applications of Reinforcement Learning in the Finance Technology (Fintech)\nhave acquired a lot of admiration lately. Undoubtedly Reinforcement Learning,\nthrough its vast competence and proficiency, has aided remarkable results in\nthe field of Fintech. The objective of this systematic survey is to perform an\nexploratory study on a correlation between reinforcement learning and Fintech\nto highlight the prediction accuracy, complexity, scalability, risks,\nprofitability and performance. Major uses of reinforcement learning in finance\nor Fintech include portfolio optimization, credit risk reduction, investment\ncapital management, profit maximization, effective recommendation systems, and\nbetter price setting strategies. Several studies have addressed the actual\ncontribution of reinforcement learning to the performance of financial\ninstitutions. The latest studies included in this survey are publications from\n2018 onward. The survey is conducted using PRISMA technique which focuses on\nthe reporting of reviews and is based on a checklist and four-phase flow\ndiagram. The conducted survey indicates that the performance of RL-based\nstrategies in Fintech fields proves to perform considerably better than other\nstate-of-the-art algorithms. The present work discusses the use of\nreinforcement learning algorithms in diverse decision-making challenges in\nFintech and concludes that the organizations dealing with finance can benefit\ngreatly from Robo-advising, smart order channelling, market making, hedging and\noptions pricing, portfolio optimization, and optimal execution.\n",
                "链接": "https://arxiv.org/abs/2305.07466"
            },
            {
                "文章ID": "116139",
                "标题": "On the Exploitability of Reinforcement Learning with Human Feedback for\n  Large Language Models",
                "作者": " Jiongxiao Wang,  Junlin Wu,  Muhao Chen,  Yevgeniy Vorobeychik,  Chaowei Xiao",
                "发布日期": "2023-11-17",
                "摘要": "  Reinforcement Learning with Human Feedback (RLHF) is a methodology designed\nto align Large Language Models (LLMs) with human preferences, playing an\nimportant role in LLMs alignment. Despite its advantages, RLHF relies on human\nannotators to rank the text, which can introduce potential security\nvulnerabilities if any adversarial annotator (i.e., attackers) manipulates the\nranking score by up-ranking any malicious text to steer the LLM adversarially.\nTo assess the red-teaming of RLHF against human preference data poisoning, we\npropose RankPoison, a poisoning attack method on candidates' selection of\npreference rank flipping to reach certain malicious behaviors (e.g., generating\nlonger sequences, which can increase the computational cost). With poisoned\ndataset generated by RankPoison, we can perform poisoning attacks on LLMs to\ngenerate longer tokens without hurting the original safety alignment\nperformance. Moreover, applying RankPoison, we also successfully implement a\nbackdoor attack where LLMs can generate longer answers under questions with the\ntrigger word. Our findings highlight critical security challenges in RLHF,\nunderscoring the necessity for more robust alignment methods for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.09641"
            },
            {
                "文章ID": "101258",
                "标题": "Large Language Models for Difficulty Estimation of Foreign Language\n  Content with Application to Language Learning",
                "作者": " Michalis Vlachos,  Mircea Lungu,  Yash Raj Shrestha,  Johannes-Rudolf David",
                "发布日期": "2023-09-12",
                "摘要": "  We use large language models to aid learners enhance proficiency in a foreign\nlanguage. This is accomplished by identifying content on topics that the user\nis interested in, and that closely align with the learner's proficiency level\nin that foreign language. Our work centers on French content, but our approach\nis readily transferable to other languages. Our solution offers several\ndistinctive characteristics that differentiate it from existing\nlanguage-learning solutions, such as, a) the discovery of content across topics\nthat the learner cares about, thus increasing motivation, b) a more precise\nestimation of the linguistic difficulty of the content than traditional\nreadability measures, and c) the availability of both textual and video-based\ncontent. The linguistic complexity of video content is derived from the video\ncaptions. It is our aspiration that such technology will enable learners to\nremain engaged in the language-learning process by continuously adapting the\ntopics and the difficulty of the content to align with the learners' evolving\ninterests and learning objectives.\n",
                "链接": "https://arxiv.org/abs/2309.05142"
            },
            {
                "文章ID": "68450",
                "标题": "ChatGPT and a New Academic Reality: Artificial Intelligence-Written\n  Research Papers and the Ethics of the Large Language Models in Scholarly\n  Publishing",
                "作者": " Brady Lund,  Ting Wang,  Nishith Reddy Mannuru,  Bing Nie,  Somipam Shimray,  Ziang Wang",
                "发布日期": "2023-04-03",
                "摘要": "  This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer,\nwhich uses natural language processing to fulfill text-based user requests\n(i.e., a chatbot). The history and principles behind ChatGPT and similar models\nare discussed. This technology is then discussed in relation to its potential\nimpact on academia and scholarly research and publishing. ChatGPT is seen as a\npotential model for the automated preparation of essays and other types of\nscholarly manuscripts. Potential ethical issues that could arise with the\nemergence of large language models like GPT-3, the underlying technology behind\nChatGPT, and its usage by academics and researchers, are discussed and situated\nwithin the context of broader advancements in artificial intelligence, machine\nlearning, and natural language processing for research and scholarly\npublishing.\n",
                "链接": "https://arxiv.org/abs/2303.13367"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "102386",
                "标题": "Rethinking Learning Rate Tuning in the Era of Large Language Models",
                "作者": " Hongpeng Jin,  Wenqi Wei,  Xuyu Wang,  Wenbin Zhang,  Yanzhao Wu",
                "发布日期": "2023-09-19",
                "摘要": "  Large Language Models (LLMs) represent the recent success of deep learning in\nachieving remarkable human-like predictive performance. It has become a\nmainstream strategy to leverage fine-tuning to adapt LLMs for various\nreal-world applications due to the prohibitive expenses associated with LLM\ntraining. The learning rate is one of the most important hyperparameters in LLM\nfine-tuning with direct impacts on both fine-tuning efficiency and fine-tuned\nLLM quality. Existing learning rate policies are primarily designed for\ntraining traditional deep neural networks (DNNs), which may not work well for\nLLM fine-tuning. We reassess the research challenges and opportunities of\nlearning rate tuning in the coming era of Large Language Models. This paper\nmakes three original contributions. First, we revisit existing learning rate\npolicies to analyze the critical challenges of learning rate tuning in the era\nof LLMs. Second, we present LRBench++ to benchmark learning rate policies and\nfacilitate learning rate tuning for both traditional DNNs and LLMs. Third, our\nexperimental analysis with LRBench++ demonstrates the key differences between\nLLM fine-tuning and traditional DNN training and validates our analysis.\n",
                "链接": "https://arxiv.org/abs/2309.08859"
            },
            {
                "文章ID": "110634",
                "标题": "AlpaCare:Instruction-tuned Large Language Models for Medical Application",
                "作者": " Xinlu Zhang,  Chenxin Tian,  Xianjun Yang,  Lichang Chen,  Zekun Li,  Linda Ruth Petzold",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) have demonstrated significant enhancements in\ninstruction-following abilities through instruction tuning, achieving notable\nperformances across various tasks. Previous research has focused on fine-tuning\nmedical domain-specific LLMs using an extensive array of medical-specific data,\nincorporating millions of pieces of biomedical literature to augment their\nmedical capabilities. However, existing medical instruction-tuned LLMs have\nbeen constrained by the limited scope of tasks and instructions available,\nrestricting the efficacy of instruction tuning and adversely affecting\nperformance in the general domain. In this paper, we fine-tune LLaMA-series\nmodels using 52k diverse, machine-generated, medical instruction-following\ndata, MedInstruct-52k, resulting in the model AlpaCare. Comprehensive\nexperimental results on both general and medical-specific domain free-form\ninstruction evaluations showcase AlpaCare's strong medical proficiency and\ngeneralizability compared to previous instruction-tuned models in both medical\nand general domains. We provide public access to our MedInstruct-52k dataset\nand a clinician-crafted free-form instruction test set, MedInstruct-test, along\nwith our codebase, to foster further research and development. Our project page\nis available at https://github.com/XZhang97666/AlpaCare.\n",
                "链接": "https://arxiv.org/abs/2310.14558"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "117493",
                "标题": "Transfer Attacks and Defenses for Large Language Models on Coding Tasks",
                "作者": " Chi Zhang,  Zifan Wang,  Ravi Mangal,  Matt Fredrikson,  Limin Jia,  Corina Pasareanu",
                "发布日期": "2023-11-23",
                "摘要": "  Modern large language models (LLMs), such as ChatGPT, have demonstrated\nimpressive capabilities for coding tasks including writing and reasoning about\ncode. They improve upon previous neural network models of code, such as\ncode2seq or seq2seq, that already demonstrated competitive results when\nperforming tasks such as code summarization and identifying code\nvulnerabilities. However, these previous code models were shown vulnerable to\nadversarial examples, i.e. small syntactic perturbations that do not change the\nprogram's semantics, such as the inclusion of \"dead code\" through false\nconditions or the addition of inconsequential print statements, designed to\n\"fool\" the models. LLMs can also be vulnerable to the same adversarial\nperturbations but a detailed study on this concern has been lacking so far. In\nthis paper we aim to investigate the effect of adversarial perturbations on\ncoding tasks with LLMs. In particular, we study the transferability of\nadversarial examples, generated through white-box attacks on smaller code\nmodels, to LLMs. Furthermore, to make the LLMs more robust against such\nadversaries without incurring the cost of retraining, we propose prompt-based\ndefenses that involve modifying the prompt to include additional information\nsuch as examples of adversarially perturbed code and explicit instructions for\nreversing adversarial perturbations. Our experiments show that adversarial\nexamples obtained with a smaller code model are indeed transferable, weakening\nthe LLMs' performance. The proposed defenses show promise in improving the\nmodel's resilience, paving the way to more robust defensive solutions for LLMs\nin code-related applications.\n",
                "链接": "https://arxiv.org/abs/2311.13445"
            },
            {
                "文章ID": "36610",
                "标题": "Task-Agnostic Learning to Accomplish New Tasks",
                "作者": " Xianqi Zhang,  Xingtao Wang,  Xu Liu,  Wenrui Wang,  Xiaopeng Fan,  Debin Zhao",
                "发布日期": "2023-02-17",
                "摘要": "  Reinforcement Learning (RL) and Imitation Learning (IL) have made great\nprogress in robotic control in recent years. However, these methods show\nobvious deterioration for new tasks that need to be completed through new\ncombinations of actions. RL methods heavily rely on reward functions that\ncannot generalize well for new tasks, while IL methods are limited by expert\ndemonstrations which do not cover new tasks. In contrast, humans can easily\ncomplete these tasks with the fragmented knowledge learned from task-agnostic\nexperience. Inspired by this observation, this paper proposes a task-agnostic\nlearning method (TAL for short) that can learn fragmented knowledge from\ntask-agnostic data to accomplish new tasks. TAL consists of four stages. First,\nthe task-agnostic exploration is performed to collect data from interactions\nwith the environment. The collected data is organized via a knowledge graph.\nCompared with the previous sequential structure, the knowledge graph\nrepresentation is more compact and fits better for environment exploration.\nSecond, an action feature extractor is proposed and trained using the collected\nknowledge graph data for task-agnostic fragmented knowledge learning. Third, a\ncandidate action generator is designed, which applies the action feature\nextractor on a new task to generate multiple candidate action sets. Finally, an\naction proposal is designed to produce the probabilities for actions in a new\ntask according to the environmental information. The probabilities are then\nused to select actions to be executed from multiple candidate action sets to\nform the plan. Experiments on a virtual indoor scene show that the proposed\nmethod outperforms the state-of-the-art offline RL method: CQL by 35.28% and\nthe IL method: BC by 22.22%.\n",
                "链接": "https://arxiv.org/abs/2209.04100"
            },
            {
                "文章ID": "110744",
                "标题": "ALCUNA: Large Language Models Meet New Knowledge",
                "作者": " Xunjian Yin,  Baizhou Huang,  Xiaojun Wan",
                "发布日期": "2023-10-24",
                "摘要": "  With the rapid development of NLP, large-scale language models (LLMs) excel\nin various tasks across multiple domains now. However, existing benchmarks may\nnot adequately measure these models' capabilities, especially when faced with\nnew knowledge. In this paper, we address the lack of benchmarks to evaluate\nLLMs' ability to handle new knowledge, an important and challenging aspect in\nthe rapidly evolving world. We propose an approach called KnowGen that\ngenerates new knowledge by altering existing entity attributes and\nrelationships, resulting in artificial entities that are distinct from\nreal-world entities. With KnowGen, we introduce a benchmark named ALCUNA to\nassess LLMs' abilities in knowledge understanding, differentiation, and\nassociation. We benchmark several LLMs, reveals that their performance in face\nof new knowledge is not satisfactory, particularly in reasoning between new and\ninternal knowledge. We also explore the impact of entity similarity on the\nmodel's understanding of entity knowledge and the influence of contextual\nentities. We appeal to the need for caution when using LLMs in new scenarios or\nwith new knowledge, and hope that our benchmarks can help drive the development\nof LLMs in face of new knowledge.\n",
                "链接": "https://arxiv.org/abs/2310.14820"
            },
            {
                "文章ID": "114645",
                "标题": "Characterizing Large Language Models as Rationalizers of\n  Knowledge-intensive Tasks",
                "作者": " Aditi Mishra,  Sajjadur Rahman,  Hannah Kim,  Kushan Mitra,  Estevam Hruschka",
                "发布日期": "2023-11-10",
                "摘要": "  Large language models (LLMs) are proficient at generating fluent text with\nminimal task-specific supervision. Yet, their ability to provide well-grounded\nrationalizations for knowledge-intensive tasks remains under-explored. Such\ntasks, like commonsense multiple-choice questions, require rationales based on\nworld knowledge to support predictions and refute alternate options. We\nconsider the task of generating knowledge-guided rationalization in natural\nlanguage by using expert-written examples in a few-shot manner. Surprisingly,\ncrowd-workers preferred knowledge-grounded rationales over crowdsourced\nrationalizations, citing their factuality, sufficiency, and comprehensive\nrefutations. Although LLMs-generated rationales were preferable, further\nimprovements in conciseness and novelty are required. In another study, we show\nhow rationalization of incorrect model predictions erodes humans' trust in\nLLM-generated rationales. Motivated by these observations, we create a\ntwo-stage pipeline to review task predictions and eliminate potential incorrect\ndecisions before rationalization, enabling trustworthy rationale generation.\n",
                "链接": "https://arxiv.org/abs/2311.05085"
            },
            {
                "文章ID": "61947",
                "标题": "Large Language Models Fail on Trivial Alterations to Theory-of-Mind\n  Tasks",
                "作者": " Tomer Ullman",
                "发布日期": "2023-03-15",
                "摘要": "  Intuitive psychology is a pillar of common-sense reasoning. The replication\nof this reasoning in machine intelligence is an important stepping-stone on the\nway to human-like artificial intelligence. Several recent tasks and benchmarks\nfor examining this reasoning in Large-Large Models have focused in particular\non belief attribution in Theory-of-Mind tasks. These tasks have shown both\nsuccesses and failures. We consider in particular a recent purported success\ncase, and show that small variations that maintain the principles of ToM turn\nthe results on their head. We argue that in general, the zero-hypothesis for\nmodel evaluation in intuitive psychology should be skeptical, and that outlying\nfailure cases should outweigh average success rates. We also consider what\npossible future successes on Theory-of-Mind tasks by more powerful LLMs would\nmean for ToM tasks with people.\n",
                "链接": "https://arxiv.org/abs/2302.08399"
            },
            {
                "文章ID": "5760",
                "标题": "Knowledge Transfer from Large-scale Pretrained Language Models to\n  End-to-end Speech Recognizers",
                "作者": " Yotaro Kubo,  Shigeki Karita,  Michiel Bacchiani",
                "发布日期": "2022-02-17",
                "摘要": "  End-to-end speech recognition is a promising technology for enabling compact\nautomatic speech recognition (ASR) systems since it can unify the acoustic and\nlanguage model into a single neural network. However, as a drawback, training\nof end-to-end speech recognizers always requires transcribed utterances. Since\nend-to-end models are also known to be severely data hungry, this constraint is\ncrucial especially because obtaining transcribed utterances is costly and can\npossibly be impractical or impossible. This paper proposes a method for\nalleviating this issue by transferring knowledge from a language model neural\nnetwork that can be pretrained with text-only data. Specifically, this paper\nattempts to transfer semantic knowledge acquired in embedding vectors of\nlarge-scale language models. Since embedding vectors can be assumed as implicit\nrepresentations of linguistic information such as part-of-speech, intent, and\nso on, those are also expected to be useful modeling cues for ASR decoders.\nThis paper extends two types of ASR decoders, attention-based decoders and\nneural transducers, by modifying training loss functions to include embedding\nprediction terms. The proposed systems were shown to be effective for error\nrate reduction without incurring extra computational costs in the decoding\nphase.\n",
                "链接": "https://arxiv.org/abs/2202.07894"
            },
            {
                "文章ID": "32533",
                "标题": "On Transfer of Adversarial Robustness from Pretraining to Downstream\n  Tasks",
                "作者": " Laura Fee Nern,  Harsh Raj,  Maurice Georgi,  Yash Sharma",
                "发布日期": "2023-10-10",
                "摘要": "  As large-scale training regimes have gained popularity, the use of pretrained\nmodels for downstream tasks has become common practice in machine learning.\nWhile pretraining has been shown to enhance the performance of models in\npractice, the transfer of robustness properties from pretraining to downstream\ntasks remains poorly understood. In this study, we demonstrate that the\nrobustness of a linear predictor on downstream tasks can be constrained by the\nrobustness of its underlying representation, regardless of the protocol used\nfor pretraining. We prove (i) a bound on the loss that holds independent of any\ndownstream task, as well as (ii) a criterion for robust classification in\nparticular. We validate our theoretical results in practical applications, show\nhow our results can be used for calibrating expectations of downstream\nrobustness, and when our results are useful for optimal transfer learning.\nTaken together, our results offer an initial step towards characterizing the\nrequirements of the representation function for reliable post-adaptation\nperformance.\n",
                "链接": "https://arxiv.org/abs/2208.03835"
            },
            {
                "文章ID": "14047",
                "标题": "Does Robustness on ImageNet Transfer to Downstream Tasks?",
                "作者": " Yutaro Yamada,  Mayu Otani",
                "发布日期": "2022-04-11",
                "摘要": "  As clean ImageNet accuracy nears its ceiling, the research community is\nincreasingly more concerned about robust accuracy under distributional shifts.\nWhile a variety of methods have been proposed to robustify neural networks,\nthese techniques often target models trained on ImageNet classification. At the\nsame time, it is a common practice to use ImageNet pretrained backbones for\ndownstream tasks such as object detection, semantic segmentation, and image\nclassification from different domains. This raises a question: Can these robust\nimage classifiers transfer robustness to downstream tasks? For object detection\nand semantic segmentation, we find that a vanilla Swin Transformer, a variant\nof Vision Transformer tailored for dense prediction tasks, transfers robustness\nbetter than Convolutional Neural Networks that are trained to be robust to the\ncorrupted version of ImageNet. For CIFAR10 classification, we find that models\nthat are robustified for ImageNet do not retain robustness when fully\nfine-tuned. These findings suggest that current robustification techniques tend\nto emphasize ImageNet evaluations. Moreover, network architecture is a strong\nsource of robustness when we consider transfer learning.\n",
                "链接": "https://arxiv.org/abs/2204.03934"
            },
            {
                "文章ID": "108971",
                "标题": "Bootstrap Your Own Skills: Learning to Solve New Tasks with Large\n  Language Model Guidance",
                "作者": " Jesse Zhang,  Jiahui Zhang,  Karl Pertsch,  Ziyi Liu,  Xiang Ren,  Minsuk Chang,  Shao-Hua Sun,  Joseph J. Lim",
                "发布日期": "2023-10-18",
                "摘要": "  We propose BOSS, an approach that automatically learns to solve new\nlong-horizon, complex, and meaningful tasks by growing a learned skill library\nwith minimal supervision. Prior work in reinforcement learning require expert\nsupervision, in the form of demonstrations or rich reward functions, to learn\nlong-horizon tasks. Instead, our approach BOSS (BOotStrapping your own Skills)\nlearns to accomplish new tasks by performing \"skill bootstrapping,\" where an\nagent with a set of primitive skills interacts with the environment to practice\nnew skills without receiving reward feedback for tasks outside of the initial\nskill set. This bootstrapping phase is guided by large language models (LLMs)\nthat inform the agent of meaningful skills to chain together. Through this\nprocess, BOSS builds a wide range of complex and useful behaviors from a basic\nset of primitive skills. We demonstrate through experiments in realistic\nhousehold environments that agents trained with our LLM-guided bootstrapping\nprocedure outperform those trained with naive bootstrapping as well as prior\nunsupervised skill acquisition methods on zero-shot execution of unseen,\nlong-horizon tasks in new environments. Website at clvrai.com/boss.\n",
                "链接": "https://arxiv.org/abs/2310.10021"
            },
            {
                "文章ID": "41595",
                "标题": "Knowledge Distillation Transfer Sets and their Impact on Downstream NLU\n  Tasks",
                "作者": " Charith Peris,  Lizhen Tan,  Thomas Gueudre,  Turan Gojayev,  Pan Wei,  Gokmen Oz",
                "发布日期": "2022-10-19",
                "摘要": "  Teacher-student knowledge distillation is a popular technique for compressing\ntoday's prevailing large language models into manageable sizes that fit\nlow-latency downstream applications. Both the teacher and the choice of\ntransfer set used for distillation are crucial ingredients in creating a high\nquality student. Yet, the generic corpora used to pretrain the teacher and the\ncorpora associated with the downstream target domain are often significantly\ndifferent, which raises a natural question: should the student be distilled\nover the generic corpora, so as to learn from high-quality teacher predictions,\nor over the downstream task corpora to align with finetuning? Our study\ninvestigates this trade-off using Domain Classification (DC) and Intent\nClassification/Named Entity Recognition (ICNER) as downstream tasks. We distill\nseveral multilingual students from a larger multilingual LM with varying\nproportions of generic and task-specific datasets, and report their performance\nafter finetuning on DC and ICNER. We observe significant improvements across\ntasks and test sets when only task-specific corpora is used. We also report on\nhow the impact of adding task-specific data to the transfer set correlates with\nthe similarity between generic and task-specific data. Our results clearly\nindicate that, while distillation from a generic LM benefits downstream tasks,\nstudents learn better using target domain data even if it comes at the price of\nnoisier teacher predictions. In other words, target domain data still trumps\nteacher knowledge.\n",
                "链接": "https://arxiv.org/abs/2210.04834"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "114592",
                "标题": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
                "作者": " James Boyko,  Joseph Cohen,  Nathan Fox,  Maria Han Veiga,  Jennifer I-Hsiu Li,  Jing Liu,  Bernardo Modenesi,  Andreas H. Rauch,  Kenneth N. Reid,  Soumi Tribedi,  Anastasia Visheratina,  Xin Xie",
                "发布日期": "2023-11-10",
                "摘要": "  In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.\n",
                "链接": "https://arxiv.org/abs/2311.04929"
            },
            {
                "文章ID": "117074",
                "标题": "ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for\n  Interdisciplinary Science",
                "作者": " Sai Munikoti,  Anurag Acharya,  Sridevi Wagle,  Sameera Horawalavithana",
                "发布日期": "2023-11-22",
                "摘要": "  Large language models record impressive performance on many natural language\nprocessing tasks. However, their knowledge capacity is limited to the\npretraining corpus. Retrieval augmentation offers an effective solution by\nretrieving context from external knowledge sources to complement the language\nmodel. However, existing retrieval augmentation techniques ignore the\nstructural relationships between these documents. Furthermore, retrieval models\nare not explored much in scientific tasks, especially in regard to the\nfaithfulness of retrieved documents. In this paper, we propose a novel\nstructure-aware retrieval augmented language model that accommodates document\nstructure during retrieval augmentation. We create a heterogeneous document\ngraph capturing multiple types of relationships (e.g., citation, co-authorship,\netc.) that connect documents from more than 15 scientific disciplines (e.g.,\nPhysics, Medicine, Chemistry, etc.). We train a graph neural network on the\ncurated document graph to act as a structural encoder for the corresponding\npassages retrieved during the model pretraining. Particularly, along with text\nembeddings of the retrieved passages, we obtain structural embeddings of the\ndocuments (passages) and fuse them together before feeding them to the language\nmodel. We evaluate our model extensively on various scientific benchmarks that\ninclude science question-answering and scientific document classification\ntasks. Experimental results demonstrate that structure-aware retrieval improves\nretrieving more coherent, faithful and contextually relevant passages, while\nshowing a comparable performance in the overall accuracy.\n",
                "链接": "https://arxiv.org/abs/2311.12289"
            },
            {
                "文章ID": "39387",
                "标题": "Hierarchical MixUp Multi-label Classification with Imbalanced\n  Interdisciplinary Research Proposals",
                "作者": " Meng Xiao,  Min Wu,  Ziyue Qiao,  Zhiyuan Ning,  Yi Du,  Yanjie Fu,  Yuanchun Zhou",
                "发布日期": "2023-06-29",
                "摘要": "  Funding agencies are largely relied on a topic matching between domain\nexperts and research proposals to assign proposal reviewers. As proposals are\nincreasingly interdisciplinary, it is challenging to profile the\ninterdisciplinary nature of a proposal, and, thereafter, find expert reviewers\nwith an appropriate set of expertise. An essential step in solving this\nchallenge is to accurately model and classify the interdisciplinary labels of a\nproposal. Existing methodological and application-related literature, such as\ntextual classification and proposal classification, are insufficient in jointly\naddressing the three key unique issues introduced by interdisciplinary proposal\ndata: 1) the hierarchical structure of discipline labels of a proposal from\ncoarse-grain to fine-grain, e.g., from information science to AI to\nfundamentals of AI. 2) the heterogeneous semantics of various main textual\nparts that play different roles in a proposal; 3) the number of proposals is\nimbalanced between non-interdisciplinary and interdisciplinary research. Can we\nsimultaneously address the three issues in understanding the proposal's\ninterdisciplinary nature? In response to this question, we propose a\nhierarchical mixup multiple-label classification framework, which we called\nH-MixUp. H-MixUp leverages a transformer-based semantic information extractor\nand a GCN-based interdisciplinary knowledge extractor for the first and second\nissues. H-MixUp develops a fused training method of Wold-level MixUp,\nWord-level CutMix, Manifold MixUp, and Document-level MixUp to address the\nthird issue.\n",
                "链接": "https://arxiv.org/abs/2209.13912"
            },
            {
                "文章ID": "79552",
                "标题": "A Study of Generative Large Language Model for Medical Research and\n  Healthcare",
                "作者": " Cheng Peng,  Xi Yang,  Aokun Chen,  Kaleb E Smith,  Nima PourNejatian,  Anthony B Costa,  Cheryl Martin,  Mona G Flores,  Ying Zhang,  Tanja Magoc,  Gloria Lipori,  Duane A Mitchell,  Naykky S Ospina,  Mustafa M Ahmed,  William R Hogan,  Elizabeth A Shenkman,  Yi Guo,  Jiang Bian,  Yonghui Wu",
                "发布日期": "2023-11-20",
                "摘要": "  There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.\n",
                "链接": "https://arxiv.org/abs/2305.13523"
            },
            {
                "文章ID": "98470",
                "标题": "SciEval: A Multi-Level Large Language Model Evaluation Benchmark for\n  Scientific Research",
                "作者": " Liangtai Sun,  Yang Han,  Zihan Zhao,  Da Ma,  Zhennan Shen,  Baocai Chen,  Lu Chen,  Kai Yu",
                "发布日期": "2023-08-28",
                "摘要": "  Recently, there has been growing interest in using Large Language Models\n(LLMs) for scientific research. Numerous benchmarks have been proposed to\nevaluate the ability of LLMs for scientific research. However, current\nbenchmarks are mostly based on pre-collected objective questions. This design\nsuffers from data leakage problem and lacks the evaluation of subjective Q/A\nability. In this paper, we propose SciEval, a comprehensive and\nmulti-disciplinary evaluation benchmark to address these issues. Based on\nBloom's taxonomy, SciEval covers four dimensions to systematically evaluate\nscientific research ability. In particular, we design a \"dynamic\" subset based\non scientific principles to prevent evaluation from potential data leakage.\nBoth objective and subjective questions are included in SciEval. These\ncharacteristics make SciEval a more effective benchmark for scientific research\nability evaluation of LLMs. Comprehensive experiments on most advanced LLMs\nshow that, although GPT-4 achieves SOTA performance compared to other LLMs,\nthere is still substantial room for improvement, especially for dynamic\nquestions. The data and codes are now publicly available.\n",
                "链接": "https://arxiv.org/abs/2308.13149"
            },
            {
                "文章ID": "106494",
                "标题": "Benchmarking Large Language Models As AI Research Agents",
                "作者": " Qian Huang,  Jian Vora,  Percy Liang,  Jure Leskovec",
                "发布日期": "2023-10-06",
                "摘要": "  Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.\n",
                "链接": "https://arxiv.org/abs/2310.03302"
            },
            {
                "文章ID": "88595",
                "标题": "Interdisciplinary Methods in Computational Creativity: How Human\n  Variables Shape Human-Inspired AI Research",
                "作者": " Nadia M. Ady,  Faun Rice",
                "发布日期": "2023-06-30",
                "摘要": "  The word creativity originally described a concept from human psychology, but\nin the realm of computational creativity (CC), it has become much more. The\nquestion of what creativity means when it is part of a computational system\nmight be considered core to CC. Pinning down the meaning of creativity, and\nconcepts like it, becomes salient when researchers port concepts from human\npsychology to computation, a widespread practice extending beyond CC into\nartificial intelligence (AI). Yet, the human processes shaping human-inspired\ncomputational systems have been little investigated. In this paper, we question\nwhich human literatures (social sciences, psychology, neuroscience) enter AI\nscholarship and how they are translated at the port of entry. This study is\nbased on 22 in-depth, semi-structured interviews, primarily with human-inspired\nAI researchers, half of whom focus on creativity as a major research area. This\npaper focuses on findings most relevant to CC. We suggest that which human\nliterature enters AI bears greater scrutiny because ideas may become\ndisconnected from context in their home discipline. Accordingly, we recommend\nthat CC researchers document the decisions and context of their practices,\nparticularly those practices formalizing human concepts for machines.\nPublishing reflexive commentary on human elements in CC and AI would provide a\nuseful record and permit greater dialogue with other disciplines.\n",
                "链接": "https://arxiv.org/abs/2306.17070"
            },
            {
                "文章ID": "83258",
                "标题": "A Quantitative Review on Language Model Efficiency Research",
                "作者": " Meng Jiang,  Hy Dang,  Lingbo Tong",
                "发布日期": "2023-06-06",
                "摘要": "  Language models (LMs) are being scaled and becoming powerful. Improving their\nefficiency is one of the core research topics in neural information processing\nsystems. Tay et al. (2022) provided a comprehensive overview of efficient\nTransformers that have become an indispensable staple in the field of NLP.\nHowever, in the section of \"On Evaluation\", they left an open question \"which\nfundamental efficient Transformer one should consider,\" answered by \"still a\nmystery\" because \"many research papers select their own benchmarks.\"\nUnfortunately, there was not quantitative analysis about the performances of\nTransformers on any benchmarks. Moreover, state space models (SSMs) have\ndemonstrated their abilities of modeling long-range sequences with\nnon-attention mechanisms, which were not discussed in the prior review. This\narticle makes a meta analysis on the results from a set of papers on efficient\nTransformers as well as those on SSMs. It provides a quantitative review on LM\nefficiency research and gives suggestions for future research.\n",
                "链接": "https://arxiv.org/abs/2306.01768"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            },
            {
                "文章ID": "109237",
                "标题": "Large Language Model Unlearning",
                "作者": " Yuanshun Yao,  Xiaojun Xu,  Yang Liu",
                "发布日期": "2023-10-18",
                "摘要": "  We study how to perform unlearning, i.e. forgetting undesirable\n(mis)behaviors, on large language models (LLMs). We show at least three\nscenarios of aligning LLMs with human preferences can benefit from unlearning:\n(1) removing harmful responses, (2) erasing copyright-protected content as\nrequested, and (3) eliminating hallucinations. Unlearning, as an alignment\ntechnique, has three advantages. (1) It only requires negative (e.g. harmful)\nexamples, which are much easier and cheaper to collect (e.g. via red teaming or\nuser reporting) than positive (e.g. helpful and often human-written) examples\nrequired in RLHF (RL from human feedback). (2) It is computationally efficient.\n(3) It is especially effective when we know which training samples cause the\nmisbehavior. To the best of our knowledge, our work is among the first to\nexplore LLM unlearning. We are also among the first to formulate the settings,\ngoals, and evaluations in LLM unlearning. We show that if practitioners only\nhave limited resources, and therefore the priority is to stop generating\nundesirable outputs rather than to try to generate desirable outputs,\nunlearning is particularly appealing. Despite only having negative samples, our\nablation study shows that unlearning can still achieve better alignment\nperformance than RLHF with just 2% of its computational time.\n",
                "链接": "https://arxiv.org/abs/2310.10683"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "78623",
                "标题": "Towards Human-AI Collaborative Urban Science Research Enabled by\n  Pre-trained Large Language Models",
                "作者": " Jiayi Fu,  Haoying Han,  Xing Su,  Chao Fan",
                "发布日期": "2023-05-22",
                "摘要": "  Pre-trained large language models (PLMs) have the potential to support urban\nscience research through content creation, information extraction, assisted\nprogramming, text classification, and other technical advances. In this\nresearch, we explored the opportunities, challenges, and prospects of PLMs in\nurban science research. Specifically, we discussed potential applications of\nPLMs to urban institution, urban space, urban information, and citizen\nbehaviors research through seven examples using ChatGPT. We also examined the\nchallenges of PLMs in urban science research from both technical and social\nperspectives. The prospects of the application of PLMs in urban science\nresearch were then proposed. We found that PLMs can effectively aid in\nunderstanding complex concepts in urban science, facilitate urban spatial form\nidentification, assist in disaster monitoring, and sense public sentiment. At\nthe same time, however, the applications of PLMs in urban science research face\nevident threats, such as technical limitations, security, privacy, and social\nbias. The development of fundamental models based on domain knowledge and\nhuman-AI collaboration may help improve PLMs to support urban science research\nin future.\n",
                "链接": "https://arxiv.org/abs/2305.11418"
            },
            {
                "文章ID": "48817",
                "标题": "Galactica: A Large Language Model for Science",
                "作者": " Ross Taylor,  Marcin Kardas,  Guillem Cucurull,  Thomas Scialom,  Anthony Hartshorn,  Elvis Saravia,  Andrew Poulton,  Viktor Kerkez,  Robert Stojnic",
                "发布日期": "2022-11-17",
                "摘要": "  Information overload is a major obstacle to scientific progress. The\nexplosive growth in scientific literature and data has made it ever harder to\ndiscover useful insights in a large mass of information. Today scientific\nknowledge is accessed through search engines, but they are unable to organize\nscientific knowledge alone. In this paper we introduce Galactica: a large\nlanguage model that can store, combine and reason about scientific knowledge.\nWe train on a large scientific corpus of papers, reference material, knowledge\nbases and many other sources. We outperform existing models on a range of\nscientific tasks. On technical knowledge probes such as LaTeX equations,\nGalactica outperforms the latest GPT-3 by 68.2% versus 49.0%. Galactica also\nperforms well on reasoning, outperforming Chinchilla on mathematical MMLU by\n41.3% to 35.7%, and PaLM 540B on MATH with a score of 20.4% versus 8.8%. It\nalso sets a new state-of-the-art on downstream tasks such as PubMedQA and\nMedMCQA dev of 77.6% and 52.9%. And despite not being trained on a general\ncorpus, Galactica outperforms BLOOM and OPT-175B on BIG-bench. We believe these\nresults demonstrate the potential for language models as a new interface for\nscience. We open source the model for the benefit of the scientific community.\n",
                "链接": "https://arxiv.org/abs/2211.09085"
            },
            {
                "文章ID": "75961",
                "标题": "Can Large Language Models Transform Computational Social Science?",
                "作者": " Caleb Ziems,  William Held,  Omar Shaikh,  Jiaao Chen,  Zhehao Zhang,  Diyi Yang",
                "发布日期": "2023-12-08",
                "摘要": "  Large Language Models (LLMs) are capable of successfully performing many\nlanguage processing tasks zero-shot (without training data). If zero-shot LLMs\ncan also reliably classify and explain social phenomena like persuasiveness and\npolitical ideology, then LLMs could augment the Computational Social Science\n(CSS) pipeline in important ways. This work provides a road map for using LLMs\nas CSS tools. Towards this end, we contribute a set of prompting best practices\nand an extensive evaluation pipeline to measure the zero-shot performance of 13\nlanguage models on 25 representative English CSS benchmarks. On taxonomic\nlabeling tasks (classification), LLMs fail to outperform the best fine-tuned\nmodels but still achieve fair levels of agreement with humans. On free-form\ncoding tasks (generation), LLMs produce explanations that often exceed the\nquality of crowdworkers' gold references. We conclude that the performance of\ntoday's LLMs can augment the CSS research pipeline in two ways: (1) serving as\nzero-shot data annotators on human annotation teams, and (2) bootstrapping\nchallenging creative generation tasks (e.g., explaining the underlying\nattributes of a text). In summary, LLMs are posed to meaningfully participate\nin} social science analysis in partnership with humans.\n",
                "链接": "https://arxiv.org/abs/2305.03514"
            },
            {
                "文章ID": "106494",
                "标题": "Benchmarking Large Language Models As AI Research Agents",
                "作者": " Qian Huang,  Jian Vora,  Percy Liang,  Jure Leskovec",
                "发布日期": "2023-10-06",
                "摘要": "  Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.\n",
                "链接": "https://arxiv.org/abs/2310.03302"
            },
            {
                "文章ID": "71835",
                "标题": "Emergent autonomous scientific research capabilities of large language\n  models",
                "作者": " Daniil A. Boiko,  Robert MacKnight,  Gabe Gomes",
                "发布日期": "2023-04-12",
                "摘要": "  Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n",
                "链接": "https://arxiv.org/abs/2304.05332"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            },
            {
                "文章ID": "36178",
                "标题": "YouTube and Science: Models for Research Impact",
                "作者": " Abdul Rahman Shaikh,  Hamed Alhoori,  Maoyuan Sun",
                "发布日期": "2022-09-07",
                "摘要": "  Video communication has been rapidly increasing over the past decade, with\nYouTube providing a medium where users can post, discover, share, and react to\nvideos. There has also been an increase in the number of videos citing research\narticles, especially since it has become relatively commonplace for academic\nconferences to require video submissions. However, the relationship between\nresearch articles and YouTube videos is not clear, and the purpose of the\npresent paper is to address this issue. We created new datasets using YouTube\nvideos and mentions of research articles on various online platforms. We found\nthat most of the articles cited in the videos are related to medicine and\nbiochemistry. We analyzed these datasets through statistical techniques and\nvisualization, and built machine learning models to predict (1) whether a\nresearch article is cited in videos, (2) whether a research article cited in a\nvideo achieves a level of popularity, and (3) whether a video citing a research\narticle becomes popular. The best models achieved F1 scores between 80% and\n94%. According to our results, research articles mentioned in more tweets and\nnews coverage have a higher chance of receiving video citations. We also found\nthat video views are important for predicting citations and increasing research\narticles' popularity and public engagement with science.\n",
                "链接": "https://arxiv.org/abs/2209.02380"
            },
            {
                "文章ID": "106021",
                "标题": "OceanGPT: A Large Language Model for Ocean Science Tasks",
                "作者": " Zhen Bi,  Ningyu Zhang,  Yida Xue,  Yixin Ou,  Daxiong Ji,  Guozhou Zheng,  Huajun Chen",
                "发布日期": "2023-10-26",
                "摘要": "  Ocean science, which delves into the oceans that are reservoirs of life and\nbiodiversity, is of great significance given that oceans cover over 70% of our\nplanet's surface. Recently, advances in Large Language Models (LLMs) have\ntransformed the paradigm in science. Despite the success in other domains,\ncurrent LLMs often fall short in catering to the needs of domain experts like\noceanographers, and the potential of LLMs for ocean science is under-explored.\nThe intrinsic reason may be the immense and intricate nature of ocean data as\nwell as the necessity for higher granularity and richness in knowledge. To\nalleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean\ndomain, which is expert in various ocean science tasks. We propose DoInstruct,\na novel framework to automatically obtain a large volume of ocean domain\ninstruction data, which generates instructions based on multi-agent\ncollaboration. Additionally, we construct the first oceanography benchmark,\nOceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though\ncomprehensive experiments, OceanGPT not only shows a higher level of knowledge\nexpertise for oceans science tasks but also gains preliminary embodied\nintelligence capabilities in ocean technology. Codes, data and checkpoints will\nsoon be available at https://github.com/zjunlp/KnowLM.\n",
                "链接": "https://arxiv.org/abs/2310.02031"
            },
            {
                "文章ID": "89660",
                "标题": "What Should Data Science Education Do with Large Language Models?",
                "作者": " Xinming Tu,  James Zou,  Weijie J. Su,  Linjun Zhang",
                "发布日期": "2023-07-10",
                "摘要": "  The rapid advances of large language models (LLMs), such as ChatGPT, are\nrevolutionizing data science and statistics. These state-of-the-art tools can\nstreamline complex processes. As a result, it reshapes the role of data\nscientists. We argue that LLMs are transforming the responsibilities of data\nscientists, shifting their focus from hands-on coding, data-wrangling and\nconducting standard analyses to assessing and managing analyses performed by\nthese automated AIs. This evolution of roles is reminiscent of the transition\nfrom a software engineer to a product manager. We illustrate this transition\nwith concrete data science case studies using LLMs in this paper. These\ndevelopments necessitate a meaningful evolution in data science education.\nPedagogy must now place greater emphasis on cultivating diverse skillsets among\nstudents, such as LLM-informed creativity, critical thinking, AI-guided\nprogramming. LLMs can also play a significant role in the classroom as\ninteractive teaching and learning tools, contributing to personalized\neducation. This paper discusses the opportunities, resources and open\nchallenges for each of these directions. As with any transformative technology,\nintegrating LLMs into education calls for careful consideration. While LLMs can\nperform repetitive tasks efficiently, it's crucial to remember that their role\nis to supplement human intelligence and creativity, not to replace it.\nTherefore, the new era of data science education should balance the benefits of\nLLMs while fostering complementary human expertise and innovations. In\nconclusion, the rise of LLMs heralds a transformative period for data science\nand its education. This paper seeks to shed light on the emerging trends,\npotential opportunities, and challenges accompanying this paradigm shift,\nhoping to spark further discourse and investigation into this exciting,\nuncharted territory.\n",
                "链接": "https://arxiv.org/abs/2307.02792"
            },
            {
                "文章ID": "98630",
                "标题": "DARWIN Series: Domain Specific Large Language Models for Natural Science",
                "作者": " Tong Xie,  Yuwei Wan,  Wei Huang,  Zhenyu Yin,  Yixuan Liu,  Shaozhou Wang,  Qingyuan Linghu,  Chunyu Kit,  Clara Grazian,  Wenjie Zhang,  Imran Razzak,  Bram Hoex",
                "发布日期": "2023-08-29",
                "摘要": "  Emerging tools bring forth fresh approaches to work, and the field of natural\nscience is no different. In natural science, traditional manual, serial, and\nlabour-intensive work is being augmented by automated, parallel, and iterative\nprocesses driven by artificial intelligence-based experimental automation and\nmore. To add new capabilities in natural science, enabling the acceleration and\nenrichment of automation of the discovery process, we present DARWIN, a series\nof tailored LLMs for natural science, mainly in physics, chemistry, and\nmaterial science. This series relies on open-source LLM, incorporating\nstructured and unstructured scientific knowledge from public datasets and\nliterature. We fine-tuned the models using over 60,000 instruction data points,\nemphasizing factual correctness. During the fine-tuning, we introduce the\nScientific Instruction Generation (SIG) model, automating instruction\ngeneration from scientific texts. This eliminates the need for manual\nextraction or domain-specific knowledge graphs and efficiently injects\nscientific knowledge into the model. We also explore multi-task training\nstrategies, revealing interconnections between scientific tasks. DARWIN series\nnot only achieves state-of-the-art results on various scientific tasks but also\ndiminishes reliance on closed-source AI models. Our research showcases the\nability of LLM in the scientific domain, with the overarching goal of fostering\nprosperity within the broader AI for science community.\n",
                "链接": "https://arxiv.org/abs/2308.13565"
            }
        ]
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "24473",
                "标题": "An analysis of retracted papers in Computer Science",
                "作者": " Martin Shepperd,  Leila Yousefi",
                "发布日期": "2023-07-19",
                "摘要": "  Context: The retraction of research papers, for whatever reason, is a growing\nphenomenon. However, although retracted paper information is publicly available\nvia publishers, it is somewhat distributed and inconsistent. Objective: The aim\nis to assess: (i) the extent and nature of retracted research in Computer\nScience (CS) (ii) the post-retraction citation behaviour of retracted works and\n(iii) the potential impact on systematic reviews and mapping studies. Method:\nWe analyse the Retraction Watch database and take citation information from the\nWeb of Science and Google scholar. Results: We find that of the 33,955 entries\nin the Retraction watch database (16 May 2022), 2,816 are classified as CS,\ni.e., approximately 8.3%. For CS, 56% of retracted papers, provide little or no\ninformation as to the reasons. This contrasts with 26% for other disciplines.\nThere is also a remarkable disparity between different publishers, a tendency\nfor multiple versions of a retracted paper over and above the Version of Record\n(VoR), and for new citations long after a paper is officially retracted.\nConclusions: Unfortunately retraction seems to be a sufficiently common outcome\nfor a scientific paper that we as a research community need to take it more\nseriously, e.g., standardising procedures and taxonomies across publishers and\nthe provision of appropriate research tools. Finally, we recommend particular\ncaution when undertaking secondary analyses and meta-analyses which are at risk\nof becoming contaminated by these problem primary studies.\n",
                "链接": "https://arxiv.org/abs/2206.06706"
            },
            {
                "文章ID": "24067",
                "标题": "SAIBench: Benchmarking AI for Science",
                "作者": " Yatao Li,  Jianfeng Zhan",
                "发布日期": "2022-06-14",
                "摘要": "  Scientific research communities are embracing AI-based solutions to target\ntractable scientific tasks and improve research workflows. However, the\ndevelopment and evaluation of such solutions are scattered across multiple\ndisciplines. We formalize the problem of scientific AI benchmarking, and\npropose a system called SAIBench in the hope of unifying the efforts and\nenabling low-friction on-boarding of new disciplines. The system approaches\nthis goal with SAIL, a domain-specific language to decouple research problems,\nAI models, ranking criteria, and software/hardware configuration into reusable\nmodules. We show that this approach is flexible and can adapt to problems, AI\nmodels, and evaluation methods defined in different perspectives. The project\nhomepage is https://www.computercouncil.org/SAIBench\n",
                "链接": "https://arxiv.org/abs/2206.05418"
            },
            {
                "文章ID": "65341",
                "标题": "AI for Science: An Emerging Agenda",
                "作者": " Philipp Berens,  Kyle Cranmer,  Neil D. Lawrence,  Ulrike von Luxburg,  Jessica Montgomery",
                "发布日期": "2023-03-09",
                "摘要": "  This report documents the programme and the outcomes of Dagstuhl Seminar\n22382 \"Machine Learning for Science: Bridging Data-Driven and Mechanistic\nModelling\". Today's scientific challenges are characterised by complexity.\nInterconnected natural, technological, and human systems are influenced by\nforces acting across time- and spatial-scales, resulting in complex\ninteractions and emergent behaviours. Understanding these phenomena -- and\nleveraging scientific advances to deliver innovative solutions to improve\nsociety's health, wealth, and well-being -- requires new ways of analysing\ncomplex systems. The transformative potential of AI stems from its widespread\napplicability across disciplines, and will only be achieved through integration\nacross research domains. AI for science is a rendezvous point. It brings\ntogether expertise from $\\mathrm{AI}$ and application domains; combines\nmodelling knowledge with engineering know-how; and relies on collaboration\nacross disciplines and between humans and machines. Alongside technical\nadvances, the next wave of progress in the field will come from building a\ncommunity of machine learning researchers, domain experts, citizen scientists,\nand engineers working together to design and deploy effective AI tools. This\nreport summarises the discussions from the seminar and provides a roadmap to\nsuggest how different communities can collaborate to deliver a new wave of\nprogress in AI and its application for scientific discovery.\n",
                "链接": "https://arxiv.org/abs/2303.04217"
            },
            {
                "文章ID": "19147",
                "标题": "AI and Citizen Science for Serendipity",
                "作者": " Marisa Ponti,  Anastasia Skarpeti,  Bruno Kestemont",
                "发布日期": "2022-05-17",
                "摘要": "  It has been argued that introducing AI to creative practices destroys\nspontaneity, intuition and serendipity. However, the design of systems that\nleverage complex interactions between citizen scientists (members of the public\nengaged in research tasks) and computational AI methods have the potential to\nfacilitate creative exploration and chance encounters. Drawing from theories\nand literature about serendipity and computation, this article points to three\ninterrelated aspects that support the emergence of serendipity in hybrid\ncitizen science systems: the task environment; the characteristics of citizen\nscientists; and anomalies and errors.\n",
                "链接": "https://arxiv.org/abs/2205.06890"
            },
            {
                "文章ID": "91376",
                "标题": "Towards eXplainable AI for Mobility Data Science",
                "作者": " Anahid Jalali,  Anita Graser,  Clemens Heistracher",
                "发布日期": "2023-09-08",
                "摘要": "  This paper presents our ongoing work towards XAI for Mobility Data Science\napplications, focusing on explainable models that can learn from dense\ntrajectory data, such as GPS tracks of vehicles and vessels using temporal\ngraph neural networks (GNNs) and counterfactuals. We review the existing GeoXAI\nstudies, argue the need for comprehensible explanations with human-centered\napproaches, and outline a research path toward XAI for Mobility Data Science.\n",
                "链接": "https://arxiv.org/abs/2307.08461"
            },
            {
                "文章ID": "110050",
                "标题": "AI for Mathematics: A Cognitive Science Perspective",
                "作者": " Cedegao E. Zhang,  Katherine M. Collins,  Adrian Weller,  Joshua B. Tenenbaum",
                "发布日期": "2023-10-23",
                "摘要": "  Mathematics is one of the most powerful conceptual systems developed and used\nby the human species. Dreams of automated mathematicians have a storied history\nin artificial intelligence (AI). Rapid progress in AI, particularly propelled\nby advances in large language models (LLMs), has sparked renewed, widespread\ninterest in building such systems. In this work, we reflect on these goals from\na \\textit{cognitive science} perspective. We call attention to several\nclassical and ongoing research directions from cognitive science, which we\nbelieve are valuable for AI practitioners to consider when seeking to build\ntruly human (or superhuman)-level mathematical systems. We close with open\ndiscussions and questions that we believe necessitate a multi-disciplinary\nperspective -- cognitive scientists working in tandem with AI researchers and\nmathematicians -- as we move toward better mathematical AI systems which not\nonly help us push the frontier of the mathematics, but also offer glimpses into\nhow we as humans are even capable of such great cognitive feats.\n",
                "链接": "https://arxiv.org/abs/2310.13021"
            },
            {
                "文章ID": "70444",
                "标题": "Interpretable Symbolic Regression for Data Science: Analysis of the 2022\n  Competition",
                "作者": " F. O. de Franca,  M. Virgolin,  M. Kommenda,  M. S. Majumder,  M. Cranmer,  G. Espada,  L. Ingelse,  A. Fonseca,  M. Landajuela,  B. Petersen,  R. Glatt,  N. Mundhenk,  C. S. Lee,  J. D. Hochhalter,  D. L. Randall,  P. Kamienny,  H. Zhang,  G. Dick,  A. Simon,  B. Burlacu,  Jaan Kasak,  Meera Machado,  Casper Wilstrup,  W. G. La Cava",
                "发布日期": "2023-07-04",
                "摘要": "  Symbolic regression searches for analytic expressions that accurately\ndescribe studied phenomena. The main attraction of this approach is that it\nreturns an interpretable model that can be insightful to users. Historically,\nthe majority of algorithms for symbolic regression have been based on\nevolutionary algorithms. However, there has been a recent surge of new\nproposals that instead utilize approaches such as enumeration algorithms, mixed\nlinear integer programming, neural networks, and Bayesian optimization. In\norder to assess how well these new approaches behave on a set of common\nchallenges often faced in real-world data, we hosted a competition at the 2022\nGenetic and Evolutionary Computation Conference consisting of different\nsynthetic and real-world datasets which were blind to entrants. For the\nreal-world track, we assessed interpretability in a realistic way by using a\ndomain expert to judge the trustworthiness of candidate models.We present an\nin-depth analysis of the results obtained in this competition, discuss current\nchallenges of symbolic regression algorithms and highlight possible\nimprovements for future competitions.\n",
                "链接": "https://arxiv.org/abs/2304.01117"
            },
            {
                "文章ID": "121615",
                "标题": "Team-related Features in Code Review Prediction Models",
                "作者": " Eduardo Witter,  Ingrid Nunes,  Dietmar Jannach",
                "发布日期": "2023-12-12",
                "摘要": "  Modern Code Review (MCR) is an informal tool-assisted quality assurance\npractice. It relies on the asynchronous communication among the authors of code\nchanges and reviewers, who are developers that provide feedback. However, from\ncandidate developers, some are able to provide better feedback than others\ngiven a particular context. The selection of reviewers is thus an important\ntask, which can benefit from automated support. Many approaches have been\nproposed in this direction, using for example data from code review\nrepositories to recommend reviewers. In this paper, we propose the use of\nteam-related features to improve the performance of predictions that are\nhelpful to build code reviewer recommenders, with our target predictions being\nthe identification of reviewers that would participate in a review and the\nprovided amount of feedback. We evaluate the prediction power of these\nfeatures, which are related to code ownership, workload, and team relationship.\nThis evaluation was done by carefully addressing challenges imposed by the MCR\ndomain, such as temporal aspects of the dataset and unbalanced classes.\nMoreover, given that it is currently unknown how much past data is needed for\nbuilding MCR prediction models with acceptable performance, we explore the\namount of past data used to build prediction models. Our results show that,\nindividually, features related to code ownership have the best prediction\npower. However, based on feature selection, we conclude that all proposed\nfeatures together with lines of code can make the best predictions for both\nreviewer participation and amount of feedback. Regarding the amount of past\ndata, the timeframes of 3, 6, 9, and 12 months of data produce similar results.\nTherefore, models can be trained considering short timeframes, thus reducing\nthe computational costs with negligible impact in the prediction performance\n...\n",
                "链接": "https://arxiv.org/abs/2312.06244"
            },
            {
                "文章ID": "81656",
                "标题": "The impact and applications of ChatGPT: a systematic review of\n  literature reviews",
                "作者": " Irene S. Gabashvili",
                "发布日期": "2023-05-30",
                "摘要": "  The conversational artificial-intelligence (AI) technology ChatGPT has become\none of the most widely used natural language processing tools. With thousands\nof published papers demonstrating its applications across various industries\nand fields, ChatGPT has sparked significant interest in the research community.\nReviews of primary data have also begun to emerge. An overview of the available\nevidence from multiple reviews and studies could provide further insights,\nminimize redundancy, and identify areas where further research is needed.\nObjective: To evaluate the existing reviews and literature related to ChatGPT's\napplications and its potential impact on different fields by conducting a\nsystematic review of reviews and bibliometric analysis of primary literature.\nMethods: PubMed, EuropePMC, Dimensions AI, medRxiv, bioRxiv, arXiv, and Google\nScholar were searched for ChatGPT-related publications from 2022 to 4/30/2023.\nStudies including secondary data related to the application of ChatGPT were\nconsidered. Reporting and risk of bias assesment was performed using PRISMA\nguidelines. Results: A total of 305 unique records with potential relevance to\nthe review were identified from a pool of over 2,000 original articles. After\nmulti-step screening process, 11 reviews were selected, consisting of 9 reviews\nspecifically focused on ChatGPT and 2 reviews on broader AI topics that also\nincluded discussions on ChatGPT. We also conducted bibliometric analysis of\nprimary data. Conclusions: While AI has the potential to revolutionize various\nindustries, further interdisciplinary research, customized integrations, and\nethical innovation are necessary to address existing concerns and ensure its\nresponsible use. Protocol Registration: PROSPERO registration no.\nCRD42023417336, DOI 10.17605/OSF.IO/87U6Q.\n",
                "链接": "https://arxiv.org/abs/2305.18086"
            },
            {
                "文章ID": "111553",
                "标题": "An Integrative Survey on Mental Health Conversational Agents to Bridge\n  Computer Science and Medical Perspectives",
                "作者": " Young Min Cho,  Sunny Rai,  Lyle Ungar,  João Sedoc,  Sharath Chandra Guntuku",
                "发布日期": "2023-12-01",
                "摘要": "  Mental health conversational agents (a.k.a. chatbots) are widely studied for\ntheir potential to offer accessible support to those experiencing mental health\nchallenges. Previous surveys on the topic primarily consider papers published\nin either computer science or medicine, leading to a divide in understanding\nand hindering the sharing of beneficial knowledge between both domains. To\nbridge this gap, we conduct a comprehensive literature review using the PRISMA\nframework, reviewing 534 papers published in both computer science and\nmedicine. Our systematic review reveals 136 key papers on building mental\nhealth-related conversational agents with diverse characteristics of modeling\nand experimental design techniques. We find that computer science papers focus\non LLM techniques and evaluating response quality using automated metrics with\nlittle attention to the application while medical papers use rule-based\nconversational agents and outcome metrics to measure the health outcomes of\nparticipants. Based on our findings on transparency, ethics, and cultural\nheterogeneity in this review, we provide a few recommendations to help bridge\nthe disciplinary divide and enable the cross-disciplinary development of mental\nhealth conversational agents.\n",
                "链接": "https://arxiv.org/abs/2310.17017"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "121198",
                "标题": "A Review of Cooperation in Multi-agent Learning",
                "作者": " Yali Du,  Joel Z. Leibo,  Usman Islam,  Richard Willis,  Peter Sunehag",
                "发布日期": "2023-12-11",
                "摘要": "  Cooperation in multi-agent learning (MAL) is a topic at the intersection of\nnumerous disciplines, including game theory, economics, social sciences, and\nevolutionary biology. Research in this area aims to understand both how agents\ncan coordinate effectively when goals are aligned and how they may cooperate in\nsettings where gains from working together are possible but possibilities for\nconflict abound. In this paper we provide an overview of the fundamental\nconcepts, problem settings and algorithms of multi-agent learning. This\nencompasses reinforcement learning, multi-agent sequential decision-making,\nchallenges associated with multi-agent cooperation, and a comprehensive review\nof recent progress, along with an evaluation of relevant metrics. Finally we\ndiscuss open challenges in the field with the aim of inspiring new avenues for\nresearch.\n",
                "链接": "https://arxiv.org/abs/2312.05162"
            },
            {
                "文章ID": "110807",
                "标题": "LLM-Based Agent Society Investigation: Collaboration and Confrontation\n  in Avalon Gameplay",
                "作者": " Yihuai Lan,  Zhiqiang Hu,  Lei Wang,  Yang Wang,  Deheng Ye,  Peilin Zhao,  Ee-Peng Lim,  Hui Xiong,  Hao Wang",
                "发布日期": "2023-10-24",
                "摘要": "  This paper aims to investigate the open research problem of uncovering the\nsocial behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a\nrepresentative communication game, as the environment and use system prompts to\nguide LLM agents to play the game. While previous studies have conducted\npreliminary investigations into gameplay with LLM agents, there lacks research\non their social behaviors. In this paper, we present a novel framework designed\nto seamlessly adapt to Avalon gameplay. The core of our proposed framework is a\nmulti-agent system that enables efficient communication and interaction among\nagents. We evaluate the performance of our framework based on metrics from two\nperspectives: winning the game and analyzing the social behaviors of LLM\nagents. Our results demonstrate the effectiveness of our framework in\ngenerating adaptive and intelligent agents and highlight the potential of\nLLM-based agents in addressing the challenges associated with dynamic social\nenvironment interaction. By analyzing the social behaviors of LLM agents from\nthe aspects of both collaboration and confrontation, we provide insights into\nthe research and applications of this domain.\n",
                "链接": "https://arxiv.org/abs/2310.14985"
            },
            {
                "文章ID": "111094",
                "标题": "Agent-based models of social behaviour and communication in evacuations:\n  A systematic review",
                "作者": " Anne Templeton,  Hui Xie,  Steve Gwynne,  Aoife Hunt,  Pete Thompson,  Gerta Köster",
                "发布日期": "2023-10-25",
                "摘要": "  Most modern agent-based evacuation models involve interactions between\nevacuees. However, the assumed reasons for interactions and portrayal of them\nmay be overly simple. Research from social psychology suggests that people\ninteract and communicate with one another when evacuating and evacuee response\nis impacted by the way information is communicated. Thus, we conducted a\nsystematic review of agent-based evacuation models to identify 1) how social\ninteractions and communication approaches between agents are simulated, and 2)\nwhat key variables related to evacuation are addressed in these models. We\nsearched Web of Science and ScienceDirect to identify articles that simulated\ninformation exchange between agents during evacuations, and social behaviour\nduring evacuations. From the final 70 included articles, we categorised eight\ntypes of social interaction that increased in social complexity from collision\navoidance to social influence based on strength of social connections with\nother agents. In the 17 models which simulated communication, we categorised\nfour ways that agents communicate information: spatially through information\ntrails or radii around agents, via social networks and via external\ncommunication. Finally, the variables either manipulated or measured in the\nmodels were categorised into the following groups: environmental condition,\npersonal attributes of the agents, procedure, and source of information. We\ndiscuss promising directions for agent-based evacuation models to capture the\neffects of communication and group dynamics on evacuee behaviour. Moreover, we\ndemonstrate how communication and group dynamics may impact the variables\ncommonly used in agent-based evacuation models.\n",
                "链接": "https://arxiv.org/abs/2310.15761"
            },
            {
                "文章ID": "96320",
                "标题": "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate",
                "作者": " Chi-Min Chan,  Weize Chen,  Yusheng Su,  Jianxuan Yu,  Wei Xue,  Shanghang Zhang,  Jie Fu,  Zhiyuan Liu",
                "发布日期": "2023-08-15",
                "摘要": "  Text evaluation has historically posed significant challenges, often\ndemanding substantial labor and time cost. With the emergence of large language\nmodels (LLMs), researchers have explored LLMs' potential as alternatives for\nhuman evaluation. While these single-agent-based approaches show promise,\nexperimental results suggest that further advancements are needed to bridge the\ngap between their current effectiveness and human-level evaluation quality.\nRecognizing that best practices of human evaluation processes often involve\nmultiple human annotators collaborating in the evaluation, we resort to a\nmulti-agent debate framework, moving beyond single-agent prompting strategies.\nThe multi-agent-based approach enables a group of LLMs to synergize with an\narray of intelligent counterparts, harnessing their distinct capabilities and\nexpertise to enhance efficiency and effectiveness in handling intricate tasks.\nIn this paper, we construct a multi-agent referee team called ChatEval to\nautonomously discuss and evaluate the quality of generated responses from\ndifferent models on open-ended questions and traditional natural language\ngeneration (NLG) tasks. Our analysis shows that ChatEval transcends mere\ntextual scoring, offering a human-mimicking evaluation process for reliable\nassessments. Our code is available at https://github.com/chanchimin/ChatEval.\n",
                "链接": "https://arxiv.org/abs/2308.07201"
            },
            {
                "文章ID": "83868",
                "标题": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM\n  Agents",
                "作者": " Yashar Talebirad,  Amirhossein Nadiri",
                "发布日期": "2023-06-07",
                "摘要": "  In this paper, we present a novel framework for enhancing the capabilities of\nlarge language models (LLMs) by leveraging the power of multi-agent systems.\nOur framework introduces a collaborative environment where multiple intelligent\nagent components, each with distinctive attributes and roles, work together to\nhandle complex tasks more efficiently and effectively. We demonstrate the\npracticality and versatility of our framework through case studies in\nartificial general intelligence (AGI), specifically focusing on the Auto-GPT\nand BabyAGI models. We also examine the \"Gorilla\" model, which integrates\nexternal APIs into the LLM. Our framework addresses limitations and challenges\nsuch as looping issues, security risks, scalability, system evaluation, and\nethical considerations. By modeling various domains such as courtroom\nsimulations and software development scenarios, we showcase the potential\napplications and benefits of our proposed multi-agent system. Our framework\nprovides an avenue for advancing the capabilities and performance of LLMs\nthrough collaboration and knowledge exchange among intelligent agents.\n",
                "链接": "https://arxiv.org/abs/2306.03314"
            },
            {
                "文章ID": "109035",
                "标题": "Character-LLM: A Trainable Agent for Role-Playing",
                "作者": " Yunfan Shao,  Linyang Li,  Junqi Dai,  Xipeng Qiu",
                "发布日期": "2023-12-15",
                "摘要": "  Large language models (LLMs) can be used to serve as agents to simulate human\nbehaviors, given the powerful ability to understand human instructions and\nprovide high-quality generated texts. Such ability stimulates us to wonder\nwhether LLMs can simulate a person in a higher form than simple human\nbehaviors. Therefore, we aim to train an agent with the profile, experience,\nand emotional states of a specific person instead of using limited prompts to\ninstruct ChatGPT API. In this work, we introduce Character-LLM that teach LLMs\nto act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar,\netc. Our method focuses on editing profiles as experiences of a certain\ncharacter and training models to be personal simulacra with these experiences.\nTo assess the effectiveness of our approach, we build a test playground that\ninterviews trained agents and evaluates whether the agents \\textit{memorize}\ntheir characters and experiences. Experimental results show interesting\nobservations that help build future simulacra of humankind.\n",
                "链接": "https://arxiv.org/abs/2310.10158"
            },
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "118366",
                "标题": "BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical\n  Knowledge Graph Insights",
                "作者": " François Remy,  Kris Demuynck,  Thomas Demeester",
                "发布日期": "2023-11-28",
                "摘要": "  In this study, we investigate the potential of Large Language Models to\ncomplement biomedical knowledge graphs in the training of semantic models for\nthe biomedical and clinical domains. Drawing on the wealth of the UMLS\nknowledge graph and harnessing cutting-edge Large Language Models, we propose a\nnew state-of-the-art approach for obtaining high-fidelity representations of\nbiomedical concepts and sentences, consisting of three steps: an improved\ncontrastive learning phase, a novel self-distillation phase, and a weight\naveraging phase. Through rigorous evaluations via the extensive BioLORD testing\nsuite and diverse downstream tasks, we demonstrate consistent and substantial\nperformance improvements over the previous state of the art (e.g. +2pts on\nMedSTS, +2.5pts on MedNLI-S, +6.1pts on EHR-Rel-B). Besides our new\nstate-of-the-art biomedical model for English, we also distill and release a\nmultilingual model compatible with 50+ languages and finetuned on 7 European\nlanguages. Many clinical pipelines can benefit from our latest models. Our new\nmultilingual model enables a range of languages to benefit from our\nadvancements in biomedical semantic representation learning, opening a new\navenue for bioinformatics researchers around the world. As a result, we hope to\nsee BioLORD-2023 becoming a precious tool for future biomedical applications.\n",
                "链接": "https://arxiv.org/abs/2311.16075"
            },
            {
                "文章ID": "119636",
                "标题": "Deciphering Digital Detectives: Understanding LLM Behaviors and\n  Capabilities in Multi-Agent Mystery Games",
                "作者": " Dekun Wu,  Haochen Shi,  Zhiyuan Sun,  Bang Liu",
                "发布日期": "2023-12-04",
                "摘要": "  In this study, we explore the application of Large Language Models (LLMs) in\n\"Jubensha\" (Chinese murder mystery role-playing games), a novel area in\nAI-driven gaming. We introduce the first Chinese dataset specifically for\nJubensha, including character scripts and game rules, to foster AI agent\ndevelopment in this complex narrative environment. Our work also presents a\nunique multi-agent interaction framework using LLMs, allowing AI agents to\nautonomously engage in the game, enhancing the dynamics of Jubensha gameplay.\nTo evaluate these AI agents, we developed specialized methods targeting their\nmastery of case information and reasoning skills. Furthermore, we incorporated\nthe latest advancements in in-context learning to improve the agents'\nperformance in critical aspects like information gathering, murderer detection,\nand logical reasoning. The experimental results validate the effectiveness of\nour proposed methods. This work aims to offer a fresh perspective on\nunderstanding LLM capabilities and establish a new benchmark for evaluating\nlarge language model-based agents to researchers in the field.\n",
                "链接": "https://arxiv.org/abs/2312.00746"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "68991",
                "标题": "Joint fMRI Decoding and Encoding with Latent Embedding Alignment",
                "作者": " Xuelin Qian,  Yikai Wang,  Yanwei Fu,  Xinwei Sun,  Xiangyang Xue,  Jianfeng Feng",
                "发布日期": "2023-06-06",
                "摘要": "  The connection between brain activity and corresponding visual stimuli is\ncrucial in comprehending the human brain. While deep generative models have\nexhibited advancement in recovering brain recordings by generating images\nconditioned on fMRI signals, accomplishing high-quality generation with\nconsistent semantics continues to pose challenges. Moreover, the prediction of\nbrain activity from visual stimuli remains a formidable undertaking. In this\npaper, we introduce a unified framework that addresses both fMRI decoding and\nencoding. Commencing with the establishment of two latent spaces capable of\nrepresenting and reconstructing fMRI signals and visual images, respectively,\nwe proceed to align the fMRI signals and visual images within the latent space,\nthereby enabling a bidirectional transformation between the two domains. Our\nLatent Embedding Alignment (LEA) model concurrently recovers visual stimuli\nfrom fMRI signals and predicts brain activity from images within a unified\nframework. The performance of LEA surpasses that of existing methods on\nmultiple benchmark fMRI decoding and encoding datasets. By integrating fMRI\ndecoding and encoding, LEA offers a comprehensive solution for modeling the\nintricate relationship between brain activity and visual stimuli.\n",
                "链接": "https://arxiv.org/abs/2303.14730"
            },
            {
                "文章ID": "90598",
                "标题": "Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM\n  Decoding",
                "作者": " Seongjun Yang,  Gibbeum Lee,  Jaewoong Cho,  Dimitris Papailiopoulos,  Kangwook Lee",
                "发布日期": "2023-07-13",
                "摘要": "  This paper presents \"Predictive Pipelined Decoding (PPD),\" an approach that\nspeeds up greedy decoding in Large Language Models (LLMs) while maintaining the\nexact same output as the original decoding. Unlike conventional strategies, PPD\nemploys additional compute resources to parallelize the initiation of\nsubsequent token decoding during the current token decoding. This innovative\nmethod reduces decoding latency and reshapes the understanding of trade-offs in\nLLM decoding strategies. We have developed a theoretical framework that allows\nus to analyze the trade-off between computation and latency. Using this\nframework, we can analytically estimate the potential reduction in latency\nassociated with our proposed method, achieved through the assessment of the\nmatch rate, represented as p_correct. The results demonstrate that the use of\nextra computational resources has the potential to accelerate LLM greedy\ndecoding.\n",
                "链接": "https://arxiv.org/abs/2307.05908"
            },
            {
                "文章ID": "91982",
                "标题": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding\n  (Survey)",
                "作者": " Subba Reddy Oota,  Manish Gupta,  Raju S. Bapi,  Gael Jobard,  Frederic Alexandre,  Xavier Hinaut",
                "发布日期": "2023-07-21",
                "摘要": "  How does the brain represent different modes of information? Can we design a\nsystem that automatically understands what the user is thinking? Such questions\ncan be answered by studying brain recordings like functional magnetic resonance\nimaging (fMRI). As a first step, the neuroscience community has contributed\nseveral large cognitive neuroscience datasets related to passive\nreading/listening/viewing of concept words, narratives, pictures and movies.\nEncoding and decoding models using these datasets have also been proposed in\nthe past two decades. These models serve as additional tools for basic research\nin cognitive science and neuroscience. Encoding models aim at generating fMRI\nbrain representations given a stimulus automatically. They have several\npractical applications in evaluating and diagnosing neurological conditions and\nthus also help design therapies for brain damage. Decoding models solve the\ninverse problem of reconstructing the stimuli given the fMRI. They are useful\nfor designing brain-machine or brain-computer interfaces. Inspired by the\neffectiveness of deep learning models for natural language processing, computer\nvision, and speech, recently several neural encoding and decoding models have\nbeen proposed. In this survey, we will first discuss popular representations of\nlanguage, vision and speech stimuli, and present a summary of neuroscience\ndatasets. Further, we will review popular deep learning based encoding and\ndecoding architectures and note their benefits and limitations. Finally, we\nwill conclude with a brief summary and discussion about future trends. Given\nthe large amount of recently published work in the `computational cognitive\nneuroscience' community, we believe that this survey nicely organizes the\nplethora of work and presents it as a coherent story.\n",
                "链接": "https://arxiv.org/abs/2307.10246"
            },
            {
                "文章ID": "107624",
                "标题": "Encoding and Decoding Narratives: Datafication and Alternative Access\n  Models for Audiovisual Archives",
                "作者": " Yuchen Yang",
                "发布日期": "2023-10-11",
                "摘要": "  Situated in the intersection of audiovisual archives, computational methods,\nand immersive interactions, this work probes the increasingly important\naccessibility issues from a two-fold approach. Firstly, the work proposes an\nontological data model to handle complex descriptors (metadata, feature\nvectors, etc.) with regard to user interactions. Secondly, this work examines\ntext-to-video retrieval from an implementation perspective by proposing a\nclassifier-enhanced workflow to deal with complex and hybrid queries and a\ntraining data augmentation workflow to improve performance. This work serves as\nthe foundation for experimenting with novel public-facing access models to\nlarge audiovisual archives\n",
                "链接": "https://arxiv.org/abs/2310.06309"
            },
            {
                "文章ID": "5326",
                "标题": "Hierarchical Point Cloud Encoding and Decoding with Lightweight\n  Self-Attention based Model",
                "作者": " En Yen Puang,  Hao Zhang,  Hongyuan Zhu,  Wei Jing",
                "发布日期": "2022-03-16",
                "摘要": "  In this paper we present SA-CNN, a hierarchical and lightweight\nself-attention based encoding and decoding architecture for representation\nlearning of point cloud data. The proposed SA-CNN introduces convolution and\ntransposed convolution stacks to capture and generate contextual information\namong unordered 3D points. Following conventional hierarchical pipeline, the\nencoding process extracts feature in local-to-global manner, while the decoding\nprocess generates feature and point cloud in coarse-to-fine, multi-resolution\nstages. We demonstrate that SA-CNN is capable of a wide range of applications,\nnamely classification, part segmentation, reconstruction, shape retrieval, and\nunsupervised classification. While achieving the state-of-the-art or comparable\nperformance in the benchmarks, SA-CNN maintains its model complexity several\norder of magnitude lower than the others. In term of qualitative results, we\nvisualize the multi-stage point cloud reconstructions and latent walks on rigid\nobjects as well as deformable non-rigid human and robot models.\n",
                "链接": "https://arxiv.org/abs/2202.06407"
            },
            {
                "文章ID": "41529",
                "标题": "EmbryosFormer: Deformable Transformer and Collaborative\n  Encoding-Decoding for Embryos Stage Development Classification",
                "作者": " Tien-Phat Nguyen,  Trong-Thang Pham,  Tri Nguyen,  Hieu Le,  Dung Nguyen,  Hau Lam,  Phong Nguyen,  Jennifer Fowler,  Minh-Triet Tran,  Ngan Le",
                "发布日期": "2022-10-11",
                "摘要": "  The timing of cell divisions in early embryos during the In-Vitro\nFertilization (IVF) process is a key predictor of embryo viability. However,\nobserving cell divisions in Time-Lapse Monitoring (TLM) is a time-consuming\nprocess and highly depends on experts. In this paper, we propose EmbryosFormer,\na computational model to automatically detect and classify cell divisions from\noriginal time-lapse images. Our proposed network is designed as an\nencoder-decoder deformable transformer with collaborative heads. The\ntransformer contracting path predicts per-image labels and is optimized by a\nclassification head. The transformer expanding path models the temporal\ncoherency between embryo images to ensure monotonic non-decreasing constraint\nand is optimized by a segmentation head. Both contracting and expanding paths\nare synergetically learned by a collaboration head. We have benchmarked our\nproposed EmbryosFormer on two datasets: a public dataset with mouse embryos\nwith 8-cell stage and an in-house dataset with human embryos with 4-cell stage.\nSource code: https://github.com/UARK-AICV/Embryos.\n",
                "链接": "https://arxiv.org/abs/2210.04615"
            },
            {
                "文章ID": "15783",
                "标题": "Cross-view Brain Decoding",
                "作者": " Subba Reddy Oota,  Jashn Arora,  Manish Gupta,  Raju S. Bapi",
                "发布日期": "2022-04-21",
                "摘要": "  How the brain captures the meaning of linguistic stimuli across multiple\nviews is still a critical open question in neuroscience. Consider three\ndifferent views of the concept apartment: (1) picture (WP) presented with the\ntarget word label, (2) sentence (S) using the target word, and (3) word cloud\n(WC) containing the target word along with other semantically related words.\nUnlike previous efforts, which focus only on single view analysis, in this\npaper, we study the effectiveness of brain decoding in a zero-shot cross-view\nlearning setup. Further, we propose brain decoding in the novel context of\ncross-view-translation tasks like image captioning (IC), image tagging (IT),\nkeyword extraction (KE), and sentence formation (SF). Using extensive\nexperiments, we demonstrate that cross-view zero-shot brain decoding is\npractical leading to ~0.68 average pairwise accuracy across view pairs. Also,\nthe decoded representations are sufficiently detailed to enable high accuracy\nfor cross-view-translation tasks with following pairwise accuracy: IC (78.0),\nIT (83.0), KE (83.7) and SF (74.5). Analysis of the contribution of different\nbrain networks reveals exciting cognitive insights: (1) A high percentage of\nvisual voxels are involved in image captioning and image tagging tasks, and a\nhigh percentage of language voxels are involved in the sentence formation and\nkeyword extraction tasks. (2) Zero-shot accuracy of the model trained on S view\nand tested on WC view is better than same-view accuracy of the model trained\nand tested on WC view.\n",
                "链接": "https://arxiv.org/abs/2204.09564"
            },
            {
                "文章ID": "77552",
                "标题": "A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document\n  Summarization",
                "作者": " Chenhui Shen,  Liying Cheng,  Xuan-Phi Nguyen,  Yang You,  Lidong Bing",
                "发布日期": "2023-11-02",
                "摘要": "  Pre-trained language models (PLMs) have achieved outstanding achievements in\nabstractive single-document summarization (SDS). However, such benefits may not\nfully extend to multi-document summarization (MDS), where the handling of\ncross-document information is more complex. Previous works either design new\nMDS architectures or apply PLMs bluntly with concatenated source documents as a\nreformulated SDS task. While the former does not utilize previous pre-training\nefforts and may not generalize well across different domains, the latter may\nnot sufficiently attend to the intricate cross-document relationships unique to\nMDS tasks. Instead, we enforce hierarchy on both the encoder and decoder to\nbetter utilize a PLM to facilitate multi-document interactions for the MDS\ntask. Across 10 MDS benchmarks from various domains, our method outperforms or\nis competitive with the previous best models, including those with additional\nMDS pre-training or with more parameters. It outperforms its corresponding PLM\nbackbone by up to 3 Rouge-L and is favored by humans.\n",
                "链接": "https://arxiv.org/abs/2305.08503"
            },
            {
                "文章ID": "50069",
                "标题": "How do Authors' Perceptions of their Papers Compare with Co-authors'\n  Perceptions and Peer-review Decisions?",
                "作者": " Charvi Rastogi,  Ivan Stelmakh,  Alina Beygelzimer,  Yann N. Dauphin,  Percy Liang,  Jennifer Wortman Vaughan,  Zhenyu Xue, III Hal Daumé,  Emma Pierson,  Nihar B. Shah",
                "发布日期": "2022-11-24",
                "摘要": "  How do author perceptions match up to the outcomes of the peer-review process\nand perceptions of others? In a top-tier computer science conference (NeurIPS\n2021) with more than 23,000 submitting authors and 9,000 submitted papers, we\nsurvey the authors on three questions: (i) their predicted probability of\nacceptance for each of their papers, (ii) their perceived ranking of their own\npapers based on scientific contribution, and (iii) the change in their\nperception about their own papers after seeing the reviews. The salient results\nare: (1) Authors have roughly a three-fold overestimate of the acceptance\nprobability of their papers: The median prediction is 70% for an approximately\n25% acceptance rate. (2) Female authors exhibit a marginally higher\n(statistically significant) miscalibration than male authors; predictions of\nauthors invited to serve as meta-reviewers or reviewers are similarly\ncalibrated, but better than authors who were not invited to review. (3)\nAuthors' relative ranking of scientific contribution of two submissions they\nmade generally agree (93%) with their predicted acceptance probabilities, but\nthere is a notable 7% responses where authors think their better paper will\nface a worse outcome. (4) The author-provided rankings disagreed with the\npeer-review decisions about a third of the time; when co-authors ranked their\njointly authored papers, co-authors disagreed at a similar rate -- about a\nthird of the time. (5) At least 30% of respondents of both accepted and\nrejected papers said that their perception of their own paper improved after\nthe review process. The stakeholders in peer review should take these findings\ninto account in setting their expectations from peer review.\n",
                "链接": "https://arxiv.org/abs/2211.12966"
            },
            {
                "文章ID": "61341",
                "标题": "Render-and-Compare: Cross-View 6 DoF Localization from Noisy Prior",
                "作者": " Shen Yan,  Xiaoya Cheng,  Yuxiang Liu,  Juelin Zhu,  Rouwan Wu,  Yu Liu,  Maojun Zhang",
                "发布日期": "2023-02-14",
                "摘要": "  Despite the significant progress in 6-DoF visual localization, researchers\nare mostly driven by ground-level benchmarks. Compared with aerial oblique\nphotography, ground-level map collection lacks scalability and complete\ncoverage. In this work, we propose to go beyond the traditional ground-level\nsetting and exploit the cross-view localization from aerial to ground. We solve\nthis problem by formulating camera pose estimation as an iterative\nrender-and-compare pipeline and enhancing the robustness through augmenting\nseeds from noisy initial priors. As no public dataset exists for the studied\nproblem, we collect a new dataset that provides a variety of cross-view images\nfrom smartphones and drones and develop a semi-automatic system to acquire\nground-truth poses for query images. We benchmark our method as well as several\nstate-of-the-art baselines and demonstrate that our method outperforms other\napproaches by a large margin.\n",
                "链接": "https://arxiv.org/abs/2302.06287"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106837",
                "标题": "Language Agent Tree Search Unifies Reasoning Acting and Planning in\n  Language Models",
                "作者": " Andy Zhou,  Kai Yan,  Michal Shlapentokh-Rothman,  Haohan Wang,  Yu-Xiong Wang",
                "发布日期": "2023-12-06",
                "摘要": "  While large language models (LLMs) have demonstrated impressive performance\non a range of decision-making tasks, they rely on simple acting processes and\nfall short of broad deployment as autonomous agents. We introduce LATS\n(Language Agent Tree Search), a general framework that synergizes the\ncapabilities of LLMs in planning, acting, and reasoning. Drawing inspiration\nfrom Monte Carlo tree search in model-based reinforcement learning, LATS\nemploys LLMs as agents, value functions, and optimizers, repurposing their\nlatent strengths for enhanced decision-making. What is crucial in this method\nis the use of an environment for external feedback, which offers a more\ndeliberate and adaptive problem-solving mechanism that moves beyond the\nlimitations of existing techniques. Our experimental evaluation across diverse\ndomains, such as programming, HotPotQA, and WebShop, illustrates the\napplicability of LATS for both reasoning and acting. In particular, LATS\nachieves 94.4% for programming on HumanEval with GPT-4 and an average score of\n75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness\nand generality of our method.\n",
                "链接": "https://arxiv.org/abs/2310.04406"
            },
            {
                "文章ID": "109239",
                "标题": "Autonomous Tree-search Ability of Large Language Models",
                "作者": " Zheyu Zhang,  Zhuorui Ye,  Yikang Shen,  Chuang Gan",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.\n",
                "链接": "https://arxiv.org/abs/2310.10686"
            },
            {
                "文章ID": "102013",
                "标题": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "作者": " Shentong Mo,  Miao Xin",
                "发布日期": "2023-09-15",
                "摘要": "  While the recently introduced Tree of Thoughts (ToT) has heralded\nadvancements in allowing Large Language Models (LLMs) to reason through\nforesight and backtracking for global decision-making, it has overlooked the\ninherent local uncertainties in intermediate decision points or \"thoughts\".\nThese local uncertainties, intrinsic to LLMs given their potential for diverse\nresponses, remain a significant concern in the reasoning process. Addressing\nthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a\nreasoning framework tailored for LLMs. Our TouT effectively leverages Monte\nCarlo Dropout to quantify uncertainty scores associated with LLMs' diverse\nlocal responses at these intermediate steps. By marrying this local uncertainty\nquantification with global search algorithms, TouT enhances the model's\nprecision in response generation. We substantiate our approach with rigorous\nexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.\nThe empirical evidence underscores TouT's superiority over both ToT and\nchain-of-thought prompting methods.\n",
                "链接": "https://arxiv.org/abs/2309.07694"
            },
            {
                "文章ID": "35416",
                "标题": "Faithful Reasoning Using Large Language Models",
                "作者": " Antonia Creswell,  Murray Shanahan",
                "发布日期": "2022-08-31",
                "摘要": "  Although contemporary large language models (LMs) demonstrate impressive\nquestion-answering capabilities, their answers are typically the product of a\nsingle call to the model. This entails an unwelcome degree of opacity and\ncompromises performance, especially on problems that are inherently multi-step.\nTo address these limitations, we show how LMs can be made to perform faithful\nmulti-step reasoning via a process whose causal structure mirrors the\nunderlying logical structure of the problem. Our approach works by chaining\ntogether reasoning steps, where each step results from calls to two fine-tuned\nLMs, one for selection and one for inference, to produce a valid reasoning\ntrace. Our method carries out a beam search through the space of reasoning\ntraces to improve reasoning quality. We demonstrate the effectiveness of our\nmodel on multi-step logical deduction and scientific question-answering,\nshowing that it outperforms baselines on final answer accuracy, and generates\nhumanly interpretable reasoning traces whose validity can be checked by the\nuser.\n",
                "链接": "https://arxiv.org/abs/2208.14271"
            },
            {
                "文章ID": "53273",
                "标题": "Reinforcement Learning and Tree Search Methods for the Unit Commitment\n  Problem",
                "作者": " Patrick de Mars",
                "发布日期": "2022-12-13",
                "摘要": "  The unit commitment (UC) problem, which determines operating schedules of\ngeneration units to meet demand, is a fundamental task in power systems\noperation. Existing UC methods using mixed-integer programming are not\nwell-suited to highly stochastic systems. Approaches which more rigorously\naccount for uncertainty could yield large reductions in operating costs by\nreducing spinning reserve requirements; operating power stations at higher\nefficiencies; and integrating greater volumes of variable renewables. A\npromising approach to solving the UC problem is reinforcement learning (RL), a\nmethodology for optimal decision-making which has been used to conquer\nlong-standing grand challenges in artificial intelligence. This thesis explores\nthe application of RL to the UC problem and addresses challenges including\nrobustness under uncertainty; generalisability across multiple problem\ninstances; and scaling to larger power systems than previously studied. To\ntackle these issues, we develop guided tree search, a novel methodology\ncombining model-free RL and model-based planning. The UC problem is formalised\nas a Markov decision process and we develop an open-source environment based on\nreal data from Great Britain's power system to train RL agents. In problems of\nup to 100 generators, guided tree search is shown to be competitive with\ndeterministic UC methods, reducing operating costs by up to 1.4\\%. An advantage\nof RL is that the framework can be easily extended to incorporate\nconsiderations important to power systems operators such as robustness to\ngenerator failure, wind curtailment or carbon prices. When generator outages\nare considered, guided tree search saves over 2\\% in operating costs as\ncompared with methods using conventional $N-x$ reserve criteria.\n",
                "链接": "https://arxiv.org/abs/2212.06001"
            },
            {
                "文章ID": "97463",
                "标题": "Can Large Language Models Find And Fix Vulnerable Software?",
                "作者": " David Noever",
                "发布日期": "2023-08-22",
                "摘要": "  In this study, we evaluated the capability of Large Language Models (LLMs),\nparticularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing\ntheir performance against traditional static code analyzers like Snyk and\nFortify. Our analysis covered numerous repositories, including those from NASA\nand the Department of Defense. GPT-4 identified approximately four times the\nvulnerabilities than its counterparts. Furthermore, it provided viable fixes\nfor each vulnerability, demonstrating a low rate of false positives. Our tests\nencompassed 129 code samples across eight programming languages, revealing the\nhighest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to\na 90% reduction in vulnerabilities, requiring only an 11% increase in code\nlines. A critical insight was LLMs' ability to self-audit, suggesting fixes for\ntheir identified vulnerabilities and underscoring their precision. Future\nresearch should explore system-level vulnerabilities and integrate multiple\nstatic code analyzers for a holistic perspective on LLMs' potential.\n",
                "链接": "https://arxiv.org/abs/2308.10345"
            },
            {
                "文章ID": "103741",
                "标题": "Trusta: Reasoning about Assurance Cases with Formal Methods and Large\n  Language Models",
                "作者": " Zezhong Chen,  Yuxin Deng,  Wenjie Du",
                "发布日期": "2023-09-25",
                "摘要": "  Assurance cases can be used to argue for the safety of products in safety\nengineering. In safety-critical areas, the construction of assurance cases is\nindispensable. Trustworthiness Derivation Trees (TDTs) enhance assurance cases\nby incorporating formal methods, rendering it possible for automatic reasoning\nabout assurance cases. We present Trustworthiness Derivation Tree Analyzer\n(Trusta), a desktop application designed to automatically construct and verify\nTDTs. The tool has a built-in Prolog interpreter in its backend, and is\nsupported by the constraint solvers Z3 and MONA. Therefore, it can solve\nconstraints about logical formulas involving arithmetic, sets, Horn clauses\netc. Trusta also utilizes large language models to make the creation and\nevaluation of assurance cases more convenient. It allows for interactive human\nexamination and modification. We evaluated top language models like\nChatGPT-3.5, ChatGPT-4, and PaLM 2 for generating assurance cases. Our tests\nshowed a 50%-80% similarity between machine-generated and human-created cases.\nIn addition, Trusta can extract formal constraints from text in natural\nlanguages, facilitating an easier interpretation and validation process. This\nextraction is subject to human review and correction, blending the best of\nautomated efficiency with human insight. To our knowledge, this marks the first\nintegration of large language models in automatic creating and reasoning about\nassurance cases, bringing a novel approach to a traditional challenge. Through\nseveral industrial case studies, Trusta has proven to quickly find some subtle\nissues that are typically missed in manual inspection, demonstrating its\npractical value in enhancing the assurance case development process.\n",
                "链接": "https://arxiv.org/abs/2309.12941"
            },
            {
                "文章ID": "81190",
                "标题": "Levin Tree Search with Context Models",
                "作者": " Laurent Orseau,  Marcus Hutter,  Levi H. S. Lelis",
                "发布日期": "2023-06-28",
                "摘要": "  Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a\nprobability distribution over actions) and comes with a theoretical guarantee\non the number of expansions before reaching a goal node, depending on the\nquality of the policy. This guarantee can be used as a loss function, which we\ncall the LTS loss, to optimize neural networks representing the policy\n(LTS+NN). In this work we show that the neural network can be substituted with\nparameterized context models originating from the online compression literature\n(LTS+CM). We show that the LTS loss is convex under this new model, which\nallows for using standard convex optimization tools, and obtain convergence\nguarantees to the optimal parameters in an online setting for a given set of\nsolution trajectories -- guarantees that cannot be provided for neural\nnetworks. The new LTS+CM algorithm compares favorably against LTS+NN on several\nbenchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle\n(STP). The difference is particularly large on STP, where LTS+NN fails to solve\nmost of the test instances while LTS+CM solves each test instance in a fraction\nof a second. Furthermore, we show that LTS+CM is able to learn a policy that\nsolves the Rubik's cube in only a few hundred expansions, which considerably\nimproves upon previous machine learning techniques.\n",
                "链接": "https://arxiv.org/abs/2305.16945"
            },
            {
                "文章ID": "65723",
                "标题": "MathPrompter: Mathematical Reasoning using Large Language Models",
                "作者": " Shima Imani,  Liang Du,  Harsh Shrivastava",
                "发布日期": "2023-03-10",
                "摘要": "  Large Language Models (LLMs) have limited performance when solving arithmetic\nreasoning tasks and often provide incorrect answers. Unlike natural language\nunderstanding, math problems typically have a single correct answer, making the\ntask of generating accurate solutions more challenging for LLMs. To the best of\nour knowledge, we are not aware of any LLMs that indicate their level of\nconfidence in their responses which fuels a trust deficit in these models\nimpeding their adoption. To address this deficiency, we propose `MathPrompter',\na technique that improves performance of LLMs on arithmetic problems along with\nincreased reliance in the predictions. MathPrompter uses the Zero-shot\nchain-of-thought prompting technique to generate multiple Algebraic expressions\nor Python functions to solve the same math problem in different ways and\nthereby raise the confidence level in the output results. This is in contrast\nto other prompt based CoT methods, where there is no check on the validity of\nthe intermediate steps followed. Our technique improves over state-of-the-art\non the MultiArith dataset ($78.7\\%\\rightarrow92.5\\%$) evaluated using 175B\nparameter GPT-based LLM.\n",
                "链接": "https://arxiv.org/abs/2303.05398"
            },
            {
                "文章ID": "100689",
                "标题": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language\n  Models with Monte Carlo Tree Search Guided by Energy Function",
                "作者": " Haotian Xu",
                "发布日期": "2023-09-13",
                "摘要": "  Large language models (LLMs) demonstrate impressive language understanding\nand contextual learning abilities, making them suitable for natural language\nprocessing (NLP) tasks and complex mathematical reasoning. However, when\napplied to mathematical reasoning tasks, LLMs often struggle to generate\ncorrect reasoning steps and answers despite having high probabilities for the\nsolutions. To overcome this limitation and enhance the mathematical reasoning\ncapabilities of fine-tuned LLMs without additional fine-tuning steps, we\npropose a method that incorporates Monte Carlo Tree Search (MCTS) and a\nlightweight energy function to rank decision steps and enable immediate\nreaction and precise reasoning. Specifically, we re-formulate the fine-tuned\nLLMs into a Residual-based Energy Model (Residual-EBM) and employ noise\ncontrastive estimation to estimate the energy function's parameters. We then\nutilize MCTS with the energy function as a path verifier to search the output\nspace and evaluate the reasoning path. Through extensive experiments on two\nmathematical reasoning benchmarks, GSM8k and AQUA-RAT, we demonstrate the\nexceptional capabilities of our method, which significantly improves the pass@1\nmetric of the fine-tuned model without requiring additional fine-tuning or\nreinforcement learning with human feedback alignment.\n",
                "链接": "https://arxiv.org/abs/2309.03224"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "65704",
                "标题": "Extracting Accurate Materials Data from Research Papers with\n  Conversational Language Models and Prompt Engineering",
                "作者": " Maciej P. Polak,  Dane Morgan",
                "发布日期": "2023-06-28",
                "摘要": "  There has been a growing effort to replace hand extraction of data from\nresearch papers with automated data extraction based on natural language\nprocessing, language models, and recently, large language models (LLMs).\nAlthough these methods enable efficient extraction of data from large sets of\nresearch papers, they require a significant amount of up-front effort,\nexpertise, and coding. In this work we propose the ChatExtract method that can\nfully automate very accurate data extraction with minimal initial effort and\nbackground, using an advanced conversational LLM. ChatExtract consists of a set\nof engineered prompts applied to a conversational LLM that both identify\nsentences with data, extract that data, and assure the data's correctness\nthrough a series of follow-up questions. These follow-up questions largely\novercome known issues with LLMs providing factually inaccurate responses.\nChatExtract can be applied with any conversational LLMs and yields very high\nquality data extraction. In tests on materials data we find precision and\nrecall both close to 90% from the best conversational LLMs, like ChatGPT-4. We\ndemonstrate that the exceptional performance is enabled by the information\nretention in a conversational model combined with purposeful redundancy and\nintroducing uncertainty through follow-up prompts. These results suggest that\napproaches similar to ChatExtract, due to their simplicity, transferability,\nand accuracy are likely to become powerful tools for data extraction in the\nnear future. Finally, databases for critical cooling rates of metallic glasses\nand yield strengths of high entropy alloys are developed using ChatExtract.\n",
                "链接": "https://arxiv.org/abs/2303.05352"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "76839",
                "标题": "Privacy-Preserving Prompt Tuning for Large Language Model Services",
                "作者": " Yansong Li,  Zhixing Tan,  Yang Liu",
                "发布日期": "2023-05-11",
                "摘要": "  Prompt tuning provides an efficient way for users to customize Large Language\nModels (LLMs) with their private data in the emerging LLM service scenario.\nHowever, the sensitive nature of private data brings the need for privacy\npreservation in LLM service customization. Based on prompt tuning, we propose\nPrivacy-Preserving Prompt Tuning (RAPT), a framework that provides privacy\nguarantees for LLM services. \\textsc{rapt} adopts a local privacy setting,\nallowing users to privatize their data locally with local differential privacy.\nAs prompt tuning performs poorly when directly trained on privatized data, we\nintroduce a novel privatized token reconstruction task that is trained jointly\nwith the downstream task, allowing LLMs to learn better task-dependent\nrepresentations. Despite the simplicity of our framework, experiments show that\nRAPT achieves competitive performance across tasks while providing privacy\nguarantees against adversaries.\n",
                "链接": "https://arxiv.org/abs/2305.06212"
            },
            {
                "文章ID": "95315",
                "标题": "Large Language Model Prompt Chaining for Long Legal Document\n  Classification",
                "作者": " Dietrich Trautmann",
                "发布日期": "2023-08-09",
                "摘要": "  Prompting is used to guide or steer a language model in generating an\nappropriate response that is consistent with the desired outcome. Chaining is a\nstrategy used to decompose complex tasks into smaller, manageable components.\nIn this study, we utilize prompt chaining for extensive legal document\nclassification tasks, which present difficulties due to their intricate\ndomain-specific language and considerable length. Our approach begins with the\ncreation of a concise summary of the original document, followed by a semantic\nsearch for related exemplar texts and their corresponding annotations from a\ntraining corpus. Finally, we prompt for a label - based on the task - to\nassign, by leveraging the in-context learning from the few-shot prompt. We\ndemonstrate that through prompt chaining, we can not only enhance the\nperformance over zero-shot, but also surpass the micro-F1 score achieved by\nlarger models, such as ChatGPT zero-shot, using smaller models.\n",
                "链接": "https://arxiv.org/abs/2308.04138"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "97348",
                "标题": "PACE: Improving Prompt with Actor-Critic Editing for Large Language\n  Model",
                "作者": " Yihong Dong,  Kangcheng Luo,  Xue Jiang,  Zhi Jin,  Ge Li",
                "发布日期": "2023-08-22",
                "摘要": "  Large language models (LLMs) have showcased remarkable potential across\nvarious tasks by conditioning on prompts. However, the quality of different\nhuman-written prompts leads to substantial discrepancies in LLMs' performance,\nand improving prompts usually necessitates considerable human effort and\nexpertise. To this end, this paper proposes Prompt with Actor-Critic Editing\n(PACE) for LLMs to enable automatic prompt editing. Drawing inspiration from\nthe actor-critic algorithm in reinforcement learning, PACE leverages LLMs as\nthe dual roles of actors and critics, conceptualizing prompt as a type of\npolicy. PACE refines prompt, taking into account the feedback from both actors\nperforming prompt and critics criticizing response. This process helps LLMs\nbetter align prompt to a specific task, thanks to real responses and thinking\nfrom LLMs. We conduct extensive experiments on 24 instruction induction tasks\nand 21 big-bench tasks. Experimental results indicate that PACE elevates the\nrelative performance of medium/low-quality human-written prompts by up to 98\\%,\nwhich has comparable performance to high-quality human-written prompts.\nMoreover, PACE also exhibits notable efficacy for prompt generation.\n",
                "链接": "https://arxiv.org/abs/2308.10088"
            },
            {
                "文章ID": "114329",
                "标题": "Black-Box Prompt Optimization: Aligning Large Language Models without\n  Model Training",
                "作者": " Jiale Cheng,  Xiao Liu,  Kehan Zheng,  Pei Ke,  Hongning Wang,  Yuxiao Dong,  Jie Tang,  Minlie Huang",
                "发布日期": "2023-11-09",
                "摘要": "  Large language models (LLMs) have shown impressive success in various\napplications. However, these models are often not well aligned with human\nintents, which calls for additional treatments on them, that is, the alignment\nproblem. To make LLMs better follow user instructions, existing alignment\nmethods mostly focus on further training them. However, the extra training of\nLLMs are usually expensive in terms of GPU compute; worse still, LLMs of\ninterest are oftentimes not accessible for user-demanded training, such as\nGPTs. In this work, we take a different perspective -- Black-Box Prompt\nOptimization (BPO) -- to perform alignments. The idea is to optimize user\nprompts to suit LLMs' input understanding, so as to best realize users' intents\nwithout updating LLMs' parameters. BPO is model-agnostic and the empirical\nresults demonstrate that the BPO-aligned ChatGPT yields a 22% increase in the\nwin rate against its original version, and 10% for GPT-4. Importantly, the\nBPO-aligned LLMs can outperform the same models aligned by PPO and DPO, and it\nalso brings additional performance gains when combining BPO with PPO or DPO.\nCode and datasets are released at https://github.com/thu-coai/BPO.\n",
                "链接": "https://arxiv.org/abs/2311.04155"
            },
            {
                "文章ID": "120691",
                "标题": "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt\n  Engineer",
                "作者": " Junyuan Hong,  Jiachen T. Wang,  Chenhui Zhang,  Zhangheng Li,  Bo Li,  Zhangyang Wang",
                "发布日期": "2023-12-08",
                "摘要": "  Large Language Models (LLMs) have emerged as dominant tools for various\ntasks, particularly when tailored for a specific target by prompt tuning.\nNevertheless, concerns surrounding data privacy present obstacles due to the\ntuned prompts' dependency on sensitive private information. A practical\nsolution is to host a local LLM and optimize a soft prompt privately using\ndata. Yet, hosting a local model becomes problematic when model ownership is\nprotected. Alternative methods, like sending data to the model's provider for\ntraining, intensify these privacy issues facing an untrusted provider. In this\npaper, we present a novel solution called Differentially-Private Offsite Prompt\nTuning (DP-OPT) to address this challenge. Our approach involves tuning a\ndiscrete prompt on the client side and then applying it to the desired cloud\nmodels. We demonstrate that prompts suggested by LLMs themselves can be\ntransferred without compromising performance significantly. To ensure that the\nprompts do not leak private information, we introduce the first private prompt\ngeneration mechanism, by a differentially-private (DP) ensemble of in-context\nlearning with private demonstrations. With DP-OPT, generating\nprivacy-preserving prompts by Vicuna-7b can yield competitive performance\ncompared to non-private in-context learning on GPT3.5 or local private prompt\ntuning. Codes are available at https://github.com/VITA-Group/DP-OPT .\n",
                "链接": "https://arxiv.org/abs/2312.03724"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "21046",
                "标题": "End-to-End Multimodal Fact-Checking and Explanation Generation: A\n  Challenging Dataset and Models",
                "作者": "Virginia Tech  Barry Menglong Yao, Virginia Tech  Aditya Shah, Lehigh University  Lichao Sun, Virginia Tech  Jin-Hee Cho, Virginia Tech  Lifu Huang",
                "发布日期": "2023-07-10",
                "摘要": "  We propose end-to-end multimodal fact-checking and explanation generation,\nwhere the input is a claim and a large collection of web sources, including\narticles, images, videos, and tweets, and the goal is to assess the\ntruthfulness of the claim by retrieving relevant evidence and predicting a\ntruthfulness label (e.g., support, refute or not enough information), and to\ngenerate a statement to summarize and explain the reasoning and ruling process.\nTo support this research, we construct Mocheg, a large-scale dataset consisting\nof 15,601 claims where each claim is annotated with a truthfulness label and a\nruling statement, and 33,880 textual paragraphs and 12,112 images in total as\nevidence. To establish baseline performances on Mocheg, we experiment with\nseveral state-of-the-art neural architectures on the three pipelined subtasks:\nmultimodal evidence retrieval, claim verification, and explanation generation,\nand demonstrate that the performance of the state-of-the-art end-to-end\nmultimodal fact-checking does not provide satisfactory outcomes. To the best of\nour knowledge, we are the first to build the benchmark dataset and solutions\nfor end-to-end multimodal fact-checking and explanation generation. The\ndataset, source code and model checkpoints are available at\nhttps://github.com/VT-NLP/Mocheg.\n",
                "链接": "https://arxiv.org/abs/2205.12487"
            },
            {
                "文章ID": "100055",
                "标题": "End-to-End Learning on Multimodal Knowledge Graphs",
                "作者": " W. X. Wilcke,  P. Bloem,  V. de Boer,  R. H. van t Veer",
                "发布日期": "2023-09-06",
                "摘要": "  Knowledge graphs enable data scientists to learn end-to-end on heterogeneous\nknowledge. However, most end-to-end models solely learn from the relational\ninformation encoded in graphs' structure: raw values, encoded as literal nodes,\nare either omitted completely or treated as regular nodes without consideration\nfor their values. In either case we lose potentially relevant information which\ncould have otherwise been exploited by our learning methods. We propose a\nmultimodal message passing network which not only learns end-to-end from the\nstructure of graphs, but also from their possibly divers set of multimodal node\nfeatures. Our model uses dedicated (neural) encoders to naturally learn\nembeddings for node features belonging to five different types of modalities,\nincluding numbers, texts, dates, images and geometries, which are projected\ninto a joint representation space together with their relational information.\nWe implement and demonstrate our model on node classification and link\nprediction for artificial and real-worlds datasets, and evaluate the effect\nthat each modality has on the overall performance in an inverse ablation study.\nOur results indicate that end-to-end multimodal learning from any arbitrary\nknowledge graph is indeed possible, and that including multimodal information\ncan significantly affect performance, but that much depends on the\ncharacteristics of the data.\n",
                "链接": "https://arxiv.org/abs/2309.01169"
            },
            {
                "文章ID": "104271",
                "标题": "LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language\n  Models",
                "作者": " Ahmad Faiz,  Sotaro Kaneda,  Ruhan Wang,  Rita Osi,  Parteek Sharma,  Fan Chen,  Lei Jiang",
                "发布日期": "2023-09-27",
                "摘要": "  The carbon footprint associated with large language models (LLMs) is a\nsignificant concern, encompassing emissions from their training, inference,\nexperimentation, and storage processes, including operational and embodied\ncarbon emissions. An essential aspect is accurately estimating the carbon\nimpact of emerging LLMs even before their training, which heavily relies on GPU\nusage. Existing studies have reported the carbon footprint of LLM training, but\nonly one tool, mlco2, can predict the carbon footprint of new neural networks\nprior to physical training. However, mlco2 has several serious limitations. It\ncannot extend its estimation to dense or mixture-of-experts (MoE) LLMs,\ndisregards critical architectural parameters, focuses solely on GPUs, and\ncannot model embodied carbon footprints. Addressing these gaps, we introduce\n\\textit{LLMCarbon}, an end-to-end carbon footprint projection model designed\nfor both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly\nenhances the accuracy of carbon footprint estimations for various LLMs.\n",
                "链接": "https://arxiv.org/abs/2309.14393"
            },
            {
                "文章ID": "12682",
                "标题": "End-to-end Document Recognition and Understanding with Dessurt",
                "作者": " Brian Davis,  Bryan Morse,  Bryan Price,  Chris Tensmeyer,  Curtis Wigington,  Vlad Morariu",
                "发布日期": "2022-06-17",
                "摘要": "  We introduce Dessurt, a relatively simple document understanding transformer\ncapable of being fine-tuned on a greater variety of document tasks than prior\nmethods. It receives a document image and task string as input and generates\narbitrary text autoregressively as output. Because Dessurt is an end-to-end\narchitecture that performs text recognition in addition to the document\nunderstanding, it does not require an external recognition model as prior\nmethods do. Dessurt is a more flexible model than prior methods and is able to\nhandle a variety of document domains and tasks. We show that this model is\neffective at 9 different dataset-task combinations.\n",
                "链接": "https://arxiv.org/abs/2203.16618"
            },
            {
                "文章ID": "22470",
                "标题": "On the Choice of Data for Efficient Training and Validation of\n  End-to-End Driving Models",
                "作者": " Marvin Klingner,  Konstantin Müller,  Mona Mirzaie,  Jasmin Breitenstein,  Jan-Aike Termöhlen,  Tim Fingscheidt",
                "发布日期": "2022-06-02",
                "摘要": "  The emergence of data-driven machine learning (ML) has facilitated\nsignificant progress in many complicated tasks such as highly-automated\ndriving. While much effort is put into improving the ML models and learning\nalgorithms in such applications, little focus is put into how the training data\nand/or validation setting should be designed. In this paper we investigate the\ninfluence of several data design choices regarding training and validation of\ndeep driving models trainable in an end-to-end fashion. Specifically, (i) we\ninvestigate how the amount of training data influences the final driving\nperformance, and which performance limitations are induced through currently\nused mechanisms to generate training data. (ii) Further, we show by correlation\nanalysis, which validation design enables the driving performance measured\nduring validation to generalize well to unknown test environments. (iii)\nFinally, we investigate the effect of random seeding and non-determinism,\ngiving insights which reported improvements can be deemed significant. Our\nevaluations using the popular CARLA simulator provide recommendations regarding\ndata generation and driving route selection for an efficient future development\nof end-to-end driving models.\n",
                "链接": "https://arxiv.org/abs/2206.00608"
            },
            {
                "文章ID": "92569",
                "标题": "Modality Confidence Aware Training for Robust End-to-End Spoken Language\n  Understanding",
                "作者": " Suyoun Kim,  Akshat Shrivastava,  Duc Le,  Ju Lin,  Ozlem Kalinli,  Michael L. Seltzer",
                "发布日期": "2023-07-25",
                "摘要": "  End-to-end (E2E) spoken language understanding (SLU) systems that generate a\nsemantic parse from speech have become more promising recently. This approach\nuses a single model that utilizes audio and text representations from\npre-trained speech recognition models (ASR), and outperforms traditional\npipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems\nstill show weakness when text representation quality is low due to ASR\ntranscription errors. To overcome this issue, we propose a novel E2E SLU system\nthat enhances robustness to ASR errors by fusing audio and text representations\nbased on the estimated modality confidence of ASR hypotheses. We introduce two\nnovel techniques: 1) an effective method to encode the quality of ASR\nhypotheses and 2) an effective approach to integrate them into E2E SLU models.\nWe show accuracy improvements on STOP dataset and share the analysis to\ndemonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2307.12134"
            },
            {
                "文章ID": "12174",
                "标题": "Towards End-to-End Unified Scene Text Detection and Layout Analysis",
                "作者": " Shangbang Long,  Siyang Qin,  Dmitry Panteleev,  Alessandro Bissacco,  Yasuhisa Fujii,  Michalis Raptis",
                "发布日期": "2022-06-06",
                "摘要": "  Scene text detection and document layout analysis have long been treated as\ntwo separate tasks in different image domains. In this paper, we bring them\ntogether and introduce the task of unified scene text detection and layout\nanalysis. The first hierarchical scene text dataset is introduced to enable\nthis novel research task. We also propose a novel method that is able to\nsimultaneously detect scene text and form text clusters in a unified way.\nComprehensive experiments show that our unified model achieves better\nperformance than multiple well-designed baseline methods. Additionally, this\nmodel achieves state-of-the-art results on multiple scene text detection\ndatasets without the need of complex post-processing. Dataset and code:\nhttps://github.com/google-research-datasets/hiertext and\nhttps://github.com/tensorflow/models/tree/master/official/projects/unified_detector.\n",
                "链接": "https://arxiv.org/abs/2203.15143"
            },
            {
                "文章ID": "46362",
                "标题": "Unified End-to-End Speech Recognition and Endpointing for Fast and\n  Efficient Speech Systems",
                "作者": " Shaan Bijwadia,  Shuo-yiin Chang,  Bo Li,  Tara Sainath,  Chao Zhang,  Yanzhang He",
                "发布日期": "2023-02-16",
                "摘要": "  Automatic speech recognition (ASR) systems typically rely on an external\nendpointer (EP) model to identify speech boundaries. In this work, we propose a\nmethod to jointly train the ASR and EP tasks in a single end-to-end (E2E)\nmultitask model, improving EP quality by optionally leveraging information from\nthe ASR audio encoder. We introduce a \"switch\" connection, which trains the EP\nto consume either the audio frames directly or low-level latent representations\nfrom the ASR model. This results in a single E2E model that can be used during\ninference to perform frame filtering at low cost, and also make high quality\nend-of-query (EOQ) predictions based on ongoing ASR computation. We present\nresults on a voice search test set showing that, compared to separate\nsingle-task models, this approach reduces median endpoint latency by 120 ms\n(30.8% reduction), and 90th percentile latency by 170 ms (23.0% reduction),\nwithout regressing word error rate. For continuous recognition, WER improves by\n10.6% (relative).\n",
                "链接": "https://arxiv.org/abs/2211.00786"
            },
            {
                "文章ID": "122514",
                "标题": "Planning and Rendering: Towards End-to-End Product Poster Generation",
                "作者": " Zhaochen Li,  Fengheng Li,  Wei Feng,  Honghe Zhu,  An Liu,  Yaoyu Li,  Zheng Zhang,  Jingjing Lv,  Xin Zhu,  Junjie Shen,  Zhangang Lin,  Jingping Shao,  Zhenglu Yang",
                "发布日期": "2023-12-15",
                "摘要": "  End-to-end product poster generation significantly optimizes design\nefficiency and reduces production costs. Prevailing methods predominantly rely\non image-inpainting methods to generate clean background images for given\nproducts. Subsequently, poster layout generation methods are employed to\nproduce corresponding layout results. However, the background images may not be\nsuitable for accommodating textual content due to their complexity, and the\nfixed location of products limits the diversity of layout results. To alleviate\nthese issues, we propose a novel product poster generation framework named\nP\\&R. The P\\&R draws inspiration from the workflow of designers in creating\nposters, which consists of two stages: Planning and Rendering. At the planning\nstage, we propose a PlanNet to generate the layout of the product and other\nvisual components considering both the appearance features of the product and\nsemantic features of the text, which improves the diversity and rationality of\nthe layouts. At the rendering stage, we propose a RenderNet to generate the\nbackground for the product while considering the generated layout, where a\nspatial fusion module is introduced to fuse the layout of different visual\ncomponents. To foster the advancement of this field, we propose the first\nend-to-end product poster generation dataset PPG30k, comprising 30k exquisite\nproduct poster images along with comprehensive image and text annotations. Our\nmethod outperforms the state-of-the-art product poster generation methods on\nPPG30k. The PPG30k will be released soon.\n",
                "链接": "https://arxiv.org/abs/2312.08822"
            },
            {
                "文章ID": "3047",
                "标题": "Improving End-to-End Models for Set Prediction in Spoken Language\n  Understanding",
                "作者": " Hong-Kwang J. Kuo,  Zoltan Tuske,  Samuel Thomas,  Brian Kingsbury,  George Saon",
                "发布日期": "2022-01-31",
                "摘要": "  The goal of spoken language understanding (SLU) systems is to determine the\nmeaning of the input speech signal, unlike speech recognition which aims to\nproduce verbatim transcripts. Advances in end-to-end (E2E) speech modeling have\nmade it possible to train solely on semantic entities, which are far cheaper to\ncollect than verbatim transcripts. We focus on this set prediction problem,\nwhere entity order is unspecified. Using two classes of E2E models, RNN\ntransducers and attention based encoder-decoders, we show that these models\nwork best when the training entity sequence is arranged in spoken order. To\nimprove E2E SLU models when entity spoken order is unknown, we propose a novel\ndata augmentation technique along with an implicit attention based alignment\nmethod to infer the spoken order. F1 scores significantly increased by more\nthan 11% for RNN-T and about 2% for attention based encoder-decoder SLU models,\noutperforming previously reported results.\n",
                "链接": "https://arxiv.org/abs/2201.12105"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "87724",
                "标题": "Interactive Design by Integrating a Large Pre-Trained Language Model and\n  Building Information Modeling",
                "作者": " Suhyung Jang,  Ghang Lee",
                "发布日期": "2023-06-27",
                "摘要": "  This study explores the potential of generative artificial intelligence (AI)\nmodels, specifically OpenAI's generative pre-trained transformer (GPT) series,\nwhen integrated with building information modeling (BIM) tools as an\ninteractive design assistant for architectural design. The research involves\nthe development and implementation of three key components: 1) BIM2XML, a\ncomponent that translates BIM data into extensible markup language (XML)\nformat; 2) Generative AI-enabled Interactive Architectural design (GAIA), a\ncomponent that refines the input design in XML by identifying designer intent,\nrelevant objects, and their attributes, using pre-trained language models; and\n3) XML2BIM, a component that converts AI-generated XML data back into a BIM\ntool. This study validated the proposed approach through a case study involving\ndesign detailing, using the GPT series and Revit. Our findings demonstrate the\neffectiveness of state-of-the-art language models in facilitating dynamic\ncollaboration between architects and AI systems, highlighting the potential for\nfurther advancements.\n",
                "链接": "https://arxiv.org/abs/2306.14165"
            },
            {
                "文章ID": "124857",
                "标题": "PersianLLaMA: Towards Building First Persian Large Language Model",
                "作者": " Mohammad Amin Abbasi,  Arash Ghafouri,  Mahdi Firouzmandi,  Hassan Naderi,  Behrouz Minaei Bidgoli",
                "发布日期": "2023-12-27",
                "摘要": "  Despite the widespread use of the Persian language by millions globally,\nlimited efforts have been made in natural language processing for this\nlanguage. The use of large language models as effective tools in various\nnatural language processing tasks typically requires extensive textual data and\nrobust hardware resources. Consequently, the scarcity of Persian textual data\nand the unavailability of powerful hardware resources have hindered the\ndevelopment of large language models for Persian. This paper introduces the\nfirst large Persian language model, named PersianLLaMA, trained on a collection\nof Persian texts and datasets. This foundational model comes in two versions,\nwith 7 and 13 billion parameters, trained on formal and colloquial Persian\ntexts using two different approaches. PersianLLaMA has been evaluated for\nnatural language generation tasks based on the latest evaluation methods,\nnamely using larger language models, and for natural language understanding\ntasks based on automated machine metrics. The results indicate that\nPersianLLaMA significantly outperforms its competitors in both understanding\nand generating Persian text. PersianLLaMA marks an important step in the\ndevelopment of Persian natural language processing and can be a valuable\nresource for the Persian-speaking community. This large language model can be\nused for various natural language processing tasks, especially text generation\nlike chatbots, question-answering, machine translation, and text summarization\n",
                "链接": "https://arxiv.org/abs/2312.15713"
            },
            {
                "文章ID": "52107",
                "标题": "Building Metadata Inference Using a Transducer Based Language Model",
                "作者": " David Waterworth,  Subbu Sethuvenkatraman,  Quan Z. Sheng",
                "发布日期": "2022-12-06",
                "摘要": "  Solving the challenges of automatic machine translation of Building\nAutomation System text metadata is a crucial first step in efficiently\ndeploying smart building applications. The vocabulary used to describe building\nmetadata appears small compared to general natural languages, but each term has\nmultiple commonly used abbreviations. Conventional machine learning techniques\nare inefficient since they need to learn many different forms for the same\nword, and large amounts of data must be used to train these models. It is also\ndifficult to apply standard techniques such as tokenisation since this commonly\nresults in multiple output tags being associated with a single input token,\nsomething traditional sequence labelling models do not allow. Finite State\nTransducers can model sequence-to-sequence tasks where the input and output\nsequences are different lengths, and they can be combined with language models\nto ensure a valid output sequence is generated. We perform a preliminary\nanalysis into the use of transducer-based language models to parse and\nnormalise building point metadata.\n",
                "链接": "https://arxiv.org/abs/2212.01964"
            },
            {
                "文章ID": "49544",
                "标题": "AF Adapter: Continual Pretraining for Building Chinese Biomedical\n  Language Model",
                "作者": " Yongyu Yan,  Kui Xue,  Xiaoming Shi,  Qi Ye,  Jingping Liu,  Tong Ruan",
                "发布日期": "2023-10-23",
                "摘要": "  Continual pretraining is a popular way of building a domain-specific\npretrained language model from a general-domain language model. In spite of its\nhigh efficiency, continual pretraining suffers from catastrophic forgetting,\nwhich may harm the model's performance in downstream tasks. To alleviate the\nissue, in this paper, we propose a continual pretraining method for the\nBERT-based model, named Attention-FFN Adapter. Its main idea is to introduce a\nsmall number of attention heads and hidden units inside each self-attention\nlayer and feed-forward network. Furthermore, we train a domain-specific\nlanguage model named AF Adapter based RoBERTa for the Chinese biomedical\ndomain. In experiments, models are applied to downstream tasks for evaluation.\nThe results demonstrate that with only about 17% of model parameters trained,\nAF Adapter achieves 0.6%, 2% gain in performance on average, compared to strong\nbaselines. Further experimental results show that our method alleviates the\ncatastrophic forgetting problem by 11% compared to the fine-tuning method.\n",
                "链接": "https://arxiv.org/abs/2211.11363"
            },
            {
                "文章ID": "45690",
                "标题": "Modeling structure-building in the brain with CCG parsing and large\n  language models",
                "作者": " Miloš Stanojević,  Jonathan R. Brennan,  Donald Dunagan,  Mark Steedman,  John T. Hale",
                "发布日期": "2023-04-18",
                "摘要": "  To model behavioral and neural correlates of language comprehension in\nnaturalistic environments researchers have turned to broad-coverage tools from\nnatural-language processing and machine learning. Where syntactic structure is\nexplicitly modeled, prior work has relied predominantly on context-free\ngrammars (CFG), yet such formalisms are not sufficiently expressive for human\nlanguages. Combinatory Categorial Grammars (CCGs) are sufficiently expressive\ndirectly compositional models of grammar with flexible constituency that\naffords incremental interpretation. In this work we evaluate whether a more\nexpressive CCG provides a better model than a CFG for human neural signals\ncollected with fMRI while participants listen to an audiobook story. We further\ntest between variants of CCG that differ in how they handle optional adjuncts.\nThese evaluations are carried out against a baseline that includes estimates of\nnext-word predictability from a Transformer neural network language model. Such\na comparison reveals unique contributions of CCG structure-building\npredominantly in the left posterior temporal lobe: CCG-derived measures offer a\nsuperior fit to neural signals compared to those derived from a CFG. These\neffects are spatially distinct from bilateral superior temporal effects that\nare unique to predictability. Neural effects for structure-building are thus\nseparable from predictability during naturalistic listening, and those effects\nare best characterized by a grammar whose expressive power is motivated on\nindependent linguistic grounds.\n",
                "链接": "https://arxiv.org/abs/2210.16147"
            },
            {
                "文章ID": "59850",
                "标题": "Controlling for Stereotypes in Multimodal Language Model Evaluation",
                "作者": " Manuj Malik,  Richard Johansson",
                "发布日期": "2023-02-06",
                "摘要": "  We propose a methodology and design two benchmark sets for measuring to what\nextent language-and-vision language models use the visual signal in the\npresence or absence of stereotypes. The first benchmark is designed to test for\nstereotypical colors of common objects, while the second benchmark considers\ngender stereotypes. The key idea is to compare predictions when the image\nconforms to the stereotype to predictions when it does not.\n  Our results show that there is significant variation among multimodal models:\nthe recent Transformer-based FLAVA seems to be more sensitive to the choice of\nimage and less affected by stereotypes than older CNN-based models such as\nVisualBERT and LXMERT. This effect is more discernible in this type of\ncontrolled setting than in traditional evaluations where we do not know whether\nthe model relied on the stereotype or the visual signal.\n",
                "链接": "https://arxiv.org/abs/2302.01582"
            },
            {
                "文章ID": "109754",
                "标题": "Pseudointelligence: A Unifying Framework for Language Model Evaluation",
                "作者": " Shikhar Murty,  Orr Paradise,  Pratyusha Sharma",
                "发布日期": "2023-10-19",
                "摘要": "  With large language models surpassing human performance on an increasing\nnumber of benchmarks, we must take a principled approach for targeted\nevaluation of model capabilities. Inspired by pseudorandomness, we propose\npseudointelligence, which captures the maxim that \"(perceived) intelligence\nlies in the eye of the beholder\". That is, that claims of intelligence are\nmeaningful only when their evaluator is taken into account. Concretely, we\npropose a complexity-theoretic framework of model evaluation cast as a dynamic\ninteraction between a model and a learned evaluator. We demonstrate that this\nframework can be used to reason about two case studies in language model\nevaluation, as well as analyze existing evaluation methods.\n",
                "链接": "https://arxiv.org/abs/2310.12135"
            },
            {
                "文章ID": "53814",
                "标题": "Attributed Question Answering: Evaluation and Modeling for Attributed\n  Large Language Models",
                "作者": " Bernd Bohnet,  Vinh Q. Tran,  Pat Verga,  Roee Aharoni,  Daniel Andor,  Livio Baldini Soares,  Massimiliano Ciaramita,  Jacob Eisenstein,  Kuzman Ganchev,  Jonathan Herzig,  Kai Hui,  Tom Kwiatkowski,  Ji Ma,  Jianmo Ni,  Lierni Sestorain Saralegui,  Tal Schuster,  William W. Cohen,  Michael Collins,  Dipanjan Das,  Donald Metzler,  Slav Petrov,  Kellie Webster",
                "发布日期": "2023-02-14",
                "摘要": "  Large language models (LLMs) have shown impressive results while requiring\nlittle or no direct supervision. Further, there is mounting evidence that LLMs\nmay have potential in information-seeking scenarios. We believe the ability of\nan LLM to attribute the text that it generates is likely to be crucial in this\nsetting. We formulate and study Attributed QA as a key first step in the\ndevelopment of attributed LLMs. We propose a reproducible evaluation framework\nfor the task and benchmark a broad set of architectures. We take human\nannotations as a gold standard and show that a correlated automatic metric is\nsuitable for development. Our experimental work gives concrete answers to two\nkey questions (How to measure attribution?, and How well do current\nstate-of-the-art methods perform on attribution?), and give some hints as to\nhow to address a third (How to build LLMs with attribution?).\n",
                "链接": "https://arxiv.org/abs/2212.08037"
            },
            {
                "文章ID": "119119",
                "标题": "A-Scan2BIM: Assistive Scan to Building Information Modeling",
                "作者": " Weilian Song,  Jieliang Luo,  Dale Zhao,  Yan Fu,  Chin-Yi Cheng,  Yasutaka Furukawa",
                "发布日期": "2023-12-01",
                "摘要": "  This paper proposes an assistive system for architects that converts a\nlarge-scale point cloud into a standardized digital representation of a\nbuilding for Building Information Modeling (BIM) applications. The process is\nknown as Scan-to-BIM, which requires many hours of manual work even for a\nsingle building floor by a professional architect. Given its challenging\nnature, the paper focuses on helping architects on the Scan-to-BIM process,\ninstead of replacing them. Concretely, we propose an assistive Scan-to-BIM\nsystem that takes the raw sensor data and edit history (including the current\nBIM model), then auto-regressively predicts a sequence of model editing\noperations as APIs of a professional BIM software (i.e., Autodesk Revit). The\npaper also presents the first building-scale Scan2BIM dataset that contains a\nsequence of model editing operations as the APIs of Autodesk Revit. The dataset\ncontains 89 hours of Scan2BIM modeling processes by professional architects\nover 16 scenes, spanning over 35,000 m^2. We report our system's reconstruction\nquality with standard metrics, and we introduce a novel metric that measures\nhow natural the order of reconstructed operations is. A simple modification to\nthe reconstruction module helps improve performance, and our method is far\nsuperior to two other baselines in the order metric. We will release data,\ncode, and models at a-scan2bim.github.io.\n",
                "链接": "https://arxiv.org/abs/2311.18166"
            },
            {
                "文章ID": "101384",
                "标题": "Kani: A Lightweight and Highly Hackable Framework for Building Language\n  Model Applications",
                "作者": " Andrew Zhu,  Liam Dugan,  Alyssa Hwang,  Chris Callison-Burch",
                "发布日期": "2023-09-12",
                "摘要": "  Language model applications are becoming increasingly popular and complex,\noften including features like tool usage and retrieval augmentation. However,\nexisting frameworks for such applications are often opinionated, deciding for\ndevelopers how their prompts ought to be formatted and imposing limitations on\ncustomizability and reproducibility. To solve this we present Kani: a\nlightweight, flexible, and model-agnostic open-source framework for building\nlanguage model applications. Kani helps developers implement a variety of\ncomplex features by supporting the core building blocks of chat interaction:\nmodel interfacing, chat management, and robust function calling. All Kani core\nfunctions are easily overridable and well documented to empower developers to\ncustomize functionality for their own needs. Kani thus serves as a useful tool\nfor researchers, hobbyists, and industry professionals alike to accelerate\ntheir development while retaining interoperability and fine-grained control.\n",
                "链接": "https://arxiv.org/abs/2309.05542"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "23410",
                "标题": "Position Paper: Online Modeling for Offline Planning",
                "作者": " Eyal Weiss,  Gal A. Kaminka",
                "发布日期": "2022-06-22",
                "摘要": "  The definition and representation of planning problems is at the heart of AI\nplanning research. A key part is the representation of action models. Decades\nof advances improving declarative action model representations resulted in\nnumerous theoretical advances, and capable, working, domain-independent\nplanners. However, despite the maturity of the field, AI planning technology is\nstill rarely used outside the research community, suggesting that current\nrepresentations fail to capture real-world requirements, such as utilizing\ncomplex mathematical functions and models learned from data. We argue that this\nis because the modeling process is assumed to have taken place and completed\nprior to the planning process, i.e., offline modeling for offline planning.\nThere are several challenges inherent to this approach, including: limited\nexpressiveness of declarative modeling languages; early commitment to modeling\nchoices and computation, that preclude using the most appropriate resolution\nfor each action model -- which can only be known during planning; and\ndifficulty in reliably using non-declarative, learned, models.\n  We therefore suggest to change the AI planning process, such that is carries\nout online modeling in offline planning, i.e., the use of action models that\nare computed or even generated as part of the planning process, as they are\naccessed. This generalizes the existing approach (offline modeling). The\nproposed definition admits novel planning processes, and we suggest one\nconcrete implementation, demonstrating the approach. We sketch initial results\nthat were obtained as part of a first attempt to follow this approach by\nplanning with action cost estimators. We conclude by discussing open\nchallenges.\n",
                "链接": "https://arxiv.org/abs/2206.03356"
            },
            {
                "文章ID": "81054",
                "标题": "Improving Position Encoding of Transformers for Multivariate Time Series\n  Classification",
                "作者": " Navid Mohammadi Foumani,  Chang Wei Tan,  Geoffrey I. Webb,  Mahsa Salehi",
                "发布日期": "2023-05-29",
                "摘要": "  Transformers have demonstrated outstanding performance in many applications\nof deep learning. When applied to time series data, transformers require\neffective position encoding to capture the ordering of the time series data.\nThe efficacy of position encoding in time series analysis is not well-studied\nand remains controversial, e.g., whether it is better to inject absolute\nposition encoding or relative position encoding, or a combination of them. In\norder to clarify this, we first review existing absolute and relative position\nencoding methods when applied in time series classification. We then proposed a\nnew absolute position encoding method dedicated to time series data called time\nAbsolute Position Encoding (tAPE). Our new method incorporates the series\nlength and input embedding dimension in absolute position encoding.\nAdditionally, we propose computationally Efficient implementation of Relative\nPosition Encoding (eRPE) to improve generalisability for time series. We then\npropose a novel multivariate time series classification (MTSC) model combining\ntAPE/eRPE and convolution-based input encoding named ConvTran to improve the\nposition and data embedding of time series data. The proposed absolute and\nrelative position encoding methods are simple and efficient. They can be easily\nintegrated into transformer blocks and used for downstream tasks such as\nforecasting, extrinsic regression, and anomaly detection. Extensive experiments\non 32 multivariate time-series datasets show that our model is significantly\nmore accurate than state-of-the-art convolution and transformer-based models.\nCode and models are open-sourced at\n\\url{https://github.com/Navidfoumani/ConvTran}.\n",
                "链接": "https://arxiv.org/abs/2305.16642"
            },
            {
                "文章ID": "6738",
                "标题": "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks",
                "作者": " Maksim Zubkov,  Daniil Gavrilov",
                "发布日期": "2022-02-24",
                "摘要": "  Transformers achieve remarkable performance in various domains, including\nNLP, CV, audio processing, and graph analysis. However, they do not scale well\non long sequence tasks due to their quadratic complexity w.r.t. the inputs\nlength. Linear Transformers were proposed to address this limitation. However,\nthese models have shown weaker performance on the long sequence tasks comparing\nto the original one. In this paper, we explore Linear Transformer models,\nrethinking their two core components. Firstly, we improved Linear Transformer\nwith Shift-Invariant Kernel Function SIKF, which achieve higher accuracy\nwithout loss in speed. Secondly, we introduce FastRPB which stands for Fast\nRelative Positional Bias, which efficiently adds positional information to\nself-attention using Fast Fourier Transformation. FastRPB is independent of the\nself-attention mechanism and can be combined with an original self-attention\nand all its efficient variants. FastRPB has O(N log(N)) computational\ncomplexity, requiring O(N) memory w.r.t. input sequence length N.\n",
                "链接": "https://arxiv.org/abs/2202.11364"
            },
            {
                "文章ID": "61398",
                "标题": "Encoding Sentence Position in Context-Aware Neural Machine Translation\n  with Concatenation",
                "作者": " Lorenzo Lupo,  Marco Dinarelli,  Laurent Besacier",
                "发布日期": "2023-04-06",
                "摘要": "  Context-aware translation can be achieved by processing a concatenation of\nconsecutive sentences with the standard Transformer architecture. This paper\ninvestigates the intuitive idea of providing the model with explicit\ninformation about the position of the sentences contained in the concatenation\nwindow. We compare various methods to encode sentence positions into token\nrepresentations, including novel methods. Our results show that the Transformer\nbenefits from certain sentence position encoding methods on English to Russian\ntranslation if trained with a context-discounted loss (Lupo et al., 2022).\nHowever, the same benefits are not observed in English to German. Further\nempirical efforts are necessary to define the conditions under which the\nproposed approach is beneficial.\n",
                "链接": "https://arxiv.org/abs/2302.06459"
            },
            {
                "文章ID": "32836",
                "标题": "Simplified State Space Layers for Sequence Modeling",
                "作者": " Jimmy T. H. Smith,  Andrew Warrington,  Scott W. Linderman",
                "发布日期": "2023-03-06",
                "摘要": "  Models using structured state space sequence (S4) layers have achieved\nstate-of-the-art performance on long-range sequence modeling tasks. An S4 layer\ncombines linear state space models (SSMs), the HiPPO framework, and deep\nlearning to achieve high performance. We build on the design of the S4 layer\nand introduce a new state space layer, the S5 layer. Whereas an S4 layer uses\nmany independent single-input, single-output SSMs, the S5 layer uses one\nmulti-input, multi-output SSM. We establish a connection between S5 and S4, and\nuse this to develop the initialization and parameterization used by the S5\nmodel. The result is a state space layer that can leverage efficient and widely\nimplemented parallel scans, allowing S5 to match the computational efficiency\nof S4, while also achieving state-of-the-art performance on several long-range\nsequence modeling tasks. S5 averages 87.4% on the long range arena benchmark,\nand 98.5% on the most difficult Path-X task.\n",
                "链接": "https://arxiv.org/abs/2208.04933"
            },
            {
                "文章ID": "15348",
                "标题": "Dynamic Position Encoding for Transformers",
                "作者": " Joyce Zheng,  Mehdi Rezagholizadeh,  Peyman Passban",
                "发布日期": "2022-10-25",
                "摘要": "  Recurrent models have been dominating the field of neural machine translation\n(NMT) for the past few years. Transformers \\citep{vaswani2017attention}, have\nradically changed it by proposing a novel architecture that relies on a\nfeed-forward backbone and self-attention mechanism. Although Transformers are\npowerful, they could fail to properly encode sequential/positional information\ndue to their non-recurrent nature. To solve this problem, position embeddings\nare defined exclusively for each time step to enrich word information. However,\nsuch embeddings are fixed after training regardless of the task and the word\nordering system of the source or target language.\n  In this paper, we propose a novel architecture with new position embeddings\ndepending on the input text to address this shortcoming by taking the order of\ntarget words into consideration. Instead of using predefined position\nembeddings, our solution generates new embeddings to refine each word's\nposition information. Since we do not dictate the position of source tokens and\nlearn them in an end-to-end fashion, we refer to our method as dynamic position\nencoding (DPE). We evaluated the impact of our model on multiple datasets to\ntranslate from English into German, French, and Italian and observed meaningful\nimprovements in comparison to the original Transformer.\n",
                "链接": "https://arxiv.org/abs/2204.08142"
            },
            {
                "文章ID": "106867",
                "标题": "Spherical Position Encoding for Transformers",
                "作者": " Eren Unlu",
                "发布日期": "2023-10-10",
                "摘要": "  Position encoding is the primary mechanism which induces notion of sequential\norder for input tokens in transformer architectures. Even though this\nformulation in the original transformer paper has yielded plausible performance\nfor general purpose language understanding and generation, several new\nframeworks such as Rotary Position Embedding (RoPE) are proposed for further\nenhancement. In this paper, we introduce the notion of \"geotokens\" which are\ninput elements for transformer architectures, each representing an information\nrelated to a geological location. Unlike the natural language the sequential\nposition is not important for the model but the geographical coordinates are.\nIn order to induce the concept of relative position for such a setting and\nmaintain the proportion between the physical distance and distance on embedding\nspace, we formulate a position encoding mechanism based on RoPE architecture\nwhich is adjusted for spherical coordinates.\n",
                "链接": "https://arxiv.org/abs/2310.04454"
            },
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "123368",
                "标题": "Position Paper on Materials Design -- A Modern Approach",
                "作者": " Willi Grossmann,  Sebastian Eilermann,  Tim Rensmeyer,  Artur Liebert,  Michael Hohmann,  Christian Wittke,  Oliver Niggemann",
                "发布日期": "2023-12-19",
                "摘要": "  Traditional design cycles for new materials and assemblies have two\nfundamental drawbacks. The underlying physical relationships are often too\ncomplex to be precisely calculated and described. Aside from that, many unknown\nuncertainties, such as exact manufacturing parameters or materials composition,\ndominate the real assembly behavior. Machine learning (ML) methods overcome\nthese fundamental limitations through data-driven learning. In addition, modern\napproaches can specifically increase system knowledge. Representation Learning\nallows the physical, and if necessary, even symbolic interpretation of the\nlearned solution. In this way, the most complex physical relationships can be\nconsidered and quickly described. Furthermore, generative ML approaches can\nsynthesize possible morphologies of the materials based on defined conditions\nto visualize the effects of uncertainties. This modern approach accelerates the\ndesign process for new materials and enables the prediction and interpretation\nof realistic materials behavior.\n",
                "链接": "https://arxiv.org/abs/2312.10996"
            },
            {
                "文章ID": "83622",
                "标题": "Improving Grammar-based Sequence-to-Sequence Modeling with Decomposition\n  and Constraints",
                "作者": " Chao Lou,  Kewei Tu",
                "发布日期": "2023-06-06",
                "摘要": "  Neural QCFG is a grammar-based sequence-tosequence (seq2seq) model with\nstrong inductive biases on hierarchical structures. It excels in\ninterpretability and generalization but suffers from expensive inference. In\nthis paper, we study two low-rank variants of Neural QCFG for faster inference\nwith different trade-offs between efficiency and expressiveness. Furthermore,\nutilizing the symbolic interface provided by the grammar, we introduce two soft\nconstraints over tree hierarchy and source coverage. We experiment with various\ndatasets and find that our models outperform vanilla Neural QCFG in most\nsettings.\n",
                "链接": "https://arxiv.org/abs/2306.02671"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "65723",
                "标题": "MathPrompter: Mathematical Reasoning using Large Language Models",
                "作者": " Shima Imani,  Liang Du,  Harsh Shrivastava",
                "发布日期": "2023-03-10",
                "摘要": "  Large Language Models (LLMs) have limited performance when solving arithmetic\nreasoning tasks and often provide incorrect answers. Unlike natural language\nunderstanding, math problems typically have a single correct answer, making the\ntask of generating accurate solutions more challenging for LLMs. To the best of\nour knowledge, we are not aware of any LLMs that indicate their level of\nconfidence in their responses which fuels a trust deficit in these models\nimpeding their adoption. To address this deficiency, we propose `MathPrompter',\na technique that improves performance of LLMs on arithmetic problems along with\nincreased reliance in the predictions. MathPrompter uses the Zero-shot\nchain-of-thought prompting technique to generate multiple Algebraic expressions\nor Python functions to solve the same math problem in different ways and\nthereby raise the confidence level in the output results. This is in contrast\nto other prompt based CoT methods, where there is no check on the validity of\nthe intermediate steps followed. Our technique improves over state-of-the-art\non the MultiArith dataset ($78.7\\%\\rightarrow92.5\\%$) evaluated using 175B\nparameter GPT-based LLM.\n",
                "链接": "https://arxiv.org/abs/2303.05398"
            },
            {
                "文章ID": "71870",
                "标题": "Galactic ChitChat: Using Large Language Models to Converse with\n  Astronomy Literature",
                "作者": " Ioana Ciucă,  Yuan-Sen Ting",
                "发布日期": "2023-09-13",
                "摘要": "  We demonstrate the potential of the state-of-the-art OpenAI GPT-4 large\nlanguage model to engage in meaningful interactions with Astronomy papers using\nin-context prompting. To optimize for efficiency, we employ a distillation\ntechnique that effectively reduces the size of the original input paper by\n50\\%, while maintaining the paragraph structure and overall semantic integrity.\nWe then explore the model's responses using a multi-document context (ten\ndistilled documents). Our findings indicate that GPT-4 excels in the\nmulti-document domain, providing detailed answers contextualized within the\nframework of related research findings. Our results showcase the potential of\nlarge language models for the astronomical community, offering a promising\navenue for further exploration, particularly the possibility of utilizing the\nmodels for hypothesis generation.\n",
                "链接": "https://arxiv.org/abs/2304.05406"
            },
            {
                "文章ID": "94479",
                "标题": "Scaling Relationship on Learning Mathematical Reasoning with Large\n  Language Models",
                "作者": " Zheng Yuan,  Hongyi Yuan,  Chengpeng Li,  Guanting Dong,  Keming Lu,  Chuanqi Tan,  Chang Zhou,  Jingren Zhou",
                "发布日期": "2023-09-14",
                "摘要": "  Mathematical reasoning is a challenging task for large language models\n(LLMs), while the scaling relationship of it with respect to LLM capacity is\nunder-explored. In this paper, we investigate how the pre-training loss,\nsupervised data amount, and augmented data amount influence the reasoning\nperformances of a supervised LLM. We find that pre-training loss is a better\nindicator of the model's performance than the model's parameter count. We apply\nsupervised fine-tuning (SFT) with different amounts of supervised data and\nempirically find a log-linear relation between data amount and model\nperformance, and we find better models improve less with enlarged supervised\ndatasets. To augment more data samples for improving model performances without\nany human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT\nuses supervised models to generate and collect correct reasoning paths as\naugmented fine-tuning datasets. We find with augmented samples containing more\ndistinct reasoning paths, RFT improves mathematical reasoning performance more\nfor LLMs. We also find RFT brings more improvement for less performant LLMs.\nFurthermore, we combine rejection samples from multiple models which push\nLLaMA-7B to an accuracy of 49.3\\% on GSM8K which outperforms the supervised\nfine-tuning (SFT) accuracy of 35.9\\% significantly.\n",
                "链接": "https://arxiv.org/abs/2308.01825"
            },
            {
                "文章ID": "98401",
                "标题": "Diagnosing Infeasible Optimization Problems Using Large Language Models",
                "作者": " Hao Chen,  Gonzalo E. Constante-Flores,  Can Li",
                "发布日期": "2023-08-25",
                "摘要": "  Decision-making problems can be represented as mathematical optimization\nmodels, finding wide applications in fields such as economics, engineering and\nmanufacturing, transportation, and health care. Optimization models are\nmathematical abstractions of the problem of making the best decision while\nsatisfying a set of requirements or constraints. One of the primary barriers to\ndeploying these models in practice is the challenge of helping practitioners\nunderstand and interpret such models, particularly when they are infeasible,\nmeaning no decision satisfies all the constraints. Existing methods for\ndiagnosing infeasible optimization models often rely on expert systems,\nnecessitating significant background knowledge in optimization. In this paper,\nwe introduce OptiChat, a first-of-its-kind natural language-based system\nequipped with a chatbot GUI for engaging in interactive conversations about\ninfeasible optimization models. OptiChat can provide natural language\ndescriptions of the optimization model itself, identify potential sources of\ninfeasibility, and offer suggestions to make the model feasible. The\nimplementation of OptiChat is built on GPT-4, which interfaces with an\noptimization solver to identify the minimal subset of constraints that render\nthe entire optimization problem infeasible, also known as the Irreducible\nInfeasible Subset (IIS). We utilize few-shot learning, expert chain-of-thought,\nkey-retrieve, and sentiment prompts to enhance OptiChat's reliability. Our\nexperiments demonstrate that OptiChat assists both expert and non-expert users\nin improving their understanding of the optimization models, enabling them to\nquickly identify the sources of infeasibility.\n",
                "链接": "https://arxiv.org/abs/2308.12923"
            },
            {
                "文章ID": "48307",
                "标题": "Towards a Mathematics Formalisation Assistant using Large Language\n  Models",
                "作者": " Ayush Agrawal,  Siddhartha Gadgil,  Navin Goyal,  Ashvni Narayanan,  Anand Tadipatri",
                "发布日期": "2022-11-15",
                "摘要": "  Mathematics formalisation is the task of writing mathematics (i.e.,\ndefinitions, theorem statements, proofs) in natural language, as found in books\nand papers, into a formal language that can then be checked for correctness by\na program. It is a thriving activity today, however formalisation remains\ncumbersome. In this paper, we explore the abilities of a large language model\n(Codex) to help with formalisation in the Lean theorem prover. We find that\nwith careful input-dependent prompt selection and postprocessing, Codex is able\nto formalise short mathematical statements at undergrad level with nearly 75\\%\naccuracy for $120$ theorem statements. For proofs quantitative analysis is\ninfeasible and we undertake a detailed case study. We choose a diverse set of\n$13$ theorems at undergrad level with proofs that fit in two-three paragraphs.\nWe show that with a new prompting strategy Codex can formalise these proofs in\nnatural language with at least one out of twelve Codex completion being easy to\nrepair into a complete proof. This is surprising as essentially no aligned data\nexists for formalised mathematics, particularly for proofs. These results\nsuggest that large language models are a promising avenue towards fully or\npartially automating formalisation.\n",
                "链接": "https://arxiv.org/abs/2211.07524"
            },
            {
                "文章ID": "55432",
                "标题": "Using Large Language Models to Generate Engaging Captions for Data\n  Visualizations",
                "作者": " Ashley Liew,  Klaus Mueller",
                "发布日期": "2023-01-02",
                "摘要": "  Creating compelling captions for data visualizations has been a longstanding\nchallenge. Visualization researchers are typically untrained in journalistic\nreporting and hence the captions that are placed below data visualizations tend\nto be not overly engaging and rather just stick to basic observations about the\ndata. In this work we explore the opportunities offered by the newly emerging\ncrop of large language models (LLM) which use sophisticated deep learning\ntechnology to produce human-like prose. We ask, can these powerful software\ndevices be purposed to produce engaging captions for generic data\nvisualizations like a scatterplot. It turns out that the key challenge lies in\ndesigning the most effective prompt for the LLM, a task called prompt\nengineering. We report on first experiments using the popular LLM GPT-3 and\ndeliver some promising results.\n",
                "链接": "https://arxiv.org/abs/2212.14047"
            },
            {
                "文章ID": "91891",
                "标题": "Generating Mathematical Derivations with Large Language Models",
                "作者": " Jordan Meadows,  Marco Valentino,  Andre Freitas",
                "发布日期": "2023-08-09",
                "摘要": "  The derivation of mathematical results in specialised fields, using Large\nLanguage Models (LLMs), is an emerging research direction that can help\nidentify models' limitations, and potentially support mathematical discovery.\nIn this paper, we leverage a symbolic engine to generate derivations of\nequations at scale, and investigate the capabilities of LLMs when deriving goal\nequations from premises. Specifically, we employ in-context learning for GPT\nand fine-tune a range of T5 models to compare the robustness and generalisation\nof pre-training strategies to specialised models. Empirical results show that\nfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and\nout-of-distribution test sets in conventional scores. However, an in-depth\nanalysis reveals that the fine-tuned models are more sensitive to perturbations\ninvolving unseen symbols and (to a lesser extent) changes to equation\nstructure. In addition, we analyse 1.7K equations, and over 200 derivations, to\nhighlight common reasoning errors such as the inclusion of incorrect,\nirrelevant, and redundant equations. Finally, we explore the suitability of\nexisting metrics for evaluating mathematical derivations and find evidence\nthat, while they can capture general properties such as sensitivity to\nperturbations, they fail to highlight fine-grained reasoning errors and\nessential differences between models. Overall, this work demonstrates that\ntraining models on synthetic data may improve their math capabilities beyond\nmuch larger LLMs, but current metrics are not appropriately assessing the\nquality of generated mathematical text.\n",
                "链接": "https://arxiv.org/abs/2307.09998"
            },
            {
                "文章ID": "99865",
                "标题": "Extracting Mathematical Concepts with Large Language Models",
                "作者": " Valeria de Paiva,  Qiyue Gao,  Pavel Kovalev,  Lawrence S. Moss",
                "发布日期": "2023-09-06",
                "摘要": "  We extract mathematical concepts from mathematical text using generative\nlarge language models (LLMs) like ChatGPT, contributing to the field of\nautomatic term extraction (ATE) and mathematical text processing, and also to\nthe study of LLMs themselves. Our work builds on that of others in that we aim\nfor automatic extraction of terms (keywords) in one mathematical field,\ncategory theory, using as a corpus the 755 abstracts from a snapshot of the\nonline journal \"Theory and Applications of Categories\", circa 2020. Where our\nstudy diverges from previous work is in (1) providing a more thorough analysis\nof what makes mathematical term extraction a difficult problem to begin with;\n(2) paying close attention to inter-annotator disagreements; (3) providing a\nset of guidelines which both human and machine annotators could use to\nstandardize the extraction process; (4) introducing a new annotation tool to\nhelp humans with ATE, applicable to any mathematical field and even beyond\nmathematics; (5) using prompts to ChatGPT as part of the extraction process,\nand proposing best practices for such prompts; and (6) raising the question of\nwhether ChatGPT could be used as an annotator on the same level as human\nexperts. Our overall findings are that the matter of mathematical ATE is an\ninteresting field which can benefit from participation by LLMs, but LLMs\nthemselves cannot at this time surpass human performance on it.\n",
                "链接": "https://arxiv.org/abs/2309.00642"
            },
            {
                "文章ID": "63722",
                "标题": "An Independent Evaluation of ChatGPT on Mathematical Word Problems (MWP)",
                "作者": " Paulo Shakarian,  Abhinav Koyyalamudi,  Noel Ngu,  Lakshmivihari Mareedu",
                "发布日期": "2023-03-01",
                "摘要": "  We study the performance of a commercially available large language model\n(LLM) known as ChatGPT on math word problems (MWPs) from the dataset DRAW-1K.\nTo our knowledge, this is the first independent evaluation of ChatGPT. We found\nthat ChatGPT's performance changes dramatically based on the requirement to\nshow its work, failing 20% of the time when it provides work compared with 84%\nwhen it does not. Further several factors about MWPs relating to the number of\nunknowns and number of operations that lead to a higher probability of failure\nwhen compared with the prior, specifically noting (across all experiments) that\nthe probability of failure increases linearly with the number of addition and\nsubtraction operations. We also have released the dataset of ChatGPT's\nresponses to the MWPs to support further work on the characterization of LLM\nperformance and present baseline machine learning models to predict if ChatGPT\ncan correctly answer an MWP. We have released a dataset comprised of ChatGPT's\nresponses to support further research in this area.\n",
                "链接": "https://arxiv.org/abs/2302.13814"
            },
            {
                "文章ID": "104646",
                "标题": "NLPBench: Evaluating Large Language Models on Solving NLP Problems",
                "作者": " Linxin Song,  Jieyu Zhang,  Lechao Cheng,  Pengyuan Zhou,  Tianyi Zhou,  Irene Li",
                "发布日期": "2023-10-20",
                "摘要": "  Recent developments in large language models (LLMs) have shown promise in\nenhancing the capabilities of natural language processing (NLP). Despite these\nsuccesses, there remains a dearth of research dedicated to the NLP\nproblem-solving abilities of LLMs. To fill the gap in this area, we present a\nunique benchmarking dataset, NLPBench, comprising 378 college-level NLP\nquestions spanning various NLP topics sourced from Yale University's prior\nfinal exams. NLPBench includes questions with context, in which multiple\nsub-questions share the same public information, and diverse question types,\nincluding multiple choice, short answer, and math. Our evaluation, centered on\nLLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting\nstrategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study\nreveals that the effectiveness of the advanced prompting strategies can be\ninconsistent, occasionally damaging LLM performance, especially in smaller\nmodels like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated\nspecific shortcomings in LLMs' scientific problem-solving skills, with\nweaknesses in logical decomposition and reasoning notably affecting results.\n",
                "链接": "https://arxiv.org/abs/2309.15630"
            }
        ]
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "32330",
                "标题": "Tools and Methodologies for Verifying Answer Set Programs",
                "作者": "University of Nebraska Omaha  Zach Hansen",
                "发布日期": "2022-08-08",
                "摘要": "  Answer Set Programming (ASP) is a powerful declarative programming paradigm\ncommonly used for solving challenging search and optimization problems. The\nmodeling languages of ASP are supported by sophisticated solving algorithms\n(solvers) that make the solution search efficient while enabling the programmer\nto model the problem at a high level of abstraction. As an approach to\nKnowledge Representation and Reasoning, ASP benefits from its simplicity,\nconciseness and rigorously defined semantics. These characteristics make ASP a\nstraightforward way to develop formally verifiable programs. In the context of\nartificial intelligence (AI), the clarity of ASP programs lends itself to the\nconstruction of explainable, trustworthy AI. In support of these goals, my\nresearch is concerned with extending the theory and tools supporting the\nverification of ASP progams.\n",
                "链接": "https://arxiv.org/abs/2208.03096"
            },
            {
                "文章ID": "4133",
                "标题": "Verifying Inverse Model Neural Networks",
                "作者": " Chelsea Sidrane,  Sydney Katz,  Anthony Corso,  Mykel J. Kochenderfer",
                "发布日期": "2023-01-06",
                "摘要": "  Inverse problems exist in a wide variety of physical domains from aerospace\nengineering to medical imaging. The goal is to infer the underlying state from\na set of observations. When the forward model that produced the observations is\nnonlinear and stochastic, solving the inverse problem is very challenging.\nNeural networks are an appealing solution for solving inverse problems as they\ncan be trained from noisy data and once trained are computationally efficient\nto run. However, inverse model neural networks do not have guarantees of\ncorrectness built-in, which makes them unreliable for use in safety and\naccuracy-critical contexts. In this work we introduce a method for verifying\nthe correctness of inverse model neural networks. Our approach is to\noverapproximate a nonlinear, stochastic forward model with piecewise linear\nconstraints and encode both the overapproximate forward model and the neural\nnetwork inverse model as a mixed-integer program. We demonstrate this\nverification procedure on a real-world airplane fuel gauge case study. The\nability to verify and consequently trust inverse model neural networks allows\ntheir use in a wide variety of contexts, from aerospace to medicine.\n",
                "链接": "https://arxiv.org/abs/2202.02429"
            },
            {
                "文章ID": "89037",
                "标题": "Tools for Verifying Neural Models' Training Data",
                "作者": " Dami Choi,  Yonadav Shavit,  David Duvenaud",
                "发布日期": "2023-07-04",
                "摘要": "  It is important that consumers and regulators can verify the provenance of\nlarge neural models to evaluate their capabilities and risks. We introduce the\nconcept of a \"Proof-of-Training-Data\": any protocol that allows a model trainer\nto convince a Verifier of the training data that produced a set of model\nweights. Such protocols could verify the amount and kind of data and compute\nused to train the model, including whether it was trained on specific harmful\nor beneficial data sources. We explore efficient verification strategies for\nProof-of-Training-Data that are compatible with most current large-model\ntraining procedures. These include a method for the model-trainer to verifiably\npre-commit to a random seed used in training, and a method that exploits\nmodels' tendency to temporarily overfit to training data in order to detect\nwhether a given data-point was included in training. We show experimentally\nthat our verification procedures can catch a wide variety of attacks, including\nall known attacks from the Proof-of-Learning literature.\n",
                "链接": "https://arxiv.org/abs/2307.00682"
            },
            {
                "文章ID": "28068",
                "标题": "Verifying the Union of Manifolds Hypothesis for Image Data",
                "作者": " Bradley C. A. Brown,  Anthony L. Caterini,  Brendan Leigh Ross,  Jesse C. Cresswell,  Gabriel Loaiza-Ganem",
                "发布日期": "2023-03-06",
                "摘要": "  Deep learning has had tremendous success at learning low-dimensional\nrepresentations of high-dimensional data. This success would be impossible if\nthere was no hidden low-dimensional structure in data of interest; this\nexistence is posited by the manifold hypothesis, which states that the data\nlies on an unknown manifold of low intrinsic dimension. In this paper, we argue\nthat this hypothesis does not properly capture the low-dimensional structure\ntypically present in image data. Assuming that data lies on a single manifold\nimplies intrinsic dimension is identical across the entire data space, and does\nnot allow for subregions of this space to have a different number of factors of\nvariation. To address this deficiency, we consider the union of manifolds\nhypothesis, which states that data lies on a disjoint union of manifolds of\nvarying intrinsic dimensions. We empirically verify this hypothesis on\ncommonly-used image datasets, finding that indeed, observed data lies on a\ndisconnected set and that intrinsic dimension is not constant. We also provide\ninsights into the implications of the union of manifolds hypothesis in deep\nlearning, both supervised and unsupervised, showing that designing models with\nan inductive bias for this structure improves performance across classification\nand generative modelling tasks. Our code is available at\nhttps://github.com/layer6ai-labs/UoMH.\n",
                "链接": "https://arxiv.org/abs/2207.02862"
            },
            {
                "文章ID": "38509",
                "标题": "A Capability and Skill Model for Heterogeneous Autonomous Robots",
                "作者": " Luis Miguel Vieira da Silva,  Aljosha Köcher,  Alexander Fay",
                "发布日期": "2023-02-10",
                "摘要": "  Teams of heterogeneous autonomous robots become increasingly important due to\ntheir facilitation of various complex tasks. For such heterogeneous robots,\nthere is currently no consistent way of describing the functions that each\nrobot provides. In the field of manufacturing, capability modeling is\nconsidered a promising approach to semantically model functions provided by\ndifferent machines. This contribution investigates how to apply and extend\ncapability models from manufacturing to the field of autonomous robots and\npresents an approach for such a capability model.\n",
                "链接": "https://arxiv.org/abs/2209.10900"
            },
            {
                "文章ID": "114416",
                "标题": "Human Conditional Reasoning in Answer Set Programming",
                "作者": " Chiaki Sakama",
                "发布日期": "2023-11-09",
                "摘要": "  Given a conditional sentence P=>Q (if P then Q) and respective facts, four\ndifferent types of inferences are observed in human reasoning. Affirming the\nantecedent (AA) (or modus ponens) reasons Q from P; affirming the consequent\n(AC) reasons P from Q; denying the antecedent (DA) reasons -Q from -P; and\ndenying the consequent (DC) (or modus tollens) reasons -P from -Q. Among them,\nAA and DC are logically valid, while AC and DA are logically invalid and often\ncalled logical fallacies. Nevertheless, humans often perform AC or DA as\npragmatic inference in daily life. In this paper, we realize AC, DA and DC\ninferences in answer set programming. Eight different types of completion are\nintroduced and their semantics are given by answer sets. We investigate formal\nproperties and characterize human reasoning tasks in cognitive psychology.\nThose completions are also applied to commonsense reasoning in AI.\n",
                "链接": "https://arxiv.org/abs/2311.04412"
            },
            {
                "文章ID": "58559",
                "标题": "ThoughtSource: A central hub for large language model reasoning data",
                "作者": " Simon Ott,  Konstantin Hebenstreit,  Valentin Liévin,  Christoffer Egeberg Hother,  Milad Moradi,  Maximilian Mayrhauser,  Robert Praas,  Ole Winther,  Matthias Samwald",
                "发布日期": "2023-07-28",
                "摘要": "  Large language models (LLMs) such as GPT-4 have recently demonstrated\nimpressive results across a wide range of tasks. LLMs are still limited,\nhowever, in that they frequently fail at complex reasoning, their reasoning\nprocesses are opaque, they are prone to 'hallucinate' facts, and there are\nconcerns about their underlying biases. Letting models verbalize reasoning\nsteps as natural language, a technique known as chain-of-thought prompting, has\nrecently been proposed as a way to address some of these issues. Here we\npresent ThoughtSource, a meta-dataset and software library for chain-of-thought\n(CoT) reasoning. The goal of ThoughtSource is to improve future artificial\nintelligence systems by facilitating qualitative understanding of CoTs,\nenabling empirical evaluations, and providing training data. This first release\nof ThoughtSource integrates seven scientific/medical, three general-domain and\nfive math word question answering datasets.\n",
                "链接": "https://arxiv.org/abs/2301.11596"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "86386",
                "标题": "TOBY: A Tool for Exploring Data in Academic Survey Papers",
                "作者": " Tathagata Chakraborti,  Jungkoo Kang,  Christian Muise,  Sarath Sreedharan,  Michael Walker,  Daniel Szafir,  Tom Williams",
                "发布日期": "2023-06-21",
                "摘要": "  This paper describes TOBY, a visualization tool that helps a user explore the\ncontents of an academic survey paper. The visualization consists of four\ncomponents: a hierarchical view of taxonomic data in the survey, a document\nsimilarity view in the space of taxonomic classes, a network view of citations,\nand a new paper recommendation tool. In this paper, we will discuss these\nfeatures in the context of three separate deployments of the tool.\n",
                "链接": "https://arxiv.org/abs/2306.10051"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            }
        ]
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "41197",
                "标题": "\"Help Me Help the AI\": Understanding How Explainability Can Support\n  Human-AI Interaction",
                "作者": " Sunnie S. Y. Kim,  Elizabeth Anne Watkins,  Olga Russakovsky,  Ruth Fong,  Andrés Monroy-Hernández",
                "发布日期": "2023-02-20",
                "摘要": "  Despite the proliferation of explainable AI (XAI) methods, little is\nunderstood about end-users' explainability needs and behaviors around XAI\nexplanations. To address this gap and contribute to understanding how\nexplainability can support human-AI interaction, we conducted a mixed-methods\nstudy with 20 end-users of a real-world AI application, the Merlin bird\nidentification app, and inquired about their XAI needs, uses, and perceptions.\nWe found that participants desire practically useful information that can\nimprove their collaboration with the AI, more so than technical system details.\nRelatedly, participants intended to use XAI explanations for various purposes\nbeyond understanding the AI's outputs: calibrating trust, improving their task\nskills, changing their behavior to supply better inputs to the AI, and giving\nconstructive feedback to developers. Finally, among existing XAI approaches,\nparticipants preferred part-based explanations that resemble human reasoning\nand explanations. We discuss the implications of our findings and provide\nrecommendations for future XAI design.\n",
                "链接": "https://arxiv.org/abs/2210.03735"
            },
            {
                "文章ID": "71870",
                "标题": "Galactic ChitChat: Using Large Language Models to Converse with\n  Astronomy Literature",
                "作者": " Ioana Ciucă,  Yuan-Sen Ting",
                "发布日期": "2023-09-13",
                "摘要": "  We demonstrate the potential of the state-of-the-art OpenAI GPT-4 large\nlanguage model to engage in meaningful interactions with Astronomy papers using\nin-context prompting. To optimize for efficiency, we employ a distillation\ntechnique that effectively reduces the size of the original input paper by\n50\\%, while maintaining the paragraph structure and overall semantic integrity.\nWe then explore the model's responses using a multi-document context (ten\ndistilled documents). Our findings indicate that GPT-4 excels in the\nmulti-document domain, providing detailed answers contextualized within the\nframework of related research findings. Our results showcase the potential of\nlarge language models for the astronomical community, offering a promising\navenue for further exploration, particularly the possibility of utilizing the\nmodels for hypothesis generation.\n",
                "链接": "https://arxiv.org/abs/2304.05406"
            },
            {
                "文章ID": "4941",
                "标题": "Help Me Explore: Minimal Social Interventions for Graph-Based Autotelic\n  Agents",
                "作者": " Ahmed Akakzia,  Olivier Serris,  Olivier Sigaud,  Cédric Colas",
                "发布日期": "2022-02-11",
                "摘要": "  In the quest for autonomous agents learning open-ended repertoires of skills,\nmost works take a Piagetian perspective: learning trajectories are the results\nof interactions between developmental agents and their physical environment.\nThe Vygotskian perspective, on the other hand, emphasizes the centrality of the\nsocio-cultural environment: higher cognitive functions emerge from\ntransmissions of socio-cultural processes internalized by the agent. This paper\nargues that both perspectives could be coupled within the learning of autotelic\nagents to foster their skill acquisition. To this end, we make two\ncontributions: 1) a novel social interaction protocol called Help Me Explore\n(HME), where autotelic agents can benefit from both individual and socially\nguided exploration. In social episodes, a social partner suggests goals at the\nfrontier of the learning agent knowledge. In autotelic episodes, agents can\neither learn to master their own discovered goals or autonomously rehearse\nfailed social goals; 2) GANGSTR, a graph-based autotelic agent for manipulation\ndomains capable of decomposing goals into sequences of intermediate sub-goals.\nWe show that when learning within HME, GANGSTR overcomes its individual\nlearning limits by mastering the most complex configurations (e.g. stacks of 5\nblocks) with only few social interventions.\n",
                "链接": "https://arxiv.org/abs/2202.05129"
            },
            {
                "文章ID": "124874",
                "标题": "AHAM: Adapt, Help, Ask, Model -- Harvesting LLMs for literature mining",
                "作者": " Boshko Koloski,  Nada Lavrač,  Bojan Cestnik,  Senja Pollak,  Blaž Škrlj,  Andrej Kastrin",
                "发布日期": "2023-12-27",
                "摘要": "  In an era marked by a rapid increase in scientific publications, researchers\ngrapple with the challenge of keeping pace with field-specific advances. We\npresent the `AHAM' methodology and a metric that guides the domain-specific\n\\textbf{adapt}ation of the BERTopic topic modeling framework to improve\nscientific text analysis. By utilizing the LLaMa2 generative language model, we\ngenerate topic definitions via one-shot learning by crafting prompts with the\n\\textbf{help} of domain experts to guide the LLM for literature mining by\n\\textbf{asking} it to model the topic names. For inter-topic similarity\nevaluation, we leverage metrics from language generation and translation\nprocesses to assess lexical and semantic similarity of the generated topics.\nOur system aims to reduce both the ratio of outlier topics to the total number\nof topics and the similarity between topic definitions. The methodology has\nbeen assessed on a newly gathered corpus of scientific papers on\nliterature-based discovery. Through rigorous evaluation by domain experts, AHAM\nhas been validated as effective in uncovering intriguing and novel insights\nwithin broad research areas. We explore the impact of domain adaptation of\nsentence-transformers for the task of topic \\textbf{model}ing using two\ndatasets, each specialized to specific scientific domains within arXiv and\nmedarxiv. We evaluate the impact of data size, the niche of adaptation, and the\nimportance of domain adaptation. Our results suggest a strong interaction\nbetween domain adaptation and topic modeling precision in terms of outliers and\ntopic definitions.\n",
                "链接": "https://arxiv.org/abs/2312.15784"
            },
            {
                "文章ID": "97463",
                "标题": "Can Large Language Models Find And Fix Vulnerable Software?",
                "作者": " David Noever",
                "发布日期": "2023-08-22",
                "摘要": "  In this study, we evaluated the capability of Large Language Models (LLMs),\nparticularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing\ntheir performance against traditional static code analyzers like Snyk and\nFortify. Our analysis covered numerous repositories, including those from NASA\nand the Department of Defense. GPT-4 identified approximately four times the\nvulnerabilities than its counterparts. Furthermore, it provided viable fixes\nfor each vulnerability, demonstrating a low rate of false positives. Our tests\nencompassed 129 code samples across eight programming languages, revealing the\nhighest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to\na 90% reduction in vulnerabilities, requiring only an 11% increase in code\nlines. A critical insight was LLMs' ability to self-audit, suggesting fixes for\ntheir identified vulnerabilities and underscoring their precision. Future\nresearch should explore system-level vulnerabilities and integrate multiple\nstatic code analyzers for a holistic perspective on LLMs' potential.\n",
                "链接": "https://arxiv.org/abs/2308.10345"
            },
            {
                "文章ID": "57742",
                "标题": "Neural Architecture Search: Insights from 1000 Papers",
                "作者": " Colin White,  Mahmoud Safari,  Rhea Sukthanker,  Binxin Ru,  Thomas Elsken,  Arber Zela,  Debadeepta Dey,  Frank Hutter",
                "发布日期": "2023-01-26",
                "摘要": "  In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized\nand comprehensive guide to neural architecture search. We give a taxonomy of\nsearch spaces, algorithms, and speedup techniques, and we discuss resources\nsuch as benchmarks, best practices, other surveys, and open-source libraries.\n",
                "链接": "https://arxiv.org/abs/2301.08727"
            },
            {
                "文章ID": "33735",
                "标题": "HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create\n  Customized Content with Models",
                "作者": " Swaroop Mishra,  Elnaz Nouri",
                "发布日期": "2023-06-14",
                "摘要": "  Controlling the text generated by language models and customizing the content\nhas been a long-standing challenge. Existing prompting techniques proposed in\npursuit of providing control are task-specific and lack generality; this\nprovides overwhelming choices for non-expert users to find a suitable method\nfor their task. The effort associated with those techniques, such as in writing\nexamples, explanations, instructions, etc. further limits their adoption among\nnon-expert users. In this paper, we propose a simple prompting strategy HELP ME\nTHINK where we encourage GPT3 to help non-expert users by asking a set of\nrelevant questions and leveraging user answers to execute the task. We\ndemonstrate the efficacy of our technique HELP ME THINK on a variety of tasks.\nSpecifically, we focus on tasks that are hard for average humans and require\nsignificant thinking to perform. We hope our work will encourage the\ndevelopment of unconventional ways to harness the power of large language\nmodels.\n",
                "链接": "https://arxiv.org/abs/2208.08232"
            },
            {
                "文章ID": "84494",
                "标题": "covLLM: Large Language Models for COVID-19 Biomedical Literature",
                "作者": " Yousuf A. Khan,  Clarisse Hokia,  Jennifer Xu,  Ben Ehlert",
                "发布日期": "2023-06-09",
                "摘要": "  The COVID-19 pandemic led to 1.1 million deaths in the United States, despite\nthe explosion of coronavirus research. These new findings are slow to translate\nto clinical interventions, leading to poorer patient outcomes and unnecessary\ndeaths. One reason is that clinicians, overwhelmed by patients, struggle to\nkeep pace with the rate of new coronavirus literature. A potential solution is\ndeveloping a tool for evaluating coronavirus literature using large language\nmodels (LLMs) -- neural networks that are deployed for natural language\nprocessing. LLMs can be used to summarize and extract user-specified\ninformation. The greater availability and advancement of LLMs and pre-processed\ncoronavirus literature databases provide the opportunity to assist clinicians\nin evaluating coronavirus literature through a coronavirus literature specific\nLLM (covLLM), a tool that directly takes an inputted research article and a\nuser query to return an answer. Using the COVID-19 Open Research Dataset\n(CORD-19), we produced two datasets: (1) synCovid, which uses a combination of\nhandwritten prompts and synthetic prompts generated using OpenAI, and (2) real\nabstracts, which contains abstract and title pairs. covLLM was trained with\nLLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca\nand synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real\nabstract datasets. These models were evaluated by two human evaluators and\nChatGPT. Results demonstrate that training covLLM on the synCovid and abstract\npairs datasets performs competitively with ChatGPT and outperforms covLLM\ntrained primarily using the Alpaca dataset.\n",
                "链接": "https://arxiv.org/abs/2306.04926"
            },
            {
                "文章ID": "68539",
                "标题": "Hey Dona! Can you help me with student course registration?",
                "作者": " Vishesh Kalvakurthi,  Aparna S. Varde,  John Jenq",
                "发布日期": "2023-03-27",
                "摘要": "  In this paper, we present a demo of an intelligent personal agent called Hey\nDona (or just Dona) with virtual voice assistance in student course\nregistration. It is a deployed project in the theme of AI for education. In\nthis digital age with a myriad of smart devices, users often delegate tasks to\nagents. While pointing and clicking supersedes the erstwhile command-typing,\nmodern devices allow users to speak commands for agents to execute tasks,\nenhancing speed and convenience. In line with this progress, Dona is an\nintelligent agent catering to student needs by automated, voice-operated course\nregistration, spanning a multitude of accents, entailing task planning\noptimization, with some language translation as needed. Dona accepts voice\ninput by microphone (Bluetooth, wired microphone), converts human voice to\ncomputer understandable language, performs query processing as per user\ncommands, connects with the Web to search for answers, models task\ndependencies, imbibes quality control, and conveys output by speaking to users\nas well as displaying text, thus enabling human-AI interaction by speech cum\ntext. It is meant to work seamlessly on desktops, smartphones etc. and in\nindoor as well as outdoor settings. To the best of our knowledge, Dona is among\nthe first of its kind as an intelligent personal agent for voice assistance in\nstudent course registration. Due to its ubiquitous access for educational\nneeds, Dona directly impacts AI for education. It makes a broader impact on\nsmart city characteristics of smart living and smart people due to its\ncontributions to providing benefits for new ways of living and assisting 21st\ncentury education, respectively.\n",
                "链接": "https://arxiv.org/abs/2303.13548"
            },
            {
                "文章ID": "112727",
                "标题": "Efficient Classification of Student Help Requests in Programming Courses\n  Using Large Language Models",
                "作者": " Jaromir Savelka,  Paul Denny,  Mark Liffiton,  Brad Sheese",
                "发布日期": "2023-11-01",
                "摘要": "  The accurate classification of student help requests with respect to the type\nof help being sought can enable the tailoring of effective responses.\nAutomatically classifying such requests is non-trivial, but large language\nmodels (LLMs) appear to offer an accessible, cost-effective solution. This\nstudy evaluates the performance of the GPT-3.5 and GPT-4 models for classifying\nhelp requests from students in an introductory programming class. In zero-shot\ntrials, GPT-3.5 and GPT-4 exhibited comparable performance on most categories,\nwhile GPT-4 outperformed GPT-3.5 in classifying sub-categories for requests\nrelated to debugging. Fine-tuning the GPT-3.5 model improved its performance to\nsuch an extent that it approximated the accuracy and consistency across\ncategories observed between two human raters. Overall, this study demonstrates\nthe feasibility of using LLMs to enhance educational systems through the\nautomated classification of student needs.\n",
                "链接": "https://arxiv.org/abs/2310.20105"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "36500",
                "标题": "Tag-Aware Document Representation for Research Paper Recommendation",
                "作者": " Hebatallah A. Mohamed,  Giuseppe Sansonetti,  Alessandro Micarelli",
                "发布日期": "2022-09-09",
                "摘要": "  Finding online research papers relevant to one's interests is very\nchallenging due to the increasing number of publications. Therefore,\npersonalized research paper recommendation has become a significant and timely\nresearch topic. Collaborative filtering is a successful recommendation\napproach, which exploits the ratings given to items by users as a source of\ninformation for learning to make accurate recommendations. However, the ratings\nare often very sparse as in the research paper domain, due to the huge number\nof publications growing every year. Therefore, more attention has been drawn to\nhybrid methods that consider both ratings and content information.\nNevertheless, most of the hybrid recommendation approaches that are based on\ntext embedding have utilized bag-of-words techniques, which ignore word order\nand semantic meaning. In this paper, we propose a hybrid approach that\nleverages deep semantic representation of research papers based on social tags\nassigned by users. The experimental evaluation is performed on CiteULike, a\nreal and publicly available dataset. The obtained findings show that the\nproposed model is effective in recommending research papers even when the\nrating data is very sparse.\n",
                "链接": "https://arxiv.org/abs/2209.03660"
            },
            {
                "文章ID": "98511",
                "标题": "Kissing to Find a Match: Efficient Low-Rank Permutation Representation",
                "作者": " Hannah Dröge,  Zorah Lähner,  Yuval Bahat,  Onofre Martorell,  Felix Heide,  Michael Möller",
                "发布日期": "2023-08-28",
                "摘要": "  Permutation matrices play a key role in matching and assignment problems\nacross the fields, especially in computer vision and robotics. However, memory\nfor explicitly representing permutation matrices grows quadratically with the\nsize of the problem, prohibiting large problem instances. In this work, we\npropose to tackle the curse of dimensionality of large permutation matrices by\napproximating them using low-rank matrix factorization, followed by a\nnonlinearity. To this end, we rely on the Kissing number theory to infer the\nminimal rank required for representing a permutation matrix of a given size,\nwhich is significantly smaller than the problem size. This leads to a drastic\nreduction in computation and memory costs, e.g., up to $3$ orders of magnitude\nless memory for a problem of size $n=20000$, represented using $8.4\\times10^5$\nelements in two small matrices instead of using a single huge matrix with\n$4\\times 10^8$ elements. The proposed representation allows for accurate\nrepresentations of large permutation matrices, which in turn enables handling\nlarge problems that would have been infeasible otherwise. We demonstrate the\napplicability and merits of the proposed approach through a series of\nexperiments on a range of problems that involve predicting permutation\nmatrices, from linear and quadratic assignment to shape matching problems.\n",
                "链接": "https://arxiv.org/abs/2308.13252"
            },
            {
                "文章ID": "60173",
                "标题": "Proposing Novel Extrapolative Compounds by Nested Variational\n  Autoencoders",
                "作者": " Yoshihiro Osakabe,  Akinori Asahara",
                "发布日期": "2023-02-07",
                "摘要": "  Materials informatics (MI), which uses artificial intelligence and data\nanalysis techniques to improve the efficiency of materials development, is\nattracting increasing interest from industry. One of its main applications is\nthe rapid development of new high-performance compounds. Recently, several deep\ngenerative models have been proposed to suggest candidate compounds that are\nexpected to satisfy the desired performance. However, they usually have the\nproblem of requiring a large amount of experimental datasets for training to\nachieve sufficient accuracy. In actual cases, it is often possible to\naccumulate only about 1000 experimental data at most. Therefore, the authors\nproposed a deep generative model with nested two variational autoencoders\n(VAEs). The outer VAE learns the structural features of compounds using\nlarge-scale public data, while the inner VAE learns the relationship between\nthe latent variables of the outer VAE and the properties from small-scale\nexperimental data. To generate high performance compounds beyond the range of\nthe training data, the authors also proposed a loss function that amplifies the\ncorrelation between a component of latent variables of the inner VAE and\nmaterial properties. The results indicated that this loss function contributes\nto improve the probability of generating high-performance candidates.\nFurthermore, as a result of verification test with an actual customer in\nchemical industry, it was confirmed that the proposed method is effective in\nreducing the number of experiments to $1/4$ compared to a conventional method.\n",
                "链接": "https://arxiv.org/abs/2302.02555"
            },
            {
                "文章ID": "16842",
                "标题": "Extremal GloVe: Theoretically Accurate Distributed Word Embedding by\n  Tail Inference",
                "作者": " Hao Wang",
                "发布日期": "2022-04-28",
                "摘要": "  Distributed word embeddings such as Word2Vec and GloVe have been widely\nadopted in industrial context settings. Major technical applications of GloVe\ninclude recommender systems and natural language processing. The fundamental\ntheory behind GloVe relies on the selection of a weighting function in the\nweighted least squres formulation that computes the powered ratio of word\noccurrence count and the maximum word count in the corpus. However, the initial\nformulation of GloVe is not theoretically sound in two aspects, namely the\nselection of the weighting function and its power exponent is ad-hoc. In this\npaper, we utilize the theory of extreme value analysis and propose a\ntheoretically accurate version of GloVe. By reformulating the weighted least\nsquares loss function as the expected loss function and accurately choosing the\npower exponent, we create a theoretically accurate version of GloVe. We\ndemonstrate the competitiveness of our algorithm and show that the initial\nformulation of GloVe with the suggested optimal parameter can be viewed as a\nspecial case of our paradigm.\n",
                "链接": "https://arxiv.org/abs/2204.13009"
            },
            {
                "文章ID": "83545",
                "标题": "Discussion Paper: The Threat of Real Time Deepfakes",
                "作者": " Guy Frankovits,  Yisroel Mirsky",
                "发布日期": "2023-06-06",
                "摘要": "  Generative deep learning models are able to create realistic audio and video.\nThis technology has been used to impersonate the faces and voices of\nindividuals. These ``deepfakes'' are being used to spread misinformation,\nenable scams, perform fraud, and blackmail the innocent. The technology\ncontinues to advance and today attackers have the ability to generate deepfakes\nin real-time. This new capability poses a significant threat to society as\nattackers begin to exploit the technology in advances social engineering\nattacks. In this paper, we discuss the implications of this emerging threat,\nidentify the challenges with preventing these attacks and suggest a better\ndirection for researching stronger defences.\n",
                "链接": "https://arxiv.org/abs/2306.02487"
            },
            {
                "文章ID": "42603",
                "标题": "Multilingual Word Sense Disambiguation with Unified Sense Representation",
                "作者": " Ying Su,  Hongming Zhang,  Yangqiu Song,  Tong Zhang",
                "发布日期": "2022-10-17",
                "摘要": "  As a key natural language processing (NLP) task, word sense disambiguation\n(WSD) evaluates how well NLP models can understand the lexical semantics of\nwords under specific contexts. Benefited from the large-scale annotation,\ncurrent WSD systems have achieved impressive performances in English by\ncombining supervised learning with lexical knowledge. However, such success is\nhard to be replicated in other languages, where we only have limited\nannotations.In this paper, based on the multilingual lexicon BabelNet\ndescribing the same set of concepts across languages, we propose building\nknowledge and supervised-based Multilingual Word Sense Disambiguation (MWSD)\nsystems. We build unified sense representations for multiple languages and\naddress the annotation scarcity problem for MWSD by transferring annotations\nfrom rich-sourced languages to poorer ones. With the unified sense\nrepresentations, annotations from multiple languages can be jointly trained to\nbenefit the MWSD tasks. Evaluations of SemEval-13 and SemEval-15 datasets\ndemonstrate the effectiveness of our methodology.\n",
                "链接": "https://arxiv.org/abs/2210.07447"
            },
            {
                "文章ID": "49974",
                "标题": "Word-Level Representation From Bytes For Language Modeling",
                "作者": " Chu-Tak Lee,  Qipeng Guo,  Xipeng Qiu",
                "发布日期": "2022-11-24",
                "摘要": "  Modern language models mostly take sub-words as input, a design that balances\nthe trade-off between vocabulary size, number of parameters, and performance.\nHowever, sub-word tokenization still has disadvantages like not being robust to\nnoise and difficult to generalize to new languages. Also, the current trend of\nscaling up models reveals that larger models require larger embeddings but that\nmakes parallelization hard. Previous work on image classification proves\nsplitting raw input into a sequence of chucks is a strong, model-agnostic\ninductive bias. Based on this observation, we rethink the existing\ncharacter-aware method that takes character-level inputs but makes word-level\nsequence modeling and prediction. We overhaul this method by introducing a\ncross-attention network that builds word-level representation directly from\nbytes, and a sub-word level prediction based on word-level hidden states to\navoid the time and space requirement of word-level prediction. With these two\nimprovements combined, we have a token free model with slim input embeddings\nfor downstream tasks. We name our method Byte2Word and perform evaluations on\nlanguage modeling and text classification. Experiments show that Byte2Word is\non par with the strong sub-word baseline BERT but only takes up 10\\% of\nembedding size. We further test our method on synthetic noise and cross-lingual\ntransfer and find it competitive to baseline methods on both settings.\n",
                "链接": "https://arxiv.org/abs/2211.12677"
            },
            {
                "文章ID": "117266",
                "标题": "Proposing an intelligent mesh smoothing method with graph neural\n  networks",
                "作者": " Zhichao Wang,  Xinhai Chen,  Junjun Yan,  Jie Liu",
                "发布日期": "2023-11-23",
                "摘要": "  In CFD, mesh smoothing methods are commonly utilized to refine the mesh\nquality to achieve high-precision numerical simulations. Specifically,\noptimization-based smoothing is used for high-quality mesh smoothing, but it\nincurs significant computational overhead. Pioneer works improve its smoothing\nefficiency by adopting supervised learning to learn smoothing methods from\nhigh-quality meshes. However, they pose difficulty in smoothing the mesh nodes\nwith varying degrees and also need data augmentation to address the node input\nsequence problem. Additionally, the required labeled high-quality meshes\nfurther limit the applicability of the proposed method. In this paper, we\npresent GMSNet, a lightweight neural network model for intelligent mesh\nsmoothing. GMSNet adopts graph neural networks to extract features of the\nnode's neighbors and output the optimal node position. During smoothing, we\nalso introduce a fault-tolerance mechanism to prevent GMSNet from generating\nnegative volume elements. With a lightweight model, GMSNet can effectively\nsmoothing mesh nodes with varying degrees and remain unaffected by the order of\ninput data. A novel loss function, MetricLoss, is also developed to eliminate\nthe need for high-quality meshes, which provides a stable and rapid convergence\nduring training. We compare GMSNet with commonly used mesh smoothing methods on\ntwo-dimensional triangle meshes. The experimental results show that GMSNet\nachieves outstanding mesh smoothing performances with 5% model parameters of\nthe previous model, and attains 8.62 times faster than optimization-based\nsmoothing.\n",
                "链接": "https://arxiv.org/abs/2311.12815"
            },
            {
                "文章ID": "47238",
                "标题": "No Word Embedding Model Is Perfect: Evaluating the Representation\n  Accuracy for Social Bias in the Media",
                "作者": " Maximilian Spliethöver,  Maximilian Keiff,  Henning Wachsmuth",
                "发布日期": "2022-11-08",
                "摘要": "  News articles both shape and reflect public opinion across the political\nspectrum. Analyzing them for social bias can thus provide valuable insights,\nsuch as prevailing stereotypes in society and the media, which are often\nadopted by NLP models trained on respective data. Recent work has relied on\nword embedding bias measures, such as WEAT. However, several representation\nissues of embeddings can harm the measures' accuracy, including low-resource\nsettings and token frequency differences. In this work, we study what kind of\nembedding algorithm serves best to accurately measure types of social bias\nknown to exist in US online news articles. To cover the whole spectrum of\npolitical bias in the US, we collect 500k articles and review psychology\nliterature with respect to expected social bias. We then quantify social bias\nusing WEAT along with embedding algorithms that account for the aforementioned\nissues. We compare how models trained with the algorithms on news articles\nrepresent the expected social bias. Our results suggest that the standard way\nto quantify bias does not align well with knowledge from psychology. While the\nproposed algorithms reduce the~gap, they still do not fully match the\nliterature.\n",
                "链接": "https://arxiv.org/abs/2211.03634"
            },
            {
                "文章ID": "80551",
                "标题": "SPRING: Studying the Paper and Reasoning to Play Games",
                "作者": " Yue Wu,  Shrimai Prabhumoye,  So Yeon Min,  Yonatan Bisk,  Ruslan Salakhutdinov,  Amos Azaria,  Tom Mitchell,  Yuanzhi Li",
                "发布日期": "2023-12-13",
                "摘要": "  Open-world survival games pose significant challenges for AI algorithms due\nto their multi-tasking, deep exploration, and goal prioritization requirements.\nDespite reinforcement learning (RL) being popular for solving games, its high\nsample complexity limits its effectiveness in complex open-world games like\nCrafter or Minecraft. We propose a novel approach, SPRING, to read the game's\noriginal academic paper and use the knowledge learned to reason and play the\ngame through a large language model (LLM). Prompted with the LaTeX source as\ngame context and a description of the agent's current observation, our SPRING\nframework employs a directed acyclic graph (DAG) with game-related questions as\nnodes and dependencies as edges. We identify the optimal action to take in the\nenvironment by traversing the DAG and calculating LLM responses for each node\nin topological order, with the LLM's answer to final node directly translating\nto environment actions. In our experiments, we study the quality of in-context\n\"reasoning\" induced by different forms of prompts under the setting of the\nCrafter open-world environment. Our experiments suggest that LLMs, when\nprompted with consistent chain-of-thought, have great potential in completing\nsophisticated high-level trajectories. Quantitatively, SPRING with GPT-4\noutperforms all state-of-the-art RL baselines, trained for 1M steps, without\nany training. Finally, we show the potential of games as a test bed for LLMs.\n",
                "链接": "https://arxiv.org/abs/2305.15486"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "64184",
                "标题": "Mitigating Skewed Bidding for Conference Paper Assignment",
                "作者": " Inbal Rozencweig,  Reshef Meir,  Nick Mattei,  Ofra Amir",
                "发布日期": "2023-03-02",
                "摘要": "  The explosion of conference paper submissions in AI and related fields, has\nunderscored the need to improve many aspects of the peer review process,\nespecially the matching of papers and reviewers. Recent work argues that the\nkey to improve this matching is to modify aspects of the \\emph{bidding phase}\nitself, to ensure that the set of bids over papers is balanced, and in\nparticular to avoid \\emph{orphan papers}, i.e., those papers that receive no\nbids. In an attempt to understand and mitigate this problem, we have developed\na flexible bidding platform to test adaptations to the bidding process. Using\nthis platform, we performed a field experiment during the bidding phase of a\nmedium-size international workshop that compared two bidding methods. We\nfurther examined via controlled experiments on Amazon Mechanical Turk various\nfactors that affect bidding, in particular the order in which papers are\npresented \\cite{cabanac2013capitalizing,fiez2020super}; and information on\npaper demand \\cite{meir2021market}. Our results suggest that several simple\nadaptations, that can be added to any existing platform, may significantly\nreduce the skew in bids, thereby improving the allocation for both reviewers\nand conference organizers.\n",
                "链接": "https://arxiv.org/abs/2303.00435"
            },
            {
                "文章ID": "30800",
                "标题": "Information Processing Equalities and the Information-Risk Bridge",
                "作者": " Robert C. Williamson,  Zac Cranko",
                "发布日期": "2023-09-11",
                "摘要": "  We introduce two new classes of measures of information for statistical\nexperiments which generalise and subsume $\\phi$-divergences, integral\nprobability metrics, $\\mathfrak{N}$-distances (MMD), and $(f,\\Gamma)$\ndivergences between two or more distributions. This enables us to derive a\nsimple geometrical relationship between measures of information and the Bayes\nrisk of a statistical decision problem, thus extending the variational\n$\\phi$-divergence representation to multiple distributions in an entirely\nsymmetric manner. The new families of divergence are closed under the action of\nMarkov operators which yields an information processing equality which is a\nrefinement and generalisation of the classical data processing inequality. This\nequality gives insight into the significance of the choice of the hypothesis\nclass in classical risk minimization.\n",
                "链接": "https://arxiv.org/abs/2207.11987"
            },
            {
                "文章ID": "100432",
                "标题": "Information Processing by Neuron Populations in the Central Nervous\n  System: Mathematical Structure of Data and Operations",
                "作者": " Martin N. P. Nilsson",
                "发布日期": "2023-09-07",
                "摘要": "  In the intricate architecture of the mammalian central nervous system,\nneurons form populations. Axonal bundles communicate between these clusters\nusing spike trains as their medium. However, these neuron populations' precise\nencoding and operations have yet to be discovered. In our analysis, the\nstarting point is a state-of-the-art mechanistic model of a generic neuron\nendowed with plasticity. From this simple framework emerges a profound\nmathematical construct: The representation and manipulation of information can\nbe precisely characterized by an algebra of finite convex cones. Furthermore,\nthese neuron populations are not merely passive transmitters. They act as\noperators within this algebraic structure, mirroring the functionality of a\nlow-level programming language. When these populations interconnect, they\nembody succinct yet potent algebraic expressions. These networks allow them to\nimplement many operations, such as specialization, generalization, novelty\ndetection, dimensionality reduction, inverse modeling, prediction, and\nassociative memory. In broader terms, this work illuminates the potential of\nmatrix embeddings in advancing our understanding in fields like cognitive\nscience and AI. These embeddings enhance the capacity for concept processing\nand hierarchical description over their vector counterparts.\n",
                "链接": "https://arxiv.org/abs/2309.02332"
            },
            {
                "文章ID": "29358",
                "标题": "Context-sensitive neocortical neurons transform the effectiveness and\n  efficiency of neural information processing",
                "作者": " Ahsan Adeel,  Mario Franco,  Mohsin Raza,  Khubaib Ahmed",
                "发布日期": "2023-04-05",
                "摘要": "  Deep learning (DL) has big-data processing capabilities that are as good, or\neven better, than those of humans in many real-world domains, but at the cost\nof high energy requirements that may be unsustainable in some applications and\nof errors, that, though infrequent, can be large. We hypothesise that a\nfundamental weakness of DL lies in its intrinsic dependence on\nintegrate-and-fire point neurons that maximise information transmission\nirrespective of whether it is relevant in the current context or not. This\nleads to unnecessary neural firing and to the feedforward transmission of\nconflicting messages, which makes learning difficult and processing energy\ninefficient. Here we show how to circumvent these limitations by mimicking the\ncapabilities of context-sensitive neocortical neurons that receive input from\ndiverse sources as a context to amplify and attenuate the transmission of\nrelevant and irrelevant information, respectively. We demonstrate that a deep\nnetwork composed of such local processors seeks to maximise agreement between\nthe active neurons, thus restricting the transmission of conflicting\ninformation to higher levels and reducing the neural activity required to\nprocess large amounts of heterogeneous real-world data. As shown to be far more\neffective and efficient than current forms of DL, this two-point neuron study\noffers a possible step-change in transforming the cellular foundations of deep\nnetwork architectures.\n",
                "链接": "https://arxiv.org/abs/2207.07338"
            },
            {
                "文章ID": "111729",
                "标题": "The IMS Toucan System for the Blizzard Challenge 2023",
                "作者": " Florian Lux,  Julia Koch,  Sarina Meyer,  Thomas Bott,  Nadja Schauffler,  Pavel Denisov,  Antje Schweitzer,  Ngoc Thang Vu",
                "发布日期": "2023-10-27",
                "摘要": "  For our contribution to the Blizzard Challenge 2023, we improved on the\nsystem we submitted to the Blizzard Challenge 2021. Our approach entails a\nrule-based text-to-phoneme processing system that includes rule-based\ndisambiguation of homographs in the French language. It then transforms the\nphonemes to spectrograms as intermediate representations using a fast and\nefficient non-autoregressive synthesis architecture based on Conformer and\nGlow. A GAN based neural vocoder that combines recent state-of-the-art\napproaches converts the spectrogram to the final wave. We carefully designed\nthe data processing, training, and inference procedures for the challenge data.\nOur system identifier is G. Open source code and demo are available.\n",
                "链接": "https://arxiv.org/abs/2310.17499"
            },
            {
                "文章ID": "98098",
                "标题": "Reranking Passages with Coarse-to-Fine Neural Retriever using\n  List-Context Information",
                "作者": " Hongyin Zhu",
                "发布日期": "2023-08-24",
                "摘要": "  Passage reranking is a crucial task in many applications, particularly when\ndealing with large-scale documents. Traditional neural architectures are\nlimited in retrieving the best passage for a question because they usually\nmatch the question to each passage separately, seldom considering contextual\ninformation in other passages that can provide comparison and reference\ninformation. This paper presents a list-context attention mechanism to augment\nthe passage representation by incorporating the list-context information from\nother candidates. The proposed coarse-to-fine (C2F) neural retriever addresses\nthe out-of-memory limitation of the passage attention mechanism by dividing the\nlist-context modeling process into two sub-processes, allowing for efficient\nencoding of context information from a large number of candidate answers. This\nmethod can be generally used to encode context information from any number of\ncandidate answers in one pass. Different from most multi-stage information\nretrieval architectures, this model integrates the coarse and fine rankers into\nthe joint optimization process, allowing for feedback between the two layers to\nupdate the model simultaneously. Experiments demonstrate the effectiveness of\nthe proposed approach.\n",
                "链接": "https://arxiv.org/abs/2308.12022"
            },
            {
                "文章ID": "84485",
                "标题": "NOWJ at COLIEE 2023 -- Multi-Task and Ensemble Approaches in Legal\n  Information Processing",
                "作者": " Thi-Hai-Yen Vuong,  Hai-Long Nguyen,  Tan-Minh Nguyen,  Hoang-Trung Nguyen,  Thai-Binh Nguyen,  Ha-Thanh Nguyen",
                "发布日期": "2023-06-09",
                "摘要": "  This paper presents the NOWJ team's approach to the COLIEE 2023 Competition,\nwhich focuses on advancing legal information processing techniques and applying\nthem to real-world legal scenarios. Our team tackles the four tasks in the\ncompetition, which involve legal case retrieval, legal case entailment, statute\nlaw retrieval, and legal textual entailment. We employ state-of-the-art machine\nlearning models and innovative approaches, such as BERT, Longformer,\nBM25-ranking algorithm, and multi-task learning models. Although our team did\nnot achieve state-of-the-art results, our findings provide valuable insights\nand pave the way for future improvements in legal information processing.\n",
                "链接": "https://arxiv.org/abs/2306.04903"
            },
            {
                "文章ID": "35693",
                "标题": "Quantum-Classical Hybrid Information Processing via a Single Quantum\n  System",
                "作者": " Quoc Hoan Tran,  Sanjib Ghosh,  Kohei Nakajima",
                "发布日期": "2022-09-02",
                "摘要": "  Current technologies in quantum-based communications bring a new integration\nof quantum data with classical data for hybrid processing. However, the\nframeworks of these technologies are restricted to a single classical or\nquantum task, which limits their flexibility in near-term applications. We\npropose a quantum reservoir processor to harness quantum dynamics in\ncomputational tasks requiring both classical and quantum inputs. This analog\nprocessor comprises a network of quantum dots in which quantum data is incident\nto the network and classical data is encoded via a coherent field exciting the\nnetwork. We perform a multitasking application of quantum tomography and\nnonlinear equalization of classical channels. Interestingly, the tomography can\nbe performed in a closed-loop manner via the feedback control of classical\ndata. Therefore, if the classical input comes from a dynamical system,\nembedding this system in a closed loop enables hybrid processing even if access\nto the external classical input is interrupted. Finally, we demonstrate\npreparing quantum depolarizing channels as a novel quantum machine learning\ntechnique for quantum data processing.\n",
                "链接": "https://arxiv.org/abs/2209.00497"
            },
            {
                "文章ID": "97432",
                "标题": "The DKU-DUKEECE System for the Manipulation Region Location Task of ADD\n  2023",
                "作者": " Zexin Cai,  Weiqing Wang,  Yikang Wang,  Ming Li",
                "发布日期": "2023-08-22",
                "摘要": "  This paper introduces our system designed for Track 2, which focuses on\nlocating manipulated regions, in the second Audio Deepfake Detection Challenge\n(ADD 2023). Our approach involves the utilization of multiple detection systems\nto identify splicing regions and determine their authenticity. Specifically, we\ntrain and integrate two frame-level systems: one for boundary detection and the\nother for deepfake detection. Additionally, we employ a third VAE model trained\nexclusively on genuine data to determine the authenticity of a given audio\nclip. Through the fusion of these three systems, our top-performing solution\nfor the ADD challenge achieves an impressive 82.23% sentence accuracy and an F1\nscore of 60.66%. This results in a final ADD score of 0.6713, securing the\nfirst rank in Track 2 of ADD 2023.\n",
                "链接": "https://arxiv.org/abs/2308.10281"
            },
            {
                "文章ID": "99747",
                "标题": "The FruitShell French synthesis system at the Blizzard 2023 Challenge",
                "作者": " Xin Qi,  Xiaopeng Wang,  Zhiyong Wang,  Wang Liu,  Mingming Ding,  Shuchen Shi",
                "发布日期": "2023-09-04",
                "摘要": "  This paper presents a French text-to-speech synthesis system for the Blizzard\nChallenge 2023. The challenge consists of two tasks: generating high-quality\nspeech from female speakers and generating speech that closely resembles\nspecific individuals. Regarding the competition data, we conducted a screening\nprocess to remove missing or erroneous text data. We organized all symbols\nexcept for phonemes and eliminated symbols that had no pronunciation or zero\nduration. Additionally, we added word boundary and start/end symbols to the\ntext, which we have found to improve speech quality based on our previous\nexperience. For the Spoke task, we performed data augmentation according to the\ncompetition rules. We used an open-source G2P model to transcribe the French\ntexts into phonemes. As the G2P model uses the International Phonetic Alphabet\n(IPA), we applied the same transcription process to the provided competition\ndata for standardization. However, due to compiler limitations in recognizing\nspecial symbols from the IPA chart, we followed the rules to convert all\nphonemes into the phonetic scheme used in the competition data. Finally, we\nresampled all competition audio to a uniform sampling rate of 16 kHz. We\nemployed a VITS-based acoustic model with the hifigan vocoder. For the Spoke\ntask, we trained a multi-speaker model and incorporated speaker information\ninto the duration predictor, vocoder, and flow layers of the model. The\nevaluation results of our system showed a quality MOS score of 3.6 for the Hub\ntask and 3.4 for the Spoke task, placing our system at an average level among\nall participating teams.\n",
                "链接": "https://arxiv.org/abs/2309.00223"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "41191",
                "标题": "Understanding Practices, Challenges, and Opportunities for User-Engaged\n  Algorithm Auditing in Industry Practice",
                "作者": " Wesley Hanwen Deng,  Bill Boyuan Guo,  Alicia DeVrio,  Hong Shen,  Motahhare Eslami,  Kenneth Holstein",
                "发布日期": "2023-02-22",
                "摘要": "  Recent years have seen growing interest among both researchers and\npractitioners in user-engaged approaches to algorithm auditing, which directly\nengage users in detecting problematic behaviors in algorithmic systems.\nHowever, we know little about industry practitioners' current practices and\nchallenges around user-engaged auditing, nor what opportunities exist for them\nto better leverage such approaches in practice. To investigate, we conducted a\nseries of interviews and iterative co-design activities with practitioners who\nemploy user-engaged auditing approaches in their work. Our findings reveal\nseveral challenges practitioners face in appropriately recruiting and\nincentivizing user auditors, scaffolding user audits, and deriving actionable\ninsights from user-engaged audit reports. Furthermore, practitioners shared\norganizational obstacles to user-engaged auditing, surfacing a complex\nrelationship between practitioners and user auditors. Based on these findings,\nwe discuss opportunities for future HCI research to help realize the potential\n(and the mitigate risks) of user-engaged auditing in industry practice.\n",
                "链接": "https://arxiv.org/abs/2210.03709"
            },
            {
                "文章ID": "90924",
                "标题": "Digital Health Discussion Through Articles Published Until the Year\n  2021: A Digital Topic Modeling Approach",
                "作者": " Junhyoun Sung,  Hyungsook Kim",
                "发布日期": "2023-09-20",
                "摘要": "  The digital health industry has grown in popularity since the 2010s, but\nthere has been limited analysis of the topics discussed in the field across\nacademic disciplines. This study aims to analyze the research trends of digital\nhealth-related articles published on the Web of Science until 2021, in order to\nunderstand the concentration, scope, and characteristics of the research.\n15,950 digital health-related papers from the top 10 academic fields were\nanalyzed using the Web of Science. The papers were grouped into three domains:\npublic health, medicine, and electrical engineering and computer science\n(EECS). Two time periods (2012-2016 and 2017-2021) were compared using Latent\nDirichlet Allocation (LDA) for topic modeling. The number of topics was\ndetermined based on coherence score, and topic compositions were compared using\na homogeneity test. The number of optimal topics varied across domains and time\nperiods. For public health, the first and second halves had 13 and 19 topics,\nrespectively. Medicine had 14 and 25 topics, and EECS had 7 and 21 topics. Text\nanalysis revealed shared topics among the domains, but with variations in\ncomposition. The homogeneity test confirmed significant differences between the\ngroups (adjusted p-value<0.05). Six dominant themes emerged, including journal\narticle methodology, information technology, medical issues, population\ndemographics, social phenomena, and healthcare. Digital health research is\nexpanding and evolving, particularly in relation to Covid-19, where topics such\nas depression and mental disorders, education, and physical activity have\ngained prominence. There was no bias in topic composition among the three\ndomains, but other fields like kinesiology or psychology could contribute to\nfuture digital health research. Exploring expanded topics that reflect people's\nneeds for digital health over time will be crucial.\n",
                "链接": "https://arxiv.org/abs/2307.07130"
            },
            {
                "文章ID": "16810",
                "标题": "Capabilities and Skills in Manufacturing: A Survey Over the Last Decade\n  of ETFA",
                "作者": " Roman Froschauer,  Aljosha Köcher,  Kristof Meixner,  Siwara Schmitt,  Fabian Spitzer",
                "发布日期": "2022-11-07",
                "摘要": "  Industry 4.0 envisions Cyber-Physical Production Systems (CPPSs) to foster\nadaptive production of mass-customizable products. Manufacturing approaches\nbased on capabilities and skills aim to support this adaptability by\nencapsulating machine functions and decoupling them from specific production\nprocesses. At the 2022 IEEE conference on Emerging Technologies and Factory\nAutomation (ETFA), a special session on capability- and skill-based\nmanufacturing is hosted for the fourth time. However, an overview on\ncapability- and skill based systems in factory automation and manufacturing\nsystems is missing. This paper aims to provide such an overview and give\ninsights to this particular field of research. We conducted a concise\nliterature survey of papers covering the topics of capabilities and skills in\nmanufacturing from the last ten years of the ETFA conference. We found 247\npapers with a notion on capabilities and skills and identified and analyzed 34\nrelevant papers which met this survey's inclusion criteria. In this paper, we\nprovide (i) an overview of the research field, (ii) an analysis of the\ncharacteristics of capabilities and skills, and (iii) a discussion on gaps and\nopportunities.\n",
                "链接": "https://arxiv.org/abs/2204.12908"
            },
            {
                "文章ID": "85110",
                "标题": "Investigating Practices and Opportunities for Cross-functional\n  Collaboration around AI Fairness in Industry Practice",
                "作者": " Wesley Hanwen Deng,  Nur Yildirim,  Monica Chang,  Motahhare Eslami,  Ken Holstein,  Michael Madaio",
                "发布日期": "2023-06-13",
                "摘要": "  An emerging body of research indicates that ineffective cross-functional\ncollaboration -- the interdisciplinary work done by industry practitioners\nacross roles -- represents a major barrier to addressing issues of fairness in\nAI design and development. In this research, we sought to better understand\npractitioners' current practices and tactics to enact cross-functional\ncollaboration for AI fairness, in order to identify opportunities to support\nmore effective collaboration. We conducted a series of interviews and design\nworkshops with 23 industry practitioners spanning various roles from 17\ncompanies. We found that practitioners engaged in bridging work to overcome\nfrictions in understanding, contextualization, and evaluation around AI\nfairness across roles. In addition, in organizational contexts with a lack of\nresources and incentives for fairness work, practitioners often piggybacked on\nexisting requirements (e.g., for privacy assessments) and AI development norms\n(e.g., the use of quantitative evaluation metrics), although they worry that\nthese tactics may be fundamentally compromised. Finally, we draw attention to\nthe invisible labor that practitioners take on as part of this bridging and\npiggybacking work to enact interdisciplinary collaboration for fairness. We\nclose by discussing opportunities for both FAccT researchers and AI\npractitioners to better support cross-functional collaboration for fairness in\nthe design and development of AI systems.\n",
                "链接": "https://arxiv.org/abs/2306.06542"
            },
            {
                "文章ID": "86605",
                "标题": "LaDe: The First Comprehensive Last-mile Delivery Dataset from Industry",
                "作者": " Lixia Wu,  Haomin Wen,  Haoyuan Hu,  Xiaowei Mao,  Yutong Xia,  Ergang Shan,  Jianbin Zhen,  Junhong Lou,  Yuxuan Liang,  Liuqing Yang,  Roger Zimmermann,  Youfang Lin,  Huaiyu Wan",
                "发布日期": "2023-06-21",
                "摘要": "  Real-world last-mile delivery datasets are crucial for research in logistics,\nsupply chain management, and spatio-temporal data mining. Despite a plethora of\nalgorithms developed to date, no widely accepted, publicly available last-mile\ndelivery dataset exists to support research in this field. In this paper, we\nintroduce \\texttt{LaDe}, the first publicly available last-mile delivery\ndataset with millions of packages from the industry. LaDe has three unique\ncharacteristics: (1) Large-scale. It involves 10,677k packages of 21k couriers\nover 6 months of real-world operation. (2) Comprehensive information. It offers\noriginal package information, such as its location and time requirements, as\nwell as task-event information, which records when and where the courier is\nwhile events such as task-accept and task-finish events happen. (3) Diversity.\nThe dataset includes data from various scenarios, including package pick-up and\ndelivery, and from multiple cities, each with its unique spatio-temporal\npatterns due to their distinct characteristics such as populations. We verify\nLaDe on three tasks by running several classical baseline models per task. We\nbelieve that the large-scale, comprehensive, diverse feature of LaDe can offer\nunparalleled opportunities to researchers in the supply chain community, data\nmining community, and beyond. The dataset homepage is publicly available at\nhttps://huggingface.co/datasets/Cainiao-AI/LaDe.\n",
                "链接": "https://arxiv.org/abs/2306.10675"
            },
            {
                "文章ID": "28727",
                "标题": "Machine Learning Security in Industry: A Quantitative Survey",
                "作者": " Kathrin Grosse,  Lukas Bieringer,  Tarek Richard Besold,  Battista Biggio,  Katharina Krombholz",
                "发布日期": "2023-03-13",
                "摘要": "  Despite the large body of academic work on machine learning security, little\nis known about the occurrence of attacks on machine learning systems in the\nwild. In this paper, we report on a quantitative study with 139 industrial\npractitioners. We analyze attack occurrence and concern and evaluate\nstatistical hypotheses on factors influencing threat perception and exposure.\nOur results shed light on real-world attacks on deployed machine learning. On\nthe organizational level, while we find no predictors for threat exposure in\nour sample, the amount of implement defenses depends on exposure to threats or\nexpected likelihood to become a target. We also provide a detailed analysis of\npractitioners' replies on the relevance of individual machine learning attacks,\nunveiling complex concerns like unreliable decision making, business\ninformation leakage, and bias introduction into models. Finally, we find that\non the individual level, prior knowledge about machine learning security\ninfluences threat perception. Our work paves the way for more research about\nadversarial machine learning in practice, but yields also insights for\nregulation and auditing.\n",
                "链接": "https://arxiv.org/abs/2207.05164"
            },
            {
                "文章ID": "74487",
                "标题": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond",
                "作者": " Jingfeng Yang,  Hongye Jin,  Ruixiang Tang,  Xiaotian Han,  Qizhang Feng,  Haoming Jiang,  Bing Yin,  Xia Hu",
                "发布日期": "2023-04-28",
                "摘要": "  This paper presents a comprehensive and practical guide for practitioners and\nend-users working with Large Language Models (LLMs) in their downstream natural\nlanguage processing (NLP) tasks. We provide discussions and insights into the\nusage of LLMs from the perspectives of models, data, and downstream tasks.\nFirstly, we offer an introduction and brief summary of current GPT- and\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training\ndata, and test data. Most importantly, we provide a detailed discussion about\nthe use and non-use cases of large language models for various natural language\nprocessing tasks, such as knowledge-intensive tasks, traditional natural\nlanguage understanding tasks, natural language generation tasks, emergent\nabilities, and considerations for specific tasks.We present various use cases\nand non-use cases to illustrate the practical applications and limitations of\nLLMs in real-world scenarios. We also try to understand the importance of data\nand the specific challenges associated with each NLP task. Furthermore, we\nexplore the impact of spurious biases on LLMs and delve into other essential\nconsiderations, such as efficiency, cost, and latency, to ensure a\ncomprehensive understanding of deploying LLMs in practice. This comprehensive\nguide aims to provide researchers and practitioners with valuable insights and\nbest practices for working with LLMs, thereby enabling the successful\nimplementation of these models in a wide range of NLP tasks. A curated list of\npractical guide resources of LLMs, regularly updated, can be found at\n\\url{https://github.com/Mooler0410/LLMsPracticalGuide}.\n",
                "链接": "https://arxiv.org/abs/2304.13712"
            },
            {
                "文章ID": "20119",
                "标题": "Survey on Fair Reinforcement Learning: Theory and Practice",
                "作者": " Pratik Gajane,  Akrati Saxena,  Maryam Tavakol,  George Fletcher,  Mykola Pechenizkiy",
                "发布日期": "2022-05-23",
                "摘要": "  Fairness-aware learning aims at satisfying various fairness constraints in\naddition to the usual performance criteria via data-driven machine learning\ntechniques. Most of the research in fairness-aware learning employs the setting\nof fair-supervised learning. However, many dynamic real-world applications can\nbe better modeled using sequential decision-making problems and fair\nreinforcement learning provides a more suitable alternative for addressing\nthese problems. In this article, we provide an extensive overview of fairness\napproaches that have been implemented via a reinforcement learning (RL)\nframework. We discuss various practical applications in which RL methods have\nbeen applied to achieve a fair solution with high accuracy. We further include\nvarious facets of the theory of fair reinforcement learning, organizing them\ninto single-agent RL, multi-agent RL, long-term fairness via RL, and offline\nlearning. Moreover, we highlight a few major issues to explore in order to\nadvance the field of fair-RL, namely - i) correcting societal biases, ii)\nfeasibility of group fairness or individual fairness, and iii) explainability\nin RL. Our work is beneficial for both researchers and practitioners as we\ndiscuss articles providing mathematical guarantees as well as articles with\nempirical studies on real-world problems.\n",
                "链接": "https://arxiv.org/abs/2205.10032"
            },
            {
                "文章ID": "78032",
                "标题": "A Survey on Causal Discovery: Theory and Practice",
                "作者": " Alessio Zanga,  Fabio Stella",
                "发布日期": "2023-11-03",
                "摘要": "  Understanding the laws that govern a phenomenon is the core of scientific\nprogress. This is especially true when the goal is to model the interplay\nbetween different aspects in a causal fashion. Indeed, causal inference itself\nis specifically designed to quantify the underlying relationships that connect\na cause to its effect. Causal discovery is a branch of the broader field of\ncausality in which causal graphs is recovered from data (whenever possible),\nenabling the identification and estimation of causal effects. In this paper, we\nexplore recent advancements in a unified manner, provide a consistent overview\nof existing algorithms developed under different settings, report useful tools\nand data, present real-world applications to understand why and how these\nmethods can be fruitfully exploited.\n",
                "链接": "https://arxiv.org/abs/2305.10032"
            },
            {
                "文章ID": "86386",
                "标题": "TOBY: A Tool for Exploring Data in Academic Survey Papers",
                "作者": " Tathagata Chakraborti,  Jungkoo Kang,  Christian Muise,  Sarath Sreedharan,  Michael Walker,  Daniel Szafir,  Tom Williams",
                "发布日期": "2023-06-21",
                "摘要": "  This paper describes TOBY, a visualization tool that helps a user explore the\ncontents of an academic survey paper. The visualization consists of four\ncomponents: a hierarchical view of taxonomic data in the survey, a document\nsimilarity view in the space of taxonomic classes, a network view of citations,\nand a new paper recommendation tool. In this paper, we will discuss these\nfeatures in the context of three separate deployments of the tool.\n",
                "链接": "https://arxiv.org/abs/2306.10051"
            }
        ]
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "24967",
                "标题": "Adversarial Privacy Protection on Speech Enhancement",
                "作者": " Mingyu Dong,  Diqun Yan,  Rangding Wang",
                "发布日期": "2022-06-17",
                "摘要": "  Speech is easily leaked imperceptibly, such as being recorded by mobile\nphones in different situations. Private content in speech may be maliciously\nextracted through speech enhancement technology. Speech enhancement technology\nhas developed rapidly along with deep neural networks (DNNs), but adversarial\nexamples can cause DNNs to fail. In this work, we propose an adversarial method\nto degrade speech enhancement systems. Experimental results show that generated\nadversarial examples can erase most content information in original examples or\nreplace it with target speech content through speech enhancement. The word\nerror rate (WER) between an enhanced original example and enhanced adversarial\nexample recognition result can reach 89.0%. WER of target attack between\nenhanced adversarial example and target example is low to 33.75% . Adversarial\nperturbation can bring the rate of change to the original example to more than\n1.4430. This work can prevent the malicious extraction of speech.\n",
                "链接": "https://arxiv.org/abs/2206.08170"
            },
            {
                "文章ID": "84613",
                "标题": "Ownership Protection of Generative Adversarial Networks",
                "作者": " Hailong Hu,  Jun Pang",
                "发布日期": "2023-06-09",
                "摘要": "  Generative adversarial networks (GANs) have shown remarkable success in image\nsynthesis, making GAN models themselves commercially valuable to legitimate\nmodel owners. Therefore, it is critical to technically protect the intellectual\nproperty of GANs. Prior works need to tamper with the training set or training\nprocess, and they are not robust to emerging model extraction attacks. In this\npaper, we propose a new ownership protection method based on the common\ncharacteristics of a target model and its stolen models. Our method can be\ndirectly applicable to all well-trained GANs as it does not require retraining\ntarget models. Extensive experimental results show that our new method can\nachieve the best protection performance, compared to the state-of-the-art\nmethods. Finally, we demonstrate the effectiveness of our method with respect\nto the number of generations of model extraction attacks, the number of\ngenerated samples, different datasets, as well as adaptive attacks.\n",
                "链接": "https://arxiv.org/abs/2306.05233"
            },
            {
                "文章ID": "62837",
                "标题": "How Generative AI models such as ChatGPT can be (Mis)Used in SPC\n  Practice, Education, and Research? An Exploratory Study",
                "作者": " Fadel M. Megahed,  Ying-Ju Chen,  Joshua A. Ferris,  Sven Knoth,  L. Allison Jones-Farmer",
                "发布日期": "2023-06-19",
                "摘要": "  Generative Artificial Intelligence (AI) models such as OpenAI's ChatGPT have\nthe potential to revolutionize Statistical Process Control (SPC) practice,\nlearning, and research. However, these tools are in the early stages of\ndevelopment and can be easily misused or misunderstood. In this paper, we give\nan overview of the development of Generative AI. Specifically, we explore\nChatGPT's ability to provide code, explain basic concepts, and create knowledge\nrelated to SPC practice, learning, and research. By investigating responses to\nstructured prompts, we highlight the benefits and limitations of the results.\nOur study indicates that the current version of ChatGPT performs well for\nstructured tasks, such as translating code from one language to another and\nexplaining well-known concepts but struggles with more nuanced tasks, such as\nexplaining less widely known terms and creating code from scratch. We find that\nusing new AI tools may help practitioners, educators, and researchers to be\nmore efficient and productive. However, in their current stages of development,\nsome results are misleading and wrong. Overall, the use of generative AI models\nin SPC must be properly validated and used in conjunction with other methods to\nensure accurate results.\n",
                "链接": "https://arxiv.org/abs/2302.10916"
            },
            {
                "文章ID": "62800",
                "标题": "On Provable Copyright Protection for Generative Models",
                "作者": " Nikhil Vyas,  Sham Kakade,  Boaz Barak",
                "发布日期": "2023-07-24",
                "摘要": "  There is a growing concern that learned conditional generative models may\noutput samples that are substantially similar to some copyrighted data $C$ that\nwas in their training set. We give a formal definition of $\\textit{near\naccess-freeness (NAF)}$ and prove bounds on the probability that a model\nsatisfying this definition outputs a sample similar to $C$, even if $C$ is\nincluded in its training set. Roughly speaking, a generative model $p$ is\n$\\textit{$k$-NAF}$ if for every potentially copyrighted data $C$, the output of\n$p$ diverges by at most $k$-bits from the output of a model $q$ that\n$\\textit{did not access $C$ at all}$. We also give generative model learning\nalgorithms, which efficiently modify the original generative model learning\nalgorithm in a black box manner, that output generative models with strong\nbounds on the probability of sampling protected content. Furthermore, we\nprovide promising experiments for both language (transformers) and image\n(diffusion) generative models, showing minimal degradation in output quality\nwhile ensuring strong protections against sampling protected content.\n",
                "链接": "https://arxiv.org/abs/2302.10870"
            },
            {
                "文章ID": "76520",
                "标题": "Leveraging Generative AI Models for Synthetic Data Generation in\n  Healthcare: Balancing Research and Privacy",
                "作者": " Aryan Jadon,  Shashank Kumar",
                "发布日期": "2023-11-15",
                "摘要": "  The widespread adoption of electronic health records and digital healthcare\ndata has created a demand for data-driven insights to enhance patient outcomes,\ndiagnostics, and treatments. However, using real patient data presents privacy\nand regulatory challenges, including compliance with HIPAA and GDPR. Synthetic\ndata generation, using generative AI models like GANs and VAEs offers a\npromising solution to balance valuable data access and patient privacy\nprotection. In this paper, we examine generative AI models for creating\nrealistic, anonymized patient data for research and training, explore synthetic\ndata applications in healthcare, and discuss its benefits, challenges, and\nfuture research directions. Synthetic data has the potential to revolutionize\nhealthcare by providing anonymized patient data while preserving privacy and\nenabling versatile applications.\n",
                "链接": "https://arxiv.org/abs/2305.05247"
            },
            {
                "文章ID": "89431",
                "标题": "Generative Adversarial Networks for Dental Patient Identity Protection\n  in Orthodontic Educational Imaging",
                "作者": " Mingchuan Tian,  Wilson Weixun Lu,  Kelvin Weng Chiong Foong,  Eugene Loh",
                "发布日期": "2023-07-06",
                "摘要": "  Objectives: This research introduces a novel area-preserving Generative\nAdversarial Networks (GAN) inversion technique for effectively de-identifying\ndental patient images. This innovative method addresses privacy concerns while\npreserving key dental features, thereby generating valuable resources for\ndental education and research.\n  Methods: We enhanced the existing GAN Inversion methodology to maximize the\npreservation of dental characteristics within the synthesized images. A\ncomprehensive technical framework incorporating several deep learning models\nwas developed to provide end-to-end development guidance and practical\napplication for image de-identification.\n  Results: Our approach was assessed with varied facial pictures, extensively\nused for diagnosing skeletal asymmetry and facial anomalies. Results\ndemonstrated our model's ability to adapt the context from one image to\nanother, maintaining compatibility, while preserving dental features essential\nfor oral diagnosis and dental education. A panel of five clinicians conducted\nan evaluation on a set of original and GAN-processed images. The generated\nimages achieved effective de-identification, maintaining the realism of\nimportant dental features and were deemed useful for dental diagnostics and\neducation.\n  Clinical Significance: Our GAN model and the encompassing framework can\nstreamline the de-identification process of dental patient images, enhancing\nefficiency in dental education. This method improves students' diagnostic\ncapabilities by offering more exposure to orthodontic malocclusions.\nFurthermore, it facilitates the creation of de-identified datasets for broader\n2D image research at major research institutions.\n",
                "链接": "https://arxiv.org/abs/2307.02019"
            },
            {
                "文章ID": "26790",
                "标题": "Rethinking Adversarial Examples for Location Privacy Protection",
                "作者": " Trung-Nghia Le,  Ta Gu,  Huy H. Nguyen,  Isao Echizen",
                "发布日期": "2022-06-29",
                "摘要": "  We have investigated a new application of adversarial examples, namely\nlocation privacy protection against landmark recognition systems. We introduce\nmask-guided multimodal projected gradient descent (MM-PGD), in which\nadversarial examples are trained on different deep models. Image contents are\nprotected by analyzing the properties of regions to identify the ones most\nsuitable for blending in adversarial examples. We investigated two region\nidentification strategies: class activation map-based MM-PGD, in which the\ninternal behaviors of trained deep models are targeted; and human-vision-based\nMM-PGD, in which regions that attract less human attention are targeted.\nExperiments on the Places365 dataset demonstrated that these strategies are\npotentially effective in defending against black-box landmark recognition\nsystems without the need for much image manipulation.\n",
                "链接": "https://arxiv.org/abs/2206.14020"
            },
            {
                "文章ID": "124440",
                "标题": "AdvCloak: Customized Adversarial Cloak for Privacy Protection",
                "作者": " Xuannan Liu,  Yaoyao Zhong,  Xing Cui,  Yuhang Zhang,  Peipei Li,  Weihong Deng",
                "发布日期": "2023-12-25",
                "摘要": "  With extensive face images being shared on social media, there has been a\nnotable escalation in privacy concerns. In this paper, we propose AdvCloak, an\ninnovative framework for privacy protection using generative models. AdvCloak\nis designed to automatically customize class-wise adversarial masks that can\nmaintain superior image-level naturalness while providing enhanced\nfeature-level generalization ability. Specifically, AdvCloak sequentially\noptimizes the generative adversarial networks by employing a two-stage training\nstrategy. This strategy initially focuses on adapting the masks to the unique\nindividual faces via image-specific training and then enhances their\nfeature-level generalization ability to diverse facial variations of\nindividuals via person-specific training. To fully utilize the limited training\ndata, we combine AdvCloak with several general geometric modeling methods, to\nbetter describe the feature subspace of source identities. Extensive\nquantitative and qualitative evaluations on both common and celebrity datasets\ndemonstrate that AdvCloak outperforms existing state-of-the-art methods in\nterms of efficiency and effectiveness.\n",
                "链接": "https://arxiv.org/abs/2312.14407"
            },
            {
                "文章ID": "106181",
                "标题": "Large Language Models Can Be Good Privacy Protection Learners",
                "作者": " Yijia Xiao,  Yiqiao Jin,  Yushi Bai,  Yue Wu,  Xianjun Yang,  Xiao Luo,  Wenchao Yu,  Xujiang Zhao,  Yanchi Liu,  Haifeng Chen,  Wei Wang,  Wei Cheng",
                "发布日期": "2023-10-10",
                "摘要": "  The proliferation of Large Language Models (LLMs) has driven considerable\ninterest in fine-tuning them with domain-specific data to create specialized\nlanguage models. Nevertheless, such domain-specific fine-tuning data often\ncontains sensitive personally identifiable information (PII). Direct\nfine-tuning LLMs on this data without privacy protection poses a risk of\nleakage. To address this challenge, we introduce Privacy Protection Language\nModels (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects\ndomain-specific knowledge while safeguarding data privacy. Our work offers a\ntheoretical analysis for model design and delves into various techniques such\nas corpus curation, penalty-based unlikelihood in training loss, and\ninstruction-based tuning, etc. Extensive experiments across diverse datasets\nand scenarios demonstrate the effectiveness of our approaches. In particular,\ninstruction tuning with both positive and negative examples, stands out as a\npromising method, effectively protecting private data while enhancing the\nmodel's knowledge. Our work underscores the potential for Large Language Models\nas robust privacy protection learners.\n",
                "链接": "https://arxiv.org/abs/2310.02469"
            },
            {
                "文章ID": "9148",
                "标题": "Membership Privacy Protection for Image Translation Models via\n  Adversarial Knowledge Distillation",
                "作者": " Saeed Ranjbar Alvar,  Lanjun Wang,  Jian Pei,  Yong Zhang",
                "发布日期": "2022-03-11",
                "摘要": "  Image-to-image translation models are shown to be vulnerable to the\nMembership Inference Attack (MIA), in which the adversary's goal is to identify\nwhether a sample is used to train the model or not. With daily increasing\napplications based on image-to-image translation models, it is crucial to\nprotect the privacy of these models against MIAs.\n  We propose adversarial knowledge distillation (AKD) as a defense method\nagainst MIAs for image-to-image translation models. The proposed method\nprotects the privacy of the training samples by improving the generalizability\nof the model. We conduct experiments on the image-to-image translation models\nand show that AKD achieves the state-of-the-art utility-privacy tradeoff by\nreducing the attack performance up to 38.9% compared with the regular training\nmodel at the cost of a slight drop in the quality of the generated output\nimages. The experimental results also indicate that the models trained by AKD\ngeneralize better than the regular training models. Furthermore, compared with\nexisting defense methods, the results show that at the same privacy protection\nlevel, image translation models trained by AKD generate outputs with higher\nquality; while at the same quality of outputs, AKD enhances the privacy\nprotection over 30%.\n",
                "链接": "https://arxiv.org/abs/2203.05212"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "11104",
                "标题": "CNNs and Transformers Perceive Hybrid Images Similar to Humans",
                "作者": " Ali Borji",
                "发布日期": "2022-03-23",
                "摘要": "  Hybrid images is a technique to generate images with two interpretations that\nchange as a function of viewing distance. It has been utilized to study\nmultiscale processing of images by the human visual system. Using 63,000 hybrid\nimages across 10 fruit categories, here we show that predictions of deep\nlearning vision models qualitatively matches with the human perception of these\nimages. Our results provide yet another evidence in support of the hypothesis\nthat Convolutional Neural Networks (CNNs) and Transformers are good at modeling\nthe feedforward sweep of information in the ventral stream of visual cortex.\nCode and data is available at https://github.com/aliborji/hybrid_images.git.\n",
                "链接": "https://arxiv.org/abs/2203.11678"
            },
            {
                "文章ID": "86417",
                "标题": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
                "作者": " Haixing Dai,  Yiwei Li,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Suhang Song,  Ye Shen,  Dajiang Zhu,  Xiang Li,  Sheng Li,  Xiaobai Yao,  Lu Shi,  Quanzheng Li,  Zhuo Chen,  Donglan Zhang,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-06-21",
                "摘要": "  In this pioneering study, inspired by AutoGPT, the state-of-the-art\nopen-source application based on the GPT-4 large language model, we develop a\nnovel tool called AD-AutoGPT which can conduct data collection, processing, and\nanalysis about complex health narratives of Alzheimer's Disease in an\nautonomous manner via users' textual prompts. We collated comprehensive data\nfrom a variety of news sources, including the Alzheimer's Association, BBC,\nMayo Clinic, and the National Institute on Aging since June 2022, leading to\nthe autonomous execution of robust trend analyses, intertopic distance maps\nvisualization, and identification of salient terms pertinent to Alzheimer's\nDisease. This approach has yielded not only a quantifiable metric of relevant\ndiscourse but also valuable insights into public focus on Alzheimer's Disease.\nThis application of AD-AutoGPT in public health signifies the transformative\npotential of AI in facilitating a data-rich understanding of complex health\nnarratives like Alzheimer's Disease in an autonomous manner, setting the\ngroundwork for future AI-driven investigations in global health landscapes.\n",
                "链接": "https://arxiv.org/abs/2306.10095"
            },
            {
                "文章ID": "123126",
                "标题": "Do Similar Entities have Similar Embeddings?",
                "作者": " Nicolas Hubert,  Heiko Paulheim,  Armelle Brun,  Davy Monticolo",
                "发布日期": "2023-12-19",
                "摘要": "  Knowledge graph embedding models (KGEMs) developed for link prediction learn\nvector representations for graph entities, known as embeddings. A common tacit\nassumption is the KGE entity similarity assumption, which states that these\nKGEMs retain the graph's structure within their embedding space, i.e., position\nsimilar entities close to one another. This desirable property make KGEMs\nwidely used in downstream tasks such as recommender systems or drug\nrepurposing. Yet, the alignment of graph similarity with embedding space\nsimilarity has rarely been formally evaluated. Typically, KGEMs are assessed\nbased on their sole link prediction capabilities, using ranked-based metrics\nsuch as Hits@K or Mean Rank. This paper challenges the prevailing assumption\nthat entity similarity in the graph is inherently mirrored in the embedding\nspace. Therefore, we conduct extensive experiments to measure the capability of\nKGEMs to cluster similar entities together, and investigate the nature of the\nunderlying factors. Moreover, we study if different KGEMs expose a different\nnotion of similarity. Datasets, pre-trained embeddings and code are available\nat: https://github.com/nicolas-hbt/similar-embeddings.\n",
                "链接": "https://arxiv.org/abs/2312.10370"
            },
            {
                "文章ID": "100452",
                "标题": "Doppelgangers: Learning to Disambiguate Images of Similar Structures",
                "作者": " Ruojin Cai,  Joseph Tung,  Qianqian Wang,  Hadar Averbuch-Elor,  Bharath Hariharan,  Noah Snavely",
                "发布日期": "2023-09-06",
                "摘要": "  We consider the visual disambiguation task of determining whether a pair of\nvisually similar images depict the same or distinct 3D surfaces (e.g., the same\nor opposite sides of a symmetric building). Illusory image matches, where two\nimages observe distinct but visually similar 3D surfaces, can be challenging\nfor humans to differentiate, and can also lead 3D reconstruction algorithms to\nproduce erroneous results. We propose a learning-based approach to visual\ndisambiguation, formulating it as a binary classification task on image pairs.\nTo that end, we introduce a new dataset for this problem, Doppelgangers, which\nincludes image pairs of similar structures with ground truth labels. We also\ndesign a network architecture that takes the spatial distribution of local\nkeypoints and matches as input, allowing for better reasoning about both local\nand global cues. Our evaluation shows that our method can distinguish illusory\nmatches in difficult cases, and can be integrated into SfM pipelines to produce\ncorrect, disambiguated 3D reconstructions. See our project page for our code,\ndatasets, and more results: http://doppelgangers-3d.github.io/.\n",
                "链接": "https://arxiv.org/abs/2309.02420"
            },
            {
                "文章ID": "88929",
                "标题": "Lottery and Sprint: Generate a Board Game with Design Sprint Method on\n  AutoGPT",
                "作者": " Maya Grace Torii,  Takahito Murakami,  Yoichi Ochiai",
                "发布日期": "2023-12-25",
                "摘要": "  In this paper, we present a novel approach using the Auto GPT system\nalongside Design Sprint methodology to facilitate board game creation for\ninexperienced users. We introduce the implementation of Auto GPT for generating\ndiverse board games and the subsequent optimization process through a\ncustomized Design Sprint. A user study is conducted to investigate the\nplayability and enjoyment of the generated games, revealing both successes and\nchallenges in employing systems like Auto GPT for board game design. Insights\nand future research directions are proposed to overcome identified limitations\nand enhance computational-driven game creation.\n",
                "链接": "https://arxiv.org/abs/2307.00348"
            },
            {
                "文章ID": "119654",
                "标题": "A Turing Test: Are AI Chatbots Behaviorally Similar to Humans?",
                "作者": " Qiaozhu Mei,  Yutong Xie,  Walter Yuan,  Matthew O. Jackson",
                "发布日期": "2023-12-05",
                "摘要": "  We administer a Turing Test to AI Chatbots. We examine how Chatbots behave in\na suite of classic behavioral games that are designed to elicit characteristics\nsuch as trust, fairness, risk-aversion, cooperation, \\textit{etc.}; as well as\na traditional Big-5 psychological survey that measures personality traits.\nChatGPT-4 passes the Turing Test in that it consistently exhibits human-like\nbehavioral and personality traits based on a comparison to the behavior of\nhundreds of thousands of humans from more than 50 countries. Chatbots also\nmodify their behavior based on previous experience and contexts ``as if'' they\nwere learning from the interactions, and change their behavior in response to\ndifferent framings of the same strategic situation. Their behaviors are often\ndistinct from average and modal human behaviors, in which case they tend to\nbehave on the more altruistic and cooperative end of the distribution. We\nestimate that they act as if they are maximizing an average of their own and\npartner's payoff.\n",
                "链接": "https://arxiv.org/abs/2312.00798"
            },
            {
                "文章ID": "108389",
                "标题": "AutoVP: An Automated Visual Prompting Framework and Benchmark",
                "作者": " Hsi-Ai Tsao,  Lei Hsiung,  Pin-Yu Chen,  Sijia Liu,  Tsung-Yi Ho",
                "发布日期": "2023-10-13",
                "摘要": "  Visual prompting (VP) is an emerging parameter-efficient fine-tuning approach\nto adapting pre-trained vision models to solve various downstream\nimage-classification tasks. However, there has hitherto been little systematic\nstudy of the design space of VP and no clear benchmark for evaluating its\nperformance. To bridge this gap, we propose AutoVP, an end-to-end expandable\nframework for automating VP design choices, along with 12 downstream\nimage-classification tasks that can serve as a holistic VP-performance\nbenchmark. Our design space covers 1) the joint optimization of the prompts; 2)\nthe selection of pre-trained models, including image classifiers and text-image\nencoders; and 3) model output mapping strategies, including nonparametric and\ntrainable label mapping. Our extensive experimental results show that AutoVP\noutperforms the best-known current VP methods by a substantial margin, having\nup to 6.7% improvement in accuracy; and attains a maximum performance increase\nof 27.5% compared to linear-probing (LP) baseline. AutoVP thus makes a two-fold\ncontribution: serving both as an efficient tool for hyperparameter tuning on VP\ndesign choices, and as a comprehensive benchmark that can reasonably be\nexpected to accelerate VP's development. The source code is available at\nhttps://github.com/IBM/AutoVP.\n",
                "链接": "https://arxiv.org/abs/2310.08381"
            },
            {
                "文章ID": "18016",
                "标题": "Do Different Deep Metric Learning Losses Lead to Similar Learned\n  Features?",
                "作者": " Konstantin Kobs,  Michael Steininger,  Andrzej Dulny,  Andreas Hotho",
                "发布日期": "2022-05-06",
                "摘要": "  Recent studies have shown that many deep metric learning loss functions\nperform very similarly under the same experimental conditions. One potential\nreason for this unexpected result is that all losses let the network focus on\nsimilar image regions or properties. In this paper, we investigate this by\nconducting a two-step analysis to extract and compare the learned visual\nfeatures of the same model architecture trained with different loss functions:\nFirst, we compare the learned features on the pixel level by correlating\nsaliency maps of the same input images. Second, we compare the clustering of\nembeddings for several image properties, e.g. object color or illumination. To\nprovide independent control over these properties, photo-realistic 3D car\nrenders similar to images in the Cars196 dataset are generated. In our\nanalysis, we compare 14 pretrained models from a recent study and find that,\neven though all models perform similarly, different loss functions can guide\nthe model to learn different features. We especially find differences between\nclassification and ranking based losses. Our analysis also shows that some\nseemingly irrelevant properties can have significant influence on the resulting\nembedding. We encourage researchers from the deep metric learning community to\nuse our methods to get insights into the features learned by their proposed\nmethods.\n",
                "链接": "https://arxiv.org/abs/2205.02698"
            },
            {
                "文章ID": "27348",
                "标题": "Is neural language acquisition similar to natural? A chronological\n  probing study",
                "作者": " Ekaterina Voloshina,  Oleg Serikov,  Tatiana Shavrina",
                "发布日期": "2022-07-04",
                "摘要": "  The probing methodology allows one to obtain a partial representation of\nlinguistic phenomena stored in the inner layers of the neural network, using\nexternal classifiers and statistical analysis. Pre-trained transformer-based\nlanguage models are widely used both for natural language understanding (NLU)\nand natural language generation (NLG) tasks making them most commonly used for\ndownstream applications. However, little analysis was carried out, whether the\nmodels were pre-trained enough or contained knowledge correlated with\nlinguistic theory. We are presenting the chronological probing study of\ntransformer English models such as MultiBERT and T5. We sequentially compare\nthe information about the language learned by the models in the process of\ntraining on corpora. The results show that 1) linguistic information is\nacquired in the early stages of training 2) both language models demonstrate\ncapabilities to capture various features from various levels of language,\nincluding morphology, syntax, and even discourse, while they also can\ninconsistently fail on tasks that are perceived as easy. We also introduce the\nopen-source framework for chronological probing research, compatible with other\ntransformer-based models.\nhttps://github.com/EkaterinaVoloshina/chronological_probing\n",
                "链接": "https://arxiv.org/abs/2207.00560"
            },
            {
                "文章ID": "20384",
                "标题": "Diversity Preference-Aware Link Recommendation for Online Social\n  Networks",
                "作者": " Kexin Yin,  Xiao Fang,  Bintong Chen,  Olivia Sheng",
                "发布日期": "2022-10-19",
                "摘要": "  Link recommendation, which recommends links to connect unlinked online social\nnetwork users, is a fundamental social network analytics problem with ample\nbusiness implications. Existing link recommendation methods tend to recommend\nsimilar friends to a user but overlook the user's diversity preference,\nalthough social psychology theories suggest the criticality of diversity\npreference to link recommendation performance. In recommender systems, a field\nrelated to link recommendation, a number of diversification methods have been\nproposed to improve the diversity of recommended items. Nevertheless, diversity\npreference is distinct from diversity studied by diversification methods. To\naddress these research gaps, we define and operationalize the concept of\ndiversity preference for link recommendation and propose a new link\nrecommendation problem: the diversity preference-aware link recommendation\nproblem. We then analyze key properties of the new link recommendation problem\nand develop a novel link recommendation method to solve the problem. Using two\nlarge-scale online social network data sets, we conduct extensive empirical\nevaluations to demonstrate the superior performance of our method over\nrepresentative diversification methods adapted for link recommendation as well\nas state-of-the-art link recommendation methods.\n",
                "链接": "https://arxiv.org/abs/2205.10689"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "78689",
                "标题": "Empower Large Language Model to Perform Better on Industrial\n  Domain-Specific Question Answering",
                "作者": " Fangkai Yang,  Pu Zhao,  Zezhong Wang,  Lu Wang,  Jue Zhang,  Mohit Garg,  Qingwei Lin,  Saravan Rajmohan,  Dongmei Zhang",
                "发布日期": "2023-10-17",
                "摘要": "  Large Language Model (LLM) has gained popularity and achieved remarkable\nresults in open-domain tasks, but its performance in real industrial\ndomain-specific scenarios is average due to its lack of specific domain\nknowledge. This issue has attracted widespread attention, but there are few\nrelevant benchmarks available. In this paper, we provide a benchmark Question\nAnswering (QA) dataset named MSQA, centered around Microsoft products and IT\ntechnical problems encountered by customers. This dataset contains industry\ncloud-specific QA knowledge, an area not extensively covered in general LLMs,\nmaking it well-suited for evaluating methods aiming to enhance LLMs'\ndomain-specific capabilities. In addition, we propose a new model interaction\nparadigm that can empower LLM to achieve better performance on domain-specific\ntasks where it is not proficient. Extensive experiments demonstrate that the\napproach following our method outperforms the commonly used LLM with retrieval\nmethods. We make our source code and sample data available at:\nhttps://aka.ms/Microsoft_QA.\n",
                "链接": "https://arxiv.org/abs/2305.11541"
            },
            {
                "文章ID": "112345",
                "标题": "Myriad: Large Multimodal Model by Applying Vision Experts for Industrial\n  Anomaly Detection",
                "作者": " Yuanze Li,  Haolin Wang,  Shihao Yuan,  Ming Liu,  Debin Zhao,  Yiwen Guo,  Chen Xu,  Guangming Shi,  Wangmeng Zuo",
                "发布日期": "2023-11-02",
                "摘要": "  Existing industrial anomaly detection (IAD) methods predict anomaly scores\nfor both anomaly detection and localization. However, they struggle to perform\na multi-turn dialog and detailed descriptions for anomaly regions, e.g., color,\nshape, and categories of industrial anomalies. Recently, large multimodal\n(i.e., vision and language) models (LMMs) have shown eminent perception\nabilities on multiple vision tasks such as image captioning, visual\nunderstanding, visual reasoning, etc., making it a competitive potential choice\nfor more comprehensible anomaly detection. However, the knowledge about anomaly\ndetection is absent in existing general LMMs, while training a specific LMM for\nanomaly detection requires a tremendous amount of annotated data and massive\ncomputation resources. In this paper, we propose a novel large multi-modal\nmodel by applying vision experts for industrial anomaly detection (dubbed\nMyriad), which leads to definite anomaly detection and high-quality anomaly\ndescription. Specifically, we adopt MiniGPT-4 as the base LMM and design an\nExpert Perception module to embed the prior knowledge from vision experts as\ntokens which are intelligible to Large Language Models (LLMs). To compensate\nfor the errors and confusions of vision experts, we introduce a domain adapter\nto bridge the visual representation gaps between generic and industrial images.\nFurthermore, we propose a Vision Expert Instructor, which enables the Q-Former\nto generate IAD domain vision-language tokens according to vision expert prior.\nExtensive experiments on MVTec-AD and VisA benchmarks demonstrate that our\nproposed method not only performs favorably against state-of-the-art methods\nunder the 1-class and few-shot settings, but also provide definite anomaly\nprediction along with detailed descriptions in IAD domain.\n",
                "链接": "https://arxiv.org/abs/2310.19070"
            },
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "87099",
                "标题": "Exploiting Multimodal Synthetic Data for Egocentric Human-Object\n  Interaction Detection in an Industrial Scenario",
                "作者": " Rosario Leonardi,  Francesco Ragusa,  Antonino Furnari,  Giovanni Maria Farinella",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we tackle the problem of Egocentric Human-Object Interaction\n(EHOI) detection in an industrial setting. To overcome the lack of public\ndatasets in this context, we propose a pipeline and a tool for generating\nsynthetic images of EHOIs paired with several annotations and data signals\n(e.g., depth maps or instance segmentation masks). Using the proposed pipeline,\nwe present EgoISM-HOI a new multimodal dataset composed of synthetic EHOI\nimages in an industrial environment with rich annotations of hands and objects.\nTo demonstrate the utility and effectiveness of synthetic EHOI data produced by\nthe proposed tool, we designed a new method that predicts and combines\ndifferent multimodal signals to detect EHOIs in RGB images. Our study shows\nthat exploiting synthetic data to pre-train the proposed method significantly\nimproves performance when tested on real-world data. Moreover, the proposed\napproach outperforms state-of-the-art class-agnostic methods. To support\nresearch in this field, we publicly release the datasets, source code, and\npre-trained models at https://iplab.dmi.unict.it/egoism-hoi.\n",
                "链接": "https://arxiv.org/abs/2306.12152"
            },
            {
                "文章ID": "124479",
                "标题": "DuaLight: Enhancing Traffic Signal Control by Leveraging\n  Scenario-Specific and Scenario-Shared Knowledge",
                "作者": " Jiaming Lu,  Jingqing Ruan,  Haoyuan Jiang,  Ziyue Li,  Hangyu Mao,  Rui Zhao",
                "发布日期": "2023-12-25",
                "摘要": "  Reinforcement learning has been revolutionizing the traditional traffic\nsignal control task, showing promising power to relieve congestion and improve\nefficiency. However, the existing methods lack effective learning mechanisms\ncapable of absorbing dynamic information inherent to a specific scenario and\nuniversally applicable dynamic information across various scenarios. Moreover,\nwithin each specific scenario, they fail to fully capture the essential\nempirical experiences about how to coordinate between neighboring and target\nintersections, leading to sub-optimal system-wide outcomes.\n  Viewing these issues, we propose DuaLight, which aims to leverage both the\nexperiential information within a single scenario and the generalizable\ninformation across various scenarios for enhanced decision-making.\nSpecifically, DuaLight introduces a scenario-specific experiential weight\nmodule with two learnable parts: Intersection-wise and Feature-wise, guiding\nhow to adaptively utilize neighbors and input features for each scenario, thus\nproviding a more fine-grained understanding of different intersections.\nFurthermore, we implement a scenario-shared Co-Train module to facilitate the\nlearning of generalizable dynamics information across different scenarios.\nEmpirical results on both real-world and synthetic scenarios show DuaLight\nachieves competitive performance across various metrics, offering a promising\nsolution to alleviate traffic congestion, with 3-7\\% improvements. The code is\navailable under: https://github.com/lujiaming-12138/DuaLight.\n",
                "链接": "https://arxiv.org/abs/2312.14532"
            },
            {
                "文章ID": "114068",
                "标题": "GLaMM: Pixel Grounding Large Multimodal Model",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Sahal Shaji,  Abdelrahman Shaker,  Salman Khan,  Hisham Cholakkal,  Rao M. Anwer,  Erix Xing,  Ming-Hsuan Yang,  Fahad S. Khan",
                "发布日期": "2023-11-07",
                "摘要": "  Large Multimodal Models (LMMs) extend Large Language Models to the vision\ndomain. Initial efforts towards LMMs used holistic images and text prompts to\ngenerate ungrounded textual responses. Very recently, region-level LMMs have\nbeen used to generate visually grounded responses. However, they are limited to\nonly referring a single object category at a time, require users to specify the\nregions in inputs, or cannot offer dense pixel-wise object grounding. In this\nwork, we present Grounding LMM (GLaMM), the first model that can generate\nnatural language responses seamlessly intertwined with corresponding object\nsegmentation masks. GLaMM not only grounds objects appearing in the\nconversations but is flexible enough to accept both textual and optional visual\nprompts (region of interest) as input. This empowers users to interact with the\nmodel at various levels of granularity, both in textual and visual domains. Due\nto the lack of standard benchmarks for the novel setting of generating visually\ngrounded detailed conversations, we introduce a comprehensive evaluation\nprotocol with our curated grounded conversations. Our proposed Grounded\nConversation Generation (GCG) task requires densely grounded concepts in\nnatural scenes at a large-scale. To this end, we propose a densely annotated\nGrounding-anything Dataset (GranD) using our proposed automated annotation\npipeline that encompasses 7.5M unique concepts grounded in a total of 810M\nregions available with segmentation masks. Besides GCG, GLaMM also performs\neffectively on several downstream tasks e.g., referring expression\nsegmentation, image and region-level captioning and vision-language\nconversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.\n",
                "链接": "https://arxiv.org/abs/2311.03356"
            },
            {
                "文章ID": "124447",
                "标题": "A Unified Industrial Large Knowledge Model Framework in Smart\n  Manufacturing",
                "作者": " Jay Lee,  Hanqi Su",
                "发布日期": "2023-12-25",
                "摘要": "  The recent emergence of large language models (LLMs) shows the potential for\nartificial general intelligence, revealing new opportunities in industry 4.0\nand smart manufacturing. However, a notable gap exists in applying these LLMs\nin industry, primarily due to their training on general knowledge rather than\ndomain-specific knowledge. Such specialized domain knowledge is vital for\neffectively addressing the complex needs of industrial applications. To bridge\nthis gap, this paper proposes an Industrial Large Knowledge Model (ILKM)\nframework emphasizing their potential to revolutionize the industry in smart\nmanufacturing. In addition, ILKMs and LLMs are compared from eight\nperspectives. Finally, \"6S Principle\" is proposed as the guideline for the\ndevelopment of ILKMs in smart manufacturing.\n",
                "链接": "https://arxiv.org/abs/2312.14428"
            },
            {
                "文章ID": "105595",
                "标题": "Application of frozen large-scale models to multimodal task-oriented\n  dialogue",
                "作者": " Tatsuki Kawamoto,  Takuma Suzuki,  Ko Miyama,  Takumi Meguro,  Tomohiro Takagi",
                "发布日期": "2023-10-03",
                "摘要": "  In this study, we use the existing Large Language Models ENnhanced to See\nFramework (LENS Framework) to test the feasibility of multimodal task-oriented\ndialogues. The LENS Framework has been proposed as a method to solve computer\nvision tasks without additional training and with fixed parameters of\npre-trained models. We used the Multimodal Dialogs (MMD) dataset, a multimodal\ntask-oriented dialogue benchmark dataset from the fashion field, and for the\nevaluation, we used the ChatGPT-based G-EVAL, which only accepts textual\nmodalities, with arrangements to handle multimodal data. Compared to\nTransformer-based models in previous studies, our method demonstrated an\nabsolute lift of 10.8% in fluency, 8.8% in usefulness, and 5.2% in relevance\nand coherence. The results show that using large-scale models with fixed\nparameters rather than using models trained on a dataset from scratch improves\nperformance in multimodal task-oriented dialogues. At the same time, we show\nthat Large Language Models (LLMs) are effective for multimodal task-oriented\ndialogues. This is expected to lead to efficient applications to existing\nsystems.\n",
                "链接": "https://arxiv.org/abs/2310.00845"
            },
            {
                "文章ID": "100082",
                "标题": "Large AI Model Empowered Multimodal Semantic Communications",
                "作者": " Feibo Jiang,  Yubo Peng,  Li Dong,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Xiaohu You",
                "发布日期": "2023-09-06",
                "摘要": "  Multimodal signals, including text, audio, image and video, can be integrated\ninto Semantic Communication (SC) for providing an immersive experience with low\nlatency and high quality at the semantic level. However, the multimodal SC has\nseveral challenges, including data heterogeneity, semantic ambiguity, and\nsignal fading. Recent advancements in large AI models, particularly in\nMultimodal Language Model (MLM) and Large Language Model (LLM), offer potential\nsolutions for these issues. To this end, we propose a Large AI Model-based\nMultimodal SC (LAM-MSC) framework, in which we first present the MLM-based\nMultimodal Alignment (MMA) that utilizes the MLM to enable the transformation\nbetween multimodal and unimodal data while preserving semantic consistency.\nThen, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows\nusers to perform personalized semantic extraction or recovery through the LLM.\nThis effectively addresses the semantic ambiguity. Finally, we apply the\nConditional Generative adversarial networks-based channel Estimation (CGE) to\nobtain Channel State Information (CSI). This approach effectively mitigates the\nimpact of fading channels in SC. Finally, we conduct simulations that\ndemonstrate the superior performance of the LAM-MSC framework.\n",
                "链接": "https://arxiv.org/abs/2309.01249"
            },
            {
                "文章ID": "108480",
                "标题": "Multimodal Large Language Model for Visual Navigation",
                "作者": " Yao-Hung Hubert Tsai,  Vansh Dhar,  Jialu Li,  Bowen Zhang,  Jian Zhang",
                "发布日期": "2023-11-07",
                "摘要": "  Recent efforts to enable visual navigation using large language models have\nmainly focused on developing complex prompt systems. These systems incorporate\ninstructions, observations, and history into massive text prompts, which are\nthen combined with pre-trained large language models to facilitate visual\nnavigation. In contrast, our approach aims to fine-tune large language models\nfor visual navigation without extensive prompt engineering. Our design involves\na simple text prompt, current observations, and a history collector model that\ngathers information from previous observations as input. For output, our design\nprovides a probability distribution of possible actions that the agent can take\nduring navigation. We train our model using human demonstrations and collision\nsignals from the Habitat-Matterport 3D Dataset (HM3D). Experimental results\ndemonstrate that our method outperforms state-of-the-art behavior cloning\nmethods and effectively reduces collision rates.\n",
                "链接": "https://arxiv.org/abs/2310.08669"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109322",
                "标题": "Enhanced Transformer Architecture for Natural Language Processing",
                "作者": " Woohyeon Moon,  Taeyoung Kim,  Bumgeun Park,  Dongsoo Har",
                "发布日期": "2023-10-18",
                "摘要": "  Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.\n",
                "链接": "https://arxiv.org/abs/2310.10930"
            },
            {
                "文章ID": "93014",
                "标题": "Evaluating Large Language Models for Radiology Natural Language\n  Processing",
                "作者": " Zhengliang Liu,  Tianyang Zhong,  Yiwei Li,  Yutong Zhang,  Yi Pan,  Zihao Zhao,  Peixin Dong,  Chao Cao,  Yuxiao Liu,  Peng Shu,  Yaonai Wei,  Zihao Wu,  Chong Ma,  Jiaqi Wang,  Sheng Wang,  Mengyue Zhou,  Zuowei Jiang,  Chunlin Li,  Jason Holmes,  Shaochen Xu,  Lu Zhang,  Haixing Dai,  Kai Zhang,  Lin Zhao,  Yuanhao Chen,  Xu Liu,  Peilong Wang,  Pingkun Yan,  Jun Liu,  Bao Ge,  Lichao Sun,  Dajiang Zhu,  Xiang Li,  Wei Liu,  Xiaoyan Cai,  Xintao Hu,  Xi Jiang,  Shu Zhang,  Xin Zhang,  Tuo Zhang,  Shijie Zhao,  Quanzheng Li,  Hongtu Zhu,  Dinggang Shen,  Tianming Liu",
                "发布日期": "2023-07-28",
                "摘要": "  The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain.\n",
                "链接": "https://arxiv.org/abs/2307.13693"
            },
            {
                "文章ID": "85203",
                "标题": "AraMUS: Pushing the Limits of Data and Model Scale for Arabic Natural\n  Language Processing",
                "作者": " Asaad Alghamdi,  Xinyu Duan,  Wei Jiang,  Zhenhai Wang,  Yimeng Wu,  Qingrong Xia,  Zhefeng Wang,  Yi Zheng,  Mehdi Rezagholizadeh,  Baoxing Huai,  Peilun Cheng,  Abbas Ghaddar",
                "发布日期": "2023-06-13",
                "摘要": "  Developing monolingual large Pre-trained Language Models (PLMs) is shown to\nbe very successful in handling different tasks in Natural Language Processing\n(NLP). In this work, we present AraMUS, the largest Arabic PLM with 11B\nparameters trained on 529GB of high-quality Arabic textual data. AraMUS\nachieves state-of-the-art performances on a diverse set of Arabic\nclassification and generative tasks. Moreover, AraMUS shows impressive few-shot\nlearning abilities compared with the best existing Arabic PLMs.\n",
                "链接": "https://arxiv.org/abs/2306.06800"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "86811",
                "标题": "RS5M: A Large Scale Vision-Language Dataset for Remote Sensing\n  Vision-Language Foundation Model",
                "作者": " Zilun Zhang,  Tiancheng Zhao,  Yulong Guo,  Jianwei Yin",
                "发布日期": "2023-12-06",
                "摘要": "  Pre-trained Vision-Language Models (VLMs) utilizing extensive image-text\npaired data have demonstrated unprecedented image-text association\ncapabilities, achieving remarkable results across various downstream tasks. A\ncritical challenge is how to make use of existing large-scale pre-trained VLMs,\nwhich are trained on common objects, to perform the domain-specific transfer\nfor accomplishing domain-related downstream tasks. A critical challenge is how\nto make use of existing large-scale pre-trained VLMs, which are trained on\ncommon objects, to perform the domain-specific transfer for accomplishing\ndomain-related downstream tasks. In this paper, we propose a new framework that\nincludes the Domain pre-trained Vision-Language Model (DVLM), bridging the gap\nbetween the General Vision-Language Model (GVLM) and domain-specific downstream\ntasks. Moreover, we present an image-text paired dataset in the field of remote\nsensing (RS), RS5M, which has 5 million RS images with English descriptions.\nThe dataset is obtained from filtering publicly available image-text paired\ndatasets and captioning label-only RS datasets with pre-trained VLM. These\nconstitute the first large-scale RS image-text paired dataset. Additionally, we\nfine-tuned the CLIP model and tried several Parameter-Efficient Fine-Tuning\nmethods on RS5M to implement the DVLM. Experimental results show that our\nproposed dataset is highly effective for various tasks, and our model GeoRSCLIP\nimproves upon the baseline or previous state-of-the-art model by $3\\%\\sim20\\%$\nin Zero-shot Classification (ZSC), $3\\%\\sim6\\%$ in Remote Sensing Cross-Modal\nText-Image Retrieval (RSCTIR) and $4\\%\\sim5\\%$ in Semantic Localization (SeLo)\ntasks. Dataset and models have been released in:\n\\url{https://github.com/om-ai-lab/RS5M}.\n",
                "链接": "https://arxiv.org/abs/2306.11300"
            },
            {
                "文章ID": "80906",
                "标题": "Large language models in biomedical natural language processing:\n  benchmarks, baselines, and recommendations",
                "作者": " Qingyu Chen,  Jingcheng Du,  Yan Hu,  Vipina Kuttichi Keloth,  Xueqing Peng,  Kalpana Raja,  Rui Zhang,  Zhiyong Lu,  Hua Xu",
                "发布日期": "2023-05-29",
                "摘要": "  Biomedical literature is growing rapidly, making it challenging to curate and\nextract knowledge manually. Biomedical natural language processing (BioNLP)\ntechniques that can automatically extract information from biomedical\nliterature help alleviate this burden. Recently, large Language Models (LLMs),\nsuch as GPT-3 and GPT-4, have gained significant attention for their impressive\nperformance. However, their effectiveness in BioNLP tasks and impact on method\ndevelopment and downstream users remain understudied. This pilot study (1)\nestablishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and\none-shot settings in eight BioNLP datasets across four applications: named\nentity recognition, relation extraction, multi-label document classification,\nand semantic similarity and reasoning, (2) examines the errors produced by the\nLLMs and categorized the errors into three types: missingness, inconsistencies,\nand unwanted artificial content, and (3) provides suggestions for using LLMs in\nBioNLP applications. We make the datasets, baselines, and results publicly\navailable to the community via\nhttps://github.com/qingyu-qc/gpt_bionlp_benchmark.\n",
                "链接": "https://arxiv.org/abs/2305.16326"
            },
            {
                "文章ID": "112674",
                "标题": "BioInstruct: Instruction Tuning of Large Language Models for Biomedical\n  Natural Language Processing",
                "作者": " Hieu Tran,  Zhichao Yang,  Zonghai Yao,  Hong Yu",
                "发布日期": "2023-11-07",
                "摘要": "  To enhance the performance of large language models (LLMs) in biomedical\nnatural language processing (BioNLP) by introducing a domain-specific\ninstruction dataset and examining its impact when combined with multi-task\nlearning principles. We created the BioInstruct, comprising 25,005 instructions\nto instruction-tune LLMs(LLaMA 1 & 2, 7B & 13B version). The instructions were\ncreated by prompting the GPT-4 language model with three-seed samples randomly\ndrawn from an 80 human curated instructions. We employed Low-Rank\nAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these\ninstruction-tuned LLMs on several BioNLP tasks, which can be grouped into three\nmajor categories: question answering(QA), information extraction(IE), and text\ngeneration(GEN). We also examined whether categories(e.g., QA, IE, and\ngeneration) of instructions impact model performance. Comparing with LLMs\nwithout instruction-tuned, our instruction-tuned LLMs demonstrated marked\nperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our\n7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed\nother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with\nvast domain-specific data or a variety of tasks. Our results also show that the\nperformance gain is significantly higher when instruction fine-tuning is\nconducted with closely related tasks. Our findings align with the observations\nof multi-task learning, suggesting the synergies between two tasks. The\nBioInstruct dataset serves as a valuable resource and instruction tuned LLMs\nlead to the best performing BioNLP applications.\n",
                "链接": "https://arxiv.org/abs/2310.19975"
            },
            {
                "文章ID": "85409",
                "标题": "EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural\n  Language Processing",
                "作者": " Iker de la Iglesia,  Aitziber Atutxa,  Koldo Gojenola,  Ander Barrena",
                "发布日期": "2023-06-14",
                "摘要": "  The utilization of clinical reports for various secondary purposes, including\nhealth research and treatment monitoring, is crucial for enhancing patient\ncare. Natural Language Processing (NLP) tools have emerged as valuable assets\nfor extracting and processing relevant information from these reports. However,\nthe availability of specialized language models for the clinical domain in\nSpanish has been limited.\n  In this paper, we introduce EriBERTa, a bilingual domain-specific language\nmodel pre-trained on extensive medical and clinical corpora. We demonstrate\nthat EriBERTa outperforms previous Spanish language models in the clinical\ndomain, showcasing its superior capabilities in understanding medical texts and\nextracting meaningful information. Moreover, EriBERTa exhibits promising\ntransfer learning abilities, allowing for knowledge transfer from one language\nto another. This aspect is particularly beneficial given the scarcity of\nSpanish clinical data.\n",
                "链接": "https://arxiv.org/abs/2306.07373"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            },
            {
                "文章ID": "115729",
                "标题": "Natural Language Processing for Financial Regulation",
                "作者": " Ixandra Achitouv,  Dragos Gorduza,  Antoine Jacquier",
                "发布日期": "2023-11-16",
                "摘要": "  This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.\n",
                "链接": "https://arxiv.org/abs/2311.08533"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "86459",
                "标题": "Genes in Intelligent Agents",
                "作者": " Fu Feng,  Jing Wang,  Xu Yang,  Xin Geng",
                "发布日期": "2023-10-30",
                "摘要": "  The genes in nature give the lives on earth the current biological\nintelligence through transmission and accumulation over billions of years.\nInspired by the biological intelligence, artificial intelligence (AI) has\ndevoted to building the machine intelligence. Although it has achieved thriving\nsuccesses, the machine intelligence still lags far behind the biological\nintelligence. The reason may lie in that animals are born with some\nintelligence encoded in their genes, but machines lack such intelligence and\nlearn from scratch. Inspired by the genes of animals, we define the ``genes''\nof machines named as the ``learngenes'' and propose the Genetic Reinforcement\nLearning (GRL). GRL is a computational framework that simulates the evolution\nof organisms in reinforcement learning (RL) and leverages the learngenes to\nlearn and evolve the intelligence agents. Leveraging GRL, we first show that\nthe learngenes take the form of the fragments of the agents' neural networks\nand can be inherited across generations. Second, we validate that the\nlearngenes can transfer ancestral experience to the agents and bring them\ninstincts and strong learning abilities. Third, we justify the Lamarckian\ninheritance of the intelligent agents and the continuous evolution of the\nlearngenes. Overall, the learngenes have taken the machine intelligence one\nmore step toward the biological intelligence.\n",
                "链接": "https://arxiv.org/abs/2306.10225"
            },
            {
                "文章ID": "120758",
                "标题": "LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent\n  Ecosystem",
                "作者": " Yingqiang Ge,  Yujie Ren,  Wenyue Hua,  Shuyuan Xu,  Juntao Tan,  Yongfeng Zhang",
                "发布日期": "2023-12-12",
                "摘要": "  This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system \"with soul\". Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level). We begin by introducing the architecture of\ntraditional OS. Then we formalize a conceptual framework for AIOS through \"LLM\nas OS (LLMOS)\", drawing analogies between AIOS and traditional OS: LLM is\nlikened to OS kernel, context window to memory, external storage to file\nsystem, hardware tools to peripheral devices, software tools to programming\nlibraries, and user prompts to user commands. Subsequently, we introduce the\nnew AIOS-Agent Ecosystem, where users can easily program Agent Applications\n(AAPs) using natural language, democratizing the development of software, which\nis different from the traditional OS-APP ecosystem. Following this, we explore\nthe diverse scope of Agent Applications. We delve into both single-agent and\nmulti-agent systems, as well as human-agent interaction. Lastly, drawing on the\ninsights from traditional OS-APP ecosystem, we propose a roadmap for the\nevolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the\nfuture research and development, suggesting systematic progresses of AIOS and\nits Agent applications.\n",
                "链接": "https://arxiv.org/abs/2312.03815"
            },
            {
                "文章ID": "49513",
                "标题": "Intelligent Computing: The Latest Advances, Challenges and Future",
                "作者": " Shiqiang Zhu,  Ting Yu,  Tao Xu,  Hongyang Chen,  Schahram Dustdar,  Sylvain Gigan,  Deniz Gunduz,  Ekram Hossain,  Yaochu Jin,  Feng Lin,  Bo Liu,  Zhiguo Wan,  Ji Zhang,  Zhifeng Zhao,  Wentao Zhu,  Zuoning Chen,  Tariq Durrani,  Huaimin Wang,  Jiangxing Wu,  Tongyi Zhang,  Yunhe Pan",
                "发布日期": "2022-11-22",
                "摘要": "  Computing is a critical driving force in the development of human\ncivilization. In recent years, we have witnessed the emergence of intelligent\ncomputing, a new computing paradigm that is reshaping traditional computing and\npromoting digital revolution in the era of big data, artificial intelligence\nand internet-of-things with new computing theories, architectures, methods,\nsystems, and applications. Intelligent computing has greatly broadened the\nscope of computing, extending it from traditional computing on data to\nincreasingly diverse computing paradigms such as perceptual intelligence,\ncognitive intelligence, autonomous intelligence, and human-computer fusion\nintelligence. Intelligence and computing have undergone paths of different\nevolution and development for a long time but have become increasingly\nintertwined in recent years: intelligent computing is not only\nintelligence-oriented but also intelligence-driven. Such cross-fertilization\nhas prompted the emergence and rapid advancement of intelligent computing.\nIntelligent computing is still in its infancy and an abundance of innovations\nin the theories, systems, and applications of intelligent computing are\nexpected to occur soon. We present the first comprehensive survey of literature\non intelligent computing, covering its theory fundamentals, the technological\nfusion of intelligence and computing, important applications, challenges, and\nfuture perspectives. We believe that this survey is highly timely and will\nprovide a comprehensive reference and cast valuable insights into intelligent\ncomputing for academic and industrial researchers and practitioners.\n",
                "链接": "https://arxiv.org/abs/2211.11281"
            },
            {
                "文章ID": "17438",
                "标题": "On verifying expectations and observations of intelligent agents",
                "作者": " Sourav Chakraborty,  Avijeet Ghosh,  Sujata Ghosh,  François Schwarzentruber",
                "发布日期": "2022-05-13",
                "摘要": "  Public observation logic (POL) is a variant of dynamic epistemic logic to\nreason about agent expectations and agent observations. Agents have certain\nexpectations, regarding the situation at hand, that are actuated by the\nrelevant protocols, and they eliminate possible worlds in which their\nexpectations do not match with their observations. In this work, we investigate\nthe computational complexity of the model checking problem for POL and prove\nits PSPACE-completeness. We also study various syntactic fragments of POL. We\nexemplify the applicability of POL model checking in verifying different\ncharacteristics and features of an interactive system with respect to the\ndistinct expectations and (matching) observations of the system. Finally, we\nprovide a discussion on the implementation of the model checking algorithms.\n",
                "链接": "https://arxiv.org/abs/2205.00784"
            },
            {
                "文章ID": "68556",
                "标题": "TinyML: Tools, Applications, Challenges, and Future Research Directions",
                "作者": " Rakhee Kallimani,  Krishna Pai,  Prasoon Raghuwanshi,  Sridhar Iyer,  Onel L. A. López",
                "发布日期": "2023-09-08",
                "摘要": "  In recent years, Artificial Intelligence (AI) and Machine learning (ML) have\ngained significant interest from both, industry and academia. Notably,\nconventional ML techniques require enormous amounts of power to meet the\ndesired accuracy, which has limited their use mainly to high-capability devices\nsuch as network nodes. However, with many advancements in technologies such as\nthe Internet of Things (IoT) and edge computing, it is desirable to incorporate\nML techniques into resource-constrained embedded devices for distributed and\nubiquitous intelligence. This has motivated the emergence of the TinyML\nparadigm which is an embedded ML technique that enables ML applications on\nmultiple cheap, resource- and power-constrained devices. However, during this\ntransition towards appropriate implementation of the TinyML technology,\nmultiple challenges such as processing capacity optimization, improved\nreliability, and maintenance of learning models' accuracy require timely\nsolutions. In this article, various avenues available for TinyML implementation\nare reviewed. Firstly, a background of TinyML is provided, followed by detailed\ndiscussions on various tools supporting TinyML. Then, state-of-art applications\nof TinyML using advanced technologies are detailed. Lastly, various research\nchallenges and future directions are identified.\n",
                "链接": "https://arxiv.org/abs/2303.13569"
            },
            {
                "文章ID": "36627",
                "标题": "Metaverse for Healthcare: A Survey on Potential Applications, Challenges\n  and Future Directions",
                "作者": " Rajeswari Chengoden,  Nancy Victor,  Thien Huynh-The,  Gokul Yenduri,  Rutvij H. Jhaveri,  Mamoun Alazab,  Sweta Bhattacharya,  Pawan Hegde,  Praveen Kumar Reddy Maddikunta,  Thippa Reddy Gadekallu",
                "发布日期": "2022-09-12",
                "摘要": "  The rapid progress in digitalization and automation have led to an\naccelerated growth in healthcare, generating novel models that are creating new\nchannels for rendering treatment with reduced cost. The Metaverse is an\nemerging technology in the digital space which has huge potential in\nhealthcare, enabling realistic experiences to the patients as well as the\nmedical practitioners. The Metaverse is a confluence of multiple enabling\ntechnologies such as artificial intelligence, virtual reality, augmented\nreality, internet of medical devices, robotics, quantum computing, etc. through\nwhich new directions for providing quality healthcare treatment and services\ncan be explored. The amalgamation of these technologies ensures immersive,\nintimate and personalized patient care. It also provides adaptive intelligent\nsolutions that eliminates the barriers between healthcare providers and\nreceivers. This article provides a comprehensive review of the Metaverse for\nhealthcare, emphasizing on the state of the art, the enabling technologies for\nadopting the Metaverse for healthcare, the potential applications and the\nrelated projects. The issues in the adaptation of the Metaverse for healthcare\napplications are also identified and the plausible solutions are highlighted as\npart of future research directions.\n",
                "链接": "https://arxiv.org/abs/2209.04160"
            },
            {
                "文章ID": "77270",
                "标题": "A Comprehensive Survey on Affective Computing; Challenges, Trends,\n  Applications, and Future Directions",
                "作者": " Sitara Afzal,  Haseeb Ali Khan,  Imran Ullah Khan,  Md. Jalil Piran,  Jong Weon Lee",
                "发布日期": "2023-05-16",
                "摘要": "  As the name suggests, affective computing aims to recognize human emotions,\nsentiments, and feelings. There is a wide range of fields that study affective\ncomputing, including languages, sociology, psychology, computer science, and\nphysiology. However, no research has ever been done to determine how machine\nlearning (ML) and mixed reality (XR) interact together. This paper discusses\nthe significance of affective computing, as well as its ideas, conceptions,\nmethods, and outcomes. By using approaches of ML and XR, we survey and discuss\nrecent methodologies in affective computing. We survey the state-of-the-art\napproaches along with current affective data resources. Further, we discuss\nvarious applications where affective computing has a significant impact, which\nwill aid future scholars in gaining a better understanding of its significance\nand practical relevance.\n",
                "链接": "https://arxiv.org/abs/2305.07665"
            },
            {
                "文章ID": "105839",
                "标题": "SmartPlay: A Benchmark for LLMs as Intelligent Agents",
                "作者": " Yue Wu,  Xuan Tang,  Tom M. Mitchell,  Yuanzhi Li",
                "发布日期": "2023-12-11",
                "摘要": "  Recent large language models (LLMs) have demonstrated great potential toward\nintelligent agents and next-gen automation, but there currently lacks a\nsystematic benchmark for evaluating LLMs' abilities as agents. We introduce\nSmartPlay: both a challenging benchmark and a methodology for evaluating LLMs\nas agents. SmartPlay consists of 6 different games, including\nRock-Paper-Scissors, Tower of Hanoi, Minecraft. Each game features a unique\nsetting, providing up to 20 evaluation settings and infinite environment\nvariations. Each game in SmartPlay uniquely challenges a subset of 9 important\ncapabilities of an intelligent LLM agent, including reasoning with object\ndependencies, planning ahead, spatial reasoning, learning from history, and\nunderstanding randomness. The distinction between the set of capabilities each\ngame test allows us to analyze each capability separately. SmartPlay serves not\nonly as a rigorous testing ground for evaluating the overall performance of LLM\nagents but also as a road-map for identifying gaps in current methodologies. We\nrelease our benchmark at github.com/microsoft/SmartPlay\n",
                "链接": "https://arxiv.org/abs/2310.01557"
            },
            {
                "文章ID": "55278",
                "标题": "A Survey on Table-and-Text HybridQA: Concepts, Methods, Challenges and\n  Future Directions",
                "作者": " Dingzirui Wang,  Longxu Dou,  Wanxiang Che",
                "发布日期": "2023-02-03",
                "摘要": "  Table-and-text hybrid question answering (HybridQA) is a widely used and\nchallenging NLP task commonly applied in the financial and scientific domain.\nThe early research focuses on migrating other QA task methods to HybridQA,\nwhile with further research, more and more HybridQA-specific methods have been\npresent. With the rapid development of HybridQA, the systematic survey is still\nunder-explored to summarize the main techniques and advance further research.\nSo we present this work to summarize the current HybridQA benchmarks and\nmethods, then analyze the challenges and future directions of this task. The\ncontributions of this paper can be summarized in three folds: (1) first survey,\nto our best knowledge, including benchmarks, methods and challenges for\nHybridQA; (2) systematic investigation with the reasonable comparison of the\nexisting systems to articulate their advantages and shortcomings; (3) detailed\nanalysis of challenges in four important dimensions to shed light on future\ndirections.\n",
                "链接": "https://arxiv.org/abs/2212.13465"
            },
            {
                "文章ID": "83868",
                "标题": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM\n  Agents",
                "作者": " Yashar Talebirad,  Amirhossein Nadiri",
                "发布日期": "2023-06-07",
                "摘要": "  In this paper, we present a novel framework for enhancing the capabilities of\nlarge language models (LLMs) by leveraging the power of multi-agent systems.\nOur framework introduces a collaborative environment where multiple intelligent\nagent components, each with distinctive attributes and roles, work together to\nhandle complex tasks more efficiently and effectively. We demonstrate the\npracticality and versatility of our framework through case studies in\nartificial general intelligence (AGI), specifically focusing on the Auto-GPT\nand BabyAGI models. We also examine the \"Gorilla\" model, which integrates\nexternal APIs into the LLM. Our framework addresses limitations and challenges\nsuch as looping issues, security risks, scalability, system evaluation, and\nethical considerations. By modeling various domains such as courtroom\nsimulations and software development scenarios, we showcase the potential\napplications and benefits of our proposed multi-agent system. Our framework\nprovides an avenue for advancing the capabilities and performance of LLMs\nthrough collaboration and knowledge exchange among intelligent agents.\n",
                "链接": "https://arxiv.org/abs/2306.03314"
            }
        ]
    }
]