[
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "113444",
                "标题": "What Makes for Good Visual Instructions? Synthesizing Complex Visual\n  Reasoning Instructions for Visual Instruction Tuning",
                "作者": " Yifan Du,  Hangyu Guo,  Kun Zhou,  Wayne Xin Zhao,  Jinpeng Wang,  Chuyuan Wang,  Mingchen Cai,  Ruihua Song,  Ji-Rong Wen",
                "发布日期": "2023-11-06",
                "摘要": "  Visual instruction tuning is an essential approach to improving the zero-shot\ngeneralization capability of Multi-modal Large Language Models (MLLMs). A surge\nof visual instruction datasets with various focuses and characteristics have\nbeen proposed recently, enabling MLLMs to achieve surprising results on\nevaluation benchmarks. To develop more capable MLLMs, in this paper, we aim to\ninvestigate a more fundamental question: ``what makes for good visual\ninstructions?''. By conducting a comprehensive empirical study, we find that\ninstructions focused on complex visual reasoning tasks are particularly\neffective in improving the performance of MLLMs on evaluation benchmarks.\nBuilding upon this finding, we design a systematic approach to automatically\ncreating high-quality complex visual reasoning instructions. Our approach\nemploys a synthesis-complication-reformulation paradigm, leveraging multiple\nstages to gradually increase the complexity of the instructions while\nguaranteeing quality. Based on this approach, we create the synthetic visual\nreasoning instruction dataset consisting of 32K examples, namely ComVint, and\nfine-tune four MLLMs on it. Experimental results demonstrate that our dataset\nconsistently enhances the performance of all the compared MLLMs, e.g.,\nimproving the performance of MiniGPT-4 and BLIP-2 on MME-Cognition by 32.6% and\n28.8%, respectively. Our code and data are publicly available at the link:\nhttps://github.com/RUCAIBox/ComVint.\n",
                "链接": "https://arxiv.org/abs/2311.01487"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "12176",
                "标题": "Separate What You Describe: Language-Queried Audio Source Separation",
                "作者": " Xubo Liu,  Haohe Liu,  Qiuqiang Kong,  Xinhao Mei,  Jinzheng Zhao,  Qiushi Huang,  Mark D. Plumbley,  Wenwu Wang",
                "发布日期": "2022-03-30",
                "摘要": "  In this paper, we introduce the task of language-queried audio source\nseparation (LASS), which aims to separate a target source from an audio mixture\nbased on a natural language query of the target source (e.g., \"a man tells a\njoke followed by people laughing\"). A unique challenge in LASS is associated\nwith the complexity of natural language description and its relation with the\naudio sources. To address this issue, we proposed LASS-Net, an end-to-end\nneural network that is learned to jointly process acoustic and linguistic\ninformation, and separate the target source that is consistent with the\nlanguage query from an audio mixture. We evaluate the performance of our\nproposed system with a dataset created from the AudioCaps dataset. Experimental\nresults show that LASS-Net achieves considerable improvements over baseline\nmethods. Furthermore, we observe that LASS-Net achieves promising\ngeneralization results when using diverse human-annotated descriptions as\nqueries, indicating its potential use in real-world scenarios. The separated\naudio samples and source code are available at\nhttps://liuxubo717.github.io/LASS-demopage.\n",
                "链接": "https://arxiv.org/abs/2203.15147"
            },
            {
                "文章ID": "38420",
                "标题": "Improved Perception of AEC Construction Details via Immersive Teaching\n  in Virtual Reality",
                "作者": " Michael Kraus,  Romana Rust,  Maximilian Rietschel,  Daniel Hall",
                "发布日期": "2022-09-23",
                "摘要": "  This work proposes, implements and tests an immersive framework upon Virtual\nReality (VR) for comprehension, knowledge development and learning process\nassisting an improved perception of complex spatial arrangements in AEC in\ncomparison to the traditional 2D projection drawing-based method. The research\nfocuses on the prototypical example of construction details as a traditionally\ndifficult teaching task for conveying geometric and semantic information to\nstudents. Our mixed-methods study analyses test results of two test panel\ngroups upon different questions about geometric and functional aspects of the\nconstruction detail as well as surveys and interviews of participating\nlecturers, students and laypersons towards their experience using the VR tool.\nThe quantitative analysis of the test results prove that for participants with\nlittle pre-existing knowledge (such as novice students), a significantly better\nlearning score for the test group is detected. Moreover, both groups rated the\nVR experience as an enjoyable and engaging way of learning. Analysis of survey\nresults towards the VR experience reveals, that students, lecturers and\nprofessionals alike enjoyed the VR experience more than traditional learning of\nthe construction detail. During the post-experiment qualitative evaluation in\nthe form of interviews, the panel expressed an improved understanding,\nincreased enthusiasm for the topic, and greater desire for other topics to be\npresented using VR tools. The expressed better understanding of design concepts\nafter the VR experience by the students is statistically significant on average\nin the exam results. The results support our core assumption, that the\npresentation of contextual 3D models is a promising teaching approach to\nillustrate content.\n",
                "链接": "https://arxiv.org/abs/2209.10617"
            },
            {
                "文章ID": "49528",
                "标题": "Recovering Fine Details for Neural Implicit Surface Reconstruction",
                "作者": " Decai Chen,  Peng Zhang,  Ingo Feldmann,  Oliver Schreer,  Peter Eisert",
                "发布日期": "2022-11-22",
                "摘要": "  Recent works on implicit neural representations have made significant\nstrides. Learning implicit neural surfaces using volume rendering has gained\npopularity in multi-view reconstruction without 3D supervision. However,\naccurately recovering fine details is still challenging, due to the underlying\nambiguity of geometry and appearance representation. In this paper, we present\nD-NeuS, a volume rendering-base neural implicit surface reconstruction method\ncapable to recover fine geometry details, which extends NeuS by two additional\nloss functions targeting enhanced reconstruction quality. First, we encourage\nthe rendered surface points from alpha compositing to have zero signed distance\nvalues, alleviating the geometry bias arising from transforming SDF to density\nfor volume rendering. Second, we impose multi-view feature consistency on the\nsurface points, derived by interpolating SDF zero-crossings from sampled points\nalong rays. Extensive quantitative and qualitative results demonstrate that our\nmethod reconstructs high-accuracy surfaces with details, and outperforms the\nstate of the art.\n",
                "链接": "https://arxiv.org/abs/2211.11320"
            },
            {
                "文章ID": "96768",
                "标题": "DeDoDe: Detect, Don't Describe -- Describe, Don't Detect for Local\n  Feature Matching",
                "作者": " Johan Edstedt,  Georg Bökman,  Mårten Wadenbäck,  Michael Felsberg",
                "发布日期": "2023-12-12",
                "摘要": "  Keypoint detection is a pivotal step in 3D reconstruction, whereby sets of\n(up to) K points are detected in each view of a scene. Crucially, the detected\npoints need to be consistent between views, i.e., correspond to the same 3D\npoint in the scene. One of the main challenges with keypoint detection is the\nformulation of the learning objective. Previous learning-based methods\ntypically jointly learn descriptors with keypoints, and treat the keypoint\ndetection as a binary classification task on mutual nearest neighbours.\nHowever, basing keypoint detection on descriptor nearest neighbours is a proxy\ntask, which is not guaranteed to produce 3D-consistent keypoints. Furthermore,\nthis ties the keypoints to a specific descriptor, complicating downstream\nusage. In this work, we instead learn keypoints directly from 3D consistency.\nTo this end, we train the detector to detect tracks from large-scale SfM. As\nthese points are often overly sparse, we derive a semi-supervised two-view\ndetection objective to expand this set to a desired number of detections. To\ntrain a descriptor, we maximize the mutual nearest neighbour objective over the\nkeypoints with a separate network. Results show that our approach, DeDoDe,\nachieves significant gains on multiple geometry benchmarks. Code is provided at\nhttps://github.com/Parskatt/DeDoDe\n",
                "链接": "https://arxiv.org/abs/2308.08479"
            },
            {
                "文章ID": "80158",
                "标题": "Instructions as Backdoors: Backdoor Vulnerabilities of Instruction\n  Tuning for Large Language Models",
                "作者": " Jiashu Xu,  Mingyu Derek Ma,  Fei Wang,  Chaowei Xiao,  Muhao Chen",
                "发布日期": "2023-05-25",
                "摘要": "  Instruction-tuned models are trained on crowdsourcing datasets with task\ninstructions to achieve superior performance. However, in this work we raise\nsecurity concerns about this training paradigm. Our studies demonstrate that an\nattacker can inject backdoors by issuing very few malicious instructions among\nthousands of gathered data and control model behavior through data poisoning,\nwithout even the need of modifying data instances or labels themselves. Through\nsuch instruction attacks, the attacker can achieve over 90% attack success rate\nacross four commonly used NLP datasets, and cause persistent backdoors that are\neasily transferred to 15 diverse datasets zero-shot. In this way, the attacker\ncan directly apply poisoned instructions designed for one dataset on many other\ndatasets. Moreover, the poisoned model cannot be cured by continual learning.\nLastly, instruction attacks show resistance to existing inference-time defense.\nThese findings highlight the need for more robust defenses against data\npoisoning attacks in instructiontuning models and underscore the importance of\nensuring data quality in instruction crowdsourcing.\n",
                "链接": "https://arxiv.org/abs/2305.14710"
            },
            {
                "文章ID": "95642",
                "标题": "Separate Anything You Describe",
                "作者": " Xubo Liu,  Qiuqiang Kong,  Yan Zhao,  Haohe Liu,  Yi Yuan,  Yuzhuo Liu,  Rui Xia,  Yuxuan Wang,  Mark D. Plumbley,  Wenwu Wang",
                "发布日期": "2023-10-30",
                "摘要": "  Language-queried audio source separation (LASS) is a new paradigm for\ncomputational auditory scene analysis (CASA). LASS aims to separate a target\nsound from an audio mixture given a natural language query, which provides a\nnatural and scalable interface for digital audio applications. Recent works on\nLASS, despite attaining promising separation performance on specific sources\n(e.g., musical instruments, limited classes of audio events), are unable to\nseparate audio concepts in the open domain. In this work, we introduce\nAudioSep, a foundation model for open-domain audio source separation with\nnatural language queries. We train AudioSep on large-scale multimodal datasets\nand extensively evaluate its capabilities on numerous tasks including audio\nevent separation, musical instrument separation, and speech enhancement.\nAudioSep demonstrates strong separation performance and impressive zero-shot\ngeneralization ability using audio captions or text labels as queries,\nsubstantially outperforming previous audio-queried and language-queried sound\nseparation models. For reproducibility of this work, we will release the source\ncode, evaluation benchmark and pre-trained model at:\nhttps://github.com/Audio-AGI/AudioSep.\n",
                "链接": "https://arxiv.org/abs/2308.05037"
            },
            {
                "文章ID": "120242",
                "标题": "MUFFIN: Curating Multi-Faceted Instructions for Improving\n  Instruction-Following",
                "作者": " Renze Lou,  Kai Zhang,  Jian Xie,  Yuxuan Sun,  Janice Ahn,  Hanzi Xu,  Yu Su,  Wenpeng Yin",
                "发布日期": "2023-12-06",
                "摘要": "  In the realm of large language models (LLMs), enhancing instruction-following\ncapability often involves curating expansive training data. This is achieved\nthrough two primary schemes: i) Scaling-Inputs: Amplifying (input, output)\npairs per task instruction, aiming for better instruction adherence. ii)\nScaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction,\noutput) pair (without requiring a separate input anymore). However, LLMs under\nScaling-Inputs tend to be overly sensitive to inputs, leading to\nmisinterpretation or non-compliance with instructions. Conversely, Scaling\nInput-Free Tasks demands a substantial number of tasks but is less effective in\ninstruction following when dealing with instances in Scaling-Inputs. This work\nintroduces MUFFIN, a new scheme of instruction-following dataset curation.\nSpecifically, we automatically Scale Tasks per Input by diversifying these\ntasks with various input facets. Experimental results across four zero-shot\nbenchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes,\nreveal that LLMs, at various scales, trained on MUFFIN generally demonstrate\nsuperior instruction-following capabilities compared to those trained on the\ntwo aforementioned schemes.\n",
                "链接": "https://arxiv.org/abs/2312.02436"
            },
            {
                "文章ID": "43709",
                "标题": "Language Does More Than Describe: On The Lack Of Figurative Speech in\n  Text-To-Image Models",
                "作者": " Ricardo Kleinlein,  Cristina Luna-Jiménez,  Fernando Fernández-Martínez",
                "发布日期": "2022-10-20",
                "摘要": "  The impressive capacity shown by recent text-to-image diffusion models to\ngenerate high-quality pictures from textual input prompts has leveraged the\ndebate about the very definition of art. Nonetheless, these models have been\ntrained using text data collected from content-based labelling protocols that\nfocus on describing the items and actions in an image but neglect any\nsubjective appraisal. Consequently, these automatic systems need rigorous\ndescriptions of the elements and the pictorial style of the image to be\ngenerated, otherwise failing to deliver. As potential indicators of the actual\nartistic capabilities of current generative models, we characterise the\nsentimentality, objectiveness and degree of abstraction of publicly available\ntext data used to train current text-to-image diffusion models. Considering the\nsharp difference observed between their language style and that typically\nemployed in artistic contexts, we suggest generative models should incorporate\nadditional sources of subjective information in their training in order to\novercome (or at least to alleviate) some of their current limitations, thus\neffectively unleashing a truly artistic and creative generation.\n",
                "链接": "https://arxiv.org/abs/2210.10578"
            }
        ]
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "2025",
                "标题": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual\n  Sentiment Analysis",
                "作者": " Shamsuddeen Hassan Muhammad,  David Ifeoluwa Adelani,  Sebastian Ruder,  Ibrahim Said Ahmad,  Idris Abdulmumin,  Bello Shehu Bello,  Monojit Choudhury,  Chris Chinenye Emezue,  Saheed Salahudeen Abdullahi,  Anuoluwapo Aremu,  Alipio Jeorge,  Pavel Brazdil",
                "发布日期": "2022-06-22",
                "摘要": "  Sentiment analysis is one of the most widely studied applications in NLP, but\nmost work focuses on languages with large amounts of data. We introduce the\nfirst large-scale human-annotated Twitter sentiment dataset for the four most\nwidely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and\nYor\\`ub\\'a ) consisting of around 30,000 annotated tweets per language (and\n14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed\ntweets. We propose text collection, filtering, processing and labeling methods\nthat enable us to create datasets for these low-resource languages. We evaluate\na rangeof pre-trained models and transfer strategies on the dataset. We find\nthat language-specific models and language-adaptivefine-tuning generally\nperform best. We release the datasets, trained models, sentiment lexicons, and\ncode to incentivizeresearch on sentiment analysis in under-represented\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2201.08277"
            },
            {
                "文章ID": "112858",
                "标题": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
                "作者": " Michael Färber,  David Lamprecht",
                "发布日期": "2023-11-01",
                "摘要": "  In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.\n",
                "链接": "https://arxiv.org/abs/2310.20475"
            },
            {
                "文章ID": "23956",
                "标题": "Sentiment analysis on electricity twitter posts",
                "作者": " Pardeep Kaur,  Maryam Edalati",
                "发布日期": "2022-06-13",
                "摘要": "  In today's world, everyone is expressive in some way, and the focus of this\nproject is on people's opinions about rising electricity prices in United\nKingdom and India using data from Twitter, a micro-blogging platform on which\npeople post messages, known as tweets. Because many people's incomes are not\ngood and they have to pay so many taxes and bills, maintaining a home has\nbecome a disputed issue these days. Despite the fact that Government offered\nsubsidy schemes to compensate people electricity bills but it is not welcomed\nby people. In this project, the aim is to perform sentiment analysis on\npeople's expressions and opinions expressed on Twitter. In order to grasp the\nelectricity prices opinion, it is necessary to carry out sentiment analysis for\nthe government and consumers in energy market. Furthermore, text present on\nthese medias are unstructured in nature, so to process them we firstly need to\npre-process the data. There are so many feature extraction techniques such as\nBag of Words, TF-IDF (Term Frequency-Inverse Document Frequency), word\nembedding, NLP based features like word count. In this project, we analysed the\nimpact of feature TF-IDF word level on electricity bills dataset of sentiment\nanalysis. We found that by using TF-IDF word level performance of sentiment\nanalysis is 3-4 higher than using N-gram features. Analysis is done using four\nclassification algorithms including Naive Bayes, Decision Tree, Random Forest,\nand Logistic Regression and considering F-Score, Accuracy, Precision, and\nRecall performance parameters.\n",
                "链接": "https://arxiv.org/abs/2206.05042"
            },
            {
                "文章ID": "3562",
                "标题": "Negativity Spreads Faster: A Large-Scale Multilingual Twitter Analysis\n  on the Role of Sentiment in Political Communication",
                "作者": " Dimosthenis Antypas,  Alun Preece,  Jose Camacho-Collados",
                "发布日期": "2023-04-05",
                "摘要": "  Social media has become extremely influential when it comes to policy making\nin modern societies, especially in the western world, where platforms such as\nTwitter allow users to follow politicians, thus making citizens more involved\nin political discussion. In the same vein, politicians use Twitter to express\ntheir opinions, debate among others on current topics and promote their\npolitical agendas aiming to influence voter behaviour. In this paper, we\nattempt to analyse tweets of politicians from three European countries and\nexplore the virality of their tweets. Previous studies have shown that tweets\nconveying negative sentiment are likely to be retweeted more frequently. By\nutilising state-of-the-art pre-trained language models, we performed sentiment\nanalysis on hundreds of thousands of tweets collected from members of\nparliament in Greece, Spain and the United Kingdom, including devolved\nadministrations. We achieved this by systematically exploring and analysing the\ndifferences between influential and less popular tweets. Our analysis indicates\nthat politicians' negatively charged tweets spread more widely, especially in\nmore recent times, and highlights interesting differences between political\nparties as well as between politicians and the general population.\n",
                "链接": "https://arxiv.org/abs/2202.00396"
            },
            {
                "文章ID": "14369",
                "标题": "Assessment of Massively Multilingual Sentiment Classifiers",
                "作者": " Krzysztof Rajda,  Łukasz Augustyniak,  Piotr Gramacki,  Marcin Gruza,  Szymon Woźniak,  Tomasz Kajdanowicz",
                "发布日期": "2022-04-12",
                "摘要": "  Models are increasing in size and complexity in the hunt for SOTA. But what\nif those 2\\% increase in performance does not make a difference in a production\nuse case? Maybe benefits from a smaller, faster model outweigh those slight\nperformance gains. Also, equally good performance across languages in\nmultilingual tasks is more important than SOTA results on a single one. We\npresent the biggest, unified, multilingual collection of sentiment analysis\ndatasets. We use these to assess 11 models and 80 high-quality sentiment\ndatasets (out of 342 raw datasets collected) in 27 languages and included\nresults on the internally annotated datasets. We deeply evaluate multiple\nsetups, including fine-tuning transformer-based models for measuring\nperformance. We compare results in numerous dimensions addressing the imbalance\nin both languages coverage and dataset sizes. Finally, we present some best\npractices for working with such a massive collection of datasets and models\nfrom a multilingual perspective.\n",
                "链接": "https://arxiv.org/abs/2204.04937"
            },
            {
                "文章ID": "22243",
                "标题": "Uzbek Sentiment Analysis based on local Restaurant Reviews",
                "作者": " Sanatbek Matlatipov,  Hulkar Rahimboeva,  Jaloliddin Rajabov,  Elmurod Kuriyozov",
                "发布日期": "2022-06-01",
                "摘要": "  Extracting useful information for sentiment analysis and classification\nproblems from a big amount of user-generated feedback, such as restaurant\nreviews, is a crucial task of natural language processing, which is not only\nfor customer satisfaction where it can give personalized services, but can also\ninfluence the further development of a company. In this paper, we present a\nwork done on collecting restaurant reviews data as a sentiment analysis dataset\nfor the Uzbek language, a member of the Turkic family which is heavily affected\nby the low-resource constraint, and provide some further analysis of the novel\ndataset by evaluation using different techniques, from logistic regression\nbased models, to support vector machines, and even deep learning models, such\nas recurrent neural networks, as well as convolutional neural networks. The\npaper includes detailed information on how the data was collected, how it was\npre-processed for better quality optimization, as well as experimental setups\nfor the evaluation process. The overall evaluation results indicate that by\nperforming pre-processing steps, such as stemming for agglutinative languages,\nthe system yields better results, eventually achieving 91% accuracy result in\nthe best performing model\n",
                "链接": "https://arxiv.org/abs/2205.15930"
            },
            {
                "文章ID": "40184",
                "标题": "Sentiment Analysis of ESG disclosures on Stock Market",
                "作者": " Sudeep R. Bapat,  Saumya Kothari,  Rushil Bansal",
                "发布日期": "2022-10-04",
                "摘要": "  In this paper, we look at the impact of Environment, Social and Governance\nrelated news articles and social media data on the stock market performance. We\npick four stocks of companies which are widely known in their domain to\nunderstand the complete effect of ESG as the newly opted investment style\nremains restricted to only the stocks with widespread information. We summarise\nlive data of both twitter tweets and newspaper articles and create a sentiment\nindex using a dictionary technique based on online information for the month of\nJuly, 2022. We look at the stock price data for all the four companies and\ncalculate the percentage change in each of them. We also compare the overall\nsentiment of the company to its percentage change over a specific historical\nperiod.\n",
                "链接": "https://arxiv.org/abs/2210.00731"
            },
            {
                "文章ID": "75848",
                "标题": "New Adversarial Image Detection Based on Sentiment Analysis",
                "作者": " Yulong Wang,  Tianxiang Li,  Shenghong Li,  Xin Yuan,  Wei Ni",
                "发布日期": "2023-05-08",
                "摘要": "  Deep Neural Networks (DNNs) are vulnerable to adversarial examples, while\nadversarial attack models, e.g., DeepFool, are on the rise and outrunning\nadversarial example detection techniques. This paper presents a new adversarial\nexample detector that outperforms state-of-the-art detectors in identifying the\nlatest adversarial attacks on image datasets. Specifically, we propose to use\nsentiment analysis for adversarial example detection, qualified by the\nprogressively manifesting impact of an adversarial perturbation on the\nhidden-layer feature maps of a DNN under attack. Accordingly, we design a\nmodularized embedding layer with the minimum learnable parameters to embed the\nhidden-layer feature maps into word vectors and assemble sentences ready for\nsentiment analysis. Extensive experiments demonstrate that the new detector\nconsistently surpasses the state-of-the-art detection algorithms in detecting\nthe latest attacks launched against ResNet and Inception neutral networks on\nthe CIFAR-10, CIFAR-100 and SVHN datasets. The detector only has about 2\nmillion parameters, and takes shorter than 4.6 milliseconds to detect an\nadversarial example generated by the latest attack models using a Tesla K80 GPU\ncard.\n",
                "链接": "https://arxiv.org/abs/2305.03173"
            },
            {
                "文章ID": "120683",
                "标题": "Sentiment Analysis of Twitter Posts on Global Conflicts",
                "作者": " Ujwal Sasikumar,  Ank Zaman,  Abdul-Rahman Mawlood-Yunis,  Prosenjit Chatterjee",
                "发布日期": "2023-12-08",
                "摘要": "  Sentiment analysis of social media data is an emerging field with vast\napplications in various domains. In this study, we developed a sentiment\nanalysis model to analyze social media sentiment, especially tweets, during\nglobal conflicting scenarios. To establish our research experiment, we\nidentified a recent global dispute incident on Twitter and collected around\n31,000 filtered Tweets for several months to analyze human sentiment worldwide.\n",
                "链接": "https://arxiv.org/abs/2312.03715"
            },
            {
                "文章ID": "22988",
                "标题": "Sentiment Analysis of Online Travel Reviews Based on Capsule Network and\n  Sentiment Lexicon",
                "作者": " Jia Wang,  Junping Du,  Yingxia Shao,  Ang Li",
                "发布日期": "2022-06-07",
                "摘要": "  With the development of online travel services, it has great application\nprospects to timely mine users' evaluation emotions for travel services and use\nthem as indicators to guide the improvement of online travel service quality.\nIn this paper, we study the text sentiment classification of online travel\nreviews based on social media online comments and propose the SCCL model based\non capsule network and sentiment lexicon. SCCL model aims at the lack of\nconsideration of local features and emotional semantic features of the text in\nthe language model that can efficiently extract text context features like BERT\nand GRU. Then make the following improvements to their shortcomings. On the one\nhand, based on BERT-BiGRU, the capsule network is introduced to extract local\nfeatures while retaining good context features. On the other hand, the\nsentiment lexicon is introduced to extract the emotional sequence of the text\nto provide richer emotional semantic features for the model. To enhance the\nuniversality of the sentiment lexicon, the improved SO-PMI algorithm based on\nTF-IDF is used to expand the lexicon, so that the lexicon can also perform well\nin the field of online travel reviews.\n",
                "链接": "https://arxiv.org/abs/2206.02160"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "77817",
                "标题": "About Evaluation of F1 Score for RECENT Relation Extraction System",
                "作者": " Michał Olek",
                "发布日期": "2023-05-17",
                "摘要": "  This document contains a discussion of the F1 score evaluation used in the\narticle 'Relation Classification with Entity Type Restriction' by Shengfei Lyu,\nHuanhuan Chen published on Findings of the Association for Computational\nLinguistics: ACL-IJCNLP 2021. The authors created a system named RECENT and\nclaim it achieves (then) a new state-of-the-art result 75.2 (previous 74.8) on\nthe TACRED dataset, while after correcting errors and reevaluation the final\nresult is 65.16\n",
                "链接": "https://arxiv.org/abs/2305.09410"
            },
            {
                "文章ID": "72313",
                "标题": "Evaluation of Social Biases in Recent Large Pre-Trained Models",
                "作者": " Swapnil Sharma,  Nikita Anand,  Kranthi Kiran G. V.,  Alind Jain",
                "发布日期": "2023-04-17",
                "摘要": "  Large pre-trained language models are widely used in the community. These\nmodels are usually trained on unmoderated and unfiltered data from open sources\nlike the Internet. Due to this, biases that we see in platforms online which\nare a reflection of those in society are in turn captured and learned by these\nmodels. These models are deployed in applications that affect millions of\npeople and their inherent biases are harmful to the targeted social groups. In\nthis work, we study the general trend in bias reduction as newer pre-trained\nmodels are released. Three recent models ( ELECTRA, DeBERTa, and DistilBERT)\nare chosen and evaluated against two bias benchmarks, StereoSet and\nCrowS-Pairs. They are compared to the baseline of BERT using the associated\nmetrics. We explore whether as advancements are made and newer, faster, lighter\nmodels are released: are they being developed responsibly such that their\ninherent social biases have been reduced compared to their older counterparts?\nThe results are compiled and we find that all the models under study do exhibit\nbiases but have generally improved as compared to BERT.\n",
                "链接": "https://arxiv.org/abs/2304.06861"
            },
            {
                "文章ID": "52576",
                "标题": "Talking About Large Language Models",
                "作者": " Murray Shanahan",
                "发布日期": "2023-02-17",
                "摘要": "  Thanks to rapid progress in artificial intelligence, we have entered an era\nwhen technology and philosophy intersect in interesting ways. Sitting squarely\nat the centre of this intersection are large language models (LLMs). The more\nadept LLMs become at mimicking human language, the more vulnerable we become to\nanthropomorphism, to seeing the systems in which they are embedded as more\nhuman-like than they really are. This trend is amplified by the natural\ntendency to use philosophically loaded terms, such as \"knows\", \"believes\", and\n\"thinks\", when describing these systems. To mitigate this trend, this paper\nadvocates the practice of repeatedly stepping back to remind ourselves of how\nLLMs, and the systems of which they form a part, actually work. The hope is\nthat increased scientific precision will encourage more philosophical nuance in\nthe discourse around artificial intelligence, both within the field and in the\npublic sphere.\n",
                "链接": "https://arxiv.org/abs/2212.03551"
            },
            {
                "文章ID": "69100",
                "标题": "Large Language Models are Diverse Role-Players for Summarization\n  Evaluation",
                "作者": " Ning Wu,  Ming Gong,  Linjun Shou,  Shining Liang,  Daxin Jiang",
                "发布日期": "2023-09-20",
                "摘要": "  Text summarization has a wide range of applications in many scenarios. The\nevaluation of the quality of the generated text is a complex problem. A big\nchallenge to language evaluation is that there is a clear divergence between\nexisting metrics and human evaluation. A document summary's quality can be\nassessed by human annotators on various criteria, both objective ones like\ngrammar and correctness, and subjective ones like informativeness,\nsuccinctness, and appeal. Most of the automatic evaluation methods like\nBLUE/ROUGE may be not able to adequately capture the above dimensions. In this\npaper, we propose a new evaluation framework based on LLMs, which provides a\ncomprehensive evaluation framework by comparing generated text and reference\ntext from both objective and subjective aspects. First, we propose to model\nobjective and subjective dimensions of generated text based on roleplayers\nprompting mechanism. Furthermore, we introduce a context-based prompting\nmechanism that is able to generate dynamic roleplayer profiles based on input\ncontext. Finally, we design a multi-roleplayer prompting technology based on\nbatch prompting and integrate multiple outputs into the final evaluation\nresults. Experimental results on three real datasets for summarization show\nthat our model is highly competitive and has a very high consistency with human\nannotators.\n",
                "链接": "https://arxiv.org/abs/2303.15078"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "107187",
                "标题": "Do Large Language Models Know about Facts?",
                "作者": " Xuming Hu,  Junzhe Chen,  Xiaochuan Li,  Yufei Guo,  Lijie Wen,  Philip S. Yu,  Zhijiang Guo",
                "发布日期": "2023-10-10",
                "摘要": "  Large language models (LLMs) have recently driven striking performance\nimprovements across a range of natural language processing tasks. The factual\nknowledge acquired during pretraining and instruction tuning can be useful in\nvarious downstream tasks, such as question answering, and language generation.\nUnlike conventional Knowledge Bases (KBs) that explicitly store factual\nknowledge, LLMs implicitly store facts in their parameters. Content generated\nby the LLMs can often exhibit inaccuracies or deviations from the truth, due to\nfacts that can be incorrectly induced or become obsolete over time. To this\nend, we aim to comprehensively evaluate the extent and scope of factual\nknowledge within LLMs by designing the benchmark Pinocchio. Pinocchio contains\n20K diverse factual questions that span different sources, timelines, domains,\nregions, and languages. Furthermore, we investigate whether LLMs are able to\ncompose multiple facts, update factual knowledge temporally, reason over\nmultiple pieces of facts, identify subtle factual differences, and resist\nadversarial examples. Extensive experiments on different sizes and types of\nLLMs show that existing LLMs still lack factual knowledge and suffer from\nvarious spurious correlations. We believe this is a critical bottleneck for\nrealizing trustworthy artificial intelligence. The dataset Pinocchio and our\ncodes will be publicly available.\n",
                "链接": "https://arxiv.org/abs/2310.05177"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "78952",
                "标题": "Revisiting Automated Topic Model Evaluation with Large Language Models",
                "作者": " Dominik Stammbach,  Vilém Zouhar,  Alexander Hoyle,  Mrinmaya Sachan,  Elliott Ash",
                "发布日期": "2023-10-24",
                "摘要": "  Topic models are used to make sense of large text collections. However,\nautomatically evaluating topic model output and determining the optimal number\nof topics both have been longstanding challenges, with no effective automated\nsolutions to date. This paper proposes using large language models to evaluate\nsuch output. We find that large language models appropriately assess the\nresulting topics, correlating more strongly with human judgments than existing\nautomated metrics. We then investigate whether we can use large language models\nto automatically determine the optimal number of topics. We automatically\nassign labels to documents and choosing configurations with the most pure\nlabels returns reasonable values for the optimal number of topics.\n",
                "链接": "https://arxiv.org/abs/2305.12152"
            },
            {
                "文章ID": "29607",
                "标题": "Can large language models reason about medical questions?",
                "作者": " Valentin Liévin,  Christoffer Egeberg Hother,  Andreas Geert Motzfeldt,  Ole Winther",
                "发布日期": "2023-12-27",
                "摘要": "  Although large language models (LLMs) often produce impressive outputs, it\nremains unclear how they perform in real-world scenarios requiring strong\nreasoning skills and expert domain knowledge. We set out to investigate whether\nclose- and open-source models (GPT-3.5, LLama-2, etc.) can be applied to answer\nand reason about difficult real-world-based questions. We focus on three\npopular medical benchmarks (MedQA-USMLE, MedMCQA, and PubMedQA) and multiple\nprompting scenarios: Chain-of-Thought (CoT, think step-by-step), few-shot and\nretrieval augmentation. Based on an expert annotation of the generated CoTs, we\nfound that InstructGPT can often read, reason and recall expert knowledge.\nLast, by leveraging advances in prompt engineering (few-shot and ensemble\nmethods), we demonstrated that GPT-3.5 not only yields calibrated predictive\ndistributions, but also reaches the passing score on three datasets:\nMedQA-USMLE 60.2%, MedMCQA 62.7% and PubMedQA 78.2%. Open-source models are\nclosing the gap: Llama-2 70B also passed the MedQA-USMLE with 62.5% accuracy.\n",
                "链接": "https://arxiv.org/abs/2207.08143"
            },
            {
                "文章ID": "70301",
                "标题": "Eight Things to Know about Large Language Models",
                "作者": " Samuel R. Bowman",
                "发布日期": "2023-04-04",
                "摘要": "  The widespread public deployment of large language models (LLMs) in recent\nmonths has prompted a wave of new attention and engagement from advocates,\npolicymakers, and scholars from many fields. This attention is a timely\nresponse to the many urgent questions that this technology raises, but it can\nsometimes miss important considerations. This paper surveys the evidence for\neight potentially surprising such points:\n  1. LLMs predictably get more capable with increasing investment, even without\ntargeted innovation.\n  2. Many important LLM behaviors emerge unpredictably as a byproduct of\nincreasing investment.\n  3. LLMs often appear to learn and use representations of the outside world.\n  4. There are no reliable techniques for steering the behavior of LLMs.\n  5. Experts are not yet able to interpret the inner workings of LLMs.\n  6. Human performance on a task isn't an upper bound on LLM performance.\n  7. LLMs need not express the values of their creators nor the values encoded\nin web text.\n  8. Brief interactions with LLMs are often misleading.\n",
                "链接": "https://arxiv.org/abs/2304.00612"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "114068",
                "标题": "GLaMM: Pixel Grounding Large Multimodal Model",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Sahal Shaji,  Abdelrahman Shaker,  Salman Khan,  Hisham Cholakkal,  Rao M. Anwer,  Erix Xing,  Ming-Hsuan Yang,  Fahad S. Khan",
                "发布日期": "2023-11-07",
                "摘要": "  Large Multimodal Models (LMMs) extend Large Language Models to the vision\ndomain. Initial efforts towards LMMs used holistic images and text prompts to\ngenerate ungrounded textual responses. Very recently, region-level LMMs have\nbeen used to generate visually grounded responses. However, they are limited to\nonly referring a single object category at a time, require users to specify the\nregions in inputs, or cannot offer dense pixel-wise object grounding. In this\nwork, we present Grounding LMM (GLaMM), the first model that can generate\nnatural language responses seamlessly intertwined with corresponding object\nsegmentation masks. GLaMM not only grounds objects appearing in the\nconversations but is flexible enough to accept both textual and optional visual\nprompts (region of interest) as input. This empowers users to interact with the\nmodel at various levels of granularity, both in textual and visual domains. Due\nto the lack of standard benchmarks for the novel setting of generating visually\ngrounded detailed conversations, we introduce a comprehensive evaluation\nprotocol with our curated grounded conversations. Our proposed Grounded\nConversation Generation (GCG) task requires densely grounded concepts in\nnatural scenes at a large-scale. To this end, we propose a densely annotated\nGrounding-anything Dataset (GranD) using our proposed automated annotation\npipeline that encompasses 7.5M unique concepts grounded in a total of 810M\nregions available with segmentation masks. Besides GCG, GLaMM also performs\neffectively on several downstream tasks e.g., referring expression\nsegmentation, image and region-level captioning and vision-language\nconversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.\n",
                "链接": "https://arxiv.org/abs/2311.03356"
            },
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "100082",
                "标题": "Large AI Model Empowered Multimodal Semantic Communications",
                "作者": " Feibo Jiang,  Yubo Peng,  Li Dong,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Xiaohu You",
                "发布日期": "2023-09-06",
                "摘要": "  Multimodal signals, including text, audio, image and video, can be integrated\ninto Semantic Communication (SC) for providing an immersive experience with low\nlatency and high quality at the semantic level. However, the multimodal SC has\nseveral challenges, including data heterogeneity, semantic ambiguity, and\nsignal fading. Recent advancements in large AI models, particularly in\nMultimodal Language Model (MLM) and Large Language Model (LLM), offer potential\nsolutions for these issues. To this end, we propose a Large AI Model-based\nMultimodal SC (LAM-MSC) framework, in which we first present the MLM-based\nMultimodal Alignment (MMA) that utilizes the MLM to enable the transformation\nbetween multimodal and unimodal data while preserving semantic consistency.\nThen, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows\nusers to perform personalized semantic extraction or recovery through the LLM.\nThis effectively addresses the semantic ambiguity. Finally, we apply the\nConditional Generative adversarial networks-based channel Estimation (CGE) to\nobtain Channel State Information (CSI). This approach effectively mitigates the\nimpact of fading channels in SC. Finally, we conduct simulations that\ndemonstrate the superior performance of the LAM-MSC framework.\n",
                "链接": "https://arxiv.org/abs/2309.01249"
            },
            {
                "文章ID": "108480",
                "标题": "Multimodal Large Language Model for Visual Navigation",
                "作者": " Yao-Hung Hubert Tsai,  Vansh Dhar,  Jialu Li,  Bowen Zhang,  Jian Zhang",
                "发布日期": "2023-11-07",
                "摘要": "  Recent efforts to enable visual navigation using large language models have\nmainly focused on developing complex prompt systems. These systems incorporate\ninstructions, observations, and history into massive text prompts, which are\nthen combined with pre-trained large language models to facilitate visual\nnavigation. In contrast, our approach aims to fine-tune large language models\nfor visual navigation without extensive prompt engineering. Our design involves\na simple text prompt, current observations, and a history collector model that\ngathers information from previous observations as input. For output, our design\nprovides a probability distribution of possible actions that the agent can take\nduring navigation. We train our model using human demonstrations and collision\nsignals from the Habitat-Matterport 3D Dataset (HM3D). Experimental results\ndemonstrate that our method outperforms state-of-the-art behavior cloning\nmethods and effectively reduces collision rates.\n",
                "链接": "https://arxiv.org/abs/2310.08669"
            },
            {
                "文章ID": "120164",
                "标题": "PixelLM: Pixel Reasoning with Large Multimodal Model",
                "作者": " Zhongwei Ren,  Zhicheng Huang,  Yunchao Wei,  Yao Zhao,  Dongmei Fu,  Jiashi Feng,  Xiaojie Jin",
                "发布日期": "2023-12-06",
                "摘要": "  While large multimodal models (LMMs) have achieved remarkable progress,\ngenerating pixel-level masks for image reasoning tasks involving multiple\nopen-world targets remains a challenge. To bridge this gap, we introduce\nPixelLM, an effective and efficient LMM for pixel-level reasoning and\nunderstanding. Central to PixelLM is a novel, lightweight pixel decoder and a\ncomprehensive segmentation codebook. The decoder efficiently produces masks\nfrom the hidden embeddings of the codebook tokens, which encode detailed\ntarget-relevant information. With this design, PixelLM harmonizes with the\nstructure of popular LMMs and avoids the need for additional costly\nsegmentation models. Furthermore, we propose a target refinement loss to\nenhance the model's ability to differentiate between multiple targets, leading\nto substantially improved mask quality. To advance research in this area, we\nconstruct MUSE, a high-quality multi-target reasoning segmentation benchmark.\nPixelLM excels across various pixel-level image reasoning and understanding\ntasks, outperforming well-established methods in multiple benchmarks, including\nMUSE, single- and multi-referring segmentation. Comprehensive ablations confirm\nthe efficacy of each proposed component. All code, models, and datasets will be\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02228"
            },
            {
                "文章ID": "104627",
                "标题": "Jointly Training Large Autoregressive Multimodal Models",
                "作者": " Emanuele Aiello,  Lili Yu,  Yixin Nie,  Armen Aghajanyan,  Barlas Oguz",
                "发布日期": "2023-09-29",
                "摘要": "  In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.\n",
                "链接": "https://arxiv.org/abs/2309.15564"
            },
            {
                "文章ID": "117408",
                "标题": "Multimodal Large Language Models: A Survey",
                "作者": " Jiayang Wu,  Wensheng Gan,  Zefeng Chen,  Shicheng Wan,  Philip S. Yu",
                "发布日期": "2023-11-23",
                "摘要": "  The exploration of multimodal language models integrates multiple data types,\nsuch as images, text, language, audio, and other heterogeneity. While the\nlatest large language models excel in text-based tasks, they often struggle to\nunderstand and process other data types. Multimodal models address this\nlimitation by combining various modalities, enabling a more comprehensive\nunderstanding of diverse data. This paper begins by defining the concept of\nmultimodal and examining the historical development of multimodal algorithms.\nFurthermore, we introduce a range of multimodal products, focusing on the\nefforts of major technology companies. A practical guide is provided, offering\ninsights into the technical aspects of multimodal models. Moreover, we present\na compilation of the latest algorithms and commonly used datasets, providing\nresearchers with valuable resources for experimentation and evaluation. Lastly,\nwe explore the applications of multimodal models and discuss the challenges\nassociated with their development. By addressing these aspects, this paper aims\nto facilitate a deeper understanding of multimodal models and their potential\nin various domains.\n",
                "链接": "https://arxiv.org/abs/2311.13165"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "95351",
                "标题": "Auditory Attention Decoding with Task-Related Multi-View Contrastive\n  Learning",
                "作者": " Xiaoyu Chen,  Changde Du,  Qiongyi Zhou,  Huiguang He",
                "发布日期": "2023-08-09",
                "摘要": "  The human brain can easily focus on one speaker and suppress others in\nscenarios such as a cocktail party. Recently, researchers found that auditory\nattention can be decoded from the electroencephalogram (EEG) data. However,\nmost existing deep learning methods are difficult to use prior knowledge of\ndifferent views (that is attended speech and EEG are task-related views) and\nextract an unsatisfactory representation. Inspired by Broadbent's filter model,\nwe decode auditory attention in a multi-view paradigm and extract the most\nrelevant and important information utilizing the missing view. Specifically, we\npropose an auditory attention decoding (AAD) method based on multi-view VAE\nwith task-related multi-view contrastive (TMC) learning. Employing TMC learning\nin multi-view VAE can utilize the missing view to accumulate prior knowledge of\ndifferent views into the fusion of representation, and extract the approximate\ntask-related representation. We examine our method on two popular AAD datasets,\nand demonstrate the superiority of our method by comparing it to the\nstate-of-the-art method.\n",
                "链接": "https://arxiv.org/abs/2308.04244"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "117885",
                "标题": "Decoding Social Sentiment in DAO: A Comparative Analysis of Blockchain\n  Governance Communities",
                "作者": " Yutong Quan,  Xintong Wu,  Wanlin Deng,  Luyao Zhang",
                "发布日期": "2023-11-30",
                "摘要": "  Blockchain technology is leading a revolutionary transformation across\ndiverse industries, with effective governance standing as a critical\ndeterminant for the success and sustainability of blockchain projects.\nCommunity forums, pivotal in engaging decentralized autonomous organizations\n(DAOs), wield a substantial impact on blockchain governance decisions.\nConcurrently, Natural Language Processing (NLP), particularly sentiment\nanalysis, provides powerful insights from textual data. While prior research\nhas explored the potential of NLP tools in social media sentiment analysis, a\ngap persists in understanding the sentiment landscape of blockchain governance\ncommunities. The evolving discourse and sentiment dynamics on the forums of top\nDAOs remain largely unknown. This paper delves deep into the evolving discourse\nand sentiment dynamics on the public forums of leading DeFi projects -- Aave,\nUniswap, Curve Dao, Aragon, Yearn.finance, Merit Circle, and Balancer --\nplacing a primary focus on discussions related to governance issues. Despite\ndiffering activity patterns, participants across these decentralized\ncommunities consistently express positive sentiments in their Discord\ndiscussions, indicating optimism towards governance decisions. Additionally,\nour research suggests a potential interplay between discussion intensity and\nsentiment dynamics, indicating that higher discussion volumes may contribute to\nmore stable and positive emotions. The insights gained from this study are\nvaluable for decision-makers in blockchain governance, underscoring the pivotal\nrole of sentiment analysis in interpreting community emotions and its evolving\nimpact on the landscape of blockchain governance. This research significantly\ncontributes to the interdisciplinary exploration of the intersection of\nblockchain and society, with a specific emphasis on the decentralized\nblockchain governance ecosystem.\n",
                "链接": "https://arxiv.org/abs/2311.14676"
            },
            {
                "文章ID": "50906",
                "标题": "Fine-tuned Sentiment Analysis of COVID-19 Vaccine-Related Social Media\n  Data: Comparative Study",
                "作者": " Chad A Melton,  Brianna M White,  Robert L Davis,  Robert A Bednarczyk,  Arash Shaban-Nejad",
                "发布日期": "2022-11-29",
                "摘要": "  This study investigated and compared public sentiment related to COVID-19\nvaccines expressed on two popular social media platforms, Reddit and Twitter,\nharvested from January 1, 2020, to March 1, 2022. To accomplish this task, we\ncreated a fine-tuned DistilRoBERTa model to predict sentiments of approximately\n9.5 million Tweets and 70 thousand Reddit comments. To fine-tune our model, our\nteam manually labeled the sentiment of 3600 Tweets and then augmented our\ndataset by the method of back-translation. Text sentiment for each social media\nplatform was then classified with our fine-tuned model using Python and the\nHuggingface sentiment analysis pipeline. Our results determined that the\naverage sentiment expressed on Twitter was more negative (52% positive) than\npositive and the sentiment expressed on Reddit was more positive than negative\n(53% positive). Though average sentiment was found to vary between these social\nmedia platforms, both displayed similar behavior related to sentiment shared at\nkey vaccine-related developments during the pandemic. Considering this similar\ntrend in shared sentiment demonstrated across social media platforms, Twitter\nand Reddit continue to be valuable data sources that public health officials\ncan utilize to strengthen vaccine confidence and combat misinformation. As the\nspread of misinformation poses a range of psychological and psychosocial risks\n(anxiety, fear, etc.), there is an urgency in understanding the public\nperspective and attitude toward shared falsities. Comprehensive educational\ndelivery systems tailored to the population's expressed sentiments that\nfacilitate digital literacy, health information-seeking behavior, and precision\nhealth promotion could aid in clarifying such misinformation.\n",
                "链接": "https://arxiv.org/abs/2211.15407"
            },
            {
                "文章ID": "109426",
                "标题": "EEG motor imagery decoding: A framework for comparative analysis with\n  channel attention mechanisms",
                "作者": " Martin Wimpff,  Leonardo Gizzi,  Jan Zerfowski,  Bin Yang",
                "发布日期": "2023-10-18",
                "摘要": "  The objective of this study is to investigate the application of various\nchannel attention mechanisms within the domain of brain-computer interface\n(BCI) for motor imagery decoding. Channel attention mechanisms can be seen as a\npowerful evolution of spatial filters traditionally used for motor imagery\ndecoding. This study systematically compares such mechanisms by integrating\nthem into a lightweight architecture framework to evaluate their impact. We\ncarefully construct a straightforward and lightweight baseline architecture\ndesigned to seamlessly integrate different channel attention mechanisms. This\napproach is contrary to previous works which only investigate one attention\nmechanism and usually build a very complex, sometimes nested architecture. Our\nframework allows us to evaluate and compare the impact of different attention\nmechanisms under the same circumstances. The easy integration of different\nchannel attention mechanisms as well as the low computational complexity\nenables us to conduct a wide range of experiments on three datasets to\nthoroughly assess the effectiveness of the baseline model and the attention\nmechanisms. Our experiments demonstrate the strength and generalizability of\nour architecture framework as well as how channel attention mechanisms can\nimprove the performance while maintaining the small memory footprint and low\ncomputational complexity of our baseline architecture. Our architecture\nemphasizes simplicity, offering easy integration of channel attention\nmechanisms, while maintaining a high degree of generalizability across\ndatasets, making it a versatile and efficient solution for EEG motor imagery\ndecoding within brain-computer interfaces.\n",
                "链接": "https://arxiv.org/abs/2310.11198"
            },
            {
                "文章ID": "21348",
                "标题": "Target-aware Abstractive Related Work Generation with Contrastive\n  Learning",
                "作者": " Xiuying Chen,  Hind Alamro,  Mingzhe Li,  Shen Gao,  Rui Yan,  Xin Gao,  Xiangliang Zhang",
                "发布日期": "2022-05-27",
                "摘要": "  The related work section is an important component of a scientific paper,\nwhich highlights the contribution of the target paper in the context of the\nreference papers. Authors can save their time and effort by using the\nautomatically generated related work section as a draft to complete the final\nrelated work. Most of the existing related work section generation methods rely\non extracting off-the-shelf sentences to make a comparative discussion about\nthe target work and the reference papers. However, such sentences need to be\nwritten in advance and are hard to obtain in practice. Hence, in this paper, we\npropose an abstractive target-aware related work generator (TAG), which can\ngenerate related work sections consisting of new sentences. Concretely, we\nfirst propose a target-aware graph encoder, which models the relationships\nbetween reference papers and the target paper with target-centered attention\nmechanisms. In the decoding process, we propose a hierarchical decoder that\nattends to the nodes of different levels in the graph with keyphrases as\nsemantic indicators. Finally, to generate a more informative related work, we\npropose multi-level contrastive optimization objectives, which aim to maximize\nthe mutual information between the generated related work with the references\nand minimize that with non-references. Extensive experiments on two public\nscholar datasets show that the proposed model brings substantial improvements\nover several strong baselines in terms of automatic and tailored human\nevaluations.\n",
                "链接": "https://arxiv.org/abs/2205.13339"
            },
            {
                "文章ID": "118350",
                "标题": "Decoding Logic Errors: A Comparative Study on Bug Detection by Students\n  and Large Language Models",
                "作者": " Stephen MacNeil,  Paul Denny,  Andrew Tran,  Juho Leinonen,  Seth Bernstein,  Arto Hellas,  Sami Sarsa,  Joanne Kim",
                "发布日期": "2023-11-28",
                "摘要": "  Identifying and resolving logic errors can be one of the most frustrating\nchallenges for novices programmers. Unlike syntax errors, for which a compiler\nor interpreter can issue a message, logic errors can be subtle. In certain\nconditions, buggy code may even exhibit correct behavior -- in other cases, the\nissue might be about how a problem statement has been interpreted. Such errors\ncan be hard to spot when reading the code, and they can also at times be missed\nby automated tests. There is great educational potential in automatically\ndetecting logic errors, especially when paired with suitable feedback for\nnovices. Large language models (LLMs) have recently demonstrated surprising\nperformance for a range of computing tasks, including generating and explaining\ncode. These capabilities are closely linked to code syntax, which aligns with\nthe next token prediction behavior of LLMs. On the other hand, logic errors\nrelate to the runtime performance of code and thus may not be as well suited to\nanalysis by LLMs. To explore this, we investigate the performance of two\npopular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly\nexplanation of logic errors. We compare LLM performance with a large cohort of\nintroductory computing students $(n=964)$ solving the same error detection\ntask. Through a mixed-methods analysis of student and model responses, we\nobserve significant improvement in logic error identification between the\nprevious and current generation of LLMs, and find that both LLM generations\nsignificantly outperform students. We outline how such models could be\nintegrated into computing education tools, and discuss their potential for\nsupporting students when learning programming.\n",
                "链接": "https://arxiv.org/abs/2311.16017"
            },
            {
                "文章ID": "53554",
                "标题": "Decoding Multi-class Motor-related Intentions with User-optimized and\n  Robust BCI System Based on Multimodal Dataset",
                "作者": " Jeong-Hyun Cho,  Byoung-Hee Kwon,  Byeong-Hoo Lee",
                "发布日期": "2022-12-15",
                "摘要": "  A brain-computer interface (BCI) based on electroencephalography (EEG) can be\nuseful for rehabilitation and the control of external devices. Five grasping\ntasks were decoded for motor execution (ME) and motor imagery (MI). During this\nexperiment, eight healthy subjects were asked to imagine and grasp five\nobjects. Analysis of EEG signals was performed after detecting muscle signals\non electromyograms (EMG) with a time interval selection technique on data taken\nfrom these ME and MI experiments. By refining only data corresponding to the\nexact time when the users performed the motor intention, the proposed method\ncan train the decoding model using only the EEG data generated by various motor\nintentions with strong correlation with a specific class. There was an accuracy\nof 70.73% for ME and 47.95% for MI for the five offline tasks. This method may\nbe applied to future applications, such as controlling robot hands with BCIs.\n",
                "链接": "https://arxiv.org/abs/2212.07083"
            },
            {
                "文章ID": "113764",
                "标题": "Citance-Contextualized Summarization of Scientific Papers",
                "作者": " Shahbaz Syed,  Ahmad Dawar Hakimi,  Khalid Al-Khatib,  Martin Potthast",
                "发布日期": "2023-11-14",
                "摘要": "  Current approaches to automatic summarization of scientific papers generate\ninformative summaries in the form of abstracts. However, abstracts are not\nintended to show the relationship between a paper and the references cited in\nit. We propose a new contextualized summarization approach that can generate an\ninformative summary conditioned on a given sentence containing the citation of\na reference (a so-called \"citance\"). This summary outlines the content of the\ncited paper relevant to the citation location. Thus, our approach extracts and\nmodels the citances of a paper, retrieves relevant passages from cited papers,\nand generates abstractive summaries tailored to each citance. We evaluate our\napproach using $\\textbf{Webis-Context-SciSumm-2023}$, a new dataset containing\n540K~computer science papers and 4.6M~citances therein.\n",
                "链接": "https://arxiv.org/abs/2311.02408"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94589",
                "标题": "Rethinking Class Activation Maps for Segmentation: Revealing Semantic\n  Information in Shallow Layers by Reducing Noise",
                "作者": " Hang-Cheng Dong,  Yuhao Jiang,  Yingyan Huang,  Jingxiao Liao,  Bingguo Liu,  Dong Ye,  Guodong Liu",
                "发布日期": "2023-08-07",
                "摘要": "  Class activation maps are widely used for explaining deep neural networks.\nDue to its ability to highlight regions of interest, it has evolved in recent\nyears as a key step in weakly supervised learning. A major limitation to the\nperformance of the class activation maps is the small spatial resolution of the\nfeature maps in the last layer of the convolutional neural network. Therefore,\nwe expect to generate high-resolution feature maps that result in high-quality\nsemantic information. In this paper, we rethink the properties of semantic\ninformation in shallow feature maps. We find that the shallow feature maps\nstill have fine-grained non-discriminative features while mixing considerable\nnon-target noise. Furthermore, we propose a simple gradient-based denoising\nmethod to filter the noise by truncating the positive gradient. Our proposed\nscheme can be easily deployed in other CAM-related methods, facilitating these\nmethods to obtain higher-quality class activation maps. We evaluate the\nproposed approach through a weakly-supervised semantic segmentation task, and a\nlarge number of experiments demonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2308.02118"
            },
            {
                "文章ID": "2704",
                "标题": "PARS: Pseudo-Label Aware Robust Sample Selection for Learning with Noisy\n  Labels",
                "作者": " Arushi Goel,  Yunlong Jiao,  Jordan Massiah",
                "发布日期": "2022-01-27",
                "摘要": "  Acquiring accurate labels on large-scale datasets is both time consuming and\nexpensive. To reduce the dependency of deep learning models on learning from\nclean labeled data, several recent research efforts are focused on learning\nwith noisy labels. These methods typically fall into three design categories to\nlearn a noise robust model: sample selection approaches, noise robust loss\nfunctions, or label correction methods. In this paper, we propose PARS:\nPseudo-Label Aware Robust Sample Selection, a hybrid approach that combines the\nbest from all three worlds in a joint-training framework to achieve robustness\nto noisy labels. Specifically, PARS exploits all training samples using both\nthe raw/noisy labels and estimated/refurbished pseudo-labels via self-training,\ndivides samples into an ambiguous and a noisy subset via loss analysis, and\ndesigns label-dependent noise-aware loss functions for both sets of filtered\nlabels. Results show that PARS significantly outperforms the state of the art\non extensive studies on the noisy CIFAR-10 and CIFAR-100 datasets, particularly\non challenging high-noise and low-resource settings. In particular, PARS\nachieved an absolute 12% improvement in test accuracy on the CIFAR-100 dataset\nwith 90% symmetric label noise, and an absolute 27% improvement in test\naccuracy when only 1/5 of the noisy labels are available during training as an\nadditional restriction. On a real-world noisy dataset, Clothing1M, PARS\nachieves competitive results to the state of the art.\n",
                "链接": "https://arxiv.org/abs/2201.10836"
            },
            {
                "文章ID": "93146",
                "标题": "PNT-Edge: Towards Robust Edge Detection with Noisy Labels by Learning\n  Pixel-level Noise Transitions",
                "作者": " Wenjie Xuan,  Shanshan Zhao,  Yu Yao,  Juhua Liu,  Tongliang Liu,  Yixin Chen,  Bo Du,  Dacheng Tao",
                "发布日期": "2023-10-17",
                "摘要": "  Relying on large-scale training data with pixel-level labels, previous edge\ndetection methods have achieved high performance. However, it is hard to\nmanually label edges accurately, especially for large datasets, and thus the\ndatasets inevitably contain noisy labels. This label-noise issue has been\nstudied extensively for classification, while still remaining under-explored\nfor edge detection. To address the label-noise issue for edge detection, this\npaper proposes to learn Pixel-level NoiseTransitions to model the\nlabel-corruption process. To achieve it, we develop a novel Pixel-wise Shift\nLearning (PSL) module to estimate the transition from clean to noisy labels as\na displacement field. Exploiting the estimated noise transitions, our model,\nnamed PNT-Edge, is able to fit the prediction to clean labels. In addition, a\nlocal edge density regularization term is devised to exploit local structure\ninformation for better transition learning. This term encourages learning large\nshifts for the edges with complex local structures. Experiments on SBD and\nCityscapes demonstrate the effectiveness of our method in relieving the impact\nof label noise. Codes are available at https://github.com/DREAMXFAR/PNT-Edge.\n",
                "链接": "https://arxiv.org/abs/2307.14070"
            },
            {
                "文章ID": "64813",
                "标题": "Fine-Grained Classification with Noisy Labels",
                "作者": " Qi Wei,  Lei Feng,  Haoliang Sun,  Ren Wang,  Chenhui Guo,  Yilong Yin",
                "发布日期": "2023-03-07",
                "摘要": "  Learning with noisy labels (LNL) aims to ensure model generalization given a\nlabel-corrupted training set. In this work, we investigate a rarely studied\nscenario of LNL on fine-grained datasets (LNL-FG), which is more practical and\nchallenging as large inter-class ambiguities among fine-grained classes cause\nmore noisy labels. We empirically show that existing methods that work well for\nLNL fail to achieve satisfying performance for LNL-FG, arising the practical\nneed of effective solutions for LNL-FG. To this end, we propose a novel\nframework called stochastic noise-tolerated supervised contrastive learning\n(SNSCL) that confronts label noise by encouraging distinguishable\nrepresentation. Specifically, we design a noise-tolerated supervised\ncontrastive learning loss that incorporates a weight-aware mechanism for noisy\nlabel correction and selectively updating momentum queue lists. By this\nmechanism, we mitigate the effects of noisy anchors and avoid inserting noisy\nlabels into the momentum-updated queue. Besides, to avoid manually-defined\naugmentation strategies in contrastive learning, we propose an efficient\nstochastic module that samples feature embeddings from a generated\ndistribution, which can also enhance the representation ability of deep models.\nSNSCL is general and compatible with prevailing robust LNL strategies to\nimprove their performance for LNL-FG. Extensive experiments demonstrate the\neffectiveness of SNSCL.\n",
                "链接": "https://arxiv.org/abs/2303.02404"
            },
            {
                "文章ID": "8323",
                "标题": "Learning from Label Proportions by Learning with Label Noise",
                "作者": " Jianxin Zhang,  Yutong Wang,  Clayton Scott",
                "发布日期": "2023-09-26",
                "摘要": "  Learning from label proportions (LLP) is a weakly supervised classification\nproblem where data points are grouped into bags, and the label proportions\nwithin each bag are observed instead of the instance-level labels. The task is\nto learn a classifier to predict the individual labels of future individual\ninstances. Prior work on LLP for multi-class data has yet to develop a\ntheoretically grounded algorithm. In this work, we provide a theoretically\ngrounded approach to LLP based on a reduction to learning with label noise,\nusing the forward correction (FC) loss of \\citet{Patrini2017MakingDN}. We\nestablish an excess risk bound and generalization error analysis for our\napproach, while also extending the theory of the FC loss which may be of\nindependent interest. Our approach demonstrates improved empirical performance\nin deep learning scenarios across multiple datasets and architectures, compared\nto the leading existing methods.\n",
                "链接": "https://arxiv.org/abs/2203.02496"
            },
            {
                "文章ID": "15729",
                "标题": "Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in\n  Text Classification",
                "作者": " Dawei Zhu,  Michael A. Hedderich,  Fangzhou Zhai,  David Ifeoluwa Adelani,  Dietrich Klakow",
                "发布日期": "2022-04-21",
                "摘要": "  Incorrect labels in training data occur when human annotators make mistakes\nor when the data is generated via weak or distant supervision. It has been\nshown that complex noise-handling techniques - by modeling, cleaning or\nfiltering the noisy instances - are required to prevent models from fitting\nthis label noise. However, we show in this work that, for text classification\ntasks with modern NLP models like BERT, over a variety of noise types, existing\nnoisehandling methods do not always improve its performance, and may even\ndeteriorate it, suggesting the need for further investigation. We also back our\nobservations with a comprehensive analysis.\n",
                "链接": "https://arxiv.org/abs/2204.09371"
            },
            {
                "文章ID": "33910",
                "标题": "Automatic Detection of Noisy Electrocardiogram Signals without Explicit\n  Noise Labels",
                "作者": " Radhika Dua,  Jiyoung Lee,  Joon-myoung Kwon,  Edward Choi",
                "发布日期": "2022-08-19",
                "摘要": "  Electrocardiogram (ECG) signals are beneficial in diagnosing cardiovascular\ndiseases, which are one of the leading causes of death. However, they are often\ncontaminated by noise artifacts and affect the automatic and manual diagnosis\nprocess. Automatic deep learning-based examination of ECG signals can lead to\ninaccurate diagnosis, and manual analysis involves rejection of noisy ECG\nsamples by clinicians, which might cost extra time. To address this limitation,\nwe present a two-stage deep learning-based framework to automatically detect\nthe noisy ECG samples. Through extensive experiments and analysis on two\ndifferent datasets, we observe that the deep learning-based framework can\ndetect slightly and highly noisy ECG samples effectively. We also study the\ntransfer of the model learned on one dataset to another dataset and observe\nthat the framework effectively detects noisy ECG samples.\n",
                "链接": "https://arxiv.org/abs/2208.08853"
            },
            {
                "文章ID": "123805",
                "标题": "FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy\n  Labels",
                "作者": " Jichang Li,  Guanbin Li,  Hui Cheng,  Zicheng Liao,  Yizhou Yu",
                "发布日期": "2023-12-21",
                "摘要": "  Federated learning with noisy labels (F-LNL) aims at seeking an optimal\nserver model via collaborative distributed learning by aggregating multiple\nclient models trained with local noisy or clean samples. On the basis of a\nfederated learning framework, recent advances primarily adopt label noise\nfiltering to separate clean samples from noisy ones on each client, thereby\nmitigating the negative impact of label noise. However, these prior methods do\nnot learn noise filters by exploiting knowledge across all clients, leading to\nsub-optimal and inferior noise filtering performance and thus damaging training\nstability. In this paper, we present FedDiv to tackle the challenges of F-LNL.\nSpecifically, we propose a global noise filter called Federated Noise Filter\nfor effectively identifying samples with noisy labels on every client, thereby\nraising stability during local training sessions. Without sacrificing data\nprivacy, this is achieved by modeling the global distribution of label noise\nacross all clients. Then, in an effort to make the global model achieve higher\nperformance, we introduce a Predictive Consistency based Sampler to identify\nmore credible local data for local model training, thus preventing noise\nmemorization and further boosting the training stability. Extensive experiments\non CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \\texttt{FedDiv}\nachieves superior performance over state-of-the-art F-LNL methods under\ndifferent label noise settings for both IID and non-IID data partitions. Source\ncode is publicly available at https://github.com/lijichang/FLNL-FedDiv.\n",
                "链接": "https://arxiv.org/abs/2312.12263"
            },
            {
                "文章ID": "78327",
                "标题": "NoisywikiHow: A Benchmark for Learning with Real-world Noisy Labels in\n  Natural Language Processing",
                "作者": " Tingting Wu,  Xiao Ding,  Minji Tang,  Hao Zhang,  Bing Qin,  Ting Liu",
                "发布日期": "2023-05-19",
                "摘要": "  Large-scale datasets in the real world inevitably involve label noise. Deep\nmodels can gradually overfit noisy labels and thus degrade model\ngeneralization. To mitigate the effects of label noise, learning with noisy\nlabels (LNL) methods are designed to achieve better generalization performance.\nDue to the lack of suitable datasets, previous studies have frequently employed\nsynthetic label noise to mimic real-world label noise. However, synthetic noise\nis not instance-dependent, making this approximation not always effective in\npractice. Recent research has proposed benchmarks for learning with real-world\nnoisy labels. However, the noise sources within may be single or fuzzy, making\nbenchmarks different from data with heterogeneous label noises in the real\nworld. To tackle these issues, we contribute NoisywikiHow, the largest NLP\nbenchmark built with minimal supervision. Specifically, inspired by human\ncognition, we explicitly construct multiple sources of label noise to imitate\nhuman errors throughout the annotation, replicating real-world noise, whose\ncorruption is affected by both ground-truth labels and instances. Moreover, we\nprovide a variety of noise levels to support controlled experiments on noisy\ndata, enabling us to evaluate LNL methods systematically and comprehensively.\nAfter that, we conduct extensive multi-dimensional experiments on a broad range\nof LNL methods, obtaining new and intriguing findings.\n",
                "链接": "https://arxiv.org/abs/2305.10709"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "3914",
                "标题": "On Monte Carlo Tree Search for Weighted Vertex Coloring",
                "作者": " Cyril Grelier,  Olivier Goudet,  Jin-Kao Hao",
                "发布日期": "2022-04-08",
                "摘要": "  This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.\n",
                "链接": "https://arxiv.org/abs/2202.01665"
            },
            {
                "文章ID": "53055",
                "标题": "Lookahead Pathology in Monte-Carlo Tree Search",
                "作者": " Khoi P. N. Nguyen,  Raghuram Ramanujan",
                "发布日期": "2022-12-13",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is an adversarial search paradigm that first\nfound prominence with its success in the domain of computer Go. Early\ntheoretical work established the game-theoretic soundness and convergence\nbounds for Upper Confidence bounds applied to Trees (UCT), the most popular\ninstantiation of MCTS; however, there remain notable gaps in our understanding\nof how UCT behaves in practice. In this work, we address one such gap by\nconsidering the question of whether UCT can exhibit lookahead pathology -- a\nparadoxical phenomenon first observed in Minimax search where greater search\neffort leads to worse decision-making. We introduce a novel family of synthetic\ngames that offer rich modeling possibilities while remaining amenable to\nmathematical analysis. Our theoretical and experimental results suggest that\nUCT is indeed susceptible to pathological behavior in a range of games drawn\nfrom this family.\n",
                "链接": "https://arxiv.org/abs/2212.05208"
            },
            {
                "文章ID": "54835",
                "标题": "Feature Acquisition using Monte Carlo Tree Search",
                "作者": " Sungsoo Lim,  Diego Klabjan,  Mark Shapiro",
                "发布日期": "2022-12-23",
                "摘要": "  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n",
                "链接": "https://arxiv.org/abs/2212.11360"
            },
            {
                "文章ID": "67092",
                "标题": "Proof Number Based Monte-Carlo Tree Search",
                "作者": " Jakub Kowalski,  Elliot Doe,  Mark H. M. Winands,  Daniel Górski,  Dennis J. N. J. Soemers",
                "发布日期": "2023-12-22",
                "摘要": "  This paper proposes a new game-search algorithm, PN-MCTS, which combines\nMonte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two\nalgorithms have been successfully applied for decision making in a range of\ndomains. We define three areas where the additional knowledge provided by the\nproof and disproof numbers gathered in MCTS trees might be used: final move\nselection, solving subtrees, and the UCB1 selection mechanism. We test all\npossible combinations on different time settings, playing against vanilla UCT\non several games: Lines of Action ($7$$\\times$$7$ and $8$$\\times$$8$ board\nsizes), MiniShogi, Knightthrough, and Awari. Furthermore, we extend this new\nalgorithm to properly address games with draws, like Awari, by adding an\nadditional layer of PNS on top of the MCTS tree. The experiments show that\nPN-MCTS confidently outperforms MCTS in all tested game domains, achieving win\nrates up to 96.2\\% for Lines of Action.\n",
                "链接": "https://arxiv.org/abs/2303.09449"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "107708",
                "标题": "Accelerating Monte Carlo Tree Search with Probability Tree State\n  Abstraction",
                "作者": " Yangqing Fu,  Ming Sun,  Buqing Nie,  Yue Gao",
                "发布日期": "2023-10-11",
                "摘要": "  Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have\nachieved superhuman performance in many challenging tasks. However, the\ncomputational complexity of MCTS-based algorithms is influenced by the size of\nthe search space. To address this issue, we propose a novel probability tree\nstate abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A\ngeneral tree state abstraction with path transitivity is defined. In addition,\nthe probability tree state abstraction is proposed for fewer mistakes during\nthe aggregation step. Furthermore, the theoretical guarantees of the\ntransitivity and aggregation error bound are justified. To evaluate the\neffectiveness of the PTSA algorithm, we integrate it with state-of-the-art\nMCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental\nresults on different tasks demonstrate that our method can accelerate the\ntraining process of state-of-the-art algorithms with 10%-45% search space\nreduction.\n",
                "链接": "https://arxiv.org/abs/2310.06513"
            },
            {
                "文章ID": "7216",
                "标题": "Decision Making in Non-Stationary Environments with Policy-Augmented\n  Monte Carlo Tree Search",
                "作者": " Geoffrey Pettet,  Ayan Mukhopadhyay,  Abhishek Dubey",
                "发布日期": "2022-03-01",
                "摘要": "  Decision-making under uncertainty (DMU) is present in many important\nproblems. An open challenge is DMU in non-stationary environments, where the\ndynamics of the environment can change over time. Reinforcement Learning (RL),\na popular approach for DMU problems, learns a policy by interacting with a\nmodel of the environment offline. Unfortunately, if the environment changes the\npolicy can become stale and take sub-optimal actions, and relearning the policy\nfor the updated environment takes time and computational effort. An alternative\nis online planning approaches such as Monte Carlo Tree Search (MCTS), which\nperform their computation at decision time. Given the current environment, MCTS\nplans using high-fidelity models to determine promising action trajectories.\nThese models can be updated as soon as environmental changes are detected to\nimmediately incorporate them into decision making. However, MCTS's convergence\ncan be slow for domains with large state-action spaces. In this paper, we\npresent a novel hybrid decision-making approach that combines the strengths of\nRL and planning while mitigating their weaknesses. Our approach, called Policy\nAugmented MCTS (PA-MCTS), integrates a policy's actin-value estimates into\nMCTS, using the estimates to seed the action trajectories favored by the\nsearch. We hypothesize that PA-MCTS will converge more quickly than standard\nMCTS while making better decisions than the policy can make on its own when\nfaced with nonstationary environments. We test our hypothesis by comparing\nPA-MCTS with pure MCTS and an RL agent applied to the classical CartPole\nenvironment. We find that PC-MCTS can achieve higher cumulative rewards than\nthe policy in isolation under several environmental shifts while converging in\nsignificantly fewer iterations than pure MCTS.\n",
                "链接": "https://arxiv.org/abs/2202.13003"
            },
            {
                "文章ID": "22592",
                "标题": "Policy Gradient Algorithms with Monte-Carlo Tree Search for Non-Markov\n  Decision Processes",
                "作者": " Tetsuro Morimura,  Kazuhiro Ota,  Kenshi Abe,  Peinan Zhang",
                "发布日期": "2022-06-03",
                "摘要": "  Policy gradient (PG) is a reinforcement learning (RL) approach that optimizes\na parameterized policy model for an expected return using gradient ascent.\nGiven a well-parameterized policy model, such as a neural network model, with\nappropriate initial parameters, the PG algorithms work well even when\nenvironment does not have the Markov property. Otherwise, they can be trapped\non a plateau or suffer from peakiness effects. As another successful RL\napproach, algorithms based on Monte-Carlo Tree Search (MCTS), which include\nAlphaZero, have obtained groundbreaking results especially on the board game\nplaying domain. They are also suitable to be applied to non-Markov decision\nprocesses. However, since the standard MCTS does not have the ability to learn\nstate representation, the size of the tree-search space can be too large to\nsearch. In this work, we examine a mixture policy of PG and MCTS to complement\neach other's difficulties and take advantage of them. We derive conditions for\nasymptotic convergence with results of a two-timescale stochastic approximation\nand propose an algorithm that satisfies these conditions. The effectivity of\nthe proposed methods is verified through numerical experiments on non-Markov\ndecision processes.\n",
                "链接": "https://arxiv.org/abs/2206.01011"
            },
            {
                "文章ID": "5386",
                "标题": "Anytime Capacity Expansion in Medical Residency Match by Monte Carlo\n  Tree Search",
                "作者": " Kenshi Abe,  Junpei Komiyama,  Atsushi Iwasaki",
                "发布日期": "2022-05-24",
                "摘要": "  This paper considers the capacity expansion problem in two-sided matchings,\nwhere the policymaker is allowed to allocate some extra seats as well as the\nstandard seats. In medical residency match, each hospital accepts a limited\nnumber of doctors. Such capacity constraints are typically given in advance.\nHowever, such exogenous constraints can compromise the welfare of the doctors;\nsome popular hospitals inevitably dismiss some of their favorite doctors.\nMeanwhile, it is often the case that the hospitals are also benefited to accept\na few extra doctors. To tackle the problem, we propose an anytime method that\nthe upper confidence tree searches the space of capacity expansions, each of\nwhich has a resident-optimal stable assignment that the deferred acceptance\nmethod finds. Constructing a good search tree representation significantly\nboosts the performance of the proposed method. Our simulation shows that the\nproposed method identifies an almost optimal capacity expansion with a\nsignificantly smaller computational budget than exact methods based on\nmixed-integer programming.\n",
                "链接": "https://arxiv.org/abs/2202.06570"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "95613",
                "标题": "Performance Analysis of Transformer Based Models (BERT, ALBERT and\n  RoBERTa) in Fake News Detection",
                "作者": " Shafna Fitria Nur Azizah,  Hasan Dwi Cahyono,  Sari Widya Sihwi,  Wisnu Widiarto",
                "发布日期": "2023-08-10",
                "摘要": "  Fake news is fake material in a news media format but is not processed\nproperly by news agencies. The fake material can provoke or defame significant\nentities or individuals or potentially even for the personal interests of the\ncreators, causing problems for society. Distinguishing fake news and real news\nis challenging due to limited of domain knowledge and time constraints.\nAccording to the survey, the top three areas most exposed to hoaxes and\nmisinformation by residents are in Banten, DKI Jakarta and West Java. The model\nof transformers is referring to an approach in the field of artificial\nintelligence (AI) in natural language processing utilizing the deep learning\narchitectures. Transformers exercise a powerful attention mechanism to process\ntext in parallel and produce rich and contextual word representations. A\nprevious study indicates a superior performance of a transformer model known as\nBERT over and above non transformer approach. However, some studies suggest the\nperformance can be improved with the use of improved BERT models known as\nALBERT and RoBERTa. However, the modified BERT models are not well explored for\ndetecting fake news in Bahasa Indonesia. In this research, we explore those\ntransformer models and found that ALBERT outperformed other models with 87.6%\naccuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)\nrespectively. Source code available at:\nhttps://github.com/Shafna81/fakenewsdetection.git\n",
                "链接": "https://arxiv.org/abs/2308.04950"
            },
            {
                "文章ID": "48125",
                "标题": "Xu at SemEval-2022 Task 4: Pre-BERT Neural Network Methods vs Post-BERT\n  RoBERTa Approach for Patronizing and Condescending Language Detection",
                "作者": " Jinghua Xu",
                "发布日期": "2022-11-15",
                "摘要": "  This paper describes my participation in the SemEval-2022 Task 4: Patronizing\nand Condescending Language Detection. I participate in both subtasks:\nPatronizing and Condescending Language (PCL) Identification and Patronizing and\nCondescending Language Categorization, with the main focus put on subtask 1.\nThe experiments compare pre-BERT neural network (NN) based systems against\npost-BERT pretrained language model RoBERTa. This research finds NN-based\nsystems in the experiments perform worse on the task compared to the pretrained\nlanguage models. The top-performing RoBERTa system is ranked 26 out of 78 teams\n(F1-score: 54.64) in subtask 1, and 23 out of 49 teams (F1-score: 30.03) in\nsubtask 2.\n",
                "链接": "https://arxiv.org/abs/2211.06874"
            },
            {
                "文章ID": "28107",
                "标题": "Sensitivity Analysis on Transferred Neural Architectures of BERT and\n  GPT-2 for Financial Sentiment Analysis",
                "作者": " Tracy Qian,  Andy Xie,  Camille Bruckmann",
                "发布日期": "2022-07-08",
                "摘要": "  The explosion in novel NLP word embedding and deep learning techniques has\ninduced significant endeavors into potential applications. One of these\ndirections is in the financial sector. Although there is a lot of work done in\nstate-of-the-art models like GPT and BERT, there are relatively few works on\nhow well these methods perform through fine-tuning after being pre-trained, as\nwell as info on how sensitive their parameters are. We investigate the\nperformance and sensitivity of transferred neural architectures from\npre-trained GPT-2 and BERT models. We test the fine-tuning performance based on\nfreezing transformer layers, batch size, and learning rate. We find the\nparameters of BERT are hypersensitive to stochasticity in fine-tuning and that\nGPT-2 is more stable in such practice. It is also clear that the earlier layers\nof GPT-2 and BERT contain essential word pattern information that should be\nmaintained.\n",
                "链接": "https://arxiv.org/abs/2207.03037"
            },
            {
                "文章ID": "18471",
                "标题": "A Dataset and BERT-based Models for Targeted Sentiment Analysis on\n  Turkish Texts",
                "作者": " M. Melih Mutlu,  Arzucan Özgür",
                "发布日期": "2022-05-10",
                "摘要": "  Targeted Sentiment Analysis aims to extract sentiment towards a particular\ntarget from a given text. It is a field that is attracting attention due to the\nincreasing accessibility of the Internet, which leads people to generate an\nenormous amount of data. Sentiment analysis, which in general requires\nannotated data for training, is a well-researched area for widely studied\nlanguages such as English. For low-resource languages such as Turkish, there is\na lack of such annotated data. We present an annotated Turkish dataset suitable\nfor targeted sentiment analysis. We also propose BERT-based models with\ndifferent architectures to accomplish the task of targeted sentiment analysis.\nThe results demonstrate that the proposed models outperform the traditional\nsentiment analysis models for the targeted sentiment analysis task.\n",
                "链接": "https://arxiv.org/abs/2205.04185"
            },
            {
                "文章ID": "752",
                "标题": "Semantic and sentiment analysis of selected Bhagavad Gita translations\n  using BERT-based language framework",
                "作者": " Rohitash Chandra,  Venkatesh Kulkarni",
                "发布日期": "2022-02-16",
                "摘要": "  It is well known that translations of songs and poems not only break rhythm\nand rhyming patterns, but can also result in loss of semantic information. The\nBhagavad Gita is an ancient Hindu philosophical text originally written in\nSanskrit that features a conversation between Lord Krishna and Arjuna prior to\nthe Mahabharata war. The Bhagavad Gita is also one of the key sacred texts in\nHinduism and is known as the forefront of the Vedic corpus of Hinduism. In the\nlast two centuries, there has been a lot of interest in Hindu philosophy from\nwestern scholars; hence, the Bhagavad Gita has been translated in a number of\nlanguages. However, there is not much work that validates the quality of the\nEnglish translations. Recent progress of language models powered by deep\nlearning has enabled not only translations but a better understanding of\nlanguage and texts with semantic and sentiment analysis. Our work is motivated\nby the recent progress of language models powered by deep learning methods. In\nthis paper, we present a framework that compares selected translations (from\nSanskrit to English) of the Bhagavad Gita using semantic and sentiment\nanalyses. We use hand-labelled sentiment dataset for tuning state-of-art deep\nlearning-based language model known as bidirectional encoder representations\nfrom transformers (BERT). We provide sentiment and semantic analysis for\nselected chapters and verses across translations. Our results show that\nalthough the style and vocabulary in the respective translations vary widely,\nthe sentiment analysis and semantic similarity shows that the message conveyed\nare mostly similar.\n",
                "链接": "https://arxiv.org/abs/2201.03115"
            },
            {
                "文章ID": "824",
                "标题": "BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives",
                "作者": " Frederico Souza,  João Filho",
                "发布日期": "2022-01-11",
                "摘要": "  BERT has revolutionized the NLP field by enabling transfer learning with\nlarge language models that can capture complex textual patterns, reaching the\nstate-of-the-art for an expressive number of NLP applications. For text\nclassification tasks, BERT has already been extensively explored. However,\naspects like how to better cope with the different embeddings provided by the\nBERT output layer and the usage of language-specific instead of multilingual\nmodels are not well studied in the literature, especially for the Brazilian\nPortuguese language. The purpose of this article is to conduct an extensive\nexperimental study regarding different strategies for aggregating the features\nproduced in the BERT output layer, with a focus on the sentiment analysis task.\nThe experiments include BERT models trained with Brazilian Portuguese corpora\nand the multilingual version, contemplating multiple aggregation strategies and\nopen-source datasets with predefined training, validation, and test partitions\nto facilitate the reproducibility of the results. BERT achieved the highest\nROC-AUC values for the majority of cases as compared to TF-IDF. Nonetheless,\nTF-IDF represents a good trade-off between the predictive performance and\ncomputational cost.\n",
                "链接": "https://arxiv.org/abs/2201.03382"
            },
            {
                "文章ID": "2025",
                "标题": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual\n  Sentiment Analysis",
                "作者": " Shamsuddeen Hassan Muhammad,  David Ifeoluwa Adelani,  Sebastian Ruder,  Ibrahim Said Ahmad,  Idris Abdulmumin,  Bello Shehu Bello,  Monojit Choudhury,  Chris Chinenye Emezue,  Saheed Salahudeen Abdullahi,  Anuoluwapo Aremu,  Alipio Jeorge,  Pavel Brazdil",
                "发布日期": "2022-06-22",
                "摘要": "  Sentiment analysis is one of the most widely studied applications in NLP, but\nmost work focuses on languages with large amounts of data. We introduce the\nfirst large-scale human-annotated Twitter sentiment dataset for the four most\nwidely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and\nYor\\`ub\\'a ) consisting of around 30,000 annotated tweets per language (and\n14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed\ntweets. We propose text collection, filtering, processing and labeling methods\nthat enable us to create datasets for these low-resource languages. We evaluate\na rangeof pre-trained models and transfer strategies on the dataset. We find\nthat language-specific models and language-adaptivefine-tuning generally\nperform best. We release the datasets, trained models, sentiment lexicons, and\ncode to incentivizeresearch on sentiment analysis in under-represented\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2201.08277"
            },
            {
                "文章ID": "15455",
                "标题": "Research on Domain Information Mining and Theme Evolution of Scientific\n  Papers",
                "作者": " Changwei Zheng,  Zhe Xue,  Meiyu Liang,  Feifei Kou,  Zeli Guan",
                "发布日期": "2022-04-20",
                "摘要": "  In recent years, with the increase of social investment in scientific\nresearch, the number of research results in various fields has increased\nsignificantly. Cross-disciplinary research results have gradually become an\nemerging frontier research direction. There is a certain dependence between a\nlarge number of research results. It is difficult to effectively analyze\ntoday's scientific research results when looking at a single research field in\nisolation. How to effectively use the huge number of scientific papers to help\nresearchers becomes a challenge. This paper introduces the research status at\nhome and abroad in terms of domain information mining and topic evolution law\nof scientific and technological papers from three aspects: the semantic feature\nrepresentation learning of scientific and technological papers, the field\ninformation mining of scientific and technological papers, and the mining and\nprediction of research topic evolution rules of scientific and technological\npapers.\n",
                "链接": "https://arxiv.org/abs/2204.08476"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "55685",
                "标题": "Sentiment Analysis of COVID-19 Public Activity Restriction (PPKM) Impact\n  using BERT Method",
                "作者": "  Fransiscus,  A. S. Girsang",
                "发布日期": "2023-01-03",
                "摘要": "  Covid-19 has grown rapidly in all parts of the world and is considered an\ninternational disaster because of its wide-reaching impact. The impact of\nCovid-19 has spread to Indonesia, especially in the slowdown in economic\ngrowth. This was influenced by the implementation of Community Activity\nRestrictions (PPKM) which limited community economic activities. This study\naims to analyze the mapping of public sentiment towards PPKM policies in\nIndonesia during the pandemic based on Twitter data. Knowing the mapping of\npublic sentiment regarding PPKM is expected to help stakeholders in the policy\nevaluation process for each region. The method used is BERT with IndoBERT\nspecific model. The results showed the evaluation value of IndoBERT f-1 score\nreached 84%, precision 86%, and recall 84%. Meanwhile for the evaluation of the\nuse of SVM f-1 score 70%, 72% precision, and 70% recall. Multinominal Na\\\"ive\nBayes evaluation shows f-1 score 83%, precision 78%, and recall 80%. As a\nconclusion, BERT method with the IndoBERT model is proven to be higher than\nclassical methods such as SVM and Multinominal Na\\\"ive Bayes.\n",
                "链接": "https://arxiv.org/abs/2301.00096"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "11176",
                "标题": "4D-OR: Semantic Scene Graphs for OR Domain Modeling",
                "作者": " Ege Özsoy,  Evin Pınar Örnek,  Ulrich Eck,  Tobias Czempiel,  Federico Tombari,  Nassir Navab",
                "发布日期": "2022-03-23",
                "摘要": "  Surgical procedures are conducted in highly complex operating rooms (OR),\ncomprising different actors, devices, and interactions. To date, only medically\ntrained human experts are capable of understanding all the links and\ninteractions in such a demanding environment. This paper aims to bring the\ncommunity one step closer to automated, holistic and semantic understanding and\nmodeling of OR domain. Towards this goal, for the first time, we propose using\nsemantic scene graphs (SSG) to describe and summarize the surgical scene. The\nnodes of the scene graphs represent different actors and objects in the room,\nsuch as medical staff, patients, and medical equipment, whereas edges are the\nrelationships between them. To validate the possibilities of the proposed\nrepresentation, we create the first publicly available 4D surgical SSG dataset,\n4D-OR, containing ten simulated total knee replacement surgeries recorded with\nsix RGB-D sensors in a realistic OR simulation center. 4D-OR includes 6734\nframes and is richly annotated with SSGs, human and object poses, and clinical\nroles. We propose an end-to-end neural network-based SSG generation pipeline,\nwith a rate of success of 0.75 macro F1, indeed being able to infer semantic\nreasoning in the OR. We further demonstrate the representation power of our\nscene graphs by using it for the problem of clinical role prediction, where we\nachieve 0.85 macro F1. The code and dataset will be made available upon\nacceptance.\n",
                "链接": "https://arxiv.org/abs/2203.11937"
            },
            {
                "文章ID": "44611",
                "标题": "Composition, Attention, or Both?",
                "作者": " Ryo Yoshida,  Yohei Oseki",
                "发布日期": "2023-05-12",
                "摘要": "  In this paper, we propose a novel architecture called Composition Attention\nGrammars (CAGs) that recursively compose subtrees into a single vector\nrepresentation with a composition function, and selectively attend to previous\nstructural information with a self-attention mechanism. We investigate whether\nthese components -- the composition function and the self-attention mechanism\n-- can both induce human-like syntactic generalization. Specifically, we train\nlanguage models (LMs) with and without these two components with the model\nsizes carefully controlled, and evaluate their syntactic generalization\nperformance against six test circuits on the SyntaxGym benchmark. The results\ndemonstrated that the composition function and the self-attention mechanism\nboth play an important role to make LMs more human-like, and closer inspection\nof linguistic phenomenon implied that the composition function allowed\nsyntactic features, but not semantic features, to percolate into subtree\nrepresentations.\n",
                "链接": "https://arxiv.org/abs/2210.12958"
            },
            {
                "文章ID": "115941",
                "标题": "Grounding or Guesswork? Large Language Models are Presumptive Grounders",
                "作者": " Omar Shaikh,  Kristina Gligorić,  Ashna Khetan,  Matthias Gerstgrasser,  Diyi Yang,  Dan Jurafsky",
                "发布日期": "2023-11-16",
                "摘要": "  Effective conversation requires common ground: a shared understanding between\nthe participants. Common ground, however, does not emerge spontaneously in\nconversation. Speakers and listeners work together to both identify and\nconstruct a shared basis while avoiding misunderstanding. To accomplish\ngrounding, humans rely on a range of dialogue acts, like clarification (What do\nyou mean?) and acknowledgment (I understand.). In domains like teaching and\nemotional support, carefully constructing grounding prevents misunderstanding.\nHowever, it is unclear whether large language models (LLMs) leverage these\ndialogue acts in constructing common ground. To this end, we curate a set of\ngrounding acts and propose corresponding metrics that quantify attempted\ngrounding. We study whether LLMs use these grounding acts, simulating them\ntaking turns from several dialogue datasets, and comparing the results to\nhumans. We find that current LLMs are presumptive grounders, biased towards\nassuming common ground without using grounding acts. To understand the roots of\nthis behavior, we examine the role of instruction tuning and reinforcement\nlearning with human feedback (RLHF), finding that RLHF leads to less grounding.\nAltogether, our work highlights the need for more research investigating\ngrounding in human-AI interaction.\n",
                "链接": "https://arxiv.org/abs/2311.09144"
            },
            {
                "文章ID": "112490",
                "标题": "Security Challenges for Cloud or Fog Computing-Based AI Applications",
                "作者": " Amir Pakmehr,  Andreas Aßmuth,  Christoph P. Neumann,  Gerald Pirkl",
                "发布日期": "2023-12-22",
                "摘要": "  Security challenges for Cloud or Fog-based machine learning services pose\nseveral concerns. Securing the underlying Cloud or Fog services is essential,\nas successful attacks against these services, on which machine learning\napplications rely, can lead to significant impairments of these applications.\nBecause the requirements for AI applications can also be different, we\ndifferentiate according to whether they are used in the Cloud or in a Fog\nComputing network. This then also results in different threats or attack\npossibilities. For Cloud platforms, the responsibility for security can be\ndivided between different parties. Security deficiencies at a lower level can\nhave a direct impact on the higher level where user data is stored. While\nresponsibilities are simpler for Fog Computing networks, by moving services to\nthe edge of the network, we have to secure them against physical access to the\ndevices. We conclude by outlining specific information security requirements\nfor AI applications.\n",
                "链接": "https://arxiv.org/abs/2310.19459"
            },
            {
                "文章ID": "118191",
                "标题": "Move or Push? Studying Pseudo-Haptic Perceptions Obtained with Motion or\n  Force Input",
                "作者": " Yutaro Hirao,  Takuji Narumi,  Ferran Argelaguet,  Anatole Lecuyer",
                "发布日期": "2023-11-28",
                "摘要": "  Pseudo-haptics techniques are interesting alternatives for generating haptic\nperceptions, which entails the manipulation of haptic perception through the\nappropriate alteration of primarily visual feedback in response to body\nmovements. However, the use of pseudo-haptics techniques with a motion-input\nsystem can sometimes be limited. This paper investigates a novel approach for\nextending the potential of pseudo-haptics techniques in virtual reality (VR).\nThe proposed approach utilizes a reaction force from force-input as a\nsubstitution of haptic cue for the pseudo-haptic perception. The paper\nintroduced a manipulation method in which the vertical acceleration of the\nvirtual hand is controlled by the extent of push-in of a force sensor. Such a\nforce-input manipulation of a virtual body can not only present pseudo-haptics\nwith less physical spaces and be used by more various users including\nphysically handicapped people, but also can present the reaction force\nproportional to the user's input to the user. We hypothesized that such a\nhaptic force cue would contribute to the pseudo-haptic perception. Therefore,\nthe paper endeavors to investigate the force-input pseudo-haptic perception in\na comparison with the motion-input pseudo-haptics. The paper compared\nforce-input and motion-input manipulation in a point of achievable range and\nresolution of pseudo-haptic weight. The experimental results suggest that the\nforce-input manipulation successfully extends the range of perceptible\npseudo-weight by 80\\% in comparison to the motion-input manipulation. On the\nother hand, it is revealed that the motion-input manipulation has 1 step larger\nnumber of distinguishable weight levels and is easier to operate than the\nforce-input manipulation.\n",
                "链接": "https://arxiv.org/abs/2311.15546"
            },
            {
                "文章ID": "46387",
                "标题": "More Speaking or More Speakers?",
                "作者": " Dan Berrebbi,  Ronan Collobert,  Navdeep Jaitly,  Tatiana Likhomanenko",
                "发布日期": "2023-03-03",
                "摘要": "  Self-training (ST) and self-supervised learning (SSL) methods have\ndemonstrated strong improvements in automatic speech recognition (ASR). In\nspite of these advances, to the best of our knowledge, there is no analysis of\nhow the composition of the labelled and unlabelled datasets used in these\nmethods affects the results. In this work we aim to analyse the effect of\nnumber of speakers in the training data on a recent SSL algorithm (wav2vec\n2.0), and a recent ST algorithm (slimIPL). We perform a systematic analysis on\nboth labeled and unlabeled data by varying the number of speakers while keeping\nthe number of hours fixed and vice versa. Our findings suggest that SSL\nrequires a large amount of unlabeled data to produce high accuracy results,\nwhile ST requires a sufficient number of speakers in the labelled data,\nespecially in the low-regime setting. In this manner these two approaches\nimprove supervised learning in different regimes of data composition.\n",
                "链接": "https://arxiv.org/abs/2211.00854"
            },
            {
                "文章ID": "92148",
                "标题": "LLM Censorship: A Machine Learning Challenge or a Computer Security\n  Problem?",
                "作者": " David Glukhov,  Ilia Shumailov,  Yarin Gal,  Nicolas Papernot,  Vardan Papyan",
                "发布日期": "2023-07-25",
                "摘要": "  Large language models (LLMs) have exhibited impressive capabilities in\ncomprehending complex instructions. However, their blind adherence to provided\ninstructions has led to concerns regarding risks of malicious use. Existing\ndefence mechanisms, such as model fine-tuning or output censorship using LLMs,\nhave proven to be fallible, as LLMs can still generate problematic responses.\nCommonly employed censorship approaches treat the issue as a machine learning\nproblem and rely on another LM to detect undesirable content in LLM outputs. In\nthis paper, we present the theoretical limitations of such semantic censorship\napproaches. Specifically, we demonstrate that semantic censorship can be\nperceived as an undecidable problem, highlighting the inherent challenges in\ncensorship that arise due to LLMs' programmatic and instruction-following\ncapabilities. Furthermore, we argue that the challenges extend beyond semantic\ncensorship, as knowledgeable attackers can reconstruct impermissible outputs\nfrom a collection of permissible ones. As a result, we propose that the problem\nof censorship needs to be reevaluated; it should be treated as a security\nproblem which warrants the adaptation of security-based approaches to mitigate\npotential risks.\n",
                "链接": "https://arxiv.org/abs/2307.10719"
            },
            {
                "文章ID": "102947",
                "标题": "Love or Hate? Share or Split? Privacy-Preserving Training Using Split\n  Learning and Homomorphic Encryption",
                "作者": " Tanveer Khan,  Khoa Nguyen,  Antonis Michalas,  Alexandros Bakas",
                "发布日期": "2023-09-20",
                "摘要": "  Split learning (SL) is a new collaborative learning technique that allows\nparticipants, e.g. a client and a server, to train machine learning models\nwithout the client sharing raw data. In this setting, the client initially\napplies its part of the machine learning model on the raw data to generate\nactivation maps and then sends them to the server to continue the training\nprocess. Previous works in the field demonstrated that reconstructing\nactivation maps could result in privacy leakage of client data. In addition to\nthat, existing mitigation techniques that overcome the privacy leakage of SL\nprove to be significantly worse in terms of accuracy. In this paper, we improve\nupon previous works by constructing a protocol based on U-shaped SL that can\noperate on homomorphically encrypted data. More precisely, in our approach, the\nclient applies homomorphic encryption on the activation maps before sending\nthem to the server, thus protecting user privacy. This is an important\nimprovement that reduces privacy leakage in comparison to other SL-based works.\nFinally, our results show that, with the optimum set of parameters, training\nwith HE data in the U-shaped SL setting only reduces accuracy by 2.65% compared\nto training on plaintext. In addition, raw training data privacy is preserved.\n",
                "链接": "https://arxiv.org/abs/2309.10517"
            },
            {
                "文章ID": "2089",
                "标题": "To SMOTE, or not to SMOTE?",
                "作者": " Yotam Elor,  Hadar Averbuch-Elor",
                "发布日期": "2022-05-12",
                "摘要": "  Balancing the data before training a classifier is a popular technique to\naddress the challenges of imbalanced binary classification in tabular data.\nBalancing is commonly achieved by duplication of minority samples or by\ngeneration of synthetic minority samples. While it is well known that balancing\naffects each classifier differently, most prior empirical studies did not\ninclude strong state-of-the-art (SOTA) classifiers as baselines. In this work,\nwe are interested in understanding whether balancing is beneficial,\nparticularly in the context of SOTA classifiers. Thus, we conduct extensive\nexperiments considering three SOTA classifiers along the weaker learners used\nin previous investigations. Additionally, we carefully discern proper metrics,\nconsistent and non-consistent algorithms and hyper-parameter selection methods\nand show that these have a significant impact on prediction quality and on the\neffectiveness of balancing. Our results support the known utility of balancing\nfor weak classifiers. However, we find that balancing does not improve\nprediction performance for the strong ones. We further identify several other\nscenarios for which balancing is effective and observe that prior studies\ndemonstrated the utility of balancing by focusing on these settings.\n",
                "链接": "https://arxiv.org/abs/2201.08528"
            },
            {
                "文章ID": "3057",
                "标题": "The kilogram: inertial or gravitational mass?",
                "作者": " Giovanni Mana,  Stephan Schlamminger",
                "发布日期": "2022-08-24",
                "摘要": "  With the redefinition of the international system of units, the value of the\nPlanck constant was fixed, similarly to the values of the unperturbed ground\nstate hyperfine transition frequency of the $^{133}$Cs atom, speed of light in\nvacuum. Theoretically and differently from the past, the kilogram is now\nexplicitly defined as the unit of inertial mass. Experimentally, the kilogram\nis realized by atom count or the Kibble balance. We show that only the former\nmethod measures the inertial mass without assuming the universality of free\nfall. Therefore, the agreement between the two measures can be interpreted as a\ntest of the equivalence principle.\n",
                "链接": "https://arxiv.org/abs/2201.12136"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "13451",
                "标题": "Data Augmentation for Intent Classification with Off-the-shelf Large\n  Language Models",
                "作者": " Gaurav Sahu,  Pau Rodriguez,  Issam H. Laradji,  Parmida Atighehchian,  David Vazquez,  Dzmitry Bahdanau",
                "发布日期": "2022-04-06",
                "摘要": "  Data augmentation is a widely employed technique to alleviate the problem of\ndata scarcity. In this work, we propose a prompting-based approach to generate\nlabelled training data for intent classification with off-the-shelf language\nmodels (LMs) such as GPT-3. An advantage of this method is that no\ntask-specific LM-fine-tuning for data generation is required; hence the method\nrequires no hyper-parameter tuning and is applicable even when the available\ntraining data is very scarce. We evaluate the proposed method in a few-shot\nsetting on four diverse intent classification tasks. We find that GPT-generated\ndata significantly boosts the performance of intent classifiers when intents in\nconsideration are sufficiently distinct from each other. In tasks with\nsemantically close intents, we observe that the generated data is less helpful.\nOur analysis shows that this is because GPT often generates utterances that\nbelong to a closely-related intent instead of the desired one. We present\npreliminary evidence that a prompting-based GPT classifier could be helpful in\nfiltering the generated data to enhance its quality.\n",
                "链接": "https://arxiv.org/abs/2204.01959"
            },
            {
                "文章ID": "109508",
                "标题": "GPT-4 as an interface between researchers and computational software:\n  improving usability and reproducibility",
                "作者": " Juan C. Verduzco,  Ethan Holbrook,  Alejandro Strachan",
                "发布日期": "2023-10-19",
                "摘要": "  Large language models (LLMs) are playing an increasingly important role in\nscience and engineering. For example, their ability to parse and understand\nhuman and computer languages makes them powerful interpreters and their use in\napplications like code generation are well-documented. We explore the ability\nof the GPT-4 LLM to ameliorate two major challenges in computational materials\nscience: i) the high barriers for adoption of scientific software associated\nwith the use of custom input languages, and ii) the poor reproducibility of\npublished results due to insufficient details in the description of simulation\nmethods. We focus on a widely used software for molecular dynamics simulations,\nthe Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS), and\nquantify the usefulness of input files generated by GPT-4 from task\ndescriptions in English and its ability to generate detailed descriptions of\ncomputational tasks from input files. We find that GPT-4 can generate correct\nand ready-to-use input files for relatively simple tasks and useful starting\npoints for more complex, multi-step simulations. In addition, GPT-4's\ndescription of computational tasks from input files can be tuned from a\ndetailed set of step-by-step instructions to a summary description appropriate\nfor publications. Our results show that GPT-4 can reduce the number of routine\ntasks performed by researchers, accelerate the training of new users, and\nenhance reproducibility.\n",
                "链接": "https://arxiv.org/abs/2310.11458"
            },
            {
                "文章ID": "74683",
                "标题": "CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to\n  Guardrail Models for Virtual Assistants",
                "作者": " Albert Yu Sun,  Varun Nair,  Elliot Schumacher,  Anitha Kannan",
                "发布日期": "2023-04-28",
                "摘要": "  A wave of new task-based virtual assistants has been fueled by increasingly\npowerful large language models, such as GPT-4. These conversational agents can\nbe customized to serve customer-specific use cases, but ensuring that\nagent-generated text conforms to designer-specified rules included in prompt\ninstructions alone is challenging. Therefore, chatbot designers often use\nanother model, called a guardrail model, to verify that the agent output aligns\nwith their rules and constraints. We explore using a distillation approach to\nguardrail models to monitor the output of the first model using training data\nfrom GPT-4. We find two crucial steps to our CONSCENDI process:\nscenario-augmented generation and contrastive training examples. When\ngenerating conversational data, we generate a set of rule-breaking scenarios,\nwhich enumerate a diverse set of high-level ways a rule can be violated. This\nscenario-guided approach produces a diverse training set of rule-violating\nconversations, and it provides chatbot designers greater control over the\nclassification process. We also prompt GPT-4 to also generate contrastive\nexamples by altering conversations with violations into acceptable\nconversations. This set of borderline, contrastive examples enables the\ndistilled model to learn finer-grained distinctions between what is acceptable\nand what is not. We find that CONSCENDI results in guardrail models that\nimprove over baselines.\n",
                "链接": "https://arxiv.org/abs/2304.14364"
            },
            {
                "文章ID": "84139",
                "标题": "Certified Deductive Reasoning with Language Models",
                "作者": " Gabriel Poesia,  Kanishk Gandhi,  Eric Zelikman,  Noah D. Goodman",
                "发布日期": "2023-11-09",
                "摘要": "  Language models often achieve higher accuracy when reasoning step-by-step in\ncomplex tasks. However, even when arriving at a correct final answer, their\nrationales are often logically unsound or inconsistent. This is a major issue\nwhen reliable reasoning traces are needed, such when fine-tuning on\nmodel-generated reasoning for self-improvement. To tackle these issues, we\nintroduce a class of tools for language models called \\emph{guides}, that use\nstate and incremental constraints to guide generation. A guide can be invoked\nby the model to constrain its own generation to a set of valid statements given\nby the tool. In turn, the model's choices can change the guide's state. We show\nhow a general system for logical reasoning can be used as a guide, which we\ncall \\textsc{LogicGuide}. Given a reasoning problem in natural language, a\nmodel can formalize its assumptions for \\textsc{LogicGuide} and guarantee that\nits step-by-step reasoning is sound. In experiments on PrOntoQA, ProofWriter\nand Syllogism Validity datasets, \\textsc{LogicGuide} significantly improves the\nperformance of GPT-3, GPT-3.5 Turbo and LLaMA (accuracy gains up to 35\\%),\nwhile drastically reducing \\emph{content effects} -- the interference between\nunwanted prior assumptions and reasoning, which humans and language models\nsuffer from. We then explore bootstrapping GPT-3.5 Turbo and LLaMA using their\nown reasoning traces. We find that LogicGuide is critical: by training only on\ncertified self-generated reasoning, models can self-improve, avoiding learning\nfrom their own hallucinations. Moreover, bootstrapped models enjoy significant\nboosts on ReClor, a challenging real-world reasoning dataset, even when not\nrelying on formalization at inference time.\n",
                "链接": "https://arxiv.org/abs/2306.04031"
            },
            {
                "文章ID": "79918",
                "标题": "LLM-powered Data Augmentation for Enhanced Cross-lingual Performance",
                "作者": " Chenxi Whitehouse,  Monojit Choudhury,  Alham Fikri Aji",
                "发布日期": "2023-10-24",
                "摘要": "  This paper explores the potential of leveraging Large Language Models (LLMs)\nfor data augmentation in multilingual commonsense reasoning datasets where the\navailable training data is extremely limited. To achieve this, we utilise\nseveral LLMs, namely Dolly-v2, StableVicuna, ChatGPT, and GPT-4, to augment\nthree datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we evaluate\nthe effectiveness of fine-tuning smaller multilingual models, mBERT and XLMR,\nusing the synthesised data. We compare the performance of training with data\ngenerated in English and target languages, as well as translated\nEnglish-generated data, revealing the overall advantages of incorporating data\ngenerated by LLMs, e.g. a notable 13.4 accuracy score improvement for the best\ncase. Furthermore, we conduct a human evaluation by asking native speakers to\nassess the naturalness and logical coherence of the generated examples across\ndifferent languages. The results of the evaluation indicate that LLMs such as\nChatGPT and GPT-4 excel at producing natural and coherent text in most\nlanguages, however, they struggle to generate meaningful text in certain\nlanguages like Tamil. We also observe that ChatGPT falls short in generating\nplausible alternatives compared to the original dataset, whereas examples from\nGPT-4 exhibit competitive logical consistency.\n",
                "链接": "https://arxiv.org/abs/2305.14288"
            },
            {
                "文章ID": "56440",
                "标题": "Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models",
                "作者": " Mariam Bangura,  Kristina Barabashova,  Anna Karnysheva,  Sarah Semczuk,  Yifan Wang",
                "发布日期": "2023-01-11",
                "摘要": "  This study is devoted to the automatic generation of German drama texts. We\nsuggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the\noutline model) to generate outlines of scenes based on keywords and fine-tuning\na second model (the generation model) to generate scenes from the scene\noutline. The input for the neural model comprises two datasets: the German\nDrama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA).\nIn order to estimate the effectiveness of the proposed method, our models are\ncompared with baseline GPT-2 models. Our models perform well according to\nautomatic quantitative evaluation, but, conversely, manual qualitative analysis\nreveals a poor quality of generated texts. This may be due to the quality of\nthe dataset or training inputs.\n",
                "链接": "https://arxiv.org/abs/2301.03119"
            },
            {
                "文章ID": "98631",
                "标题": "MLLM-DataEngine: An Iterative Refinement Approach for MLLM",
                "作者": " Zhiyuan Zhao,  Linke Ouyang,  Bin Wang,  Siyuan Huang,  Pan Zhang,  Xiaoyi Dong,  Jiaqi Wang,  Conghui He",
                "发布日期": "2023-09-12",
                "摘要": "  Despite the great advance of Multimodal Large Language Models (MLLMs) in both\ninstruction dataset building and benchmarking, the independence of training and\nevaluation makes current MLLMs hard to further improve their capability under\nthe guidance of evaluation results with a relatively low human cost. In this\npaper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data\ngeneration, model training, and evaluation. Within each loop iteration, the\nMLLM-DataEngine first analyze the weakness of the model based on the evaluation\nresults, then generate a proper incremental dataset for the next training\niteration and enhance the model capability iteratively. Compared with previous\ndata collection methods which are separate from the benchmarking, the data\ngenerated by MLLM-DataEngine shows better targeting, quality, and correctness.\nFor targeting, we propose an Adaptive Bad-case Sampling module, which adjusts\nthe ratio of different types of data within each incremental dataset based on\nthe benchmarking results. For quality, we resort to GPT-4 to generate\nhigh-quality data with each given data type. For correctness, prompt design is\ncritical for the data generation results. Rather than previous hand-crafted\nprompt, we propose an Interactive Prompt Optimization strategy, which optimizes\nthe prompt with the multi-round interaction between human and GPT, and improve\nthe correctness of generated data greatly. Through extensive experiments, we\nfind our MLLM-DataEngine could boost the MLLM capability in a targeted and\nautomatic manner, with only a few human participation. We hope it could be a\ngeneral solution for the following MLLMs building. The MLLM-DataEngine has been\nopen-sourced and is now available at\nhttps://github.com/opendatalab/MLLM-DataEngine.\n",
                "链接": "https://arxiv.org/abs/2308.13566"
            },
            {
                "文章ID": "121374",
                "标题": "Sim-GPT: Text Similarity via GPT Annotated Data",
                "作者": " Shuhe Wang,  Beiming Cao,  Shengyu Zhang,  Xiaoya Li,  Jiwei Li,  Fei Wu,  Guoyin Wang,  Eduard Hovy",
                "发布日期": "2023-12-13",
                "摘要": "  Due to the lack of a large collection of high-quality labeled sentence pairs\nwith textual similarity scores, existing approaches for Semantic Textual\nSimilarity (STS) mostly rely on unsupervised techniques or training signals\nthat are only partially correlated with textual similarity, e.g., NLI-based\ndatasets. To tackle this issue, in this paper, we propose the strategy of\nmeasuring text similarity via GPT annotated data (Sim-GPT for short). The core\nidea of Sim-GPT is to generate data with STS labels using GPT-4, based on which\nan STS model is trained. Sim-GPT framework utilizes LLMs to provide a\nsubstantial amount of reliable annotated data filling the gap of the lack of\ntraining signals for STS. Sim-GPT is trained on a one-time generated dataset\nusing BERT or RoBERTa as the backbone, which offers long-term savings in cost\nand speed compared to repeatedly invoking LLMs for each sentence pair. Trained\non the examples from GPT-4 (371K), Sim-GPT yields SOTA performances on the\nwidely-used seven STS benchmarks: +0.99 over supervised-SimCSE, and +0.42 over\nthe current SOTA PromCSE model. To encourage further advancements of the field,\nwe release both models and the 371K annotated examples from GPT-4. Code, models\nand annotated data are available at: https://github.com/ShuheWang1998/Sim-GPT.\n",
                "链接": "https://arxiv.org/abs/2312.05603"
            },
            {
                "文章ID": "40967",
                "标题": "Rainier: Reinforced Knowledge Introspector for Commonsense Question\n  Answering",
                "作者": " Jiacheng Liu,  Skyler Hallinan,  Ximing Lu,  Pengfei He,  Sean Welleck,  Hannaneh Hajishirzi,  Yejin Choi",
                "发布日期": "2022-10-25",
                "摘要": "  Knowledge underpins reasoning. Recent research demonstrates that when\nrelevant knowledge is provided as additional context to commonsense question\nanswering (QA), it can substantially enhance the performance even on top of\nstate-of-the-art. The fundamental challenge is where and how to find such\nknowledge that is high quality and on point with respect to the question;\nknowledge retrieved from knowledge bases are incomplete and knowledge generated\nfrom language models are inconsistent. We present Rainier, or Reinforced\nKnowledge Introspector, that learns to generate contextually relevant knowledge\nin response to given questions. Our approach starts by imitating knowledge\ngenerated by GPT-3, then learns to generate its own knowledge via reinforcement\nlearning where rewards are shaped based on the increased performance on the\nresulting question answering. Rainier demonstrates substantial and consistent\nperformance gains when tested over 9 different commonsense benchmarks:\nincluding 5 datasets that are seen during model training, as well as 4 datasets\nthat are kept unseen. Our work is the first to report that knowledge generated\nby models that are orders of magnitude smaller than GPT-3, even without direct\nsupervision on the knowledge itself, can exceed the quality of commonsense\nknowledge elicited from GPT-3.\n",
                "链接": "https://arxiv.org/abs/2210.03078"
            },
            {
                "文章ID": "83260",
                "标题": "ProcessGPT: Transforming Business Process Management with Generative\n  Artificial Intelligence",
                "作者": " Amin Beheshti,  Jian Yang,  Quan Z. Sheng,  Boualem Benatallah,  Fabio Casati,  Schahram Dustdar,  Hamid Reza Motahari Nezhad,  Xuyun Zhang,  Shan Xue",
                "发布日期": "2023-06-06",
                "摘要": "  Generative Pre-trained Transformer (GPT) is a state-of-the-art machine\nlearning model capable of generating human-like text through natural language\nprocessing (NLP). GPT is trained on massive amounts of text data and uses deep\nlearning techniques to learn patterns and relationships within the data,\nenabling it to generate coherent and contextually appropriate text. This\nposition paper proposes using GPT technology to generate new process models\nwhen/if needed. We introduce ProcessGPT as a new technology that has the\npotential to enhance decision-making in data-centric and knowledge-intensive\nprocesses. ProcessGPT can be designed by training a generative pre-trained\ntransformer model on a large dataset of business process data. This model can\nthen be fine-tuned on specific process domains and trained to generate process\nflows and make decisions based on context and user input. The model can be\nintegrated with NLP and machine learning techniques to provide insights and\nrecommendations for process improvement. Furthermore, the model can automate\nrepetitive tasks and improve process efficiency while enabling knowledge\nworkers to communicate analysis findings, supporting evidence, and make\ndecisions. ProcessGPT can revolutionize business process management (BPM) by\noffering a powerful tool for process augmentation, automation and improvement.\nFinally, we demonstrate how ProcessGPT can be a powerful tool for augmenting\ndata engineers in maintaining data ecosystem processes within large bank\norganizations. Our scenario highlights the potential of this approach to\nimprove efficiency, reduce costs, and enhance the quality of business\noperations through the automation of data-centric and knowledge-intensive\nprocesses. These results underscore the promise of ProcessGPT as a\ntransformative technology for organizations looking to improve their process\nworkflows.\n",
                "链接": "https://arxiv.org/abs/2306.01771"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59508",
                "标题": "Open-VCLIP: Transforming CLIP to an Open-vocabulary Video Model via\n  Interpolated Weight Optimization",
                "作者": " Zejia Weng,  Xitong Yang,  Ang Li,  Zuxuan Wu,  Yu-Gang Jiang",
                "发布日期": "2023-06-01",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) has demonstrated impressive\nzero-shot learning abilities for image understanding, yet limited effort has\nbeen made to investigate CLIP for zero-shot video recognition. We introduce\nOpen-VCLIP, a simple yet effective approach that transforms CLIP into a strong\nzero-shot video classifier that can recognize unseen actions and events at test\ntime. Our framework extends CLIP with minimal modifications to model\nspatial-temporal relationships in videos, making it a specialized video\nclassifier, while striving for generalization. We formally show that training\nan Open-VCLIP is equivalent to continual learning with zero historical data. To\naddress this problem, we propose Interpolated Weight Optimization, which\nutilizes the benefit of weight interpolation in both training and test time. We\nevaluate our method on three popular and challenging action recognition\ndatasets following various zero-shot evaluation protocols and we demonstrate\nour approach outperforms state-of-the-art methods by clear margins. In\nparticular, we achieve 87.9%, 58.3%, 81.1% zero-shot accuracy on UCF, HMDB and\nKinetics-600 respectively, outperforming state-of-the-art methods by 8.3%, 7.8%\nand 12.2%. Code is released at https://github.com/wengzejia1/Open-VCLIP.\n",
                "链接": "https://arxiv.org/abs/2302.00624"
            },
            {
                "文章ID": "104220",
                "标题": "CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic\n  Segmentation For-Free",
                "作者": " Monika Wysoczańska,  Michaël Ramamonjisoa,  Tomasz Trzciński,  Oriane Siméoni",
                "发布日期": "2023-11-29",
                "摘要": "  The emergence of CLIP has opened the way for open-world image perception. The\nzero-shot classification capabilities of the model are impressive but are\nharder to use for dense tasks such as image segmentation. Several methods have\nproposed different modifications and learning schemes to produce dense output.\nInstead, we propose in this work an open-vocabulary semantic segmentation\nmethod, dubbed CLIP-DIY, which does not require any additional training or\nannotations, but instead leverages existing unsupervised object localization\napproaches. In particular, CLIP-DIY is a multi-scale approach that directly\nexploits CLIP classification abilities on patches of different sizes and\naggregates the decision in a single map. We further guide the segmentation\nusing foreground/background scores obtained using unsupervised object\nlocalization methods. With our method, we obtain state-of-the-art zero-shot\nsemantic segmentation results on PASCAL VOC and perform on par with the best\nmethods on COCO. The code is available at\nhttp://github.com/wysoczanska/clip-diy\n",
                "链接": "https://arxiv.org/abs/2309.14289"
            },
            {
                "文章ID": "41351",
                "标题": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP",
                "作者": " Feng Liang,  Bichen Wu,  Xiaoliang Dai,  Kunpeng Li,  Yinan Zhao,  Hang Zhang,  Peizhao Zhang,  Peter Vajda,  Diana Marculescu",
                "发布日期": "2023-04-04",
                "摘要": "  Open-vocabulary semantic segmentation aims to segment an image into semantic\nregions according to text descriptions, which may not have been seen during\ntraining. Recent two-stage methods first generate class-agnostic mask proposals\nand then leverage pre-trained vision-language models, e.g., CLIP, to classify\nmasked regions. We identify the performance bottleneck of this paradigm to be\nthe pre-trained CLIP model, since it does not perform well on masked images. To\naddress this, we propose to finetune CLIP on a collection of masked image\nregions and their corresponding text descriptions. We collect training data by\nmining an existing image-caption dataset (e.g., COCO Captions), using CLIP to\nmatch masked image regions to nouns in the image captions. Compared with the\nmore precise and manually annotated segmentation labels with fixed classes\n(e.g., COCO-Stuff), we find our noisy but diverse dataset can better retain\nCLIP's generalization ability. Along with finetuning the entire model, we\nutilize the \"blank\" areas in masked images using a method we dub mask prompt\ntuning. Experiments demonstrate mask prompt tuning brings significant\nimprovement without modifying any weights of CLIP, and it can further improve a\nfully finetuned model. In particular, when trained on COCO and evaluated on\nADE20K-150, our best model achieves 29.6% mIoU, which is +8.5% higher than the\nprevious state-of-the-art. For the first time, open-vocabulary generalist\nmodels match the performance of supervised specialist models in 2017 without\ndataset-specific adaptations.\n",
                "链接": "https://arxiv.org/abs/2210.04150"
            },
            {
                "文章ID": "50058",
                "标题": "Open-vocabulary Attribute Detection",
                "作者": " María A. Bravo,  Sudhanshu Mittal,  Simon Ging,  Thomas Brox",
                "发布日期": "2023-03-10",
                "摘要": "  Vision-language modeling has enabled open-vocabulary tasks where predictions\ncan be queried using any text prompt in a zero-shot manner. Existing\nopen-vocabulary tasks focus on object classes, whereas research on object\nattributes is limited due to the lack of a reliable attribute-focused\nevaluation benchmark. This paper introduces the Open-Vocabulary Attribute\nDetection (OVAD) task and the corresponding OVAD benchmark. The objective of\nthe novel task and benchmark is to probe object-level attribute information\nlearned by vision-language models. To this end, we created a clean and densely\nannotated test set covering 117 attribute classes on the 80 object classes of\nMS COCO. It includes positive and negative annotations, which enables\nopen-vocabulary evaluation. Overall, the benchmark consists of 1.4 million\nannotations. For reference, we provide a first baseline method for\nopen-vocabulary attribute detection. Moreover, we demonstrate the benchmark's\nvalue by studying the attribute detection performance of several foundation\nmodels. Project page https://ovad-benchmark.github.io\n",
                "链接": "https://arxiv.org/abs/2211.12914"
            },
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "99749",
                "标题": "What Makes Good Open-Vocabulary Detector: A Disassembling Perspective",
                "作者": " Jincheng Li,  Chunyu Xie,  Xiaoyu Wu,  Bin Wang,  Dawei Leng",
                "发布日期": "2023-09-04",
                "摘要": "  Open-vocabulary detection (OVD) is a new object detection paradigm, aiming to\nlocalize and recognize unseen objects defined by an unbounded vocabulary. This\nis challenging since traditional detectors can only learn from pre-defined\ncategories and thus fail to detect and localize objects out of pre-defined\nvocabulary. To handle the challenge, OVD leverages pre-trained cross-modal VLM,\nsuch as CLIP, ALIGN, etc. Previous works mainly focus on the open vocabulary\nclassification part, with less attention on the localization part. We argue\nthat for a good OVD detector, both classification and localization should be\nparallelly studied for the novel object categories. We show in this work that\nimproving localization as well as cross-modal classification complement each\nother, and compose a good OVD detector jointly. We analyze three families of\nOVD methods with different design emphases. We first propose a vanilla\nmethod,i.e., cropping a bounding box obtained by a localizer and resizing it\ninto the CLIP. We next introduce another approach, which combines a standard\ntwo-stage object detector with CLIP. A two-stage object detector includes a\nvisual backbone, a region proposal network (RPN), and a region of interest\n(RoI) head. We decouple RPN and ROI head (DRR) and use RoIAlign to extract\nmeaningful features. In this case, it avoids resizing objects. To further\naccelerate the training time and reduce the model parameters, we couple RPN and\nROI head (CRR) as the third approach. We conduct extensive experiments on these\nthree types of approaches in different settings. On the OVD-COCO benchmark, DRR\nobtains the best performance and achieves 35.8 Novel AP$_{50}$, an absolute 2.8\ngain over the previous state-of-the-art (SOTA). For OVD-LVIS, DRR surpasses the\nprevious SOTA by 1.9 AP$_{50}$ in rare categories. We also provide an object\ndetection dataset called PID and provide a baseline on PID.\n",
                "链接": "https://arxiv.org/abs/2309.00227"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "71939",
                "标题": "CLIP Surgery for Better Explainability with Enhancement in\n  Open-Vocabulary Tasks",
                "作者": " Yi Li,  Hualiang Wang,  Yiqun Duan,  Xiaomeng Li",
                "发布日期": "2023-04-13",
                "摘要": "  Contrastive Language-Image Pre-training (CLIP) is a powerful multimodal large\nvision model that has demonstrated significant benefits for downstream tasks,\nincluding many zero-shot learning and text-guided vision tasks. However, we\nnotice some severe problems regarding the model's explainability, which\nundermines its credibility and impedes related tasks. Specifically, we find\nCLIP prefers the background regions than the foregrounds according to the\npredicted similarity map, which contradicts human understanding. Besides, there\nare obvious noisy activations on the visualization results at irrelevant\npositions. To address these two issues, we conduct in-depth analyses and reveal\nthe reasons with new findings and evidences. Based on these insights, we\npropose the CLIP Surgery, a method that enables surgery-like modifications for\nthe inference architecture and features, for better explainability and\nenhancement in multiple open-vocabulary tasks. The proposed method has\nsignificantly improved the explainability of CLIP for both convolutional\nnetworks and vision transformers, surpassing existing methods by large margins.\nBesides, our approach also demonstrates remarkable improvements in\nopen-vocabulary segmentation and multi-label recognition tasks. For examples,\nthe mAP improvement on NUS-Wide multi-label recognition is 4.41% without any\nadditional training, and our CLIP Surgery surpasses the state-of-the-art method\nby 8.74% at mIoU on Cityscapes open-vocabulary semantic segmentation.\nFurthermore, our method benefits other tasks including multimodal visualization\nand interactive segmentation like Segment Anything Model (SAM). The code is\navailable at https://github.com/xmed-lab/CLIP_Surgery\n",
                "链接": "https://arxiv.org/abs/2304.05653"
            },
            {
                "文章ID": "86253",
                "标题": "Scaling Open-Vocabulary Object Detection",
                "作者": " Matthias Minderer,  Alexey Gritsenko,  Neil Houlsby",
                "发布日期": "2023-07-21",
                "摘要": "  Open-vocabulary object detection has benefited greatly from pretrained\nvision-language models, but is still limited by the amount of available\ndetection training data. While detection training data can be expanded by using\nWeb image-text pairs as weak supervision, this has not been done at scales\ncomparable to image-level pretraining. Here, we scale up detection data with\nself-training, which uses an existing detector to generate pseudo-box\nannotations on image-text pairs. Major challenges in scaling self-training are\nthe choice of label space, pseudo-annotation filtering, and training\nefficiency. We present the OWLv2 model and OWL-ST self-training recipe, which\naddress these challenges. OWLv2 surpasses the performance of previous\nstate-of-the-art open-vocabulary detectors already at comparable training\nscales (~10M examples). However, with OWL-ST, we can scale to over 1B examples,\nyielding further large improvement: With an L/14 architecture, OWL-ST improves\nAP on LVIS rare classes, for which the model has seen no human box annotations,\nfrom 31.2% to 44.6% (43% relative improvement). OWL-ST unlocks Web-scale\ntraining for open-world localization, similar to what has been seen for image\nclassification and language modelling.\n",
                "链接": "https://arxiv.org/abs/2306.09683"
            },
            {
                "文章ID": "115237",
                "标题": "Open-Vocabulary Video Anomaly Detection",
                "作者": " Peng Wu,  Xuerong Zhou,  Guansong Pang,  Yujia Sun,  Jing Liu,  Peng Wang,  Yanning Zhang",
                "发布日期": "2023-11-16",
                "摘要": "  Video anomaly detection (VAD) with weak supervision has achieved remarkable\nperformance in utilizing video-level labels to discriminate whether a video\nframe is normal or abnormal. However, current approaches are inherently limited\nto a closed-set setting and may struggle in open-world applications where there\ncan be anomaly categories in the test data unseen during training. A few recent\nstudies attempt to tackle a more realistic setting, open-set VAD, which aims to\ndetect unseen anomalies given seen anomalies and normal videos. However, such a\nsetting focuses on predicting frame anomaly scores, having no ability to\nrecognize the specific categories of anomalies, despite the fact that this\nability is essential for building more informed video surveillance systems.\nThis paper takes a step further and explores open-vocabulary video anomaly\ndetection (OVVAD), in which we aim to leverage pre-trained large models to\ndetect and categorize seen and unseen anomalies. To this end, we propose a\nmodel that decouples OVVAD into two mutually complementary tasks --\nclass-agnostic detection and class-specific classification -- and jointly\noptimizes both tasks. Particularly, we devise a semantic knowledge injection\nmodule to introduce semantic knowledge from large language models for the\ndetection task, and design a novel anomaly synthesis module to generate pseudo\nunseen anomaly videos with the help of large vision generation models for the\nclassification task. These semantic knowledge and synthesis anomalies\nsubstantially extend our model's capability in detecting and categorizing a\nvariety of seen and unseen anomalies. Extensive experiments on three\nwidely-used benchmarks demonstrate our model achieves state-of-the-art\nperformance on OVVAD task.\n",
                "链接": "https://arxiv.org/abs/2311.07042"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "106859",
                "标题": "Human Mobility Question Answering (Vision Paper)",
                "作者": " Hao Xue,  Flora D. Salim",
                "发布日期": "2023-10-16",
                "摘要": "  Question answering (QA) systems have attracted much attention from the\nartificial intelligence community as they can learn to answer questions based\non the given knowledge source (e.g., images in visual question answering).\nHowever, the research into question answering systems with human mobility data\nremains unexplored. Mining human mobility data is crucial for various\napplications such as smart city planning, pandemic management, and personalised\nrecommendation system. In this paper, we aim to tackle this gap and introduce a\nnovel task, that is, human mobility question answering (MobQA). The aim of the\ntask is to let the intelligent system learn from mobility data and answer\nrelated questions. This task presents a new paradigm change in mobility\nprediction research and further facilitates the research of human mobility\nrecommendation systems. To better support this novel research topic, this\nvision paper also proposes an initial design of the dataset and a potential\ndeep learning model framework for the introduced MobQA task. We hope that this\npaper will provide novel insights and open new directions in human mobility\nresearch and question answering research.\n",
                "链接": "https://arxiv.org/abs/2310.04443"
            },
            {
                "文章ID": "95020",
                "标题": "Dialogue Systems Can Generate Appropriate Responses without the Use of\n  Question Marks? -- Investigation of the Effects of Question Marks on Dialogue\n  Systems",
                "作者": " Tomoya Mizumoto,  Takato Yamazaki,  Katsumasa Yoshikawa,  Masaya Ohagi,  Toshiki Kawamoto,  Toshinori Sato",
                "发布日期": "2023-08-08",
                "摘要": "  When individuals engage in spoken discourse, various phenomena can be\nobserved that differ from those that are apparent in text-based conversation.\nWhile written communication commonly uses a question mark to denote a query, in\nspoken discourse, queries are frequently indicated by a rising intonation at\nthe end of a sentence. However, numerous speech recognition engines do not\nappend a question mark to recognized queries, presenting a challenge when\ncreating a spoken dialogue system. Specifically, the absence of a question mark\nat the end of a sentence can impede the generation of appropriate responses to\nqueries in spoken dialogue systems. Hence, we investigate the impact of\nquestion marks on dialogue systems, with the results showing that they have a\nsignificant impact. Moreover, we analyze specific examples in an effort to\ndetermine which types of utterances have the impact on dialogue systems.\n",
                "链接": "https://arxiv.org/abs/2308.03293"
            },
            {
                "文章ID": "17220",
                "标题": "End-to-end Spoken Conversational Question Answering: Task, Dataset and\n  Model",
                "作者": " Chenyu You,  Nuo Chen,  Fenglin Liu,  Shen Ge,  Xian Wu,  Yuexian Zou",
                "发布日期": "2022-05-02",
                "摘要": "  In spoken question answering, the systems are designed to answer questions\nfrom contiguous text spans within the related speech transcripts. However, the\nmost natural way that human seek or test their knowledge is via human\nconversations. Therefore, we propose a new Spoken Conversational Question\nAnswering task (SCQA), aiming at enabling the systems to model complex dialogue\nflows given the speech documents. In this task, our main objective is to build\nthe system to deal with conversational questions based on the audio recordings,\nand to explore the plausibility of providing more cues from different\nmodalities with systems in information gathering. To this end, instead of\ndirectly adopting automatically generated speech transcripts with highly noisy\ndata, we propose a novel unified data distillation approach, DDNet, which\neffectively ingests cross-modal information to achieve fine-grained\nrepresentations of the speech and language modalities. Moreover, we propose a\nsimple and novel mechanism, termed Dual Attention, by encouraging better\nalignments between audio and text to ease the process of knowledge transfer. To\nevaluate the capacity of SCQA systems in a dialogue-style interaction, we\nassemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with\nmore than 40k question-answer pairs from 4k conversations. The performance of\nthe existing state-of-the-art methods significantly degrade on our dataset,\nhence demonstrating the necessity of cross-modal information integration. Our\nexperimental results demonstrate that our proposed method achieves superior\nperformance in spoken conversational question answering tasks.\n",
                "链接": "https://arxiv.org/abs/2204.14272"
            },
            {
                "文章ID": "91898",
                "标题": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup\n  2023",
                "作者": " Aline Lima de Oliveira,  Cauê Addae da Silva Gomes,  Cecília Virginia Santos da Silva,  Charles Matheus de Sousa Alves,  Danilo Andrade Martins de Souza,  Driele Pires Ferreira Araújo Xavier,  Edgleyson Pereira da Silva,  Felipe Bezerra Martins,  Lucas Henrique Cavalcanti Santos,  Lucas Dias Maciel,  Matheus Paixão Gumercindo dos Santos,  Matheus Lafayette Vasconcelos,  Matheus Vinícius Teotonio do Nascimento Andrade,  João Guilherme Oliveira Carvalho de Melo,  João Pedro Souza Pereira de Moura,  José Ronald da Silva,  José Victor Silva Cruz,  Pedro Henrique Santana de Morais,  Pedro Paulo Salman de Oliveira,  Riei Joaquim Matos Rodrigues,  Roberto Costa Fernandes,  Ryan Vinicius Santos Morais,  Tamara Mayara Ramos Teobaldo,  Washington Igor dos Santos Silva,  Edna Natividade Silva Barros",
                "发布日期": "2023-07-20",
                "摘要": "  Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its\nfirst world title in 2022 (Division B), and is currently a three-times\nLatin-American champion. This paper presents our improvements to defend the\nSmall Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.\nThis paper aims to share some of the academic research that our team developed\nover the past year. Our team has successfully published 2 articles related to\nSSL at two high-impact conferences: the 25th RoboCup International Symposium\nand the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last\nyear, we have been continuously migrating from our past codebase to\nUnification. We will describe the new architecture implemented and some points\nof software and AI refactoring. In addition, we discuss the process of\nintegrating machined components into the mechanical system, our development for\nparticipating in the vision blackout challenge last year and what we are\npreparing for this year.\n",
                "链接": "https://arxiv.org/abs/2307.10018"
            },
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "111240",
                "标题": "BLP 2023 Task 2: Sentiment Analysis",
                "作者": " Md. Arid Hasan,  Firoj Alam,  Anika Anjum,  Shudipta Das,  Afiyat Anjum",
                "发布日期": "2023-10-26",
                "摘要": "  We present an overview of the BLP Sentiment Shared Task, organized as part of\nthe inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is\ndefined as the detection of sentiment in a given piece of social media text.\nThis task attracted interest from 71 participants, among whom 29 and 30 teams\nsubmitted systems during the development and evaluation phases, respectively.\nIn total, participants submitted 597 runs. However, a total of 15 teams\nsubmitted system description papers. The range of approaches in the submitted\nsystems spans from classical machine learning models, fine-tuning pre-trained\nmodels, to leveraging Large Language Model (LLMs) in zero- and few-shot\nsettings. In this paper, we provide a detailed account of the task setup,\nincluding dataset development and evaluation setup. Additionally, we provide a\nbrief overview of the systems submitted by the participants. All datasets and\nevaluation scripts from the shared task have been made publicly available for\nthe research community, to foster further research in this domain\n",
                "链接": "https://arxiv.org/abs/2310.16183"
            },
            {
                "文章ID": "45077",
                "标题": "Auxiliary task discovery through generate-and-test",
                "作者": " Banafsheh Rafiee,  Sina Ghiassian,  Jun Jin,  Richard Sutton,  Jun Luo,  Adam White",
                "发布日期": "2022-10-27",
                "摘要": "  In this paper, we explore an approach to auxiliary task discovery in\nreinforcement learning based on ideas from representation learning. Auxiliary\ntasks tend to improve data efficiency by forcing the agent to learn auxiliary\nprediction and control objectives in addition to the main task of maximizing\nreward, and thus producing better representations. Typically these tasks are\ndesigned by people. Meta-learning offers a promising avenue for automatic task\ndiscovery; however, these methods are computationally expensive and challenging\nto tune in practice. In this paper, we explore a complementary approach to the\nauxiliary task discovery: continually generating new auxiliary tasks and\npreserving only those with high utility. We also introduce a new measure of\nauxiliary tasks usefulness based on how useful the features induced by them are\nfor the main task. Our discovery algorithm significantly outperforms random\ntasks, hand-designed tasks, and learning without auxiliary tasks across a suite\nof environments.\n",
                "链接": "https://arxiv.org/abs/2210.14361"
            },
            {
                "文章ID": "29820",
                "标题": "Recognizing Hand Use and Hand Role at Home After Stroke from Egocentric\n  Video",
                "作者": " Meng-Fen Tsai,  Rosalie H. Wang,  Jośe Zariffa",
                "发布日期": "2022-07-22",
                "摘要": "  Introduction: Hand function is a central determinant of independence after\nstroke. Measuring hand use in the home environment is necessary to evaluate the\nimpact of new interventions, and calls for novel wearable technologies.\nEgocentric video can capture hand-object interactions in context, as well as\nshow how more-affected hands are used during bilateral tasks (for stabilization\nor manipulation). Automated methods are required to extract this information.\nObjective: To use artificial intelligence-based computer vision to classify\nhand use and hand role from egocentric videos recorded at home after stroke.\nMethods: Twenty-one stroke survivors participated in the study. A random forest\nclassifier, a SlowFast neural network, and the Hand Object Detector neural\nnetwork were applied to identify hand use and hand role at home.\nLeave-One-Subject-Out-Cross-Validation (LOSOCV) was used to evaluate the\nperformance of the three models. Between-group differences of the models were\ncalculated based on the Mathews correlation coefficient (MCC). Results: For\nhand use detection, the Hand Object Detector had significantly higher\nperformance than the other models. The macro average MCCs using this model in\nthe LOSOCV were 0.50 +- 0.23 for the more-affected hands and 0.58 +- 0.18 for\nthe less-affected hands. Hand role classification had macro average MCCs in the\nLOSOCV that were close to zero for all models. Conclusion: Using egocentric\nvideo to capture the hand use of stroke survivors at home is feasible. Pose\nestimation to track finger movements may be beneficial to classifying hand\nroles in the future.\n",
                "链接": "https://arxiv.org/abs/2207.08920"
            },
            {
                "文章ID": "27917",
                "标题": "A Dataset on Malicious Paper Bidding in Peer Review",
                "作者": " Steven Jecmen,  Minji Yoon,  Vincent Conitzer,  Nihar B. Shah,  Fei Fang",
                "发布日期": "2023-03-14",
                "摘要": "  In conference peer review, reviewers are often asked to provide \"bids\" on\neach submitted paper that express their interest in reviewing that paper. A\npaper assignment algorithm then uses these bids (along with other data) to\ncompute a high-quality assignment of reviewers to papers. However, this process\nhas been exploited by malicious reviewers who strategically bid in order to\nunethically manipulate the paper assignment, crucially undermining the peer\nreview process. For example, these reviewers may aim to get assigned to a\nfriend's paper as part of a quid-pro-quo deal. A critical impediment towards\ncreating and evaluating methods to mitigate this issue is the lack of any\npublicly-available data on malicious paper bidding. In this work, we collect\nand publicly release a novel dataset to fill this gap, collected from a mock\nconference activity where participants were instructed to bid either honestly\nor maliciously. We further provide a descriptive analysis of the bidding\nbehavior, including our categorization of different strategies employed by\nparticipants. Finally, we evaluate the ability of each strategy to manipulate\nthe assignment, and also evaluate the performance of some simple algorithms\nmeant to detect malicious bidding. The performance of these detection\nalgorithms can be taken as a baseline for future research on detecting\nmalicious bidding.\n",
                "链接": "https://arxiv.org/abs/2207.02303"
            },
            {
                "文章ID": "58619",
                "标题": "Graph Attention with Hierarchies for Multi-hop Question Answering",
                "作者": " Yunjie He,  Philip John Gorinski,  Ieva Staliunaite,  Pontus Stenetorp",
                "发布日期": "2023-01-30",
                "摘要": "  Multi-hop QA (Question Answering) is the task of finding the answer to a\nquestion across multiple documents. In recent years, a number of Deep\nLearning-based approaches have been proposed to tackle this complex task, as\nwell as a few standard benchmarks to assess models Multi-hop QA capabilities.\nIn this paper, we focus on the well-established HotpotQA benchmark dataset,\nwhich requires models to perform answer span extraction as well as support\nsentence prediction. We present two extensions to the SOTA Graph Neural Network\n(GNN) based model for HotpotQA, Hierarchical Graph Network (HGN): (i) we\ncomplete the original hierarchical structure by introducing new edges between\nthe query and context sentence nodes; (ii) in the graph propagation step, we\npropose a novel extension to Hierarchical Graph Attention Network GATH (Graph\nATtention with Hierarchies) that makes use of the graph hierarchy to update the\nnode representations in a sequential fashion. Experiments on HotpotQA\ndemonstrate the efficiency of the proposed modifications and support our\nassumptions about the effects of model related variables.\n",
                "链接": "https://arxiv.org/abs/2301.11792"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "110744",
                "标题": "ALCUNA: Large Language Models Meet New Knowledge",
                "作者": " Xunjian Yin,  Baizhou Huang,  Xiaojun Wan",
                "发布日期": "2023-10-24",
                "摘要": "  With the rapid development of NLP, large-scale language models (LLMs) excel\nin various tasks across multiple domains now. However, existing benchmarks may\nnot adequately measure these models' capabilities, especially when faced with\nnew knowledge. In this paper, we address the lack of benchmarks to evaluate\nLLMs' ability to handle new knowledge, an important and challenging aspect in\nthe rapidly evolving world. We propose an approach called KnowGen that\ngenerates new knowledge by altering existing entity attributes and\nrelationships, resulting in artificial entities that are distinct from\nreal-world entities. With KnowGen, we introduce a benchmark named ALCUNA to\nassess LLMs' abilities in knowledge understanding, differentiation, and\nassociation. We benchmark several LLMs, reveals that their performance in face\nof new knowledge is not satisfactory, particularly in reasoning between new and\ninternal knowledge. We also explore the impact of entity similarity on the\nmodel's understanding of entity knowledge and the influence of contextual\nentities. We appeal to the need for caution when using LLMs in new scenarios or\nwith new knowledge, and hope that our benchmarks can help drive the development\nof LLMs in face of new knowledge.\n",
                "链接": "https://arxiv.org/abs/2310.14820"
            },
            {
                "文章ID": "36590",
                "标题": "Cross-Modal Knowledge Transfer Without Task-Relevant Source Data",
                "作者": " Sk Miraj Ahmed,  Suhas Lohit,  Kuan-Chuan Peng,  Michael J. Jones,  Amit K. Roy-Chowdhury",
                "发布日期": "2022-09-12",
                "摘要": "  Cost-effective depth and infrared sensors as alternatives to usual RGB\nsensors are now a reality, and have some advantages over RGB in domains like\nautonomous navigation and remote sensing. As such, building computer vision and\ndeep learning systems for depth and infrared data are crucial. However, large\nlabeled datasets for these modalities are still lacking. In such cases,\ntransferring knowledge from a neural network trained on a well-labeled large\ndataset in the source modality (RGB) to a neural network that works on a target\nmodality (depth, infrared, etc.) is of great value. For reasons like memory and\nprivacy, it may not be possible to access the source data, and knowledge\ntransfer needs to work with only the source models. We describe an effective\nsolution, SOCKET: SOurce-free Cross-modal KnowledgE Transfer for this\nchallenging task of transferring knowledge from one source modality to a\ndifferent target modality without access to task-relevant source data. The\nframework reduces the modality gap using paired task-irrelevant data, as well\nas by matching the mean and variance of the target features with the batch-norm\nstatistics that are present in the source models. We show through extensive\nexperiments that our method significantly outperforms existing source-free\nmethods for classification tasks which do not account for the modality gap.\n",
                "链接": "https://arxiv.org/abs/2209.04027"
            },
            {
                "文章ID": "3183",
                "标题": "AutoDistil: Few-shot Task-agnostic Neural Architecture Search for\n  Distilling Large Language Models",
                "作者": " Dongkuan Xu,  Subhabrata Mukherjee,  Xiaodong Liu,  Debadeepta Dey,  Wenhui Wang,  Xiang Zhang,  Ahmed Hassan Awadallah,  Jianfeng Gao",
                "发布日期": "2022-02-22",
                "摘要": "  Knowledge distillation (KD) methods compress large models into smaller\nstudents with manually-designed student architectures given pre-specified\ncomputational cost. This requires several trials to find a viable student, and\nfurther repeating the process for each student or computational budget change.\nWe use Neural Architecture Search (NAS) to automatically distill several\ncompressed students with variable cost from a large model. Current works train\na single SuperLM consisting of millions of subnetworks with weight-sharing,\nresulting in interference between subnetworks of different sizes. Our framework\nAutoDistil addresses above challenges with the following steps: (a)\nIncorporates inductive bias and heuristics to partition Transformer search\nspace into K compact sub-spaces (K=3 for typical student sizes of base, small\nand tiny); (b) Trains one SuperLM for each sub-space using task-agnostic\nobjective (e.g., self-attention distillation) with weight-sharing of students;\n(c) Lightweight search for the optimal student without re-training. Fully\ntask-agnostic training and search allow students to be reused for fine-tuning\non any downstream task. Experiments on GLUE benchmark against state-of-the-art\nKD and NAS methods demonstrate AutoDistil to outperform leading compression\ntechniques with upto 2.7x reduction in computational cost and negligible loss\nin task performance.\n",
                "链接": "https://arxiv.org/abs/2201.12507"
            },
            {
                "文章ID": "36610",
                "标题": "Task-Agnostic Learning to Accomplish New Tasks",
                "作者": " Xianqi Zhang,  Xingtao Wang,  Xu Liu,  Wenrui Wang,  Xiaopeng Fan,  Debin Zhao",
                "发布日期": "2023-02-17",
                "摘要": "  Reinforcement Learning (RL) and Imitation Learning (IL) have made great\nprogress in robotic control in recent years. However, these methods show\nobvious deterioration for new tasks that need to be completed through new\ncombinations of actions. RL methods heavily rely on reward functions that\ncannot generalize well for new tasks, while IL methods are limited by expert\ndemonstrations which do not cover new tasks. In contrast, humans can easily\ncomplete these tasks with the fragmented knowledge learned from task-agnostic\nexperience. Inspired by this observation, this paper proposes a task-agnostic\nlearning method (TAL for short) that can learn fragmented knowledge from\ntask-agnostic data to accomplish new tasks. TAL consists of four stages. First,\nthe task-agnostic exploration is performed to collect data from interactions\nwith the environment. The collected data is organized via a knowledge graph.\nCompared with the previous sequential structure, the knowledge graph\nrepresentation is more compact and fits better for environment exploration.\nSecond, an action feature extractor is proposed and trained using the collected\nknowledge graph data for task-agnostic fragmented knowledge learning. Third, a\ncandidate action generator is designed, which applies the action feature\nextractor on a new task to generate multiple candidate action sets. Finally, an\naction proposal is designed to produce the probabilities for actions in a new\ntask according to the environmental information. The probabilities are then\nused to select actions to be executed from multiple candidate action sets to\nform the plan. Experiments on a virtual indoor scene show that the proposed\nmethod outperforms the state-of-the-art offline RL method: CQL by 35.28% and\nthe IL method: BC by 22.22%.\n",
                "链接": "https://arxiv.org/abs/2209.04100"
            },
            {
                "文章ID": "55221",
                "标题": "Prototype-guided Cross-task Knowledge Distillation for Large-scale\n  Models",
                "作者": " Deng Li,  Aming Wu,  Yahong Han,  Qi Tian",
                "发布日期": "2022-12-27",
                "摘要": "  Recently, large-scale pre-trained models have shown their advantages in many\ntasks. However, due to the huge computational complexity and storage\nrequirements, it is challenging to apply the large-scale model to real scenes.\nA common solution is knowledge distillation which regards the large-scale model\nas a teacher model and helps to train a small student model to obtain a\ncompetitive performance. Cross-task Knowledge distillation expands the\napplication scenarios of the large-scale pre-trained model. Existing knowledge\ndistillation works focus on directly mimicking the final prediction or the\nintermediate layers of the teacher model, which represent the global-level\ncharacteristics and are task-specific. To alleviate the constraint of different\nlabel spaces, capturing invariant intrinsic local object characteristics (such\nas the shape characteristics of the leg and tail of the cattle and horse) plays\na key role. Considering the complexity and variability of real scene tasks, we\npropose a Prototype-guided Cross-task Knowledge Distillation (ProC-KD) approach\nto transfer the intrinsic local-level object knowledge of a large-scale teacher\nnetwork to various task scenarios. First, to better transfer the generalized\nknowledge in the teacher model in cross-task scenarios, we propose a prototype\nlearning module to learn from the essential feature representation of objects\nin the teacher model. Secondly, for diverse downstream tasks, we propose a\ntask-adaptive feature augmentation module to enhance the features of the\nstudent model with the learned generalization prototype features and guide the\ntraining of the student model to improve its generalization ability. The\nexperimental results on various visual tasks demonstrate the effectiveness of\nour approach for large-scale model cross-task knowledge distillation scenes.\n",
                "链接": "https://arxiv.org/abs/2212.13180"
            },
            {
                "文章ID": "16746",
                "标题": "Heterogeneous Ensemble Knowledge Transfer for Training Large Models in\n  Federated Learning",
                "作者": " Yae Jee Cho,  Andre Manoel,  Gauri Joshi,  Robert Sim,  Dimitrios Dimitriadis",
                "发布日期": "2022-04-28",
                "摘要": "  Federated learning (FL) enables edge-devices to collaboratively learn a model\nwithout disclosing their private data to a central aggregating server. Most\nexisting FL algorithms require models of identical architecture to be deployed\nacross the clients and server, making it infeasible to train large models due\nto clients' limited system resources. In this work, we propose a novel ensemble\nknowledge transfer method named Fed-ET in which small models (different in\narchitecture) are trained on clients, and used to train a larger model at the\nserver. Unlike in conventional ensemble learning, in FL the ensemble can be\ntrained on clients' highly heterogeneous data. Cognizant of this property,\nFed-ET uses a weighted consensus distillation scheme with diversity\nregularization that efficiently extracts reliable consensus from the ensemble\nwhile improving generalization by exploiting the diversity within the ensemble.\nWe show the generalization bound for the ensemble of weighted models trained on\nheterogeneous datasets that supports the intuition of Fed-ET. Our experiments\non image and language tasks show that Fed-ET significantly outperforms other\nstate-of-the-art FL algorithms with fewer communicated parameters, and is also\nrobust against high data-heterogeneity.\n",
                "链接": "https://arxiv.org/abs/2204.12703"
            },
            {
                "文章ID": "96137",
                "标题": "Smart Knowledge Transfer using Google-like Search",
                "作者": " Srijoni Majumdar,  Partha Pratim Das",
                "发布日期": "2023-08-15",
                "摘要": "  To address the issue of rising software maintenance cost due to program\ncomprehension challenges, we propose SMARTKT (Smart Knowledge Transfer), a\nsearch framework, which extracts and integrates knowledge related to various\naspects of an application in form of a semantic graph. This graph supports\nsyntax and semantic queries and converts the process of program comprehension\ninto a {\\em google-like} search problem.\n",
                "链接": "https://arxiv.org/abs/2308.06653"
            },
            {
                "文章ID": "67341",
                "标题": "Conversational Tree Search: A New Hybrid Dialog Task",
                "作者": " Dirk Väth,  Lindsey Vanderlyn,  Ngoc Thang Vu",
                "发布日期": "2023-03-21",
                "摘要": "  Conversational interfaces provide a flexible and easy way for users to seek\ninformation that may otherwise be difficult or inconvenient to obtain. However,\nexisting interfaces generally fall into one of two categories: FAQs, where\nusers must have a concrete question in order to retrieve a general answer, or\ndialogs, where users must follow a predefined path but may receive a\npersonalized answer. In this paper, we introduce Conversational Tree Search\n(CTS) as a new task that bridges the gap between FAQ-style information\nretrieval and task-oriented dialog, allowing domain-experts to define dialog\ntrees which can then be converted to an efficient dialog policy that learns\nonly to ask the questions necessary to navigate a user to their goal. We\ncollect a dataset for the travel reimbursement domain and demonstrate a\nbaseline as well as a novel deep Reinforcement Learning architecture for this\ntask. Our results show that the new architecture combines the positive aspects\nof both the FAQ and dialog system used in the baseline and achieves higher goal\ncompletion while skipping unnecessary questions.\n",
                "链接": "https://arxiv.org/abs/2303.10227"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "111037",
                "标题": "Retrieval-based Knowledge Transfer: An Effective Approach for Extreme\n  Large Language Model Compression",
                "作者": " Jiduan Liu,  Jiahao Liu,  Qifan Wang,  Jingang Wang,  Xunliang Cai,  Dongyan Zhao,  Ran Lucien Wang,  Rui Yan",
                "发布日期": "2023-10-25",
                "摘要": "  Large-scale pre-trained language models (LLMs) have demonstrated exceptional\nperformance in various natural language processing (NLP) tasks. However, the\nmassive size of these models poses huge challenges for their deployment in\nreal-world applications. While numerous model compression techniques have been\nproposed, most of them are not well-suited for achieving extreme model\ncompression when there is a significant gap in model scale. In this paper, we\nintroduce a novel compression paradigm called Retrieval-based Knowledge\nTransfer (RetriKT), which effectively transfers the knowledge of LLMs to\nextremely small-scale models (e.g., 1%). In particular, our approach extracts\nknowledge from LLMs to construct a knowledge store, from which the small-scale\nmodel can retrieve relevant information and leverage it for effective\ninference. To improve the quality of the model, soft prompt tuning and Proximal\nPolicy Optimization (PPO) reinforcement learning techniques are employed.\nExtensive experiments are conducted on low-resource tasks from SuperGLUE and\nGLUE benchmarks. The results demonstrate that the proposed approach\nsignificantly enhances the performance of small-scale models by leveraging the\nknowledge from LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.15594"
            }
        ]
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "81656",
                "标题": "The impact and applications of ChatGPT: a systematic review of\n  literature reviews",
                "作者": " Irene S. Gabashvili",
                "发布日期": "2023-05-30",
                "摘要": "  The conversational artificial-intelligence (AI) technology ChatGPT has become\none of the most widely used natural language processing tools. With thousands\nof published papers demonstrating its applications across various industries\nand fields, ChatGPT has sparked significant interest in the research community.\nReviews of primary data have also begun to emerge. An overview of the available\nevidence from multiple reviews and studies could provide further insights,\nminimize redundancy, and identify areas where further research is needed.\nObjective: To evaluate the existing reviews and literature related to ChatGPT's\napplications and its potential impact on different fields by conducting a\nsystematic review of reviews and bibliometric analysis of primary literature.\nMethods: PubMed, EuropePMC, Dimensions AI, medRxiv, bioRxiv, arXiv, and Google\nScholar were searched for ChatGPT-related publications from 2022 to 4/30/2023.\nStudies including secondary data related to the application of ChatGPT were\nconsidered. Reporting and risk of bias assesment was performed using PRISMA\nguidelines. Results: A total of 305 unique records with potential relevance to\nthe review were identified from a pool of over 2,000 original articles. After\nmulti-step screening process, 11 reviews were selected, consisting of 9 reviews\nspecifically focused on ChatGPT and 2 reviews on broader AI topics that also\nincluded discussions on ChatGPT. We also conducted bibliometric analysis of\nprimary data. Conclusions: While AI has the potential to revolutionize various\nindustries, further interdisciplinary research, customized integrations, and\nethical innovation are necessary to address existing concerns and ensure its\nresponsible use. Protocol Registration: PROSPERO registration no.\nCRD42023417336, DOI 10.17605/OSF.IO/87U6Q.\n",
                "链接": "https://arxiv.org/abs/2305.18086"
            },
            {
                "文章ID": "110591",
                "标题": "\"Why Should I Review This Paper?\" Unifying Semantic, Topic, and Citation\n  Factors for Paper-Reviewer Matching",
                "作者": " Yu Zhang,  Yanzhen Shen,  Xiusi Chen,  Bowen Jin,  Jiawei Han",
                "发布日期": "2023-10-24",
                "摘要": "  As many academic conferences are overwhelmed by a rapidly increasing number\nof paper submissions, automatically finding appropriate reviewers for each\nsubmission becomes a more urgent need than ever. Various factors have been\nconsidered by previous attempts on this task to measure the expertise relevance\nbetween a paper and a reviewer, including whether the paper is semantically\nclose to, shares topics with, and cites previous papers of the reviewer.\nHowever, the majority of previous studies take only one of these factors into\naccount, leading to an incomprehensive evaluation of paper-reviewer relevance.\nTo bridge this gap, in this paper, we propose a unified model for\npaper-reviewer matching that jointly captures semantic, topic, and citation\nfactors. In the unified model, a contextualized language model backbone is\nshared by all factors to learn common knowledge, while instruction tuning is\nintroduced to characterize the uniqueness of each factor by producing\nfactor-aware paper embeddings. Experiments on four datasets (one of which is\nnewly contributed by us) across different fields, including machine learning,\ncomputer vision, information retrieval, and data mining, consistently validate\nthe effectiveness of our proposed UniPR model in comparison with\nstate-of-the-art paper-reviewer matching methods and scientific pre-trained\nlanguage models.\n",
                "链接": "https://arxiv.org/abs/2310.14483"
            },
            {
                "文章ID": "27917",
                "标题": "A Dataset on Malicious Paper Bidding in Peer Review",
                "作者": " Steven Jecmen,  Minji Yoon,  Vincent Conitzer,  Nihar B. Shah,  Fei Fang",
                "发布日期": "2023-03-14",
                "摘要": "  In conference peer review, reviewers are often asked to provide \"bids\" on\neach submitted paper that express their interest in reviewing that paper. A\npaper assignment algorithm then uses these bids (along with other data) to\ncompute a high-quality assignment of reviewers to papers. However, this process\nhas been exploited by malicious reviewers who strategically bid in order to\nunethically manipulate the paper assignment, crucially undermining the peer\nreview process. For example, these reviewers may aim to get assigned to a\nfriend's paper as part of a quid-pro-quo deal. A critical impediment towards\ncreating and evaluating methods to mitigate this issue is the lack of any\npublicly-available data on malicious paper bidding. In this work, we collect\nand publicly release a novel dataset to fill this gap, collected from a mock\nconference activity where participants were instructed to bid either honestly\nor maliciously. We further provide a descriptive analysis of the bidding\nbehavior, including our categorization of different strategies employed by\nparticipants. Finally, we evaluate the ability of each strategy to manipulate\nthe assignment, and also evaluate the performance of some simple algorithms\nmeant to detect malicious bidding. The performance of these detection\nalgorithms can be taken as a baseline for future research on detecting\nmalicious bidding.\n",
                "链接": "https://arxiv.org/abs/2207.02303"
            },
            {
                "文章ID": "20490",
                "标题": "CYRUS Soccer Simulation 2D Team Description Paper 2022",
                "作者": " Nader Zare,  Arad Firouzkouhi,  Omid Amini,  Mahtab Sarvmaili,  Aref Sayareh,  Saba Ramezani Rad,  Stan Matwin,  Amilcar Soares",
                "发布日期": "2022-05-24",
                "摘要": "  Soccer Simulation 2D League is one of the major leagues of RoboCup\ncompetitions. In a Soccer Simulation 2D (SS2D) game, two teams of 11 players\nand one coach compete against each other. The players are only allowed to\ncommunicate with the server that is called Soccer Simulation Server. This paper\nintroduces the previous and current research of the CYRUS soccer simulation\nteam, the champion of RoboCup 2021. We will present our idea about improving\nUnmarking Decisioning and Positioning by using Pass Prediction Deep Neural\nNetwork. Based on our experimental results, this idea proven to be effective on\nincreasing the winning rate of Cyrus against opponents.\n",
                "链接": "https://arxiv.org/abs/2205.10953"
            },
            {
                "文章ID": "40544",
                "标题": "Ten Years after ImageNet: A 360{\\deg} Perspective on AI",
                "作者": " Sanjay Chawla,  Preslav Nakov,  Ahmed Ali,  Wendy Hall,  Issa Khalil,  Xiaosong Ma,  Husrev Taha Sencar,  Ingmar Weber,  Michael Wooldridge,  Ting Yu",
                "发布日期": "2022-10-06",
                "摘要": "  It is ten years since neural networks made their spectacular comeback.\nPrompted by this anniversary, we take a holistic perspective on Artificial\nIntelligence (AI). Supervised Learning for cognitive tasks is effectively\nsolved - provided we have enough high-quality labeled data. However, deep\nneural network models are not easily interpretable, and thus the debate between\nblackbox and whitebox modeling has come to the fore. The rise of attention\nnetworks, self-supervised learning, generative modeling, and graph neural\nnetworks has widened the application space of AI. Deep Learning has also\npropelled the return of reinforcement learning as a core building block of\nautonomous decision making systems. The possible harms made possible by new AI\ntechnologies have raised socio-technical issues such as transparency, fairness,\nand accountability. The dominance of AI by Big-Tech who control talent,\ncomputing resources, and most importantly, data may lead to an extreme AI\ndivide. Failure to meet high expectations in high profile, and much heralded\nflagship projects like self-driving vehicles could trigger another AI winter.\n",
                "链接": "https://arxiv.org/abs/2210.01797"
            },
            {
                "文章ID": "103497",
                "标题": "Empowering Precision Medicine: AI-Driven Schizophrenia Diagnosis via EEG\n  Signals: A Comprehensive Review from 2002-2023",
                "作者": " Mahboobeh Jafari,  Delaram Sadeghi,  Afshin Shoeibi,  Hamid Alinejad-Rokny,  Amin Beheshti,  David López García,  Zhaolin Chen,  U. Rajendra Acharya,  Juan M. Gorriz",
                "发布日期": "2023-09-22",
                "摘要": "  Schizophrenia (SZ) is a prevalent mental disorder characterized by cognitive,\nemotional, and behavioral changes. Symptoms of SZ include hallucinations,\nillusions, delusions, lack of motivation, and difficulties in concentration.\nDiagnosing SZ involves employing various tools, including clinical interviews,\nphysical examinations, psychological evaluations, the Diagnostic and\nStatistical Manual of Mental Disorders (DSM), and neuroimaging techniques.\nElectroencephalography (EEG) recording is a significant functional neuroimaging\nmodality that provides valuable insights into brain function during SZ.\nHowever, EEG signal analysis poses challenges for neurologists and scientists\ndue to the presence of artifacts, long-term recordings, and the utilization of\nmultiple channels. To address these challenges, researchers have introduced\nartificial intelligence (AI) techniques, encompassing conventional machine\nlearning (ML) and deep learning (DL) methods, to aid in SZ diagnosis. This\nstudy reviews papers focused on SZ diagnosis utilizing EEG signals and AI\nmethods. The introduction section provides a comprehensive explanation of SZ\ndiagnosis methods and intervention techniques. Subsequently, review papers in\nthis field are discussed, followed by an introduction to the AI methods\nemployed for SZ diagnosis and a summary of relevant papers presented in tabular\nform. Additionally, this study reports on the most significant challenges\nencountered in SZ diagnosis, as identified through a review of papers in this\nfield. Future directions to overcome these challenges are also addressed. The\ndiscussion section examines the specific details of each paper, culminating in\nthe presentation of conclusions and findings.\n",
                "链接": "https://arxiv.org/abs/2309.12202"
            },
            {
                "文章ID": "17497",
                "标题": "What Factors Should Paper-Reviewer Assignments Rely On? Community\n  Perspectives on Issues and Ideals in Conference Peer-Review",
                "作者": " Terne Sasha Thorn Jakobsen,  Anna Rogers",
                "发布日期": "2022-05-04",
                "摘要": "  Both scientific progress and individual researcher careers depend on the\nquality of peer review, which in turn depends on paper-reviewer matching.\nSurprisingly, this problem has been mostly approached as an automated\nrecommendation problem rather than as a matter where different stakeholders\n(area chairs, reviewers, authors) have accumulated experience worth taking into\naccount. We present the results of the first survey of the NLP community,\nidentifying common issues and perspectives on what factors should be considered\nby paper-reviewer matching systems. This study contributes actionable\nrecommendations for improving future NLP conferences, and desiderata for\ninterpretable peer review assignments.\n",
                "链接": "https://arxiv.org/abs/2205.01005"
            },
            {
                "文章ID": "108537",
                "标题": "Advancing Perception in Artificial Intelligence through Principles of\n  Cognitive Science",
                "作者": " Palaash Agrawal,  Cheston Tan,  Heena Rathore",
                "发布日期": "2023-10-16",
                "摘要": "  Although artificial intelligence (AI) has achieved many feats at a rapid\npace, there still exist open problems and fundamental shortcomings related to\nperformance and resource efficiency. Since AI researchers benchmark a\nsignificant proportion of performance standards through human intelligence,\ncognitive sciences-inspired AI is a promising domain of research. Studying\ncognitive science can provide a fresh perspective to building fundamental\nblocks in AI research, which can lead to improved performance and efficiency.\nIn this review paper, we focus on the cognitive functions of perception, which\nis the process of taking signals from one's surroundings as input, and\nprocessing them to understand the environment. Particularly, we study and\ncompare its various processes through the lens of both cognitive sciences and\nAI. Through this study, we review all current major theories from various\nsub-disciplines of cognitive science (specifically neuroscience, psychology and\nlinguistics), and draw parallels with theories and techniques from current\npractices in AI. We, hence, present a detailed collection of methods in AI for\nresearchers to build AI systems inspired by cognitive science. Further, through\nthe process of reviewing the state of cognitive-inspired AI, we point out many\ngaps in the current state of AI (with respect to the performance of the human\nbrain), and hence present potential directions for researchers to develop\nbetter perception systems in AI.\n",
                "链接": "https://arxiv.org/abs/2310.08803"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "108320",
                "标题": "Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse\n  Autoencoders",
                "作者": " Luke Marks,  Amir Abdullah,  Luna Mendez,  Rauno Arike,  Philip Torr,  Fazl Barez",
                "发布日期": "2023-11-29",
                "摘要": "  Large language models (LLMs) aligned to human preferences via reinforcement\nlearning from human feedback (RLHF) underpin many commercial applications of\nLLM technology. Despite this, the impacts of RLHF on LLM internals remain\nopaque. We propose a novel method for interpreting implicit reward models\n(IRMs) in LLMs learned through RLHF. Our approach trains pairs of autoencoders\non activations from a base LLM and its RLHF-tuned variant. Through a comparison\nof autoencoder hidden spaces, we identify features that reflect the accuracy of\nthe learned IRM. To illustrate our method, we fine-tune an LLM via RLHF to\nlearn a token-utility mapping and maximize the aggregate utility of generated\ntext. This is the first application of sparse autoencoders to interpreting\nIRMs. Our method provides an abstract approximation of reward integrity and\nholds promise for measuring alignment between specified objectives and learned\nmodel behaviors.\n",
                "链接": "https://arxiv.org/abs/2310.08164"
            },
            {
                "文章ID": "114829",
                "标题": "Efficiently Adapting Pretrained Language Models To New Languages",
                "作者": " Zoltan Csaki,  Pian Pawakapan,  Urmish Thakker,  Qiantong Xu",
                "发布日期": "2023-12-18",
                "摘要": "  Recent large language models (LLM) exhibit sub-optimal performance on\nlow-resource languages, as the training data of these models is usually\ndominated by English and other high-resource languages. Furthermore, it is\nchallenging to train models for low-resource languages, especially from\nscratch, due to a lack of high quality training data. Adapting pretrained LLMs\nreduces the need for data in the new language while also providing cross\nlingual transfer capabilities. However, naively adapting to new languages leads\nto catastrophic forgetting and poor tokenizer efficiency. In this work, we\nstudy how to efficiently adapt any existing pretrained LLM to a new language\nwithout running into these issues. In particular, we improve the encoding\nefficiency of the tokenizer by adding new tokens from the target language and\nstudy the data mixing recipe to mitigate forgetting. Our experiments on\nadapting an English LLM to Hungarian and Thai show that our recipe can reach\nbetter performance than open source models on the target language, with minimal\nregressions on English.\n",
                "链接": "https://arxiv.org/abs/2311.05741"
            },
            {
                "文章ID": "90293",
                "标题": "Secrets of RLHF in Large Language Models Part I: PPO",
                "作者": " Rui Zheng,  Shihan Dou,  Songyang Gao,  Yuan Hua,  Wei Shen,  Binghai Wang,  Yan Liu,  Senjie Jin,  Qin Liu,  Yuhao Zhou,  Limao Xiong,  Lu Chen,  Zhiheng Xi,  Nuo Xu,  Wenbin Lai,  Minghao Zhu,  Cheng Chang,  Zhangyue Yin,  Rongxiang Weng,  Wensen Cheng,  Haoran Huang,  Tianxiang Sun,  Hang Yan,  Tao Gui,  Qi Zhang,  Xipeng Qiu,  Xuanjing Huang",
                "发布日期": "2023-07-19",
                "摘要": "  Large language models (LLMs) have formulated a blueprint for the advancement\nof artificial general intelligence. Its primary objective is to function as a\nhuman-centric (helpful, honest, and harmless) assistant. Alignment with humans\nassumes paramount significance, and reinforcement learning with human feedback\n(RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.\nCurrent technical routes usually include \\textbf{reward models} to measure\nhuman preferences, \\textbf{Proximal Policy Optimization} (PPO) to optimize\npolicy model outputs, and \\textbf{process supervision} to improve step-by-step\nreasoning capabilities. However, due to the challenges of reward design,\nenvironment interaction, and agent training, coupled with huge trial and error\ncost of large language models, there is a significant barrier for AI\nresearchers to motivate the development of technical alignment and safe landing\nof LLMs. The stable training of RLHF has still been a puzzle. In the first\nreport, we dissect the framework of RLHF, re-evaluate the inner workings of\nPPO, and explore how the parts comprising PPO algorithms impact policy agent\ntraining. We identify policy constraints being the key factor for the effective\nimplementation of the PPO algorithm. Therefore, we explore the PPO-max, an\nadvanced version of PPO algorithm, to efficiently improve the training\nstability of the policy model. Based on our main results, we perform a\ncomprehensive analysis of RLHF abilities compared with SFT models and ChatGPT.\nThe absence of open-source implementations has posed significant challenges to\nthe investigation of LLMs alignment. Therefore, we are eager to release\ntechnical reports, reward models and PPO codes, aiming to make modest\ncontributions to the advancement of LLMs.\n",
                "链接": "https://arxiv.org/abs/2307.04964"
            },
            {
                "文章ID": "115552",
                "标题": "How good are Large Language Models on African Languages?",
                "作者": " Jessica Ojo,  Kelechi Ogueji,  Pontus Stenetorp,  David I. Adelani",
                "发布日期": "2023-11-15",
                "摘要": "  Recent advancements in natural language processing have led to the\nproliferation of large language models (LLMs). These models have been shown to\nyield good performance, using in-context learning, even on unseen tasks and\nlanguages. Additionally, they have been widely adopted as\nlanguage-model-as-a-service commercial APIs like GPT-4 API. However, their\nperformance on African languages is largely unknown. We present an analysis of\nthree popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks\n(news topic classification, sentiment classification, machine translation,\nquestion answering, and named entity recognition) across 30 African languages,\nspanning different language families and geographical regions. Our results\nsuggest that all LLMs produce below-par performance on African languages, and\nthere is a large gap in performance compared to high-resource languages like\nEnglish most tasks. We find that GPT-4 has an average or impressive performance\non classification tasks but very poor results on generative tasks like machine\ntranslation. Surprisingly, we find that mT0 had the best overall on\ncross-lingual QA, better than the state-of-the-art supervised model (i.e.\nfine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the\nworst performance due to its limited multilingual capabilities and\nEnglish-centric pre-training corpus. In general, our findings present a\ncall-to-action to ensure African languages are well represented in large\nlanguage models, given their growing popularity.\n",
                "链接": "https://arxiv.org/abs/2311.07978"
            },
            {
                "文章ID": "36594",
                "标题": "Multilingual Transformer Language Model for Speech Recognition in\n  Low-resource Languages",
                "作者": " Li Miao,  Jian Wu,  Piyush Behre,  Shuangyu Chang,  Sarangarajan Parthasarathy",
                "发布日期": "2022-09-12",
                "摘要": "  It is challenging to train and deploy Transformer LMs for hybrid speech\nrecognition 2nd pass re-ranking in low-resource languages due to (1) data\nscarcity in low-resource languages, (2) expensive computing costs for training\nand refreshing 100+ monolingual models, and (3) hosting inefficiency\nconsidering sparse traffic. In this study, we present a new way to group\nmultiple low-resource locales together and optimize the performance of\nMultilingual Transformer LMs in ASR. Our Locale-group Multilingual Transformer\nLMs outperform traditional multilingual LMs along with reducing maintenance\ncosts and operating expenses. Further, for low-resource but high-traffic\nlocales where deploying monolingual models is feasible, we show that\nfine-tuning our locale-group multilingual LMs produces better monolingual LM\ncandidates than baseline monolingual LMs.\n",
                "链接": "https://arxiv.org/abs/2209.04041"
            },
            {
                "文章ID": "79143",
                "标题": "PrOnto: Language Model Evaluations for 859 Languages",
                "作者": " Luke Gessler",
                "发布日期": "2023-05-23",
                "摘要": "  Evaluation datasets are critical resources for measuring the quality of\npretrained language models. However, due to the high cost of dataset\nannotation, these resources are scarce for most languages other than English,\nmaking it difficult to assess the quality of language models. In this work, we\npresent a new method for evaluation dataset construction which enables any\nlanguage with a New Testament translation to receive a suite of evaluation\ndatasets suitable for pretrained language model evaluation. The method\ncritically involves aligning verses with those in the New Testament portion of\nEnglish OntoNotes, and then projecting annotations from English to the target\nlanguage, with no manual annotation required. We apply this method to 1051 New\nTestament translations in 859 and make them publicly available. Additionally,\nwe conduct experiments which demonstrate the efficacy of our method for\ncreating evaluation tasks which can assess language model quality.\n",
                "链接": "https://arxiv.org/abs/2305.12612"
            },
            {
                "文章ID": "43618",
                "标题": "Language Model Decomposition: Quantifying the Dependency and Correlation\n  of Language Models",
                "作者": " Hao Zhang",
                "发布日期": "2022-10-24",
                "摘要": "  Pre-trained language models (LMs), such as BERT (Devlin et al., 2018) and its\nvariants, have led to significant improvements on various NLP tasks in past\nyears. However, a theoretical framework for studying their relationships is\nstill missing. In this paper, we fill this gap by investigating the linear\ndependency between pre-trained LMs. The linear dependency of LMs is defined\nanalogously to the linear dependency of vectors. We propose Language Model\nDecomposition (LMD) to represent a LM using a linear combination of other LMs\nas basis, and derive the closed-form solution. A goodness-of-fit metric for LMD\nsimilar to the coefficient of determination is defined and used to measure the\nlinear dependency of a set of LMs. In experiments, we find that BERT and eleven\n(11) BERT-like LMs are 91% linearly dependent. This observation suggests that\ncurrent state-of-the-art (SOTA) LMs are highly \"correlated\". To further advance\nSOTA we need more diverse and novel LMs that are less dependent on existing\nLMs.\n",
                "链接": "https://arxiv.org/abs/2210.10289"
            },
            {
                "文章ID": "82397",
                "标题": "Red Teaming Language Model Detectors with Language Models",
                "作者": " Zhouxing Shi,  Yihan Wang,  Fan Yin,  Xiangning Chen,  Kai-Wei Chang,  Cho-Jui Hsieh",
                "发布日期": "2023-10-20",
                "摘要": "  The prevalence and strong capability of large language models (LLMs) present\nsignificant safety and ethical risks if exploited by malicious users. To\nprevent the potentially deceptive usage of LLMs, recent works have proposed\nalgorithms to detect LLM-generated text and protect LLMs. In this paper, we\ninvestigate the robustness and reliability of these LLM detectors under\nadversarial attacks. We study two types of attack strategies: 1) replacing\ncertain words in an LLM's output with their synonyms given the context; 2)\nautomatically searching for an instructional prompt to alter the writing style\nof the generation. In both strategies, we leverage an auxiliary LLM to generate\nthe word replacements or the instructional prompt. Different from previous\nworks, we consider a challenging setting where the auxiliary LLM can also be\nprotected by a detector. Experiments reveal that our attacks effectively\ncompromise the performance of all detectors in the study with plausible\ngenerations, underscoring the urgent need to improve the robustness of\nLLM-generated text detection systems.\n",
                "链接": "https://arxiv.org/abs/2305.19713"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "21046",
                "标题": "End-to-End Multimodal Fact-Checking and Explanation Generation: A\n  Challenging Dataset and Models",
                "作者": "Virginia Tech  Barry Menglong Yao, Virginia Tech  Aditya Shah, Lehigh University  Lichao Sun, Virginia Tech  Jin-Hee Cho, Virginia Tech  Lifu Huang",
                "发布日期": "2023-07-10",
                "摘要": "  We propose end-to-end multimodal fact-checking and explanation generation,\nwhere the input is a claim and a large collection of web sources, including\narticles, images, videos, and tweets, and the goal is to assess the\ntruthfulness of the claim by retrieving relevant evidence and predicting a\ntruthfulness label (e.g., support, refute or not enough information), and to\ngenerate a statement to summarize and explain the reasoning and ruling process.\nTo support this research, we construct Mocheg, a large-scale dataset consisting\nof 15,601 claims where each claim is annotated with a truthfulness label and a\nruling statement, and 33,880 textual paragraphs and 12,112 images in total as\nevidence. To establish baseline performances on Mocheg, we experiment with\nseveral state-of-the-art neural architectures on the three pipelined subtasks:\nmultimodal evidence retrieval, claim verification, and explanation generation,\nand demonstrate that the performance of the state-of-the-art end-to-end\nmultimodal fact-checking does not provide satisfactory outcomes. To the best of\nour knowledge, we are the first to build the benchmark dataset and solutions\nfor end-to-end multimodal fact-checking and explanation generation. The\ndataset, source code and model checkpoints are available at\nhttps://github.com/VT-NLP/Mocheg.\n",
                "链接": "https://arxiv.org/abs/2205.12487"
            },
            {
                "文章ID": "104271",
                "标题": "LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language\n  Models",
                "作者": " Ahmad Faiz,  Sotaro Kaneda,  Ruhan Wang,  Rita Osi,  Parteek Sharma,  Fan Chen,  Lei Jiang",
                "发布日期": "2023-09-27",
                "摘要": "  The carbon footprint associated with large language models (LLMs) is a\nsignificant concern, encompassing emissions from their training, inference,\nexperimentation, and storage processes, including operational and embodied\ncarbon emissions. An essential aspect is accurately estimating the carbon\nimpact of emerging LLMs even before their training, which heavily relies on GPU\nusage. Existing studies have reported the carbon footprint of LLM training, but\nonly one tool, mlco2, can predict the carbon footprint of new neural networks\nprior to physical training. However, mlco2 has several serious limitations. It\ncannot extend its estimation to dense or mixture-of-experts (MoE) LLMs,\ndisregards critical architectural parameters, focuses solely on GPUs, and\ncannot model embodied carbon footprints. Addressing these gaps, we introduce\n\\textit{LLMCarbon}, an end-to-end carbon footprint projection model designed\nfor both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly\nenhances the accuracy of carbon footprint estimations for various LLMs.\n",
                "链接": "https://arxiv.org/abs/2309.14393"
            },
            {
                "文章ID": "22470",
                "标题": "On the Choice of Data for Efficient Training and Validation of\n  End-to-End Driving Models",
                "作者": " Marvin Klingner,  Konstantin Müller,  Mona Mirzaie,  Jasmin Breitenstein,  Jan-Aike Termöhlen,  Tim Fingscheidt",
                "发布日期": "2022-06-02",
                "摘要": "  The emergence of data-driven machine learning (ML) has facilitated\nsignificant progress in many complicated tasks such as highly-automated\ndriving. While much effort is put into improving the ML models and learning\nalgorithms in such applications, little focus is put into how the training data\nand/or validation setting should be designed. In this paper we investigate the\ninfluence of several data design choices regarding training and validation of\ndeep driving models trainable in an end-to-end fashion. Specifically, (i) we\ninvestigate how the amount of training data influences the final driving\nperformance, and which performance limitations are induced through currently\nused mechanisms to generate training data. (ii) Further, we show by correlation\nanalysis, which validation design enables the driving performance measured\nduring validation to generalize well to unknown test environments. (iii)\nFinally, we investigate the effect of random seeding and non-determinism,\ngiving insights which reported improvements can be deemed significant. Our\nevaluations using the popular CARLA simulator provide recommendations regarding\ndata generation and driving route selection for an efficient future development\nof end-to-end driving models.\n",
                "链接": "https://arxiv.org/abs/2206.00608"
            },
            {
                "文章ID": "100055",
                "标题": "End-to-End Learning on Multimodal Knowledge Graphs",
                "作者": " W. X. Wilcke,  P. Bloem,  V. de Boer,  R. H. van t Veer",
                "发布日期": "2023-09-06",
                "摘要": "  Knowledge graphs enable data scientists to learn end-to-end on heterogeneous\nknowledge. However, most end-to-end models solely learn from the relational\ninformation encoded in graphs' structure: raw values, encoded as literal nodes,\nare either omitted completely or treated as regular nodes without consideration\nfor their values. In either case we lose potentially relevant information which\ncould have otherwise been exploited by our learning methods. We propose a\nmultimodal message passing network which not only learns end-to-end from the\nstructure of graphs, but also from their possibly divers set of multimodal node\nfeatures. Our model uses dedicated (neural) encoders to naturally learn\nembeddings for node features belonging to five different types of modalities,\nincluding numbers, texts, dates, images and geometries, which are projected\ninto a joint representation space together with their relational information.\nWe implement and demonstrate our model on node classification and link\nprediction for artificial and real-worlds datasets, and evaluate the effect\nthat each modality has on the overall performance in an inverse ablation study.\nOur results indicate that end-to-end multimodal learning from any arbitrary\nknowledge graph is indeed possible, and that including multimodal information\ncan significantly affect performance, but that much depends on the\ncharacteristics of the data.\n",
                "链接": "https://arxiv.org/abs/2309.01169"
            },
            {
                "文章ID": "12682",
                "标题": "End-to-end Document Recognition and Understanding with Dessurt",
                "作者": " Brian Davis,  Bryan Morse,  Bryan Price,  Chris Tensmeyer,  Curtis Wigington,  Vlad Morariu",
                "发布日期": "2022-06-17",
                "摘要": "  We introduce Dessurt, a relatively simple document understanding transformer\ncapable of being fine-tuned on a greater variety of document tasks than prior\nmethods. It receives a document image and task string as input and generates\narbitrary text autoregressively as output. Because Dessurt is an end-to-end\narchitecture that performs text recognition in addition to the document\nunderstanding, it does not require an external recognition model as prior\nmethods do. Dessurt is a more flexible model than prior methods and is able to\nhandle a variety of document domains and tasks. We show that this model is\neffective at 9 different dataset-task combinations.\n",
                "链接": "https://arxiv.org/abs/2203.16618"
            },
            {
                "文章ID": "24922",
                "标题": "DeepFormableTag: End-to-end Generation and Recognition of Deformable\n  Fiducial Markers",
                "作者": " Mustafa B. Yaldiz,  Andreas Meuleman,  Hyeonjoong Jang,  Hyunho Ha,  Min H. Kim",
                "发布日期": "2022-06-17",
                "摘要": "  Fiducial markers have been broadly used to identify objects or embed messages\nthat can be detected by a camera. Primarily, existing detection methods assume\nthat markers are printed on ideally planar surfaces. Markers often fail to be\nrecognized due to various imaging artifacts of optical/perspective distortion\nand motion blur. To overcome these limitations, we propose a novel deformable\nfiducial marker system that consists of three main parts: First, a fiducial\nmarker generator creates a set of free-form color patterns to encode\nsignificantly large-scale information in unique visual codes. Second, a\ndifferentiable image simulator creates a training dataset of photorealistic\nscene images with the deformed markers, being rendered during optimization in a\ndifferentiable manner. The rendered images include realistic shading with\nspecular reflection, optical distortion, defocus and motion blur, color\nalteration, imaging noise, and shape deformation of markers. Lastly, a trained\nmarker detector seeks the regions of interest and recognizes multiple marker\npatterns simultaneously via inverse deformation transformation. The deformable\nmarker creator and detector networks are jointly optimized via the\ndifferentiable photorealistic renderer in an end-to-end manner, allowing us to\nrobustly recognize a wide range of deformable markers with high accuracy. Our\ndeformable marker system is capable of decoding 36-bit messages successfully at\n~29 fps with severe shape deformation. Results validate that our system\nsignificantly outperforms the traditional and data-driven marker methods. Our\nlearning-based marker system opens up new interesting applications of fiducial\nmarkers, including cost-effective motion capture of the human body, active 3D\nscanning using our fiducial markers' array as structured light patterns, and\nrobust augmented reality rendering of virtual objects on dynamic surfaces.\n",
                "链接": "https://arxiv.org/abs/2206.08026"
            },
            {
                "文章ID": "12174",
                "标题": "Towards End-to-End Unified Scene Text Detection and Layout Analysis",
                "作者": " Shangbang Long,  Siyang Qin,  Dmitry Panteleev,  Alessandro Bissacco,  Yasuhisa Fujii,  Michalis Raptis",
                "发布日期": "2022-06-06",
                "摘要": "  Scene text detection and document layout analysis have long been treated as\ntwo separate tasks in different image domains. In this paper, we bring them\ntogether and introduce the task of unified scene text detection and layout\nanalysis. The first hierarchical scene text dataset is introduced to enable\nthis novel research task. We also propose a novel method that is able to\nsimultaneously detect scene text and form text clusters in a unified way.\nComprehensive experiments show that our unified model achieves better\nperformance than multiple well-designed baseline methods. Additionally, this\nmodel achieves state-of-the-art results on multiple scene text detection\ndatasets without the need of complex post-processing. Dataset and code:\nhttps://github.com/google-research-datasets/hiertext and\nhttps://github.com/tensorflow/models/tree/master/official/projects/unified_detector.\n",
                "链接": "https://arxiv.org/abs/2203.15143"
            },
            {
                "文章ID": "122514",
                "标题": "Planning and Rendering: Towards End-to-End Product Poster Generation",
                "作者": " Zhaochen Li,  Fengheng Li,  Wei Feng,  Honghe Zhu,  An Liu,  Yaoyu Li,  Zheng Zhang,  Jingjing Lv,  Xin Zhu,  Junjie Shen,  Zhangang Lin,  Jingping Shao,  Zhenglu Yang",
                "发布日期": "2023-12-15",
                "摘要": "  End-to-end product poster generation significantly optimizes design\nefficiency and reduces production costs. Prevailing methods predominantly rely\non image-inpainting methods to generate clean background images for given\nproducts. Subsequently, poster layout generation methods are employed to\nproduce corresponding layout results. However, the background images may not be\nsuitable for accommodating textual content due to their complexity, and the\nfixed location of products limits the diversity of layout results. To alleviate\nthese issues, we propose a novel product poster generation framework named\nP\\&R. The P\\&R draws inspiration from the workflow of designers in creating\nposters, which consists of two stages: Planning and Rendering. At the planning\nstage, we propose a PlanNet to generate the layout of the product and other\nvisual components considering both the appearance features of the product and\nsemantic features of the text, which improves the diversity and rationality of\nthe layouts. At the rendering stage, we propose a RenderNet to generate the\nbackground for the product while considering the generated layout, where a\nspatial fusion module is introduced to fuse the layout of different visual\ncomponents. To foster the advancement of this field, we propose the first\nend-to-end product poster generation dataset PPG30k, comprising 30k exquisite\nproduct poster images along with comprehensive image and text annotations. Our\nmethod outperforms the state-of-the-art product poster generation methods on\nPPG30k. The PPG30k will be released soon.\n",
                "链接": "https://arxiv.org/abs/2312.08822"
            },
            {
                "文章ID": "92569",
                "标题": "Modality Confidence Aware Training for Robust End-to-End Spoken Language\n  Understanding",
                "作者": " Suyoun Kim,  Akshat Shrivastava,  Duc Le,  Ju Lin,  Ozlem Kalinli,  Michael L. Seltzer",
                "发布日期": "2023-07-25",
                "摘要": "  End-to-end (E2E) spoken language understanding (SLU) systems that generate a\nsemantic parse from speech have become more promising recently. This approach\nuses a single model that utilizes audio and text representations from\npre-trained speech recognition models (ASR), and outperforms traditional\npipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems\nstill show weakness when text representation quality is low due to ASR\ntranscription errors. To overcome this issue, we propose a novel E2E SLU system\nthat enhances robustness to ASR errors by fusing audio and text representations\nbased on the estimated modality confidence of ASR hypotheses. We introduce two\nnovel techniques: 1) an effective method to encode the quality of ASR\nhypotheses and 2) an effective approach to integrate them into E2E SLU models.\nWe show accuracy improvements on STOP dataset and share the analysis to\ndemonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2307.12134"
            },
            {
                "文章ID": "46362",
                "标题": "Unified End-to-End Speech Recognition and Endpointing for Fast and\n  Efficient Speech Systems",
                "作者": " Shaan Bijwadia,  Shuo-yiin Chang,  Bo Li,  Tara Sainath,  Chao Zhang,  Yanzhang He",
                "发布日期": "2023-02-16",
                "摘要": "  Automatic speech recognition (ASR) systems typically rely on an external\nendpointer (EP) model to identify speech boundaries. In this work, we propose a\nmethod to jointly train the ASR and EP tasks in a single end-to-end (E2E)\nmultitask model, improving EP quality by optionally leveraging information from\nthe ASR audio encoder. We introduce a \"switch\" connection, which trains the EP\nto consume either the audio frames directly or low-level latent representations\nfrom the ASR model. This results in a single E2E model that can be used during\ninference to perform frame filtering at low cost, and also make high quality\nend-of-query (EOQ) predictions based on ongoing ASR computation. We present\nresults on a voice search test set showing that, compared to separate\nsingle-task models, this approach reduces median endpoint latency by 120 ms\n(30.8% reduction), and 90th percentile latency by 170 ms (23.0% reduction),\nwithout regressing word error rate. For continuous recognition, WER improves by\n10.6% (relative).\n",
                "链接": "https://arxiv.org/abs/2211.00786"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "6241",
                "标题": "Reward Modeling for Mitigating Toxicity in Transformer-based Language\n  Models",
                "作者": " Farshid Faal,  Ketra Schmitt,  Jia Yuan Yu",
                "发布日期": "2022-07-28",
                "摘要": "  Transformer-based language models are able to generate fluent text and be\nefficiently adapted across various natural language generation tasks. However,\nlanguage models that are pretrained on large unlabeled web text corpora have\nbeen shown to suffer from degenerating toxic content and social bias behaviors,\nconsequently hindering their safe deployment. Various detoxification methods\nwere proposed to mitigate the language model's toxicity; however, these methods\nstruggled to detoxify language models when conditioned on prompts that contain\nspecific social identities related to gender, race, or religion. In this study,\nwe propose Reinforce-Detoxify; A reinforcement learning-based method for\nmitigating toxicity in language models. We address the challenge of safety in\nlanguage models and propose a new reward model that is able to detect toxic\ncontent and mitigate unintended bias towards social identities in toxicity\nprediction. The experiments demonstrate that the Reinforce-Detoxify method for\nlanguage model detoxification outperforms existing detoxification approaches in\nautomatic evaluation metrics, indicating the ability of our approach in\nlanguage model detoxification and less prone to unintended bias toward social\nidentities in generated content.\n",
                "链接": "https://arxiv.org/abs/2202.09662"
            },
            {
                "文章ID": "81738",
                "标题": "Direct Preference Optimization: Your Language Model is Secretly a Reward\n  Model",
                "作者": " Rafael Rafailov,  Archit Sharma,  Eric Mitchell,  Stefano Ermon,  Christopher D. Manning,  Chelsea Finn",
                "发布日期": "2023-12-14",
                "摘要": "  While large-scale unsupervised language models (LMs) learn broad world\nknowledge and some reasoning skills, achieving precise control of their\nbehavior is difficult due to the completely unsupervised nature of their\ntraining. Existing methods for gaining such steerability collect human labels\nof the relative quality of model generations and fine-tune the unsupervised LM\nto align with these preferences, often with reinforcement learning from human\nfeedback (RLHF). However, RLHF is a complex and often unstable procedure, first\nfitting a reward model that reflects the human preferences, and then\nfine-tuning the large unsupervised LM using reinforcement learning to maximize\nthis estimated reward without drifting too far from the original model. In this\npaper we introduce a new parameterization of the reward model in RLHF that\nenables extraction of the corresponding optimal policy in closed form, allowing\nus to solve the standard RLHF problem with only a simple classification loss.\nThe resulting algorithm, which we call Direct Preference Optimization (DPO), is\nstable, performant, and computationally lightweight, eliminating the need for\nsampling from the LM during fine-tuning or performing significant\nhyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align\nwith human preferences as well as or better than existing methods. Notably,\nfine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of\ngenerations, and matches or improves response quality in summarization and\nsingle-turn dialogue while being substantially simpler to implement and train.\n",
                "链接": "https://arxiv.org/abs/2305.18290"
            },
            {
                "文章ID": "110451",
                "标题": "Learning Reward for Physical Skills using Large Language Model",
                "作者": " Yuwei Zeng,  Yiqing Xu",
                "发布日期": "2023-10-24",
                "摘要": "  Learning reward functions for physical skills are challenging due to the vast\nspectrum of skills, the high-dimensionality of state and action space, and\nnuanced sensory feedback. The complexity of these tasks makes acquiring expert\ndemonstration data both costly and time-consuming. Large Language Models (LLMs)\ncontain valuable task-related knowledge that can aid in learning these reward\nfunctions. However, the direct application of LLMs for proposing reward\nfunctions has its limitations such as numerical instability and inability to\nincorporate the environment feedback. We aim to extract task knowledge from\nLLMs using environment feedback to create efficient reward functions for\nphysical skills. Our approach consists of two components. We first use the LLM\nto propose features and parameterization of the reward function. Next, we\nupdate the parameters of this proposed reward function through an iterative\nself-alignment process. In particular, this process minimizes the ranking\ninconsistency between the LLM and our learned reward functions based on the new\nobservations. We validated our method by testing it on three simulated physical\nskill learning tasks, demonstrating effective support for our design choices.\n",
                "链接": "https://arxiv.org/abs/2310.14092"
            },
            {
                "文章ID": "40287",
                "标题": "Reward Learning with Trees: Methods and Evaluation",
                "作者": " Tom Bewley,  Jonathan Lawry,  Arthur Richards,  Rachel Craddock,  Ian Henderson",
                "发布日期": "2022-10-04",
                "摘要": "  Recent efforts to learn reward functions from human feedback have tended to\nuse deep neural networks, whose lack of transparency hampers our ability to\nexplain agent behaviour or verify alignment. We explore the merits of learning\nintrinsically interpretable tree models instead. We develop a recently proposed\nmethod for learning reward trees from preference labels, and show it to be\nbroadly competitive with neural networks on challenging high-dimensional tasks,\nwith good robustness to limited or corrupted data. Having found that reward\ntree learning can be done effectively in complex settings, we then consider why\nit should be used, demonstrating that the interpretable reward structure gives\nsignificant scope for traceability, verification and explanation.\n",
                "链接": "https://arxiv.org/abs/2210.01007"
            },
            {
                "文章ID": "58975",
                "标题": "Direct Preference-based Policy Optimization without Reward Modeling",
                "作者": " Gaon An,  Junhyeok Lee,  Xingdong Zuo,  Norio Kosaka,  Kyung-Min Kim,  Hyun Oh Song",
                "发布日期": "2023-10-30",
                "摘要": "  Preference-based reinforcement learning (PbRL) is an approach that enables RL\nagents to learn from preference, which is particularly useful when formulating\na reward function is challenging. Existing PbRL methods generally involve a\ntwo-step procedure: they first learn a reward model based on given preference\ndata and then employ off-the-shelf reinforcement learning algorithms using the\nlearned reward model. However, obtaining an accurate reward model solely from\npreference information, especially when the preference is from human teachers,\ncan be difficult. Instead, we propose a PbRL algorithm that directly learns\nfrom preference without requiring any reward modeling. To achieve this, we\nadopt a contrastive learning framework to design a novel policy scoring metric\nthat assigns a high score to policies that align with the given preferences. We\napply our algorithm to offline RL tasks with actual human preference labels and\nshow that our algorithm outperforms or is on par with the existing PbRL\nmethods. Notably, on high-dimensional control tasks, our algorithm surpasses\noffline RL methods that learn with ground-truth reward information. Finally, we\nshow that our algorithm can be successfully applied to fine-tune large language\nmodels.\n",
                "链接": "https://arxiv.org/abs/2301.12842"
            },
            {
                "文章ID": "59850",
                "标题": "Controlling for Stereotypes in Multimodal Language Model Evaluation",
                "作者": " Manuj Malik,  Richard Johansson",
                "发布日期": "2023-02-06",
                "摘要": "  We propose a methodology and design two benchmark sets for measuring to what\nextent language-and-vision language models use the visual signal in the\npresence or absence of stereotypes. The first benchmark is designed to test for\nstereotypical colors of common objects, while the second benchmark considers\ngender stereotypes. The key idea is to compare predictions when the image\nconforms to the stereotype to predictions when it does not.\n  Our results show that there is significant variation among multimodal models:\nthe recent Transformer-based FLAVA seems to be more sensitive to the choice of\nimage and less affected by stereotypes than older CNN-based models such as\nVisualBERT and LXMERT. This effect is more discernible in this type of\ncontrolled setting than in traditional evaluations where we do not know whether\nthe model relied on the stereotype or the visual signal.\n",
                "链接": "https://arxiv.org/abs/2302.01582"
            },
            {
                "文章ID": "109754",
                "标题": "Pseudointelligence: A Unifying Framework for Language Model Evaluation",
                "作者": " Shikhar Murty,  Orr Paradise,  Pratyusha Sharma",
                "发布日期": "2023-10-19",
                "摘要": "  With large language models surpassing human performance on an increasing\nnumber of benchmarks, we must take a principled approach for targeted\nevaluation of model capabilities. Inspired by pseudorandomness, we propose\npseudointelligence, which captures the maxim that \"(perceived) intelligence\nlies in the eye of the beholder\". That is, that claims of intelligence are\nmeaningful only when their evaluator is taken into account. Concretely, we\npropose a complexity-theoretic framework of model evaluation cast as a dynamic\ninteraction between a model and a learned evaluator. We demonstrate that this\nframework can be used to reason about two case studies in language model\nevaluation, as well as analyze existing evaluation methods.\n",
                "链接": "https://arxiv.org/abs/2310.12135"
            },
            {
                "文章ID": "64063",
                "标题": "Reward Design with Language Models",
                "作者": " Minae Kwon,  Sang Michael Xie,  Kalesha Bullard,  Dorsa Sadigh",
                "发布日期": "2023-03-02",
                "摘要": "  Reward design in reinforcement learning (RL) is challenging since specifying\nhuman notions of desired behavior may be difficult via reward functions or\nrequire many expert demonstrations. Can we instead cheaply design rewards using\na natural language interface? This paper explores how to simplify reward design\nby prompting a large language model (LLM) such as GPT-3 as a proxy reward\nfunction, where the user provides a textual prompt containing a few examples\n(few-shot) or a description (zero-shot) of the desired behavior. Our approach\nleverages this proxy reward function in an RL framework. Specifically, users\nspecify a prompt once at the beginning of training. During training, the LLM\nevaluates an RL agent's behavior against the desired behavior described by the\nprompt and outputs a corresponding reward signal. The RL agent then uses this\nreward to update its behavior. We evaluate whether our approach can train\nagents aligned with user objectives in the Ultimatum Game, matrix games, and\nthe DealOrNoDeal negotiation task. In all three tasks, we show that RL agents\ntrained with our framework are well-aligned with the user's objectives and\noutperform RL agents trained with reward functions learned via supervised\nlearning\n",
                "链接": "https://arxiv.org/abs/2303.00001"
            },
            {
                "文章ID": "53814",
                "标题": "Attributed Question Answering: Evaluation and Modeling for Attributed\n  Large Language Models",
                "作者": " Bernd Bohnet,  Vinh Q. Tran,  Pat Verga,  Roee Aharoni,  Daniel Andor,  Livio Baldini Soares,  Massimiliano Ciaramita,  Jacob Eisenstein,  Kuzman Ganchev,  Jonathan Herzig,  Kai Hui,  Tom Kwiatkowski,  Ji Ma,  Jianmo Ni,  Lierni Sestorain Saralegui,  Tal Schuster,  William W. Cohen,  Michael Collins,  Dipanjan Das,  Donald Metzler,  Slav Petrov,  Kellie Webster",
                "发布日期": "2023-02-14",
                "摘要": "  Large language models (LLMs) have shown impressive results while requiring\nlittle or no direct supervision. Further, there is mounting evidence that LLMs\nmay have potential in information-seeking scenarios. We believe the ability of\nan LLM to attribute the text that it generates is likely to be crucial in this\nsetting. We formulate and study Attributed QA as a key first step in the\ndevelopment of attributed LLMs. We propose a reproducible evaluation framework\nfor the task and benchmark a broad set of architectures. We take human\nannotations as a gold standard and show that a correlated automatic metric is\nsuitable for development. Our experimental work gives concrete answers to two\nkey questions (How to measure attribution?, and How well do current\nstate-of-the-art methods perform on attribution?), and give some hints as to\nhow to address a third (How to build LLMs with attribution?).\n",
                "链接": "https://arxiv.org/abs/2212.08037"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "59864",
                "标题": "Modeling Sequential Sentence Relation to Improve Cross-lingual Dense\n  Retrieval",
                "作者": " Shunyu Zhang,  Yaobo Liang,  Ming Gong,  Daxin Jiang,  Nan Duan",
                "发布日期": "2023-02-06",
                "摘要": "  Recently multi-lingual pre-trained language models (PLM) such as mBERT and\nXLM-R have achieved impressive strides in cross-lingual dense retrieval.\nDespite its successes, they are general-purpose PLM while the multilingual PLM\ntailored for cross-lingual retrieval is still unexplored. Motivated by an\nobservation that the sentences in parallel documents are approximately in the\nsame order, which is universal across languages, we propose to model this\nsequential sentence relation to facilitate cross-lingual representation\nlearning. Specifically, we propose a multilingual PLM called masked sentence\nmodel (MSM), which consists of a sentence encoder to generate the sentence\nrepresentations, and a document encoder applied to a sequence of sentence\nvectors from a document. The document encoder is shared for all languages to\nmodel the universal sequential sentence relation across languages. To train the\nmodel, we propose a masked sentence prediction task, which masks and predicts\nthe sentence vector via a hierarchical contrastive loss with sampled negatives.\nComprehensive experiments on four cross-lingual retrieval tasks show MSM\nsignificantly outperforms existing advanced pre-training models, demonstrating\nthe effectiveness and stronger cross-lingual retrieval capabilities of our\napproach. Code and model will be available.\n",
                "链接": "https://arxiv.org/abs/2302.01626"
            },
            {
                "文章ID": "50330",
                "标题": "Sequential Gradient Coding For Straggler Mitigation",
                "作者": " M. Nikhil Krishnan,  MohammadReza Ebrahimi,  Ashish Khisti",
                "发布日期": "2023-06-29",
                "摘要": "  In distributed computing, slower nodes (stragglers) usually become a\nbottleneck. Gradient Coding (GC), introduced by Tandon et al., is an efficient\ntechnique that uses principles of error-correcting codes to distribute gradient\ncomputation in the presence of stragglers. In this paper, we consider the\ndistributed computation of a sequence of gradients $\\{g(1),g(2),\\ldots,g(J)\\}$,\nwhere processing of each gradient $g(t)$ starts in round-$t$ and finishes by\nround-$(t+T)$. Here $T\\geq 0$ denotes a delay parameter. For the GC scheme,\ncoding is only across computing nodes and this results in a solution where\n$T=0$. On the other hand, having $T>0$ allows for designing schemes which\nexploit the temporal dimension as well. In this work, we propose two schemes\nthat demonstrate improved performance compared to GC. Our first scheme combines\nGC with selective repetition of previously unfinished tasks and achieves\nimproved straggler mitigation. In our second scheme, which constitutes our main\ncontribution, we apply GC to a subset of the tasks and repetition for the\nremainder of the tasks. We then multiplex these two classes of tasks across\nworkers and rounds in an adaptive manner, based on past straggler patterns.\nUsing theoretical analysis, we demonstrate that our second scheme achieves\nsignificant reduction in the computational load. In our experiments, we study a\npractical setting of concurrently training multiple neural networks over an AWS\nLambda cluster involving 256 worker nodes, where our framework naturally\napplies. We demonstrate that the latter scheme can yield a 16\\% improvement in\nruntime over the baseline GC scheme, in the presence of naturally occurring,\nnon-simulated stragglers.\n",
                "链接": "https://arxiv.org/abs/2211.13802"
            },
            {
                "文章ID": "78876",
                "标题": "Sequential Memory with Temporal Predictive Coding",
                "作者": " Mufeng Tang,  Helen Barron,  Rafal Bogacz",
                "发布日期": "2023-10-27",
                "摘要": "  Forming accurate memory of sequential stimuli is a fundamental function of\nbiological agents. However, the computational mechanism underlying sequential\nmemory in the brain remains unclear. Inspired by neuroscience theories and\nrecent successes in applying predictive coding (PC) to \\emph{static} memory\ntasks, in this work we propose a novel PC-based model for \\emph{sequential}\nmemory, called \\emph{temporal predictive coding} (tPC). We show that our tPC\nmodels can memorize and retrieve sequential inputs accurately with a\nbiologically plausible neural implementation. Importantly, our analytical study\nreveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN)\nwith an implicit statistical whitening process, which leads to more stable\nperformance in sequential memory tasks of structured inputs. Moreover, we find\nthat tPC exhibits properties consistent with behavioral observations and\ntheories in neuroscience, thereby strengthening its biological relevance. Our\nwork establishes a possible computational mechanism underlying sequential\nmemory in the brain that can also be theoretically interpreted using existing\nmemory model frameworks.\n",
                "链接": "https://arxiv.org/abs/2305.11982"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "2912",
                "标题": "Vision Checklist: Towards Testable Error Analysis of Image Models to\n  Help System Designers Interrogate Model Capabilities",
                "作者": " Xin Du,  Benedicte Legastelois,  Bhargavi Ganesh,  Ajitha Rajan,  Hana Chockler,  Vaishak Belle,  Stuart Anderson,  Subramanian Ramamoorthy",
                "发布日期": "2022-02-01",
                "摘要": "  Using large pre-trained models for image recognition tasks is becoming\nincreasingly common owing to the well acknowledged success of recent models\nlike vision transformers and other CNN-based models like VGG and Resnet. The\nhigh accuracy of these models on benchmark tasks has translated into their\npractical use across many domains including safety-critical applications like\nautonomous driving and medical diagnostics. Despite their widespread use, image\nmodels have been shown to be fragile to changes in the operating environment,\nbringing their robustness into question. There is an urgent need for methods\nthat systematically characterise and quantify the capabilities of these models\nto help designers understand and provide guarantees about their safety and\nrobustness. In this paper, we propose Vision Checklist, a framework aimed at\ninterrogating the capabilities of a model in order to produce a report that can\nbe used by a system designer for robustness evaluations. This framework\nproposes a set of perturbation operations that can be applied on the underlying\ndata to generate test samples of different types. The perturbations reflect\npotential changes in operating environments, and interrogate various properties\nranging from the strictly quantitative to more qualitative. Our framework is\nevaluated on multiple datasets like Tinyimagenet, CIFAR10, CIFAR100 and\nCamelyon17 and for models like ViT and Resnet. Our Vision Checklist proposes a\nspecific set of evaluations that can be integrated into the previously proposed\nconcept of a model card. Robustness evaluations like our checklist will be\ncrucial in future safety evaluations of visual perception modules, and be\nuseful for a wide range of stakeholders including designers, deployers, and\nregulators involved in the certification of these systems. Source code of\nVision Checklist would be open for public use.\n",
                "链接": "https://arxiv.org/abs/2201.11674"
            },
            {
                "文章ID": "12740",
                "标题": "ESGBERT: Language Model to Help with Classification Tasks Related to\n  Companies Environmental, Social, and Governance Practices",
                "作者": " Srishti Mehra,  Robert Louka,  Yixun Zhang",
                "发布日期": "2022-04-01",
                "摘要": "  Environmental, Social, and Governance (ESG) are non-financial factors that\nare garnering attention from investors as they increasingly look to apply these\nas part of their analysis to identify material risks and growth opportunities.\nSome of this attention is also driven by clients who, now more aware than ever,\nare demanding for their money to be managed and invested responsibly. As the\ninterest in ESG grows, so does the need for investors to have access to\nconsumable ESG information. Since most of it is in text form in reports,\ndisclosures, press releases, and 10-Q filings, we see a need for sophisticated\nNLP techniques for classification tasks for ESG text. We hypothesize that an\nESG domain-specific pre-trained model will help with such and study building of\nthe same in this paper. We explored doing this by fine-tuning BERTs pre-trained\nweights using ESG specific text and then further fine-tuning the model for a\nclassification task. We were able to achieve accuracy better than the original\nBERT and baseline models in environment-specific classification tasks.\n",
                "链接": "https://arxiv.org/abs/2203.16788"
            },
            {
                "文章ID": "3180",
                "标题": "Does Transliteration Help Multilingual Language Modeling?",
                "作者": " Ibraheem Muhammad Moosa,  Mahmud Elahi Akhter,  Ashfia Binte Habib",
                "发布日期": "2023-08-01",
                "摘要": "  Script diversity presents a challenge to Multilingual Language Models (MLLM)\nby reducing lexical overlap among closely related languages. Therefore,\ntransliterating closely related languages that use different writing scripts to\na common script may improve the downstream task performance of MLLMs. We\nempirically measure the effect of transliteration on MLLMs in this context. We\nspecifically focus on the Indic languages, which have the highest script\ndiversity in the world, and we evaluate our models on the IndicGLUE benchmark.\nWe perform the Mann-Whitney U test to rigorously verify whether the effect of\ntransliteration is significant or not. We find that transliteration benefits\nthe low-resource languages without negatively affecting the comparatively\nhigh-resource languages. We also measure the cross-lingual representation\nsimilarity of the models using centered kernel alignment on parallel sentences\nfrom the FLORES-101 dataset. We find that for parallel sentences across\ndifferent languages, the transliteration-based model learns sentence\nrepresentations that are more similar.\n",
                "链接": "https://arxiv.org/abs/2201.12501"
            },
            {
                "文章ID": "88347",
                "标题": "Distributional Modeling for Location-Aware Adversarial Patches",
                "作者": " Xingxing Wei,  Shouwei Ruan,  Yinpeng Dong,  Hang Su",
                "发布日期": "2023-06-29",
                "摘要": "  Adversarial patch is one of the important forms of performing adversarial\nattacks in the physical world. To improve the naturalness and aggressiveness of\nexisting adversarial patches, location-aware patches are proposed, where the\npatch's location on the target object is integrated into the optimization\nprocess to perform attacks. Although it is effective, efficiently finding the\noptimal location for placing the patches is challenging, especially under the\nblack-box attack settings. In this paper, we propose the Distribution-Optimized\nAdversarial Patch (DOPatch), a novel method that optimizes a multimodal\ndistribution of adversarial locations instead of individual ones. DOPatch has\nseveral benefits: Firstly, we find that the locations' distributions across\ndifferent models are pretty similar, and thus we can achieve efficient\nquery-based attacks to unseen models using a distributional prior optimized on\na surrogate model. Secondly, DOPatch can generate diverse adversarial samples\nby characterizing the distribution of adversarial locations. Thus we can\nimprove the model's robustness to location-aware patches via carefully designed\nDistributional-Modeling Adversarial Training (DOP-DMAT). We evaluate DOPatch on\nvarious face recognition and image recognition tasks and demonstrate its\nsuperiority and efficiency over existing methods. We also conduct extensive\nablation studies and analyses to validate the effectiveness of our method and\nprovide insights into the distribution of adversarial locations.\n",
                "链接": "https://arxiv.org/abs/2306.16131"
            },
            {
                "文章ID": "27024",
                "标题": "Masked Part-Of-Speech Model: Does Modeling Long Context Help\n  Unsupervised POS-tagging?",
                "作者": " Xiang Zhou,  Shiyue Zhang,  Mohit Bansal",
                "发布日期": "2022-07-01",
                "摘要": "  Previous Part-Of-Speech (POS) induction models usually assume certain\nindependence assumptions (e.g., Markov, unidirectional, local dependency) that\ndo not hold in real languages. For example, the subject-verb agreement can be\nboth long-term and bidirectional. To facilitate flexible dependency modeling,\nwe propose a Masked Part-of-Speech Model (MPoSM), inspired by the recent\nsuccess of Masked Language Models (MLM). MPoSM can model arbitrary tag\ndependency and perform POS induction through the objective of masked POS\nreconstruction. We achieve competitive results on both the English Penn WSJ\ndataset as well as the universal treebank containing 10 diverse languages.\nThough modeling the long-term dependency should ideally help this task, our\nablation study shows mixed trends in different languages. To better understand\nthis phenomenon, we design a novel synthetic experiment that can specifically\ndiagnose the model's ability to learn tag agreement. Surprisingly, we find that\neven strong baselines fail to solve this problem consistently in a very\nsimplified setting: the agreement between adjacent words. Nonetheless, MPoSM\nachieves overall better performance. Lastly, we conduct a detailed error\nanalysis to shed light on other remaining challenges. Our code is available at\nhttps://github.com/owenzx/MPoSM\n",
                "链接": "https://arxiv.org/abs/2206.14969"
            },
            {
                "文章ID": "65043",
                "标题": "Both eyes open: Vigilant Incentives help Regulatory Markets improve AI\n  Safety",
                "作者": " Paolo Bova,  Alessandro Di Stefano,  The Anh Han",
                "发布日期": "2023-03-07",
                "摘要": "  In the context of rapid discoveries by leaders in AI, governments must\nconsider how to design regulation that matches the increasing pace of new AI\ncapabilities. Regulatory Markets for AI is a proposal designed with\nadaptability in mind. It involves governments setting outcome-based targets for\nAI companies to achieve, which they can show by purchasing services from a\nmarket of private regulators. We use an evolutionary game theory model to\nexplore the role governments can play in building a Regulatory Market for AI\nsystems that deters reckless behaviour. We warn that it is alarmingly easy to\nstumble on incentives which would prevent Regulatory Markets from achieving\nthis goal. These 'Bounty Incentives' only reward private regulators for\ncatching unsafe behaviour. We argue that AI companies will likely learn to\ntailor their behaviour to how much effort regulators invest, discouraging\nregulators from innovating. Instead, we recommend that governments always\nreward regulators, except when they find that those regulators failed to detect\nunsafe behaviour that they should have. These 'Vigilant Incentives' could\nencourage private regulators to find innovative ways to evaluate cutting-edge\nAI systems.\n",
                "链接": "https://arxiv.org/abs/2303.03174"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "61811",
                "标题": "Tree-Based Representation and Generation of Natural and Mathematical\n  Language",
                "作者": " Alexander Scarlatos,  Andrew Lan",
                "发布日期": "2023-02-17",
                "摘要": "  Mathematical language in scientific communications and educational scenarios\nis important yet relatively understudied compared to natural languages. Recent\nworks on mathematical language focus either on representing stand-alone\nmathematical expressions, especially in their natural tree format, or\nmathematical reasoning in pre-trained natural language models. Existing works\non jointly modeling and generating natural and mathematical languages simply\ntreat mathematical expressions as text, without accounting for the rigid\nstructural properties of mathematical expressions. In this paper, we propose a\nseries of modifications to existing language models to jointly represent and\ngenerate text and math: representing mathematical expressions as sequences of\nnode tokens in their operator tree format, using math symbol and tree position\nembeddings to preserve the semantic and structural properties of mathematical\nexpressions, and using a constrained decoding method to generate mathematically\nvalid expressions. We ground our modifications in GPT-2, resulting in a model\nMathGPT, and demonstrate that it outperforms baselines on mathematical\nexpression generation tasks.\n",
                "链接": "https://arxiv.org/abs/2302.07974"
            },
            {
                "文章ID": "85371",
                "标题": "Mathematical conjecture generation using machine intelligence",
                "作者": " Challenger Mishra,  Subhayan Roy Moulik,  Rahul Sarkar",
                "发布日期": "2023-06-13",
                "摘要": "  Conjectures have historically played an important role in the development of\npure mathematics. We propose a systematic approach to finding abstract patterns\nin mathematical data, in order to generate conjectures about mathematical\ninequalities, using machine intelligence. We focus on strict inequalities of\ntype f < g and associate them with a vector space. By geometerising this space,\nwhich we refer to as a conjecture space, we prove that this space is isomorphic\nto a Banach manifold. We develop a structural understanding of this conjecture\nspace by studying linear automorphisms of this manifold and show that this\nspace admits several free group actions. Based on these insights, we propose an\nalgorithmic pipeline to generate novel conjectures using geometric gradient\ndescent, where the metric is informed by the invariances of the conjecture\nspace. As proof of concept, we give a toy algorithm to generate novel\nconjectures about the prime counting function and diameters of Cayley graphs of\nnon-abelian simple groups. We also report private communications with\ncolleagues in which some conjectures were proved, and highlight that some\nconjectures generated using this procedure are still unproven. Finally, we\npropose a pipeline of mathematical discovery in this space and highlight the\nimportance of domain expertise in this pipeline.\n",
                "链接": "https://arxiv.org/abs/2306.07277"
            },
            {
                "文章ID": "106324",
                "标题": "Notes on a Path to AI Assistance in Mathematical Reasoning",
                "作者": " Alex Kontorovich",
                "发布日期": "2023-10-05",
                "摘要": "  These informal notes are based on the author's lecture at the National\nAcademies of Science, Engineering, and Mathematics workshop on \"AI to Assist\nMathematical Reasoning\" in June 2023. The goal is to think through a path by\nwhich we might arrive at AI that is useful for the research mathematician.\n",
                "链接": "https://arxiv.org/abs/2310.02896"
            },
            {
                "文章ID": "110277",
                "标题": "Three Questions Concerning the Use of Large Language Models to\n  Facilitate Mathematics Learning",
                "作者": " An-Zi Yen,  Wei-Ling Hsu",
                "发布日期": "2023-10-23",
                "摘要": "  Due to the remarkable language understanding and generation abilities of\nlarge language models (LLMs), their use in educational applications has been\nexplored. However, little work has been done on investigating the pedagogical\nability of LLMs in helping students to learn mathematics. In this position\npaper, we discuss the challenges associated with employing LLMs to enhance\nstudents' mathematical problem-solving skills by providing adaptive feedback.\nApart from generating the wrong reasoning processes, LLMs can misinterpret the\nmeaning of the question, and also exhibit difficulty in understanding the given\nquestions' rationales when attempting to correct students' answers. Three\nresearch questions are formulated.\n",
                "链接": "https://arxiv.org/abs/2310.13615"
            },
            {
                "文章ID": "21205",
                "标题": "NaturalProver: Grounded Mathematical Proof Generation with Language\n  Models",
                "作者": " Sean Welleck,  Jiacheng Liu,  Ximing Lu,  Hannaneh Hajishirzi,  Yejin Choi",
                "发布日期": "2022-11-02",
                "摘要": "  Theorem proving in natural mathematical language - the mixture of symbolic\nand natural language used by humans - plays a central role in mathematical\nadvances and education, and tests aspects of reasoning that are core to\nintelligence. Yet it has remained underexplored with modern generative models.\nWe study large-scale language models on two new generation tasks: suggesting\nthe next step in a mathematical proof, and full proof generation. We develop\nNaturalProver, a language model that generates proofs by conditioning on\nbackground references (e.g. theorems and definitions that are either retrieved\nor human-provided), and optionally enforces their presence with constrained\ndecoding. On theorems from the NaturalProofs benchmark, NaturalProver improves\nthe quality of next-step suggestions and generated proofs over fine-tuned\nGPT-3, according to human evaluations from university-level mathematics\nstudents. NaturalProver is capable of proving some theorems that require short\n(2-6 step) proofs, and providing next-step suggestions that are rated as\ncorrect and useful over 40% of the time, which is to our knowledge the first\ndemonstration of these capabilities using neural language models.\n",
                "链接": "https://arxiv.org/abs/2205.12910"
            },
            {
                "文章ID": "111569",
                "标题": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
                "作者": " Hassen Saidi,  Susmit Jha,  Tuhin Sahai",
                "发布日期": "2023-10-27",
                "摘要": "  As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.\n",
                "链接": "https://arxiv.org/abs/2310.17064"
            },
            {
                "文章ID": "61747",
                "标题": "Generation of Highlights from Research Papers Using Pointer-Generator\n  Networks and SciBERT Embeddings",
                "作者": " Tohida Rehman,  Debarshi Kumar Sanyal,  Samiran Chattopadhyay,  Plaban Kumar Bhowmick,  Partha Pratim Das",
                "发布日期": "2023-09-19",
                "摘要": "  Nowadays many research articles are prefaced with research highlights to\nsummarize the main findings of the paper. Highlights not only help researchers\nprecisely and quickly identify the contributions of a paper, they also enhance\nthe discoverability of the article via search engines. We aim to automatically\nconstruct research highlights given certain segments of a research paper. We\nuse a pointer-generator network with coverage mechanism and a contextual\nembedding layer at the input that encodes the input tokens into SciBERT\nembeddings. We test our model on a benchmark dataset, CSPubSum, and also\npresent MixSub, a new multi-disciplinary corpus of papers for automatic\nresearch highlight generation. For both CSPubSum and MixSub, we have observed\nthat the proposed model achieves the best performance compared to related\nvariants and other models proposed in the literature. On the CSPubSum dataset,\nour model achieves the best performance when the input is only the abstract of\na paper as opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2\nand ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR score of\n32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On the\nnew MixSub dataset, where only the abstract is the input, our proposed model\n(when trained on the whole training corpus without distinguishing between the\nsubject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,\n9.76 and 29.3, respectively, METEOR score of 24.00, and BERTScore F1 of 85.25.\n",
                "链接": "https://arxiv.org/abs/2302.07729"
            },
            {
                "文章ID": "22325",
                "标题": "PAGER: Progressive Attribute-Guided Extendable Robust Image Generation",
                "作者": " Zohreh Azizi,  C. -C. Jay Kuo",
                "发布日期": "2022-08-24",
                "摘要": "  This work presents a generative modeling approach based on successive\nsubspace learning (SSL). Unlike most generative models in the literature, our\nmethod does not utilize neural networks to analyze the underlying source\ndistribution and synthesize images. The resulting method, called the\nprogressive attribute-guided extendable robust image generative (PAGER) model,\nhas advantages in mathematical transparency, progressive content generation,\nlower training time, robust performance with fewer training samples, and\nextendibility to conditional image generation. PAGER consists of three modules:\ncore generator, resolution enhancer, and quality booster. The core generator\nlearns the distribution of low-resolution images and performs unconditional\nimage generation. The resolution enhancer increases image resolution via\nconditional generation. Finally, the quality booster adds finer details to\ngenerated images. Extensive experiments on MNIST, Fashion-MNIST, and CelebA\ndatasets are conducted to demonstrate generative performance of PAGER.\n",
                "链接": "https://arxiv.org/abs/2206.00162"
            },
            {
                "文章ID": "51056",
                "标题": "Peano: Learning Formal Mathematical Reasoning",
                "作者": " Gabriel Poesia,  Noah D. Goodman",
                "发布日期": "2023-06-21",
                "摘要": "  General mathematical reasoning is computationally undecidable, but humans\nroutinely solve new problems. Moreover, discoveries developed over centuries\nare taught to subsequent generations quickly. What structure enables this, and\nhow might that inform automated mathematical reasoning? We posit that central\nto both puzzles is the structure of procedural abstractions underlying\nmathematics. We explore this idea in a case study on 5 sections of beginning\nalgebra on the Khan Academy platform. To define a computational foundation, we\nintroduce Peano, a theorem-proving environment where the set of valid actions\nat any point is finite. We use Peano to formalize introductory algebra problems\nand axioms, obtaining well-defined search problems. We observe existing\nreinforcement learning methods for symbolic reasoning to be insufficient to\nsolve harder problems. Adding the ability to induce reusable abstractions\n(\"tactics\") from its own solutions allows an agent to make steady progress,\nsolving all problems. Furthermore, these abstractions induce an order to the\nproblems, seen at random during training. The recovered order has significant\nagreement with the expert-designed Khan Academy curriculum, and\nsecond-generation agents trained on the recovered curriculum learn\nsignificantly faster. These results illustrate the synergistic role of\nabstractions and curricula in the cultural transmission of mathematics.\n",
                "链接": "https://arxiv.org/abs/2211.15864"
            }
        ]
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "13999",
                "标题": "Characterizing User Behaviors in Open-Source Software User Forums: An\n  Empirical Study",
                "作者": " Jazlyn Hellman,  Jiahao Chen,  Md. Sami Uddin,  Jinghui Cheng,  Jin L. C. Guo",
                "发布日期": "2022-04-11",
                "摘要": "  User forums of Open Source Software (OSS) enable end-users to collaboratively\ndiscuss problems concerning the OSS applications. Despite decades of research\non OSS, we know very little about how end-users engage with OSS communities on\nthese forums, in particular, the challenges that hinder their continuous and\nmeaningful participation in the OSS community. Many previous works are\ndeveloper-centric and overlook the importance of end-user forums. As a result,\nend-users' expectations are seldom reflected in OSS development. To better\nunderstand user behaviors in OSS user forums, we carried out an empirical study\nanalyzing about 1.3 million posts from user forums of four popular OSS\napplications: Zotero, Audacity, VLC, and RStudio. Through analyzing the\ncontribution patterns of three common user types (end-users, developers, and\norganizers), we observed that end-users not only initiated most of the threads\n(above 96% of threads in three projects, 86% in the other), but also acted as\nthe significant contributors for responding to other users' posts, even though\nthey tended to lack confidence in their activities as indicated by\npsycho-linguistic analyses. Moreover, we found end-users more open, reflecting\na more positive emotion in communication than organizers and developers in the\nforums. Our work contributes new knowledge about end-users' activities and\nbehaviors in OSS user forums that the vital OSS stakeholders can leverage to\nimprove end-user engagement in the OSS development process.\n",
                "链接": "https://arxiv.org/abs/2204.03770"
            },
            {
                "文章ID": "90634",
                "标题": "PolyLM: An Open Source Polyglot Large Language Model",
                "作者": " Xiangpeng Wei,  Haoran Wei,  Huan Lin,  Tianhao Li,  Pei Zhang,  Xingzhang Ren,  Mei Li,  Yu Wan,  Zhiwei Cao,  Binbin Xie,  Tianxiang Hu,  Shangjie Li,  Binyuan Hui,  Bowen Yu,  Dayiheng Liu,  Baosong Yang,  Fei Huang,  Jun Xie",
                "发布日期": "2023-07-13",
                "摘要": "  Large language models (LLMs) demonstrate remarkable ability to comprehend,\nreason, and generate following nature language instructions. However, the\ndevelopment of LLMs has been primarily focused on high-resource languages, such\nas English, thereby limiting their applicability and research in other\nlanguages. Consequently, we present PolyLM, a multilingual LLM trained on 640\nbillion (B) tokens, avaliable in two model sizes: 1.7B and 13B. To enhance its\nmultilingual capabilities, we 1) integrate bilingual data into training data;\nand 2) adopt a curriculum learning strategy that increases the proportion of\nnon-English data from 30% in the first stage to 60% in the final stage during\npre-training. Further, we propose a multilingual self-instruct method which\nautomatically generates 132.7K diverse multilingual instructions for model\nfine-tuning. To assess the model's performance, we collect several existing\nmultilingual tasks, including multilingual understanding, question answering,\ngeneration, and translation. Extensive experiments show that PolyLM surpasses\nother open-source models such as LLaMA and BLOOM on multilingual tasks while\nmaintaining comparable performance in English. Our models, alone with the\ninstruction data and multilingual benchmark, are available at:\n\\url{https://modelscope.cn/models/damo/nlp_polylm_13b_text_generation}.\n",
                "链接": "https://arxiv.org/abs/2307.06018"
            },
            {
                "文章ID": "105314",
                "标题": "GASS: Generalizing Audio Source Separation with Large-scale Data",
                "作者": " Jordi Pons,  Xiaoyu Liu,  Santiago Pascual,  Joan Serrà",
                "发布日期": "2023-10-03",
                "摘要": "  Universal source separation targets at separating the audio sources of an\narbitrary mix, removing the constraint to operate on a specific domain like\nspeech or music. Yet, the potential of universal source separation is limited\nbecause most existing works focus on mixes with predominantly sound events, and\nsmall training datasets also limit its potential for supervised learning. Here,\nwe study a single general audio source separation (GASS) model trained to\nseparate speech, music, and sound events in a supervised fashion with a\nlarge-scale dataset. We assess GASS models on a diverse set of tasks. Our\nstrong in-distribution results show the feasibility of GASS models, and the\ncompetitive out-of-distribution performance in sound event and speech\nseparation shows its generalization abilities. Yet, it is challenging for GASS\nmodels to generalize for separating out-of-distribution cinematic and music\ncontent. We also fine-tune GASS models on each dataset and consistently\noutperform the ones without pre-training. All fine-tuned models (except the\nmusic separation one) obtain state-of-the-art results in their respective\nbenchmarks.\n",
                "链接": "https://arxiv.org/abs/2310.00140"
            },
            {
                "文章ID": "95277",
                "标题": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation",
                "作者": " Jiaju Lin,  Haoran Zhao,  Aochi Zhang,  Yiting Wu,  Huqiuyue Ping,  Qin Chen",
                "发布日期": "2023-08-09",
                "摘要": "  With ChatGPT-like large language models (LLM) prevailing in the community,\nhow to evaluate the ability of LLMs is an open question. Existing evaluation\nmethods suffer from following shortcomings: (1) constrained evaluation\nabilities, (2) vulnerable benchmarks, (3) unobjective metrics. We suggest that\ntask-based evaluation, where LLM agents complete tasks in a simulated\nenvironment, is a one-for-all solution to solve above problems. We present\nAgentSims, an easy-to-use infrastructure for researchers from all disciplines\nto test the specific capacities they are interested in. Researchers can build\ntheir evaluation tasks by adding agents and buildings on an interactive GUI or\ndeploy and test new support mechanisms, i.e. memory, planning and tool-use\nsystems, by a few lines of codes. Our demo is available at\nhttps://agentsims.com .\n",
                "链接": "https://arxiv.org/abs/2308.04026"
            },
            {
                "文章ID": "99684",
                "标题": "Large-Scale Public Data Improves Differentially Private Image Generation\n  Quality",
                "作者": " Ruihan Wu,  Chuan Guo,  Kamalika Chaudhuri",
                "发布日期": "2023-09-04",
                "摘要": "  Public data has been frequently used to improve the privacy-accuracy\ntrade-off of differentially private machine learning, but prior work largely\nassumes that this data come from the same distribution as the private. In this\nwork, we look at how to use generic large-scale public data to improve the\nquality of differentially private image generation in Generative Adversarial\nNetworks (GANs), and provide an improved method that uses public data\neffectively. Our method works under the assumption that the support of the\npublic data distribution contains the support of the private; an example of\nthis is when the public data come from a general-purpose internet-scale image\nsource, while the private data consist of images of a specific type. Detailed\nevaluations show that our method achieves SOTA in terms of FID score and other\nmetrics compared with existing methods that use public data, and can generate\nhigh-quality, photo-realistic images in a differentially private manner.\n",
                "链接": "https://arxiv.org/abs/2309.00008"
            },
            {
                "文章ID": "111764",
                "标题": "An Open Source Data Contamination Report for Large Language Models",
                "作者": " Yucheng Li",
                "发布日期": "2023-12-19",
                "摘要": "  Data contamination in language model evaluation is increasingly prevalent as\nthe popularity of large language models. It allows models to \"cheat\" via\nmemorisation instead of displaying true capabilities. Therefore, contamination\nanalysis has became an crucial part of reliable model evaluation to validate\nresults. However, existing contamination analysis is usually conducted\ninternally by LLM developers and often lacks transparency and completeness.\nThis paper present an open source data contamination reports for the Llama\nseries models. We analyse six popular multi-choice QA benchmarks and quantify\ntheir overlapping with the training set of Llama. Various levels of\ncontamination ranging from 1\\% to 8.7\\% are found across benchmarks. Our\ncomparison also reveals that Llama models can gain over 5\\% higher accuracy on\ncontaminated subsets versus clean subsets. Data and code are available at:\nhttps://github.com/liyucheng09/Contamination_Detector.\n",
                "链接": "https://arxiv.org/abs/2310.17589"
            },
            {
                "文章ID": "53799",
                "标题": "A Data Source Dependency Analysis Framework for Large Scale Data Science\n  Projects",
                "作者": " Laurent Boué,  Pratap Kunireddy,  Pavle Subotić",
                "发布日期": "2022-12-16",
                "摘要": "  Dependency hell is a well-known pain point in the development of large\nsoftware projects and machine learning (ML) code bases are not immune from it.\nIn fact, ML applications suffer from an additional form, namely, \"data source\ndependency hell\". This term refers to the central role played by data and its\nunique quirks that often lead to unexpected failures of ML models which cannot\nbe explained by code changes. In this paper, we present an automated dependency\nmapping framework that allows MLOps engineers to monitor the whole dependency\nmap of their models in a fast paced engineering environment and thus mitigate\nahead of time the consequences of any data source changes (e.g., re-train\nmodel, ignore data, set default data etc.). Our system is based on a unified\nand generic approach, employing techniques from static analysis, from which\ndata sources can be identified reliably for any type of dependency on a wide\nrange of source languages and artefacts. The dependency mapping framework is\nexposed as a REST web API where the only input is the path to the Git\nrepository hosting the code base. Currently used by MLOps engineers at\nMicrosoft, we expect such dependency map APIs to be adopted more widely by\nMLOps engineers in the future.\n",
                "链接": "https://arxiv.org/abs/2212.07951"
            },
            {
                "文章ID": "83460",
                "标题": "A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean\n  Language Models",
                "作者": " Hyunwoong Ko,  Kichang Yang,  Minho Ryu,  Taekyoon Choi,  Seungmu Yang,  Jiwung Hyun,  Sungho Park,  Kyubyong Park",
                "发布日期": "2023-06-07",
                "摘要": "  Polyglot is a pioneering project aimed at enhancing the non-English language\nperformance of multilingual language models. Despite the availability of\nvarious multilingual models such as mBERT (Devlin et al., 2019), XGLM (Lin et\nal., 2022), and BLOOM (Scao et al., 2022), researchers and developers often\nresort to building monolingual models in their respective languages due to the\ndissatisfaction with the current multilingual models non-English language\ncapabilities. Addressing this gap, we seek to develop advanced multilingual\nlanguage models that offer improved performance in non-English languages. In\nthis paper, we introduce the Polyglot Korean models, which represent a specific\nfocus rather than being multilingual in nature. In collaboration with TUNiB,\nour team collected 1.2TB of Korean data meticulously curated for our research\njourney. We made a deliberate decision to prioritize the development of Korean\nmodels before venturing into multilingual models. This choice was motivated by\nmultiple factors: firstly, the Korean models facilitated performance\ncomparisons with existing multilingual models; and finally, they catered to the\nspecific needs of Korean companies and researchers. This paper presents our\nwork in developing the Polyglot Korean models, which propose some steps towards\naddressing the non-English language performance gap in multilingual language\nmodels.\n",
                "链接": "https://arxiv.org/abs/2306.02254"
            },
            {
                "文章ID": "67898",
                "标题": "Reasonable Scale Machine Learning with Open-Source Metaflow",
                "作者": " Jacopo Tagliabue,  Hugo Bowne-Anderson,  Ville Tuulos,  Savin Goyal,  Romain Cledat,  David Berg",
                "发布日期": "2023-03-22",
                "摘要": "  As Machine Learning (ML) gains adoption across industries and new use cases,\npractitioners increasingly realize the challenges around effectively developing\nand iterating on ML systems: reproducibility, debugging, scalability, and\ndocumentation are elusive goals for real-world pipelines outside tech-first\ncompanies. In this paper, we review the nature of ML-oriented workloads and\nargue that re-purposing existing tools won't solve the current productivity\nissues, as ML peculiarities warrant specialized development tooling. We then\nintroduce Metaflow, an open-source framework for ML projects explicitly\ndesigned to boost the productivity of data practitioners by abstracting away\nthe execution of ML code from the definition of the business logic. We show how\nour design addresses the main challenges in ML operations (MLOps), and document\nthrough examples, interviews and use cases its practical impact on the field.\n",
                "链接": "https://arxiv.org/abs/2303.11761"
            },
            {
                "文章ID": "88335",
                "标题": "ChatLaw: Open-Source Legal Large Language Model with Integrated External\n  Knowledge Bases",
                "作者": " Jiaxi Cui,  Zongjian Li,  Yang Yan,  Bohua Chen,  Li Yuan",
                "发布日期": "2023-06-29",
                "摘要": "  Large Language Models (LLMs) have shown the potential to revolutionize\nnatural language processing tasks in various domains, sparking great interest\nin vertical-specific large models. However, unlike proprietary models such as\nBloombergGPT and FinGPT, which have leveraged their unique data accumulations\nto make strides in the finance domain, there hasn't not many similar large\nlanguage models in the Chinese legal domain to facilitate its digital\ntransformation.\n  In this paper, we propose an open-source legal large language model named\nChatLaw. Due to the importance of data quality, we carefully designed a legal\ndomain fine-tuning dataset. Additionally, to overcome the problem of model\nhallucinations in legal data screening during reference data retrieval, we\nintroduce a method that combines vector database retrieval with keyword\nretrieval to effectively reduce the inaccuracy of relying solely on vector\ndatabase retrieval. Furthermore, we propose a self-attention method to enhance\nthe ability of large models to overcome errors present in reference data,\nfurther optimizing the issue of model hallucinations at the model level and\nimproving the problem-solving capabilities of large models. We also\nopen-sourced our model and part of the data at\nhttps://github.com/PKU-YuanGroup/ChatLaw.\n",
                "链接": "https://arxiv.org/abs/2306.16092"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109322",
                "标题": "Enhanced Transformer Architecture for Natural Language Processing",
                "作者": " Woohyeon Moon,  Taeyoung Kim,  Bumgeun Park,  Dongsoo Har",
                "发布日期": "2023-10-18",
                "摘要": "  Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.\n",
                "链接": "https://arxiv.org/abs/2310.10930"
            },
            {
                "文章ID": "93014",
                "标题": "Evaluating Large Language Models for Radiology Natural Language\n  Processing",
                "作者": " Zhengliang Liu,  Tianyang Zhong,  Yiwei Li,  Yutong Zhang,  Yi Pan,  Zihao Zhao,  Peixin Dong,  Chao Cao,  Yuxiao Liu,  Peng Shu,  Yaonai Wei,  Zihao Wu,  Chong Ma,  Jiaqi Wang,  Sheng Wang,  Mengyue Zhou,  Zuowei Jiang,  Chunlin Li,  Jason Holmes,  Shaochen Xu,  Lu Zhang,  Haixing Dai,  Kai Zhang,  Lin Zhao,  Yuanhao Chen,  Xu Liu,  Peilong Wang,  Pingkun Yan,  Jun Liu,  Bao Ge,  Lichao Sun,  Dajiang Zhu,  Xiang Li,  Wei Liu,  Xiaoyan Cai,  Xintao Hu,  Xi Jiang,  Shu Zhang,  Xin Zhang,  Tuo Zhang,  Shijie Zhao,  Quanzheng Li,  Hongtu Zhu,  Dinggang Shen,  Tianming Liu",
                "发布日期": "2023-07-28",
                "摘要": "  The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain.\n",
                "链接": "https://arxiv.org/abs/2307.13693"
            },
            {
                "文章ID": "21836",
                "标题": "L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models,\n  and Library",
                "作者": " Raviraj Joshi",
                "发布日期": "2022-06-01",
                "摘要": "  Despite being the third most popular language in India, the Marathi language\nlacks useful NLP resources. Moreover, popular NLP libraries do not have support\nfor the Marathi language. With L3Cube-MahaNLP, we aim to build resources and a\nlibrary for Marathi natural language processing. We present datasets and\ntransformer models for supervised tasks like sentiment analysis, named entity\nrecognition, and hate speech detection. We have also published a monolingual\nMarathi corpus for unsupervised language modeling tasks. Overall we present\nMahaCorpus, MahaSent, MahaNER, and MahaHate datasets and their corresponding\nMahaBERT models fine-tuned on these datasets. We aim to move ahead of benchmark\ndatasets and prepare useful resources for Marathi. The resources are available\nat https://github.com/l3cube-pune/MarathiNLP.\n",
                "链接": "https://arxiv.org/abs/2205.14728"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "75927",
                "标题": "Online Gesture Recognition using Transformer and Natural Language\n  Processing",
                "作者": " G. C. M. Silvestre,  F. Balado,  O. Akinremi,  M. Ramo",
                "发布日期": "2023-05-08",
                "摘要": "  The Transformer architecture is shown to provide a powerful machine\ntransduction framework for online handwritten gestures corresponding to glyph\nstrokes of natural language sentences. The attention mechanism is successfully\nused to create latent representations of an end-to-end encoder-decoder model,\nsolving multi-level segmentation while also learning some language features and\nsyntax rules. The additional use of a large decoding space with some learned\nByte-Pair-Encoding (BPE) is shown to provide robustness to ablated inputs and\nsyntax rules. The encoder stack was directly fed with spatio-temporal data\ntokens potentially forming an infinitely large input vocabulary, an approach\nthat finds applications beyond that of this work. Encoder transfer learning\ncapabilities is also demonstrated on several languages resulting in faster\noptimisation and shared parameters. A new supervised dataset of online\nhandwriting gestures suitable for generic handwriting recognition tasks was\nused to successfully train a small transformer model to an average normalised\nLevenshtein accuracy of 96% on English or German sentences and 94% in French.\n",
                "链接": "https://arxiv.org/abs/2305.03407"
            },
            {
                "文章ID": "64313",
                "标题": "Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language\n  Processing",
                "作者": " Sheng Zhang,  Yanbo Xu,  Naoto Usuyama,  Jaspreet Bagga,  Robert Tinn,  Sam Preston,  Rajesh Rao,  Mu Wei,  Naveen Valluri,  Cliff Wong,  Matthew P. Lungren,  Tristan Naumann,  Hoifung Poon",
                "发布日期": "2023-03-03",
                "摘要": "  Contrastive pretraining on parallel image-text data has attained great\nsuccess in vision-language processing (VLP), as exemplified by CLIP and related\nmethods. However, prior explorations tend to focus on general domains in the\nweb. Biomedical images and text are rather different, but publicly available\ndatasets are small and skew toward chest X-ray, thus severely limiting\nprogress. In this paper, we conducted by far the largest study on biomedical\nVLP, using 15 million figure-caption pairs extracted from biomedical research\narticles in PubMed Central. Our dataset (PMC-15M) is two orders of magnitude\nlarger than existing biomedical image-text datasets such as MIMIC-CXR, and\nspans a diverse range of biomedical images. The standard CLIP method is\nsuboptimal for the biomedical domain. We propose BiomedCLIP with\ndomain-specific adaptations tailored to biomedical VLP. We conducted extensive\nexperiments and ablation studies on standard biomedical imaging tasks from\nretrieval to classification to visual question-answering (VQA). BiomedCLIP\nestablished new state of the art in a wide range of standard datasets,\nsubstantially outperformed prior VLP approaches. Surprisingly, BiomedCLIP even\noutperformed radiology-specific state-of-the-art models such as BioViL on\nradiology-specific tasks such as RSNA pneumonia detection, thus highlighting\nthe utility in large-scale pretraining across all biomedical image types. We\nwill release our models at https://aka.ms/biomedclip to facilitate future\nresearch in biomedical VLP.\n",
                "链接": "https://arxiv.org/abs/2303.00915"
            },
            {
                "文章ID": "80906",
                "标题": "Large language models in biomedical natural language processing:\n  benchmarks, baselines, and recommendations",
                "作者": " Qingyu Chen,  Jingcheng Du,  Yan Hu,  Vipina Kuttichi Keloth,  Xueqing Peng,  Kalpana Raja,  Rui Zhang,  Zhiyong Lu,  Hua Xu",
                "发布日期": "2023-05-29",
                "摘要": "  Biomedical literature is growing rapidly, making it challenging to curate and\nextract knowledge manually. Biomedical natural language processing (BioNLP)\ntechniques that can automatically extract information from biomedical\nliterature help alleviate this burden. Recently, large Language Models (LLMs),\nsuch as GPT-3 and GPT-4, have gained significant attention for their impressive\nperformance. However, their effectiveness in BioNLP tasks and impact on method\ndevelopment and downstream users remain understudied. This pilot study (1)\nestablishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and\none-shot settings in eight BioNLP datasets across four applications: named\nentity recognition, relation extraction, multi-label document classification,\nand semantic similarity and reasoning, (2) examines the errors produced by the\nLLMs and categorized the errors into three types: missingness, inconsistencies,\nand unwanted artificial content, and (3) provides suggestions for using LLMs in\nBioNLP applications. We make the datasets, baselines, and results publicly\navailable to the community via\nhttps://github.com/qingyu-qc/gpt_bionlp_benchmark.\n",
                "链接": "https://arxiv.org/abs/2305.16326"
            },
            {
                "文章ID": "112674",
                "标题": "BioInstruct: Instruction Tuning of Large Language Models for Biomedical\n  Natural Language Processing",
                "作者": " Hieu Tran,  Zhichao Yang,  Zonghai Yao,  Hong Yu",
                "发布日期": "2023-11-07",
                "摘要": "  To enhance the performance of large language models (LLMs) in biomedical\nnatural language processing (BioNLP) by introducing a domain-specific\ninstruction dataset and examining its impact when combined with multi-task\nlearning principles. We created the BioInstruct, comprising 25,005 instructions\nto instruction-tune LLMs(LLaMA 1 & 2, 7B & 13B version). The instructions were\ncreated by prompting the GPT-4 language model with three-seed samples randomly\ndrawn from an 80 human curated instructions. We employed Low-Rank\nAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these\ninstruction-tuned LLMs on several BioNLP tasks, which can be grouped into three\nmajor categories: question answering(QA), information extraction(IE), and text\ngeneration(GEN). We also examined whether categories(e.g., QA, IE, and\ngeneration) of instructions impact model performance. Comparing with LLMs\nwithout instruction-tuned, our instruction-tuned LLMs demonstrated marked\nperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our\n7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed\nother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with\nvast domain-specific data or a variety of tasks. Our results also show that the\nperformance gain is significantly higher when instruction fine-tuning is\nconducted with closely related tasks. Our findings align with the observations\nof multi-task learning, suggesting the synergies between two tasks. The\nBioInstruct dataset serves as a valuable resource and instruction tuned LLMs\nlead to the best performing BioNLP applications.\n",
                "链接": "https://arxiv.org/abs/2310.19975"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            }
        ]
    }
]